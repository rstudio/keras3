---
title: Timeseries classification from scratch
date-created: 2020/07/21
last-modified: 2023/11/10
description: Training a timeseries classifier from scratch on the FordA dataset from
  the UCR/UEA archive.
output: rmarkdown::html_vignette
domain: timeseries
category: basic
vignette: >
  %\VignetteIndexEntry{Timeseries classification from scratch}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

This example shows how to do timeseries classification from scratch, starting from raw
CSV timeseries files on disk. We demonstrate the workflow on the FordA dataset from the
[UCR/UEA archive](https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/).

## Setup


``` r
library(keras3)
use_backend("jax")
```

## Load the data: the FordA dataset

### Dataset description

The dataset we are using here is called FordA.
The data comes from the UCR archive.
The dataset contains 3601 training instances and another 1320 testing instances.
Each timeseries corresponds to a measurement of engine noise captured by a motor sensor.
For this task, the goal is to automatically detect the presence of a specific issue with
the engine. The problem is a balanced binary classification task. The full description of
this dataset can be found [here](http://www.j-wichard.de/publications/FordPaper.pdf).

### Read the TSV data

We will use the `FordA_TRAIN` file for training and the
`FordA_TEST` file for testing. The simplicity of this dataset
allows us to demonstrate effectively how to use ConvNets for timeseries classification.
In this file, the first column corresponds to the label.



``` r
get_data <- function(path) {
  if(path |> startsWith("https://"))
    path <- get_file(origin = path)  # cache file locally

  data <- readr::read_tsv(
    path, col_names = FALSE,
    # Each row is: one integer (the label),
    # followed by 500 doubles (the timeseries)
    col_types = paste0("i", strrep("d", 500))
  )

  y <- as.matrix(data[[1]])
  x <- as.matrix(data[,-1])
  dimnames(x) <- dimnames(y) <- NULL

  list(x, y)
}

root_url <- "https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/"
c(x_train, y_train) %<-% get_data(paste0(root_url, "FordA_TRAIN.tsv"))
c(x_test, y_test) %<-% get_data(paste0(root_url, "FordA_TEST.tsv"))

str(keras3:::named_list(
  x_train, y_train,
  x_test, y_test
))
```

```
## List of 4
##  $ x_train: num [1:3601, 1:500] -0.797 0.805 0.728 -0.234 -0.171 ...
##  $ y_train: int [1:3601, 1] -1 1 -1 -1 -1 1 1 1 1 1 ...
##  $ x_test : num [1:1320, 1:500] -0.14 0.334 0.717 1.24 -1.159 ...
##  $ y_test : int [1:1320, 1] -1 -1 -1 1 -1 1 -1 -1 1 1 ...
```


## Visualize the data

Here we visualize one timeseries example for each class in the dataset.


``` r
plot(NULL, main = "Timeseries Data",
     xlab = "Timepoints",  ylab = "Values",
     xlim = c(1, ncol(x_test)),
     ylim = range(x_test))
grid()
lines(x_test[match(-1, y_test), ], col = "blue")
lines(x_test[match( 1, y_test), ], col = "red")
legend("topright", legend=c("label -1", "label 1"), col=c("blue", "red"), lty=1)
```

![Plot of Example Timeseries Data](timeseries_classification_from_scratch/unnamed-chunk-3-1.png)


## Standardize the data

Our timeseries are already in a single length (500). However, their values are
usually in various ranges. This is not ideal for a neural network;
in general we should seek to make the input values normalized.
For this specific dataset, the data is already z-normalized: each timeseries sample
has a mean equal to zero and a standard deviation equal to one. This type of
normalization is very common for timeseries classification problems, see
[Bagnall et al. (2016)](https://link.springer.com/article/10.1007/s10618-016-0483-9).

Note that the timeseries data used here are univariate, meaning we only have one channel
per timeseries example.
We will therefore transform the timeseries into a multivariate one with one channel
using a simple reshaping via numpy.
This will allow us to construct a model that is easily applicable to multivariate time
series.


``` r
dim(x_train) <- c(dim(x_train), 1)
dim(x_test) <- c(dim(x_test), 1)
```


Finally, in order to use `sparse_categorical_crossentropy`, we will have to count
the number of classes beforehand.


``` r
num_classes <- length(unique(y_train))
```


Now we shuffle the training set because we will be using the `validation_split` option
later when training.


``` r
c(x_train, y_train) %<-% listarrays::shuffle_rows(x_train, y_train)
# idx <- sample.int(nrow(x_train))
# x_train %<>% .[idx,, ,drop = FALSE]
# y_train %<>% .[idx,  ,drop = FALSE]
```


Standardize the labels to positive integers.
The expected labels will then be 0 and 1.


``` r
y_train[y_train == -1L] <- 0L
y_test[y_test == -1L] <- 0L
```


## Build a model

We build a Fully Convolutional Neural Network originally proposed in
[this paper](https://arxiv.org/abs/1611.06455).
The implementation is based on the TF 2 version provided
[here](https://github.com/hfawaz/dl-4-tsc/).
The following hyperparameters (kernel_size, filters, the usage of BatchNorm) were found
via random search using [KerasTuner](https://github.com/keras-team/keras-tuner).


``` r
make_model <- function(input_shape) {
  inputs <- keras_input(input_shape)

  outputs <- inputs |>
    # conv1
    layer_conv_1d(filters = 64, kernel_size = 3, padding = "same") |>
    layer_batch_normalization() |>
    layer_activation_relu() |>
    # conv2
    layer_conv_1d(filters = 64, kernel_size = 3, padding = "same") |>
    layer_batch_normalization() |>
    layer_activation_relu() |>
    # conv3
    layer_conv_1d(filters = 64, kernel_size = 3, padding = "same") |>
    layer_batch_normalization() |>
    layer_activation_relu() |>
    # pooling
    layer_global_average_pooling_1d() |>
    # final output
    layer_dense(num_classes, activation = "softmax")

  keras_model(inputs, outputs)
}

model <- make_model(input_shape = dim(x_train)[-1])
```


``` r
model
```

```
## [1mModel: "functional"[0m
## â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
## â”ƒ[1m [0m[1mLayer (type)               [0m[1m [0mâ”ƒ[1m [0m[1mOutput Shape         [0m[1m [0mâ”ƒ[1m [0m[1m   Param #[0m[1m [0mâ”ƒ[1m [0m[1mTraiâ€¦[0m[1m [0mâ”ƒ
## â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
## â”‚ input_layer ([38;5;33mInputLayer[0m)    â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m1[0m)        â”‚          [38;5;34m0[0m â”‚   [1m-[0m   â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ conv1d ([38;5;33mConv1D[0m)             â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚        [38;5;34m256[0m â”‚   [1;38;5;34mY[0m   â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ batch_normalization         â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚        [38;5;34m256[0m â”‚   [1;38;5;34mY[0m   â”‚
## â”‚ ([38;5;33mBatchNormalization[0m)        â”‚                       â”‚            â”‚       â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ re_lu ([38;5;33mReLU[0m)                â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚          [38;5;34m0[0m â”‚   [1m-[0m   â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ conv1d_1 ([38;5;33mConv1D[0m)           â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚     [38;5;34m12,352[0m â”‚   [1;38;5;34mY[0m   â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ batch_normalization_1       â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚        [38;5;34m256[0m â”‚   [1;38;5;34mY[0m   â”‚
## â”‚ ([38;5;33mBatchNormalization[0m)        â”‚                       â”‚            â”‚       â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ re_lu_1 ([38;5;33mReLU[0m)              â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚          [38;5;34m0[0m â”‚   [1m-[0m   â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ conv1d_2 ([38;5;33mConv1D[0m)           â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚     [38;5;34m12,352[0m â”‚   [1;38;5;34mY[0m   â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ batch_normalization_2       â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚        [38;5;34m256[0m â”‚   [1;38;5;34mY[0m   â”‚
## â”‚ ([38;5;33mBatchNormalization[0m)        â”‚                       â”‚            â”‚       â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ re_lu_2 ([38;5;33mReLU[0m)              â”‚ ([38;5;45mNone[0m, [38;5;34m500[0m, [38;5;34m64[0m)       â”‚          [38;5;34m0[0m â”‚   [1m-[0m   â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ global_average_pooling1d    â”‚ ([38;5;45mNone[0m, [38;5;34m64[0m)            â”‚          [38;5;34m0[0m â”‚   [1m-[0m   â”‚
## â”‚ ([38;5;33mGlobalAveragePooling1D[0m)    â”‚                       â”‚            â”‚       â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ dense ([38;5;33mDense[0m)               â”‚ ([38;5;45mNone[0m, [38;5;34m2[0m)             â”‚        [38;5;34m130[0m â”‚   [1;38;5;34mY[0m   â”‚
## â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
## [1m Total params: [0m[38;5;34m25,858[0m (101.01 KB)
## [1m Trainable params: [0m[38;5;34m25,474[0m (99.51 KB)
## [1m Non-trainable params: [0m[38;5;34m384[0m (1.50 KB)
```

``` r
plot(model, show_shapes = TRUE)
```

<div class="figure">
<img src="timeseries_classification_from_scratch/unnamed-chunk-9-1.png" alt="plot of chunk unnamed-chunk-9" width="801" />
<p class="caption">plot of chunk unnamed-chunk-9</p>
</div>



## Train the model


``` r
epochs <- 500
batch_size <- 32

callbacks <- c(
  callback_model_checkpoint(
    "best_model.keras", save_best_only = TRUE,
    monitor = "val_loss"
  ),
  callback_reduce_lr_on_plateau(
    monitor = "val_loss", factor = 0.5,
    patience = 20, min_lr = 0.0001
  ),
  callback_early_stopping(
    monitor = "val_loss", patience = 50,
    verbose = 1
  )
)


model |> compile(
  optimizer = "adam",
  loss = "sparse_categorical_crossentropy",
  metrics = "sparse_categorical_accuracy"
)

history <- model |> fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = epochs,
  callbacks = callbacks,
  validation_split = 0.2
)
```

```
## Epoch 1/500
## 90/90 - 3s - 34ms/step - loss: 0.5312 - sparse_categorical_accuracy: 0.7198 - val_loss: 0.7874 - val_sparse_categorical_accuracy: 0.4896 - learning_rate: 0.0010
## Epoch 2/500
## 90/90 - 0s - 2ms/step - loss: 0.4811 - sparse_categorical_accuracy: 0.7556 - val_loss: 0.8985 - val_sparse_categorical_accuracy: 0.4896 - learning_rate: 0.0010
## Epoch 3/500
## 90/90 - 0s - 2ms/step - loss: 0.4643 - sparse_categorical_accuracy: 0.7684 - val_loss: 1.1350 - val_sparse_categorical_accuracy: 0.4896 - learning_rate: 0.0010
## Epoch 4/500
## 90/90 - 0s - 2ms/step - loss: 0.4107 - sparse_categorical_accuracy: 0.7983 - val_loss: 0.7328 - val_sparse_categorical_accuracy: 0.4951 - learning_rate: 0.0010
## Epoch 5/500
## 90/90 - 0s - 2ms/step - loss: 0.4155 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.7886 - val_sparse_categorical_accuracy: 0.5298 - learning_rate: 0.0010
## Epoch 6/500
## 90/90 - 0s - 2ms/step - loss: 0.3998 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.4159 - val_sparse_categorical_accuracy: 0.8363 - learning_rate: 0.0010
## Epoch 7/500
## 90/90 - 0s - 2ms/step - loss: 0.3891 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.5396 - val_sparse_categorical_accuracy: 0.7046 - learning_rate: 0.0010
## Epoch 8/500
## 90/90 - 0s - 2ms/step - loss: 0.3760 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.3723 - val_sparse_categorical_accuracy: 0.8197 - learning_rate: 0.0010
## Epoch 9/500
## 90/90 - 0s - 2ms/step - loss: 0.3733 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.6365 - val_sparse_categorical_accuracy: 0.6810 - learning_rate: 0.0010
## Epoch 10/500
## 90/90 - 0s - 2ms/step - loss: 0.3646 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.3703 - val_sparse_categorical_accuracy: 0.8322 - learning_rate: 0.0010
## Epoch 11/500
## 90/90 - 0s - 2ms/step - loss: 0.3652 - sparse_categorical_accuracy: 0.8260 - val_loss: 0.5962 - val_sparse_categorical_accuracy: 0.7323 - learning_rate: 0.0010
## Epoch 12/500
## 90/90 - 0s - 1ms/step - loss: 0.3534 - sparse_categorical_accuracy: 0.8351 - val_loss: 0.3979 - val_sparse_categorical_accuracy: 0.8183 - learning_rate: 0.0010
## Epoch 13/500
## 90/90 - 0s - 2ms/step - loss: 0.3376 - sparse_categorical_accuracy: 0.8528 - val_loss: 0.6167 - val_sparse_categorical_accuracy: 0.6796 - learning_rate: 0.0010
## Epoch 14/500
## 90/90 - 0s - 2ms/step - loss: 0.3331 - sparse_categorical_accuracy: 0.8497 - val_loss: 0.3568 - val_sparse_categorical_accuracy: 0.8447 - learning_rate: 0.0010
## Epoch 15/500
## 90/90 - 0s - 2ms/step - loss: 0.3277 - sparse_categorical_accuracy: 0.8531 - val_loss: 0.6883 - val_sparse_categorical_accuracy: 0.6422 - learning_rate: 0.0010
## Epoch 16/500
## 90/90 - 0s - 2ms/step - loss: 0.3284 - sparse_categorical_accuracy: 0.8611 - val_loss: 0.3709 - val_sparse_categorical_accuracy: 0.7892 - learning_rate: 0.0010
## Epoch 17/500
## 90/90 - 0s - 2ms/step - loss: 0.3108 - sparse_categorical_accuracy: 0.8632 - val_loss: 0.5851 - val_sparse_categorical_accuracy: 0.6879 - learning_rate: 0.0010
## Epoch 18/500
## 90/90 - 0s - 2ms/step - loss: 0.3100 - sparse_categorical_accuracy: 0.8587 - val_loss: 0.5103 - val_sparse_categorical_accuracy: 0.7254 - learning_rate: 0.0010
## Epoch 19/500
## 90/90 - 0s - 2ms/step - loss: 0.3137 - sparse_categorical_accuracy: 0.8611 - val_loss: 0.4150 - val_sparse_categorical_accuracy: 0.8072 - learning_rate: 0.0010
## Epoch 20/500
## 90/90 - 0s - 2ms/step - loss: 0.3053 - sparse_categorical_accuracy: 0.8729 - val_loss: 0.7566 - val_sparse_categorical_accuracy: 0.7074 - learning_rate: 0.0010
## Epoch 21/500
## 90/90 - 0s - 2ms/step - loss: 0.2870 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.3925 - val_sparse_categorical_accuracy: 0.8031 - learning_rate: 0.0010
## Epoch 22/500
## 90/90 - 0s - 2ms/step - loss: 0.2926 - sparse_categorical_accuracy: 0.8774 - val_loss: 0.8940 - val_sparse_categorical_accuracy: 0.7171 - learning_rate: 0.0010
## Epoch 23/500
## 90/90 - 0s - 2ms/step - loss: 0.2757 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.8682 - learning_rate: 0.0010
## Epoch 24/500
## 90/90 - 0s - 2ms/step - loss: 0.2749 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.3510 - val_sparse_categorical_accuracy: 0.8599 - learning_rate: 0.0010
## Epoch 25/500
## 90/90 - 0s - 2ms/step - loss: 0.2669 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.5174 - val_sparse_categorical_accuracy: 0.7406 - learning_rate: 0.0010
## Epoch 26/500
## 90/90 - 0s - 2ms/step - loss: 0.3097 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.3543 - val_sparse_categorical_accuracy: 0.8405 - learning_rate: 0.0010
## Epoch 27/500
## 90/90 - 0s - 2ms/step - loss: 0.2660 - sparse_categorical_accuracy: 0.8962 - val_loss: 0.2928 - val_sparse_categorical_accuracy: 0.8849 - learning_rate: 0.0010
## Epoch 28/500
## 90/90 - 0s - 2ms/step - loss: 0.2822 - sparse_categorical_accuracy: 0.8799 - val_loss: 0.9162 - val_sparse_categorical_accuracy: 0.7143 - learning_rate: 0.0010
## Epoch 29/500
## 90/90 - 0s - 2ms/step - loss: 0.2579 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.8991 - val_sparse_categorical_accuracy: 0.7115 - learning_rate: 0.0010
## Epoch 30/500
## 90/90 - 0s - 2ms/step - loss: 0.2595 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.7615 - val_sparse_categorical_accuracy: 0.7115 - learning_rate: 0.0010
## Epoch 31/500
## 90/90 - 0s - 2ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.8934 - val_loss: 0.5930 - val_sparse_categorical_accuracy: 0.6893 - learning_rate: 0.0010
## Epoch 32/500
## 90/90 - 0s - 2ms/step - loss: 0.2558 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.2707 - val_sparse_categorical_accuracy: 0.8904 - learning_rate: 0.0010
## Epoch 33/500
## 90/90 - 0s - 2ms/step - loss: 0.2429 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.2465 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 0.0010
## Epoch 34/500
## 90/90 - 0s - 2ms/step - loss: 0.2329 - sparse_categorical_accuracy: 0.9076 - val_loss: 0.2450 - val_sparse_categorical_accuracy: 0.9029 - learning_rate: 0.0010
## Epoch 35/500
## 90/90 - 0s - 2ms/step - loss: 0.2485 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.3781 - val_sparse_categorical_accuracy: 0.7906 - learning_rate: 0.0010
## Epoch 36/500
## 90/90 - 0s - 2ms/step - loss: 0.2393 - sparse_categorical_accuracy: 0.9021 - val_loss: 0.3515 - val_sparse_categorical_accuracy: 0.8474 - learning_rate: 0.0010
## Epoch 37/500
## 90/90 - 0s - 2ms/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.2477 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 0.0010
## Epoch 38/500
## 90/90 - 0s - 2ms/step - loss: 0.2357 - sparse_categorical_accuracy: 0.9052 - val_loss: 1.9719 - val_sparse_categorical_accuracy: 0.7046 - learning_rate: 0.0010
## Epoch 39/500
## 90/90 - 0s - 2ms/step - loss: 0.2326 - sparse_categorical_accuracy: 0.9076 - val_loss: 0.6842 - val_sparse_categorical_accuracy: 0.7323 - learning_rate: 0.0010
## Epoch 40/500
## 90/90 - 0s - 1ms/step - loss: 0.2268 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.2562 - val_sparse_categorical_accuracy: 0.8877 - learning_rate: 0.0010
## Epoch 41/500
## 90/90 - 0s - 2ms/step - loss: 0.2137 - sparse_categorical_accuracy: 0.9160 - val_loss: 0.2388 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 0.0010
## Epoch 42/500
## 90/90 - 0s - 2ms/step - loss: 0.2042 - sparse_categorical_accuracy: 0.9257 - val_loss: 0.2926 - val_sparse_categorical_accuracy: 0.8738 - learning_rate: 0.0010
## Epoch 43/500
## 90/90 - 0s - 2ms/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.3329 - val_sparse_categorical_accuracy: 0.8558 - learning_rate: 0.0010
## Epoch 44/500
## 90/90 - 0s - 2ms/step - loss: 0.2071 - sparse_categorical_accuracy: 0.9181 - val_loss: 0.5715 - val_sparse_categorical_accuracy: 0.7337 - learning_rate: 0.0010
## Epoch 45/500
## 90/90 - 0s - 1ms/step - loss: 0.2031 - sparse_categorical_accuracy: 0.9274 - val_loss: 0.3827 - val_sparse_categorical_accuracy: 0.8433 - learning_rate: 0.0010
## Epoch 46/500
## 90/90 - 0s - 2ms/step - loss: 0.2051 - sparse_categorical_accuracy: 0.9212 - val_loss: 0.3262 - val_sparse_categorical_accuracy: 0.8239 - learning_rate: 0.0010
## Epoch 47/500
## 90/90 - 0s - 2ms/step - loss: 0.1867 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.5011 - val_sparse_categorical_accuracy: 0.7573 - learning_rate: 0.0010
## Epoch 48/500
## 90/90 - 0s - 2ms/step - loss: 0.1843 - sparse_categorical_accuracy: 0.9313 - val_loss: 0.2048 - val_sparse_categorical_accuracy: 0.9098 - learning_rate: 0.0010
## Epoch 49/500
## 90/90 - 0s - 2ms/step - loss: 0.1725 - sparse_categorical_accuracy: 0.9344 - val_loss: 0.4119 - val_sparse_categorical_accuracy: 0.7989 - learning_rate: 0.0010
## Epoch 50/500
## 90/90 - 0s - 2ms/step - loss: 0.1747 - sparse_categorical_accuracy: 0.9392 - val_loss: 0.2083 - val_sparse_categorical_accuracy: 0.9251 - learning_rate: 0.0010
## Epoch 51/500
## 90/90 - 0s - 2ms/step - loss: 0.1699 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.2493 - val_sparse_categorical_accuracy: 0.8960 - learning_rate: 0.0010
## Epoch 52/500
## 90/90 - 0s - 2ms/step - loss: 0.1533 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.2077 - val_sparse_categorical_accuracy: 0.9057 - learning_rate: 0.0010
## Epoch 53/500
## 90/90 - 0s - 2ms/step - loss: 0.1451 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.2244 - val_sparse_categorical_accuracy: 0.9085 - learning_rate: 0.0010
## Epoch 54/500
## 90/90 - 0s - 2ms/step - loss: 0.1369 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.3116 - val_sparse_categorical_accuracy: 0.8710 - learning_rate: 0.0010
## Epoch 55/500
## 90/90 - 0s - 2ms/step - loss: 0.1334 - sparse_categorical_accuracy: 0.9587 - val_loss: 0.1950 - val_sparse_categorical_accuracy: 0.9209 - learning_rate: 0.0010
## Epoch 56/500
## 90/90 - 0s - 2ms/step - loss: 0.1320 - sparse_categorical_accuracy: 0.9597 - val_loss: 0.2799 - val_sparse_categorical_accuracy: 0.8849 - learning_rate: 0.0010
## Epoch 57/500
## 90/90 - 0s - 1ms/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.7242 - val_sparse_categorical_accuracy: 0.6879 - learning_rate: 0.0010
## Epoch 58/500
## 90/90 - 0s - 2ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.1674 - val_sparse_categorical_accuracy: 0.9362 - learning_rate: 0.0010
## Epoch 59/500
## 90/90 - 0s - 2ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.1979 - val_sparse_categorical_accuracy: 0.9293 - learning_rate: 0.0010
## Epoch 60/500
## 90/90 - 0s - 2ms/step - loss: 0.1218 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.1404 - val_sparse_categorical_accuracy: 0.9404 - learning_rate: 0.0010
## Epoch 61/500
## 90/90 - 0s - 2ms/step - loss: 0.1164 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.4375 - val_sparse_categorical_accuracy: 0.8544 - learning_rate: 0.0010
## Epoch 62/500
## 90/90 - 0s - 2ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.2831 - val_sparse_categorical_accuracy: 0.8779 - learning_rate: 0.0010
## Epoch 63/500
## 90/90 - 0s - 2ms/step - loss: 0.1220 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.4892 - val_sparse_categorical_accuracy: 0.8086 - learning_rate: 0.0010
## Epoch 64/500
## 90/90 - 0s - 2ms/step - loss: 0.1203 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.1836 - val_sparse_categorical_accuracy: 0.9112 - learning_rate: 0.0010
## Epoch 65/500
## 90/90 - 0s - 2ms/step - loss: 0.1188 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.2473 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 0.0010
## Epoch 66/500
## 90/90 - 0s - 2ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.2903 - val_sparse_categorical_accuracy: 0.8793 - learning_rate: 0.0010
## Epoch 67/500
## 90/90 - 0s - 2ms/step - loss: 0.1081 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.9684 - val_sparse_categorical_accuracy: 0.6852 - learning_rate: 0.0010
## Epoch 68/500
## 90/90 - 0s - 2ms/step - loss: 0.1097 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.2351 - val_sparse_categorical_accuracy: 0.9098 - learning_rate: 0.0010
## Epoch 69/500
## 90/90 - 0s - 2ms/step - loss: 0.1175 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.2542 - val_sparse_categorical_accuracy: 0.8932 - learning_rate: 0.0010
## Epoch 70/500
## 90/90 - 0s - 2ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1458 - val_sparse_categorical_accuracy: 0.9376 - learning_rate: 0.0010
## Epoch 71/500
## 90/90 - 0s - 1ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.2210 - val_sparse_categorical_accuracy: 0.9126 - learning_rate: 0.0010
## Epoch 72/500
## 90/90 - 0s - 2ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2073 - val_sparse_categorical_accuracy: 0.9140 - learning_rate: 0.0010
## Epoch 73/500
## 90/90 - 0s - 2ms/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.2574 - val_sparse_categorical_accuracy: 0.8932 - learning_rate: 0.0010
## Epoch 74/500
## 90/90 - 0s - 2ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.1631 - val_sparse_categorical_accuracy: 0.9473 - learning_rate: 0.0010
## Epoch 75/500
## 90/90 - 0s - 2ms/step - loss: 0.1165 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.1965 - val_sparse_categorical_accuracy: 0.9223 - learning_rate: 0.0010
## Epoch 76/500
## 90/90 - 0s - 2ms/step - loss: 0.1119 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.1976 - val_sparse_categorical_accuracy: 0.9140 - learning_rate: 0.0010
## Epoch 77/500
## 90/90 - 0s - 2ms/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.5981 - val_sparse_categorical_accuracy: 0.7906 - learning_rate: 0.0010
## Epoch 78/500
## 90/90 - 0s - 2ms/step - loss: 0.1001 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.2985 - val_sparse_categorical_accuracy: 0.8752 - learning_rate: 0.0010
## Epoch 79/500
## 90/90 - 0s - 2ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.3294 - val_sparse_categorical_accuracy: 0.8724 - learning_rate: 0.0010
## Epoch 80/500
## 90/90 - 0s - 2ms/step - loss: 0.1043 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.1991 - val_sparse_categorical_accuracy: 0.9251 - learning_rate: 0.0010
## Epoch 81/500
## 90/90 - 0s - 2ms/step - loss: 0.0985 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.1398 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 5.0000e-04
## Epoch 82/500
## 90/90 - 0s - 2ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 5.0000e-04
## Epoch 83/500
## 90/90 - 0s - 2ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1149 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 5.0000e-04
## Epoch 84/500
## 90/90 - 0s - 2ms/step - loss: 0.0881 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.1607 - val_sparse_categorical_accuracy: 0.9334 - learning_rate: 5.0000e-04
## Epoch 85/500
## 90/90 - 0s - 2ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1296 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 5.0000e-04
## Epoch 86/500
## 90/90 - 0s - 2ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1132 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 5.0000e-04
## Epoch 87/500
## 90/90 - 0s - 2ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.1351 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 5.0000e-04
## Epoch 88/500
## 90/90 - 0s - 1ms/step - loss: 0.0876 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 5.0000e-04
## Epoch 89/500
## 90/90 - 0s - 2ms/step - loss: 0.0934 - sparse_categorical_accuracy: 0.9681 - val_loss: 0.2393 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 5.0000e-04
## Epoch 90/500
## 90/90 - 0s - 1ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.2534 - val_sparse_categorical_accuracy: 0.9029 - learning_rate: 5.0000e-04
## Epoch 91/500
## 90/90 - 0s - 2ms/step - loss: 0.0913 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.2081 - val_sparse_categorical_accuracy: 0.9126 - learning_rate: 5.0000e-04
## Epoch 92/500
## 90/90 - 0s - 2ms/step - loss: 0.0867 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.1279 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 5.0000e-04
## Epoch 93/500
## 90/90 - 0s - 2ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.2089 - val_sparse_categorical_accuracy: 0.8946 - learning_rate: 5.0000e-04
## Epoch 94/500
## 90/90 - 0s - 2ms/step - loss: 0.0890 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.6251 - val_sparse_categorical_accuracy: 0.7989 - learning_rate: 5.0000e-04
## Epoch 95/500
## 90/90 - 0s - 2ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1388 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 5.0000e-04
## Epoch 96/500
## 90/90 - 0s - 2ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.1196 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 5.0000e-04
## Epoch 97/500
## 90/90 - 0s - 2ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1315 - val_sparse_categorical_accuracy: 0.9431 - learning_rate: 5.0000e-04
## Epoch 98/500
## 90/90 - 0s - 2ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.1239 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 5.0000e-04
## Epoch 99/500
## 90/90 - 0s - 2ms/step - loss: 0.0854 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.1539 - val_sparse_categorical_accuracy: 0.9320 - learning_rate: 5.0000e-04
## Epoch 100/500
## 90/90 - 0s - 2ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.2027 - val_sparse_categorical_accuracy: 0.9168 - learning_rate: 5.0000e-04
## Epoch 101/500
## 90/90 - 0s - 2ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.1227 - val_sparse_categorical_accuracy: 0.9431 - learning_rate: 5.0000e-04
## Epoch 102/500
## 90/90 - 0s - 2ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.1093 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 5.0000e-04
## Epoch 103/500
## 90/90 - 0s - 2ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1155 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 5.0000e-04
## Epoch 104/500
## 90/90 - 0s - 2ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1608 - val_sparse_categorical_accuracy: 0.9445 - learning_rate: 5.0000e-04
## Epoch 105/500
## 90/90 - 0s - 2ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1185 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 5.0000e-04
## Epoch 106/500
## 90/90 - 0s - 2ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.2285 - val_sparse_categorical_accuracy: 0.9209 - learning_rate: 5.0000e-04
## Epoch 107/500
## 90/90 - 0s - 2ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 5.0000e-04
## Epoch 108/500
## 90/90 - 0s - 2ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1976 - val_sparse_categorical_accuracy: 0.9265 - learning_rate: 5.0000e-04
## Epoch 109/500
## 90/90 - 0s - 2ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1228 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 5.0000e-04
## Epoch 110/500
## 90/90 - 0s - 2ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1475 - val_sparse_categorical_accuracy: 0.9376 - learning_rate: 5.0000e-04
## Epoch 111/500
## 90/90 - 0s - 2ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.2636 - val_sparse_categorical_accuracy: 0.8974 - learning_rate: 5.0000e-04
## Epoch 112/500
## 90/90 - 0s - 2ms/step - loss: 0.0811 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.1808 - val_sparse_categorical_accuracy: 0.9237 - learning_rate: 5.0000e-04
## Epoch 113/500
## 90/90 - 0s - 2ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1251 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 5.0000e-04
## Epoch 114/500
## 90/90 - 0s - 2ms/step - loss: 0.0928 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 5.0000e-04
## Epoch 115/500
## 90/90 - 0s - 2ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1148 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 5.0000e-04
## Epoch 116/500
## 90/90 - 0s - 2ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1791 - val_sparse_categorical_accuracy: 0.9431 - learning_rate: 5.0000e-04
## Epoch 117/500
## 90/90 - 0s - 2ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1294 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 5.0000e-04
## Epoch 118/500
## 90/90 - 0s - 2ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.1320 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 5.0000e-04
## Epoch 119/500
## 90/90 - 0s - 2ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1345 - val_sparse_categorical_accuracy: 0.9445 - learning_rate: 5.0000e-04
## Epoch 120/500
## 90/90 - 0s - 2ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1328 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 5.0000e-04
## Epoch 121/500
## 90/90 - 0s - 2ms/step - loss: 0.0799 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1124 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 5.0000e-04
## Epoch 122/500
## 90/90 - 0s - 2ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1087 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 5.0000e-04
## Epoch 123/500
## 90/90 - 0s - 2ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1379 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 5.0000e-04
## Epoch 124/500
## 90/90 - 0s - 2ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9691 - val_loss: 0.7959 - val_sparse_categorical_accuracy: 0.7074 - learning_rate: 5.0000e-04
## Epoch 125/500
## 90/90 - 0s - 2ms/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.1250 - val_sparse_categorical_accuracy: 0.9473 - learning_rate: 5.0000e-04
## Epoch 126/500
## 90/90 - 0s - 2ms/step - loss: 0.0790 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 5.0000e-04
## Epoch 127/500
## 90/90 - 0s - 1ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.2524 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 5.0000e-04
## Epoch 128/500
## 90/90 - 0s - 2ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1639 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 5.0000e-04
## Epoch 129/500
## 90/90 - 0s - 2ms/step - loss: 0.0794 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1178 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 5.0000e-04
## Epoch 130/500
## 90/90 - 0s - 2ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1082 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 5.0000e-04
## Epoch 131/500
## 90/90 - 0s - 2ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.3958 - val_sparse_categorical_accuracy: 0.8558 - learning_rate: 5.0000e-04
## Epoch 132/500
## 90/90 - 0s - 2ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1175 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 5.0000e-04
## Epoch 133/500
## 90/90 - 0s - 2ms/step - loss: 0.0710 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1348 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 5.0000e-04
## Epoch 134/500
## 90/90 - 0s - 2ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.4152 - val_sparse_categorical_accuracy: 0.8544 - learning_rate: 5.0000e-04
## Epoch 135/500
## 90/90 - 0s - 2ms/step - loss: 0.0725 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1069 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 2.5000e-04
## Epoch 136/500
## 90/90 - 0s - 2ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.1346 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04
## Epoch 137/500
## 90/90 - 0s - 2ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.1188 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04
## Epoch 138/500
## 90/90 - 0s - 2ms/step - loss: 0.0709 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1106 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 2.5000e-04
## Epoch 139/500
## 90/90 - 0s - 2ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1013 - val_sparse_categorical_accuracy: 0.9695 - learning_rate: 2.5000e-04
## Epoch 140/500
## 90/90 - 0s - 2ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.1082 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 2.5000e-04
## Epoch 141/500
## 90/90 - 0s - 2ms/step - loss: 0.0671 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1072 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04
## Epoch 142/500
## 90/90 - 0s - 2ms/step - loss: 0.0665 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 2.5000e-04
## Epoch 143/500
## 90/90 - 0s - 2ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.1199 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 2.5000e-04
## Epoch 144/500
## 90/90 - 0s - 2ms/step - loss: 0.0635 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1295 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04
## Epoch 145/500
## 90/90 - 0s - 2ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1432 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04
## Epoch 146/500
## 90/90 - 0s - 2ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 2.5000e-04
## Epoch 147/500
## 90/90 - 0s - 2ms/step - loss: 0.0725 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 2.5000e-04
## Epoch 148/500
## 90/90 - 0s - 2ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.2066 - val_sparse_categorical_accuracy: 0.9223 - learning_rate: 2.5000e-04
## Epoch 149/500
## 90/90 - 0s - 2ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1336 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04
## Epoch 150/500
## 90/90 - 0s - 2ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1479 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 2.5000e-04
## Epoch 151/500
## 90/90 - 0s - 2ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1103 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04
## Epoch 152/500
## 90/90 - 0s - 2ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 2.5000e-04
## Epoch 153/500
## 90/90 - 0s - 2ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 2.5000e-04
## Epoch 154/500
## 90/90 - 0s - 2ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1470 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 2.5000e-04
## Epoch 155/500
## 90/90 - 0s - 2ms/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04
## Epoch 156/500
## 90/90 - 0s - 2ms/step - loss: 0.0715 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.1191 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04
## Epoch 157/500
## 90/90 - 0s - 2ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1757 - val_sparse_categorical_accuracy: 0.9293 - learning_rate: 2.5000e-04
## Epoch 158/500
## 90/90 - 0s - 2ms/step - loss: 0.0716 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1094 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04
## Epoch 159/500
## 90/90 - 0s - 2ms/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1213 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 2.5000e-04
## Epoch 160/500
## 90/90 - 0s - 2ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1588 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 1.2500e-04
## Epoch 161/500
## 90/90 - 0s - 1ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1205 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.2500e-04
## Epoch 162/500
## 90/90 - 0s - 2ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1174 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.2500e-04
## Epoch 163/500
## 90/90 - 0s - 2ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1097 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04
## Epoch 164/500
## 90/90 - 0s - 2ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.2500e-04
## Epoch 165/500
## 90/90 - 0s - 2ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 1.2500e-04
## Epoch 166/500
## 90/90 - 0s - 2ms/step - loss: 0.0597 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1046 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.2500e-04
## Epoch 167/500
## 90/90 - 0s - 2ms/step - loss: 0.0610 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1061 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 1.2500e-04
## Epoch 168/500
## 90/90 - 0s - 1ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.2500e-04
## Epoch 169/500
## 90/90 - 0s - 2ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1116 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.2500e-04
## Epoch 170/500
## 90/90 - 0s - 2ms/step - loss: 0.0641 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.2500e-04
## Epoch 171/500
## 90/90 - 0s - 2ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1024 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.2500e-04
## Epoch 172/500
## 90/90 - 0s - 2ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.2500e-04
## Epoch 173/500
## 90/90 - 0s - 2ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1027 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.2500e-04
## Epoch 174/500
## 90/90 - 0s - 2ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.2500e-04
## Epoch 175/500
## 90/90 - 0s - 2ms/step - loss: 0.0642 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1115 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.2500e-04
## Epoch 176/500
## 90/90 - 0s - 2ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.1149 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.2500e-04
## Epoch 177/500
## 90/90 - 0s - 2ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.2500e-04
## Epoch 178/500
## 90/90 - 0s - 2ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1304 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 1.2500e-04
## Epoch 179/500
## 90/90 - 0s - 2ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1149 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.2500e-04
## Epoch 180/500
## 90/90 - 0s - 2ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.1320 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.2500e-04
## Epoch 181/500
## 90/90 - 0s - 2ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1161 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.2500e-04
## Epoch 182/500
## 90/90 - 0s - 2ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1234 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04
## Epoch 183/500
## 90/90 - 0s - 2ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1030 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.2500e-04
## Epoch 184/500
## 90/90 - 0s - 2ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1114 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 1.2500e-04
## Epoch 185/500
## 90/90 - 0s - 2ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1051 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.2500e-04
## Epoch 186/500
## 90/90 - 0s - 2ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1067 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.2500e-04
## Epoch 187/500
## 90/90 - 0s - 2ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1008 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04
## Epoch 188/500
## 90/90 - 0s - 2ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.2500e-04
## Epoch 189/500
## 90/90 - 0s - 2ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1457 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.2500e-04
## Epoch 190/500
## 90/90 - 0s - 2ms/step - loss: 0.0656 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1659 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 1.2500e-04
## Epoch 191/500
## 90/90 - 0s - 2ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1349 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.2500e-04
## Epoch 192/500
## 90/90 - 0s - 2ms/step - loss: 0.0648 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1094 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.2500e-04
## Epoch 193/500
## 90/90 - 0s - 2ms/step - loss: 0.0607 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1238 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.2500e-04
## Epoch 194/500
## 90/90 - 0s - 2ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1022 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.2500e-04
## Epoch 195/500
## 90/90 - 0s - 2ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.0000e-04
## Epoch 196/500
## 90/90 - 0s - 2ms/step - loss: 0.0613 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 197/500
## 90/90 - 0s - 2ms/step - loss: 0.0580 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 198/500
## 90/90 - 0s - 2ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.1150 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 199/500
## 90/90 - 0s - 2ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1158 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.0000e-04
## Epoch 200/500
## 90/90 - 0s - 2ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1163 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 201/500
## 90/90 - 0s - 2ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1381 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.0000e-04
## Epoch 202/500
## 90/90 - 0s - 2ms/step - loss: 0.0572 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 203/500
## 90/90 - 0s - 2ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1106 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 204/500
## 90/90 - 0s - 2ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 205/500
## 90/90 - 0s - 2ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 206/500
## 90/90 - 0s - 2ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1082 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.0000e-04
## Epoch 207/500
## 90/90 - 0s - 2ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 208/500
## 90/90 - 0s - 2ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1182 - val_sparse_categorical_accuracy: 0.9695 - learning_rate: 1.0000e-04
## Epoch 209/500
## 90/90 - 0s - 2ms/step - loss: 0.0568 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1367 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.0000e-04
## Epoch 210/500
## 90/90 - 0s - 2ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 211/500
## 90/90 - 0s - 2ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 212/500
## 90/90 - 0s - 2ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 213/500
## 90/90 - 0s - 2ms/step - loss: 0.0610 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 214/500
## 90/90 - 0s - 2ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 215/500
## 90/90 - 0s - 2ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1159 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 216/500
## 90/90 - 0s - 2ms/step - loss: 0.0561 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1106 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 217/500
## 90/90 - 0s - 2ms/step - loss: 0.0563 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1230 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 218/500
## 90/90 - 0s - 2ms/step - loss: 0.0620 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1015 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 219/500
## 90/90 - 0s - 2ms/step - loss: 0.0579 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1292 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.0000e-04
## Epoch 220/500
## 90/90 - 0s - 2ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1050 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 221/500
## 90/90 - 0s - 2ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 222/500
## 90/90 - 0s - 2ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 223/500
## 90/90 - 0s - 2ms/step - loss: 0.0568 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.0996 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.0000e-04
## Epoch 224/500
## 90/90 - 0s - 2ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.0987 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 225/500
## 90/90 - 0s - 2ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 226/500
## 90/90 - 0s - 2ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1073 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 227/500
## 90/90 - 0s - 2ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1030 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 228/500
## 90/90 - 0s - 2ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 1.0000e-04
## Epoch 229/500
## 90/90 - 0s - 2ms/step - loss: 0.0560 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.0000e-04
## Epoch 230/500
## 90/90 - 0s - 2ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 231/500
## 90/90 - 0s - 2ms/step - loss: 0.0600 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1003 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 232/500
## 90/90 - 0s - 2ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1022 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 233/500
## 90/90 - 0s - 2ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.0000e-04
## Epoch 234/500
## 90/90 - 0s - 2ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1110 - val_sparse_categorical_accuracy: 0.9695 - learning_rate: 1.0000e-04
## Epoch 235/500
## 90/90 - 0s - 2ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 236/500
## 90/90 - 0s - 2ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1062 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 237/500
## 90/90 - 0s - 2ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1344 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 1.0000e-04
## Epoch 238/500
## 90/90 - 0s - 2ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.1174 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 239/500
## 90/90 - 0s - 2ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 240/500
## 90/90 - 0s - 2ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1112 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 241/500
## 90/90 - 0s - 2ms/step - loss: 0.0565 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1244 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.0000e-04
## Epoch 242/500
## 90/90 - 0s - 2ms/step - loss: 0.0557 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 243/500
## 90/90 - 0s - 2ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1149 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 1.0000e-04
## Epoch 244/500
## 90/90 - 0s - 2ms/step - loss: 0.0599 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1197 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 245/500
## 90/90 - 0s - 2ms/step - loss: 0.0561 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1140 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 246/500
## 90/90 - 0s - 2ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1072 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 247/500
## 90/90 - 0s - 2ms/step - loss: 0.0528 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1169 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 248/500
## 90/90 - 0s - 2ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1143 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 249/500
## 90/90 - 0s - 1ms/step - loss: 0.0573 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1370 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.0000e-04
## Epoch 250/500
## 90/90 - 0s - 2ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1027 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 251/500
## 90/90 - 0s - 1ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1062 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 252/500
## 90/90 - 0s - 2ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.1015 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.0000e-04
## Epoch 253/500
## 90/90 - 0s - 2ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1201 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 254/500
## 90/90 - 0s - 2ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 255/500
## 90/90 - 0s - 2ms/step - loss: 0.0539 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1048 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 256/500
## 90/90 - 0s - 2ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 257/500
## 90/90 - 0s - 2ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1086 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 258/500
## 90/90 - 0s - 2ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 1.0000e-04
## Epoch 259/500
## 90/90 - 0s - 2ms/step - loss: 0.0509 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.1101 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 260/500
## 90/90 - 0s - 2ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 261/500
## 90/90 - 0s - 2ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1197 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 262/500
## 90/90 - 0s - 2ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1033 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 263/500
## 90/90 - 0s - 2ms/step - loss: 0.0518 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1211 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 1.0000e-04
## Epoch 264/500
## 90/90 - 0s - 2ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1090 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.0000e-04
## Epoch 265/500
## 90/90 - 0s - 2ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 266/500
## 90/90 - 0s - 2ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 267/500
## 90/90 - 0s - 2ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.1179 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 268/500
## 90/90 - 0s - 2ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 269/500
## 90/90 - 0s - 2ms/step - loss: 0.0550 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.1022 - val_sparse_categorical_accuracy: 0.9695 - learning_rate: 1.0000e-04
## Epoch 270/500
## 90/90 - 0s - 2ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.1008 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 271/500
## 90/90 - 0s - 2ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 272/500
## 90/90 - 0s - 2ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 273/500
## 90/90 - 0s - 2ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1017 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 274/500
## 90/90 - 0s - 2ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.0987 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 275/500
## 90/90 - 0s - 2ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1119 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 276/500
## 90/90 - 0s - 2ms/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 277/500
## 90/90 - 0s - 2ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 278/500
## 90/90 - 0s - 2ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1352 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 1.0000e-04
## Epoch 279/500
## 90/90 - 0s - 2ms/step - loss: 0.0553 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1038 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 280/500
## 90/90 - 0s - 2ms/step - loss: 0.0535 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1050 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 281/500
## 90/90 - 0s - 2ms/step - loss: 0.0512 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1066 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 282/500
## 90/90 - 0s - 2ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1164 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 283/500
## 90/90 - 0s - 2ms/step - loss: 0.0548 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 284/500
## 90/90 - 0s - 2ms/step - loss: 0.0572 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1169 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 285/500
## 90/90 - 0s - 2ms/step - loss: 0.0545 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1110 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 286/500
## 90/90 - 0s - 2ms/step - loss: 0.0530 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1360 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.0000e-04
## Epoch 287/500
## 90/90 - 0s - 2ms/step - loss: 0.0516 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 288/500
## 90/90 - 0s - 2ms/step - loss: 0.0522 - sparse_categorical_accuracy: 0.9844 - val_loss: 0.1323 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.0000e-04
## Epoch 289/500
## 90/90 - 0s - 2ms/step - loss: 0.0534 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1107 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 290/500
## 90/90 - 0s - 2ms/step - loss: 0.0556 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.1120 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 1.0000e-04
## Epoch 291/500
## 90/90 - 0s - 2ms/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 292/500
## 90/90 - 0s - 2ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1024 - val_sparse_categorical_accuracy: 0.9681 - learning_rate: 1.0000e-04
## Epoch 293/500
## 90/90 - 0s - 2ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1055 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 294/500
## 90/90 - 0s - 2ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.1076 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 295/500
## 90/90 - 0s - 2ms/step - loss: 0.0572 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1168 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 296/500
## 90/90 - 0s - 2ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1041 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 297/500
## 90/90 - 0s - 2ms/step - loss: 0.0554 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1002 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 298/500
## 90/90 - 0s - 2ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 299/500
## 90/90 - 0s - 2ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1225 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 300/500
## 90/90 - 0s - 2ms/step - loss: 0.0498 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 301/500
## 90/90 - 0s - 2ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 302/500
## 90/90 - 0s - 2ms/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.1401 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.0000e-04
## Epoch 303/500
## 90/90 - 0s - 1ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.1022 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 304/500
## 90/90 - 0s - 2ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1038 - val_sparse_categorical_accuracy: 0.9695 - learning_rate: 1.0000e-04
## Epoch 305/500
## 90/90 - 0s - 1ms/step - loss: 0.0531 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 306/500
## 90/90 - 0s - 2ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.1054 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 307/500
## 90/90 - 0s - 2ms/step - loss: 0.0561 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1112 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.0000e-04
## Epoch 308/500
## 90/90 - 0s - 2ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9823 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 309/500
## 90/90 - 0s - 2ms/step - loss: 0.0549 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 310/500
## 90/90 - 0s - 2ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 311/500
## 90/90 - 0s - 2ms/step - loss: 0.0525 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1125 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 1.0000e-04
## Epoch 312/500
## 90/90 - 0s - 2ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1086 - val_sparse_categorical_accuracy: 0.9695 - learning_rate: 1.0000e-04
## Epoch 313/500
## 90/90 - 0s - 2ms/step - loss: 0.0509 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1093 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 314/500
## 90/90 - 0s - 1ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 315/500
## 90/90 - 0s - 2ms/step - loss: 0.0551 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 316/500
## 90/90 - 0s - 2ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 317/500
## 90/90 - 0s - 2ms/step - loss: 0.0517 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9695 - learning_rate: 1.0000e-04
## Epoch 318/500
## 90/90 - 0s - 2ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.1055 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.0000e-04
## Epoch 319/500
## 90/90 - 0s - 2ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1128 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04
## Epoch 320/500
## 90/90 - 0s - 2ms/step - loss: 0.0481 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.1081 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04
## Epoch 321/500
## 90/90 - 0s - 1ms/step - loss: 0.0525 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1266 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 1.0000e-04
## Epoch 322/500
## 90/90 - 0s - 2ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9667 - learning_rate: 1.0000e-04
## Epoch 323/500
## 90/90 - 0s - 2ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1177 - val_sparse_categorical_accuracy: 0.9695 - learning_rate: 1.0000e-04
## Epoch 324/500
## 90/90 - 0s - 2ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1101 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 1.0000e-04
## Epoch 324: early stopping
```


## Evaluate model on test data


``` r
model <- load_model("best_model.keras")

results <- model |> evaluate(x_test, y_test)
```

```
## 42/42 - 1s - 15ms/step - loss: 0.0972 - sparse_categorical_accuracy: 0.9705
```

``` r
str(results)
```

```
## List of 2
##  $ loss                       : num 0.0972
##  $ sparse_categorical_accuracy: num 0.97
```

``` r
cat(
  "Test accuracy: ", results$sparse_categorical_accuracy, "\n",
  "Test loss: ", results$loss, "\n",
  sep = ""
)
```

```
## Test accuracy: 0.9704546
## Test loss: 0.0971889
```


## Plot the model's training history


``` r
plot(history)
```

![Plot of Training History Metrics](timeseries_classification_from_scratch/unnamed-chunk-12-1.png)

Plot just the training and validation accuracy:

``` r
plot(history, metric = "sparse_categorical_accuracy") +
  # scale x axis to actual number of epochs run before early stopping
  ggplot2::xlim(0, length(history$metrics$loss))
```

![Plot of Accuracy During Training](timeseries_classification_from_scratch/unnamed-chunk-13-1.png)

We can see how the training accuracy reaches almost 0.95 after 100 epochs.
However, by observing the validation accuracy we can see how the network still needs
training until it reaches almost 0.97 for both the validation and the training accuracy
after 200 epochs. Beyond the 200th epoch, if we continue on training, the validation
accuracy will start decreasing while the training accuracy will continue on increasing:
the model starts overfitting.
