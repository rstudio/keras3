% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/metrics.R
\name{metric_sparse_categorical_crossentropy}
\alias{metric_sparse_categorical_crossentropy}
\title{Computes the crossentropy metric between the labels and predictions}
\usage{
metric_sparse_categorical_crossentropy(
  y_true,
  y_pred,
  from_logits = FALSE,
  axis = -1L,
  ...,
  name = "sparse_categorical_crossentropy",
  dtype = NULL
)
}
\arguments{
\item{y_true}{Tensor of true targets.}

\item{y_pred}{Tensor of predicted targets.}

\item{from_logits}{(Optional) Whether output is expected to be a logits tensor.
By default, we consider that output encodes a probability distribution.}

\item{axis}{(Optional) (1-based) Defaults to -1. The dimension along which the metric is computed.}

\item{...}{Passed on to the underlying metric. Used for forwards and backwards compatibility.}

\item{name}{(Optional) string name of the metric instance.}

\item{dtype}{(Optional) data type of the metric result.}
}
\value{
If \code{y_true} and \code{y_pred} are missing, a (subclassed) \code{Metric}
instance is returned. The \code{Metric} object can be passed directly to
\code{compile(metrics = )} or used as a standalone object. See \code{?Metric} for
example usage.

Alternatively, if called with \code{y_true} and \code{y_pred} arguments, then the
computed case-wise values for the mini-batch are returned directly.
}
\description{
Computes the crossentropy metric between the labels and predictions
}
\details{
Use this crossentropy metric when there are two or more label classes.
We expect labels to be provided as integers. If you want to provide labels
using \code{one-hot} representation, please use \code{CategoricalCrossentropy} metric.
There should be \verb{# classes} floating point values per feature for \code{y_pred}
and a single floating point value per feature for \code{y_true}.

In the snippet below, there is a single floating point value per example for
\code{y_true} and \verb{# classes} floating pointing values per example for \code{y_pred}.
The shape of \code{y_true} is \verb{[batch_size]} and the shape of \code{y_pred} is
\verb{[batch_size, num_classes]}.
}
\seealso{
Other metrics: 
\code{\link{custom_metric}()},
\code{\link{metric_accuracy}()},
\code{\link{metric_auc}()},
\code{\link{metric_binary_accuracy}()},
\code{\link{metric_binary_crossentropy}()},
\code{\link{metric_categorical_accuracy}()},
\code{\link{metric_categorical_crossentropy}()},
\code{\link{metric_categorical_hinge}()},
\code{\link{metric_cosine_similarity}()},
\code{\link{metric_false_negatives}()},
\code{\link{metric_false_positives}()},
\code{\link{metric_hinge}()},
\code{\link{metric_kullback_leibler_divergence}()},
\code{\link{metric_logcosh_error}()},
\code{\link{metric_mean_absolute_error}()},
\code{\link{metric_mean_absolute_percentage_error}()},
\code{\link{metric_mean_iou}()},
\code{\link{metric_mean_relative_error}()},
\code{\link{metric_mean_squared_error}()},
\code{\link{metric_mean_squared_logarithmic_error}()},
\code{\link{metric_mean_tensor}()},
\code{\link{metric_mean_wrapper}()},
\code{\link{metric_mean}()},
\code{\link{metric_poisson}()},
\code{\link{metric_precision_at_recall}()},
\code{\link{metric_precision}()},
\code{\link{metric_recall_at_precision}()},
\code{\link{metric_recall}()},
\code{\link{metric_root_mean_squared_error}()},
\code{\link{metric_sensitivity_at_specificity}()},
\code{\link{metric_sparse_categorical_accuracy}()},
\code{\link{metric_sparse_top_k_categorical_accuracy}()},
\code{\link{metric_specificity_at_sensitivity}()},
\code{\link{metric_squared_hinge}()},
\code{\link{metric_sum}()},
\code{\link{metric_top_k_categorical_accuracy}()},
\code{\link{metric_true_negatives}()},
\code{\link{metric_true_positives}()}
}
\concept{metrics}
