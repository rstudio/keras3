% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model.R
\name{fit_generator}
\alias{fit_generator}
\title{Fits the model on data yielded batch-by-batch by a generator.}
\usage{
fit_generator(model, generator, steps_per_epoch, epochs = 1, verbose = 1,
  callbacks = NULL, validation_data = NULL, validation_steps = NULL,
  class_weight = NULL, max_q_size = 10, workers = 1,
  pickle_safe = FALSE, initial_epoch = 0)
}
\arguments{
\item{model}{Keras model}

\item{generator}{a generator. The output of the generator must be either - a
list (inputs, targets) - a list (inputs, targets, sample_weights). All
arrays should contain the same number of samples. The generator is expected
to loop over its data indefinitely. An epoch finishes when
\code{steps_per_epoch} samples have been seen by the model.}

\item{steps_per_epoch}{Total number of steps (batches of samples) to yield
from \code{generator} before declaring one epoch finished and starting the next
epoch. It should typically be equal to the number of unique samples if your
dataset divided by the batch size.}

\item{epochs}{integer, total number of iterations on the data.}

\item{verbose}{verbosity mode, 0, 1, or 2.}

\item{callbacks}{list of callbacks to be called during training.}

\item{validation_data}{this can be either - a generator for the validation
data - a list (inputs, targets) - a list (inputs, targets, sample_weights).}

\item{validation_steps}{Only relevant if \code{validation_data} is a generator.
Total number of steps (batches of samples) to yield from \code{generator} before
stopping.}

\item{class_weight}{dictionary mapping class indices to a weight for the
class.}

\item{max_q_size}{maximum size for the generator queue}

\item{workers}{maximum number of processes to spin up when using process
based threading}

\item{pickle_safe}{if TRUE, use process based threading. Note that because
this implementation relies on multiprocessing, you should not pass non
picklable arguments to the generator as they can't be passed easily to
children processes.}

\item{initial_epoch}{epoch at which to start training (useful for resuming a
previous training run)}
}
\value{
Training history object (invisibly)
}
\description{
The generator is run in parallel to the model, for efficiency. For instance,
this allows you to do real-time data augmentation on images on CPU in
parallel to training your model on GPU.
}
\seealso{
Other model functions: \code{\link{compile}},
  \code{\link{evaluate_generator}}, \code{\link{evaluate}},
  \code{\link{fit.tensorflow.contrib.keras.python.keras.engine.training.Model}},
  \code{\link{get_config}}, \code{\link{get_layer}},
  \code{\link{keras_model_sequential}},
  \code{\link{keras_model}},
  \code{\link{predict.tensorflow.contrib.keras.python.keras.engine.training.Model}},
  \code{\link{predict_generator}},
  \code{\link{predict_on_batch}},
  \code{\link{predict_proba}},
  \code{\link{summary.tensorflow.contrib.keras.python.keras.engine.training.Model}},
  \code{\link{train_on_batch}}
}
