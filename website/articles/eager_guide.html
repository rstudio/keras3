<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Keras with Eager Execution • keras</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<script src="../extra.js"></script><meta property="og:title" content="Keras with Eager Execution">
<meta property="og:description" content="">
<meta property="og:image" content="/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">keras</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">2.2.0.9001</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Getting Started</li>
    <li>
      <a href="../articles/getting_started.html">Overview</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_classification.html">Tutorial: Basic Classification</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_text_classification.html">Tutorial: Text Classification</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_regression.html">Tutorial: Basic Regression</a>
    </li>
    <li>
      <a href="../articles/tutorial_overfit_underfit.html">Tutorial: Overfitting and Underfitting</a>
    </li>
    <li>
      <a href="../articles/tutorial_save_and_restore.html">Tutorial: Save and Restore Models</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../articles/guide_keras.html">Guide to Keras Basics</a>
    </li>
    <li>
      <a href="../articles/sequential_model.html">Sequential Model in Depth</a>
    </li>
    <li>
      <a href="../articles/functional_api.html">Functional API in Depth</a>
    </li>
    <li>
      <a href="../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li>
      <a href="../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li>
      <a href="../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../articles/eager_guide.html">Eager Execution</a>
    </li>
    <li>
      <a href="../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../articles/custom_layers.html">Custom Layers</a>
    </li>
    <li>
      <a href="../articles/custom_models.html">Custom Models</a>
    </li>
  </ul>
</li>
<li>
  <a href="../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="https://github.com/rstudio/keras">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Keras with Eager Execution</h1>
            
      
      
      <div class="hidden name"><code>eager_guide.Rmd</code></div>

    </div>

    
    
<p>Eager execution is a way to train a Keras model without building a graph. Operations return values, not tensors. Consequently, you can inspect what goes in and comes out of an operation simply by printing a variable’s contents. This is an important advantage in model development and debugging.</p>
<p>You can use eager execution with Keras as long as you use the TensorFlow implementation. This guide gives an outline of the workflow by way of a simple regression example. Specifically, you will see how to:</p>
<ul>
<li>Set up your environment for eager execution</li>
<li>Define the main ingredients: a Keras model, an optimizer and a loss function</li>
<li>Feed data to the training routine</li>
<li>Write a simple training loop that does backprop on the model’s weights</li>
<li>Make predictions on the test set</li>
<li>Save the model’s weights</li>
</ul>
<div id="requirements" class="section level2">
<h2 class="hasAnchor">
<a href="#requirements" class="anchor"></a>Requirements</h2>
<p>To use eager execution with Keras, you need a current version of the R package <code>keras</code> with a TensorFlow backend of version at least 1.9.</p>
<p>The following preamble is required when using eager execution:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(keras)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="co"># make sure we use the tensorflow implementation of Keras</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="co"># this line has to be executed immediately after loading the library</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw"><a href="../reference/use_implementation.html">use_implementation</a></span>(<span class="st">"tensorflow"</span>)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="kw">library</span>(tensorflow)</a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co"># enable eager execution</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co"># the argument device_policy is needed only when using a GPU</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="kw"><a href="http://www.rdocumentation.org/packages/tensorflow/topics/tfe_enable_eager_execution">tfe_enable_eager_execution</a></span>(<span class="dt">device_policy =</span> <span class="st">"silent"</span>)</a></code></pre></div>
<p>When in doubt, check if you are in fact using eager execution:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">tf<span class="op">$</span><span class="kw">executing_eagerly</span>()</a></code></pre></div>
</div>
<div id="define-a-model" class="section level2">
<h2 class="hasAnchor">
<a href="#define-a-model" class="anchor"></a>Define a model</h2>
<p>Models for use with eager execution are defined as Keras <a href="https://tensorflow.rstudio.com/keras/articles/custom_models.html">custom models</a>.</p>
<p>Custom models are usually made up of normal Keras layers, which you configure as usual. However, you are free to implement custom logic in the model’s (implicit) <em>call</em> function.</p>
<p>Our simple regression example will use <code>iris</code> to predict <code>Sepal.Width</code> from <code>Petal.Length</code>, <code>Sepal.Length</code> and <code>Petal.Width</code>.</p>
<p>Here is a model that can be used for that purpose:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># model instantiator </span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">iris_regression_model &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">name =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">  </a>
<a class="sourceLine" id="cb3-4" data-line-number="4">  <span class="kw"><a href="../reference/keras_model_custom.html">keras_model_custom</a></span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">    </a>
<a class="sourceLine" id="cb3-6" data-line-number="6">    <span class="co"># define any number of layers here</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">    self<span class="op">$</span>dense1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">32</span>)</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">    self<span class="op">$</span>dropout &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dropout.html">layer_dropout</a></span>(<span class="dt">rate =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb3-9" data-line-number="9">    self<span class="op">$</span>dense2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-10" data-line-number="10">    </a>
<a class="sourceLine" id="cb3-11" data-line-number="11">    <span class="co"># this is the "call" function that defines what happens when the model is called</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12">    <span class="cf">function</span> (x, <span class="dt">mask =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb3-13" data-line-number="13">      x <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb3-14" data-line-number="14"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense1</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb3-15" data-line-number="15"><span class="st">        </span>self<span class="op">$</span><span class="kw">dropout</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb3-16" data-line-number="16"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense2</span>()</a>
<a class="sourceLine" id="cb3-17" data-line-number="17">    }</a>
<a class="sourceLine" id="cb3-18" data-line-number="18">  })</a>
<a class="sourceLine" id="cb3-19" data-line-number="19">}</a></code></pre></div>
<p>The model is created simply by instantiating it via its wrapper:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">model &lt;-<span class="st"> </span><span class="kw">iris_regression_model</span>()</a></code></pre></div>
<p>At this point, the shapes of the model’s weights are still unknown (note how no <code>input_shape</code> has been defined for its first layer). You can, however, already call the model on some dummy data:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">model</span>(<span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(<span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">3</span>)))</a></code></pre></div>
<pre><code>tf.Tensor(
[[-1.1474639]
 [-1.0472134]], shape=(2, 1), dtype=float32)</code></pre>
<p>After that call, you can inspect the model’s weights using</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">model<span class="op">$</span>weights</a></code></pre></div>
<p>This will not just display the tensor shapes, but the actual weight values.</p>
</div>
<div id="losses-and-optimizers" class="section level2">
<h2 class="hasAnchor">
<a href="#losses-and-optimizers" class="anchor"></a>Losses and optimizers</h2>
<p>An appropriate loss function for a regression task like this is mean squared error:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">mse_loss &lt;-<span class="st"> </span><span class="cf">function</span>(y_true, y_pred, x) {</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">  <span class="co"># it's required to use a TensorFlow function here, not loss_mean_squared_error() from Keras</span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">  mse &lt;-<span class="st"> </span>tf<span class="op">$</span>losses<span class="op">$</span><span class="kw">mean_squared_error</span>(y_true, y_pred)</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">  <span class="co"># here you could compute and add other losses </span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5">  mse</a>
<a class="sourceLine" id="cb8-6" data-line-number="6">}</a></code></pre></div>
<p>Note how we have to use loss functions from TensorFlow, not the Keras equivalents. In the same vein, we need to use an optimizer from the <code>tf$train</code> module.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co"># have to use an optimizer from tf$train, not Keras</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">AdamOptimizer</span>()</a></code></pre></div>
</div>
<div id="use-tfdatasets-to-feed-the-data" class="section level2">
<h2 class="hasAnchor">
<a href="#use-tfdatasets-to-feed-the-data" class="anchor"></a>Use tfdatasets to feed the data</h2>
<p>In eager execution, you use <a href="https://tensorflow.rstudio.com/tools/tfdatasets">tfdatasets</a> to stream input and target data to the model. In our simple <code>iris</code> example, we use <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/tensor_slices_dataset.html">tensor_slices_dataset</a> to directly create a dataset from the underlying R matrices <code>x_train</code> and <code>y_train</code>.</p>
<p>However, a wide variety of other <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/#section-creating-datasets">dataset creation</a> functions is available. Datasets also allow for a variety of pre-processing <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/#section-transforming-datasets">transformations</a>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">x_train &lt;-</a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw">c</span>(<span class="st">"Petal.Length"</span>, <span class="st">"Sepal.Length"</span>, <span class="st">"Petal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">y_train &lt;-</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw">c</span>(<span class="st">"Sepal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb10-5" data-line-number="5"></a>
<a class="sourceLine" id="cb10-6" data-line-number="6"><span class="co"># Convert to approriate tensor floating point type for backend</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7">x_train &lt;-<span class="st"> </span><span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(x_train)</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">y_train &lt;-<span class="st"> </span><span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(y_train)</a>
<a class="sourceLine" id="cb10-9" data-line-number="9"></a>
<a class="sourceLine" id="cb10-10" data-line-number="10"><span class="co"># same for test set</span></a>
<a class="sourceLine" id="cb10-11" data-line-number="11">x_test &lt;-</a>
<a class="sourceLine" id="cb10-12" data-line-number="12"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw">c</span>(<span class="st">"Petal.Length"</span>, <span class="st">"Sepal.Length"</span>, <span class="st">"Petal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb10-13" data-line-number="13">y_test &lt;-</a>
<a class="sourceLine" id="cb10-14" data-line-number="14"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw">c</span>(<span class="st">"Sepal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb10-15" data-line-number="15">x_test &lt;-<span class="st"> </span><span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(x_test)</a>
<a class="sourceLine" id="cb10-16" data-line-number="16">y_test &lt;-<span class="st"> </span><span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(y_test)</a>
<a class="sourceLine" id="cb10-17" data-line-number="17"></a>
<a class="sourceLine" id="cb10-18" data-line-number="18"><span class="kw">library</span>(tfdatasets)</a>
<a class="sourceLine" id="cb10-19" data-line-number="19">train_dataset &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/tensor_slices_dataset">tensor_slices_dataset</a></span>(<span class="kw">list</span> (x_train, y_train)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-20" data-line-number="20"><span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/dataset_batch">dataset_batch</a></span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb10-21" data-line-number="21">test_dataset &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/tensor_slices_dataset">tensor_slices_dataset</a></span>(<span class="kw">list</span> (x_test, y_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb10-22" data-line-number="22"><span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/dataset_batch">dataset_batch</a></span>(<span class="dv">10</span>)</a></code></pre></div>
<p>Data is accessed from a dataset via <code>make_iterator_one_shot</code> (to create an iterator) and <code>iterator_get_next</code> (to obtain the next batch).</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">iter &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/make-iterator">make_iterator_one_shot</a></span>(train_dataset)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">batch &lt;-<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/iterator_get_next">iterator_get_next</a></span>(iter)</a></code></pre></div>
<p>Datasets are available in non-eager (graph) execution as well. However, in eager mode, we can examine the actual values returned from the iterator:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">batch</a></code></pre></div>
<pre><code>[[1]]
tf.Tensor(
[[1.4 5.1 0.2]
 [1.4 4.9 0.2]
 [1.3 4.7 0.2]
 [1.5 4.6 0.2]
 [1.4 5.  0.2]
 [1.7 5.4 0.4]
 [1.4 4.6 0.3]
 [1.5 5.  0.2]
 [1.4 4.4 0.2]
 [1.5 4.9 0.1]], shape=(10, 3), dtype=float32)

[[2]]
tf.Tensor(
[[3.5]
 [3. ]
 [3.2]
 [3.1]
 [3.6]
 [3.9]
 [3.4]
 [3.4]
 [2.9]
 [3.1]], shape=(10, 1), dtype=float32)</code></pre>
</div>
<div id="training-loop" class="section level2">
<h2 class="hasAnchor">
<a href="#training-loop" class="anchor"></a>Training loop</h2>
<p>With eager execution, you take full control over the training process.</p>
<p>In general, you will have at least two loops: an outer loop over epochs, and an inner loop over batches of data returned by the iterator (implemented implicitly by <code>until_out_of_range</code>). The iterator is recreated at the start of each new epoch.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2"></a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(n_epochs)) {</a>
<a class="sourceLine" id="cb14-4" data-line-number="4">  </a>
<a class="sourceLine" id="cb14-5" data-line-number="5">  iter &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/make-iterator">make_iterator_one_shot</a></span>(train_dataset)</a>
<a class="sourceLine" id="cb14-6" data-line-number="6">  total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7">  </a>
<a class="sourceLine" id="cb14-8" data-line-number="8">  <span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/until_out_of_range">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb14-9" data-line-number="9">    </a>
<a class="sourceLine" id="cb14-10" data-line-number="10">    <span class="co"># get a new batch and run forward pass on it </span></a>
<a class="sourceLine" id="cb14-11" data-line-number="11">    </a>
<a class="sourceLine" id="cb14-12" data-line-number="12">    <span class="co"># calculate loss </span></a>
<a class="sourceLine" id="cb14-13" data-line-number="13">    </a>
<a class="sourceLine" id="cb14-14" data-line-number="14">    <span class="co"># calculate gradients of loss w.r.t. model weights</span></a>
<a class="sourceLine" id="cb14-15" data-line-number="15">    </a>
<a class="sourceLine" id="cb14-16" data-line-number="16">    <span class="co"># update model weights</span></a>
<a class="sourceLine" id="cb14-17" data-line-number="17">    </a>
<a class="sourceLine" id="cb14-18" data-line-number="18">  })</a>
<a class="sourceLine" id="cb14-19" data-line-number="19">  </a>
<a class="sourceLine" id="cb14-20" data-line-number="20">  <span class="kw">cat</span>(<span class="st">"Total loss (epoch): "</span>, i, <span class="st">": "</span>, <span class="kw">as.numeric</span>(total_loss), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a class="sourceLine" id="cb14-21" data-line-number="21">}</a></code></pre></div>
<p>Filling in the missing pieces in the above outline, we will see that</p>
<ul>
<li>Forward propagation is simply a call to <code>model()</code>.</li>
<li>This call has to happen inside the context of a <code>GradientTape</code> that records all operations.</li>
<li>Loss is calculated using the loss function defined before.</li>
<li>From the loss on the one hand and the model’s current weights on the other hand, <code>GradientTape</code> then determines the gradients.</li>
<li>Finally, the optimizer applies the gradients to the weights in its algorithm-specific way.</li>
</ul>
<p>Here is the complete code for the training loop:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2"></a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="co"># loop over epochs</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(n_epochs)) {</a>
<a class="sourceLine" id="cb15-5" data-line-number="5">  </a>
<a class="sourceLine" id="cb15-6" data-line-number="6">  <span class="co"># create fresh iterator from dataset</span></a>
<a class="sourceLine" id="cb15-7" data-line-number="7">  iter &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/make-iterator">make_iterator_one_shot</a></span>(train_dataset)</a>
<a class="sourceLine" id="cb15-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb15-9" data-line-number="9">  <span class="co"># accumulate current epoch's loss (for display purposes only)</span></a>
<a class="sourceLine" id="cb15-10" data-line-number="10">  total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb15-11" data-line-number="11">  </a>
<a class="sourceLine" id="cb15-12" data-line-number="12">  <span class="co"># loop once through the dataset</span></a>
<a class="sourceLine" id="cb15-13" data-line-number="13">  <span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/until_out_of_range">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb15-14" data-line-number="14">    </a>
<a class="sourceLine" id="cb15-15" data-line-number="15">    <span class="co"># get next batch</span></a>
<a class="sourceLine" id="cb15-16" data-line-number="16">    batch &lt;-<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/iterator_get_next">iterator_get_next</a></span>(iter)</a>
<a class="sourceLine" id="cb15-17" data-line-number="17">    x &lt;-<span class="st"> </span>batch[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb15-18" data-line-number="18">    y &lt;-<span class="st"> </span>batch[[<span class="dv">2</span>]]</a>
<a class="sourceLine" id="cb15-19" data-line-number="19">    </a>
<a class="sourceLine" id="cb15-20" data-line-number="20">    <span class="co"># forward pass is recorded by tf$GradientTape</span></a>
<a class="sourceLine" id="cb15-21" data-line-number="21">    <span class="kw">with</span>(tf<span class="op">$</span><span class="kw">GradientTape</span>() <span class="op">%as%</span><span class="st"> </span>tape, {</a>
<a class="sourceLine" id="cb15-22" data-line-number="22">     </a>
<a class="sourceLine" id="cb15-23" data-line-number="23">      <span class="co"># run model on current batch</span></a>
<a class="sourceLine" id="cb15-24" data-line-number="24">      preds &lt;-<span class="st"> </span><span class="kw">model</span>(x)</a>
<a class="sourceLine" id="cb15-25" data-line-number="25">     </a>
<a class="sourceLine" id="cb15-26" data-line-number="26">      <span class="co"># compute the loss</span></a>
<a class="sourceLine" id="cb15-27" data-line-number="27">      loss &lt;-<span class="st"> </span><span class="kw">mse_loss</span>(y, preds, x)</a>
<a class="sourceLine" id="cb15-28" data-line-number="28">    })</a>
<a class="sourceLine" id="cb15-29" data-line-number="29">    </a>
<a class="sourceLine" id="cb15-30" data-line-number="30">    <span class="co"># update total loss</span></a>
<a class="sourceLine" id="cb15-31" data-line-number="31">    total_loss &lt;-<span class="st"> </span>total_loss <span class="op">+</span><span class="st"> </span>loss</a>
<a class="sourceLine" id="cb15-32" data-line-number="32">    </a>
<a class="sourceLine" id="cb15-33" data-line-number="33">    <span class="co"># get gradients of loss w.r.t. model weights</span></a>
<a class="sourceLine" id="cb15-34" data-line-number="34">    gradients &lt;-<span class="st"> </span>tape<span class="op">$</span><span class="kw">gradient</span>(loss, model<span class="op">$</span>variables)</a>
<a class="sourceLine" id="cb15-35" data-line-number="35">    </a>
<a class="sourceLine" id="cb15-36" data-line-number="36">    <span class="co"># update model weights</span></a>
<a class="sourceLine" id="cb15-37" data-line-number="37">    optimizer<span class="op">$</span><span class="kw">apply_gradients</span>(</a>
<a class="sourceLine" id="cb15-38" data-line-number="38">      purrr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/purrr/topics/transpose">transpose</a></span>(<span class="kw">list</span>(gradients, model<span class="op">$</span>variables)),</a>
<a class="sourceLine" id="cb15-39" data-line-number="39">      <span class="dt">global_step =</span> tf<span class="op">$</span>train<span class="op">$</span><span class="kw">get_or_create_global_step</span>()</a>
<a class="sourceLine" id="cb15-40" data-line-number="40">    )</a>
<a class="sourceLine" id="cb15-41" data-line-number="41"></a>
<a class="sourceLine" id="cb15-42" data-line-number="42">  })</a>
<a class="sourceLine" id="cb15-43" data-line-number="43">  </a>
<a class="sourceLine" id="cb15-44" data-line-number="44">  <span class="kw">cat</span>(<span class="st">"Total loss (epoch): "</span>, i, <span class="st">": "</span>, <span class="kw">as.numeric</span>(total_loss), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a class="sourceLine" id="cb15-45" data-line-number="45">}</a></code></pre></div>
</div>
<div id="predictions-on-the-test-set" class="section level2">
<h2 class="hasAnchor">
<a href="#predictions-on-the-test-set" class="anchor"></a>Predictions on the test set</h2>
<p>Getting predictions on the test set is just a call to <code>model</code>, just like training has been.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">model</span>(x_test)</a></code></pre></div>
</div>
<div id="saving-and-restoring-model-weights" class="section level2">
<h2 class="hasAnchor">
<a href="#saving-and-restoring-model-weights" class="anchor"></a>Saving and restoring model weights</h2>
<p>To save model weights, create an instance of <code>tf$Checkpoint</code> and pass it the objects to be saved: in our case, the <code>model</code> and the <code>optimizer</code>. This has to happen after the respective objects have been created, but before the training loop.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">checkpoint_dir &lt;-<span class="st"> "./checkpoints"</span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2">checkpoint_prefix &lt;-<span class="st"> </span><span class="kw">file.path</span>(checkpoint_dir, <span class="st">"ckpt"</span>)</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">checkpoint &lt;-</a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="st">  </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">Checkpoint</span>(</a>
<a class="sourceLine" id="cb17-5" data-line-number="5">    <span class="dt">optimizer =</span> optimizer,</a>
<a class="sourceLine" id="cb17-6" data-line-number="6">    <span class="dt">model =</span> model</a>
<a class="sourceLine" id="cb17-7" data-line-number="7">  )</a></code></pre></div>
<p>Then at the end of each epoch, you save the model’s current weights, like so:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">checkpoint<span class="op">$</span><span class="kw">save</span>(<span class="dt">file_prefix =</span> checkpoint_prefix)</a></code></pre></div>
<p>This call saves model weights only, not the complete graph. Thus on restore, you re-create all components in the same way as above, and then load saved the model weights using e.g.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="co"># restore from recent checkpoint, you can also use a different one</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2">checkpoint<span class="op">$</span><span class="kw">restore</span>(tf<span class="op">$</span>train<span class="op">$</span><span class="kw">latest_checkpoint</span>(checkpoint_dir))</a></code></pre></div>
<p>You can then obtain predictions from the restored model, on the test set as a whole or batch-wise, using an iterator.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">model</span>(x_test)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2"></a>
<a class="sourceLine" id="cb20-3" data-line-number="3">iter &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/make-iterator">make_iterator_one_shot</a></span>(test_dataset)</a>
<a class="sourceLine" id="cb20-4" data-line-number="4"><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/until_out_of_range">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb20-5" data-line-number="5">  batch &lt;-<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/iterator_get_next">iterator_get_next</a></span>(iter)</a>
<a class="sourceLine" id="cb20-6" data-line-number="6">  preds &lt;-<span class="st"> </span><span class="kw">model</span>(batch[[<span class="dv">1</span>]])</a>
<a class="sourceLine" id="cb20-7" data-line-number="7">  <span class="kw">print</span>(preds)</a>
<a class="sourceLine" id="cb20-8" data-line-number="8">})</a></code></pre></div>
</div>
<div id="complete-example" class="section level2">
<h2 class="hasAnchor">
<a href="#complete-example" class="anchor"></a>Complete example</h2>
<p>Here is the complete example.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="kw">library</span>(keras)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="kw"><a href="../reference/use_implementation.html">use_implementation</a></span>(<span class="st">"tensorflow"</span>)</a>
<a class="sourceLine" id="cb21-3" data-line-number="3"></a>
<a class="sourceLine" id="cb21-4" data-line-number="4"><span class="kw">library</span>(tensorflow)</a>
<a class="sourceLine" id="cb21-5" data-line-number="5"><span class="kw"><a href="http://www.rdocumentation.org/packages/tensorflow/topics/tfe_enable_eager_execution">tfe_enable_eager_execution</a></span>(<span class="dt">device_policy =</span> <span class="st">"silent"</span>)</a>
<a class="sourceLine" id="cb21-6" data-line-number="6"></a>
<a class="sourceLine" id="cb21-7" data-line-number="7"><span class="kw">library</span>(tfdatasets)</a>
<a class="sourceLine" id="cb21-8" data-line-number="8"></a>
<a class="sourceLine" id="cb21-9" data-line-number="9"></a>
<a class="sourceLine" id="cb21-10" data-line-number="10"><span class="co"># Prepare training and test sets ------------------------------------------</span></a>
<a class="sourceLine" id="cb21-11" data-line-number="11"></a>
<a class="sourceLine" id="cb21-12" data-line-number="12">x_train &lt;-</a>
<a class="sourceLine" id="cb21-13" data-line-number="13"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw">c</span>(<span class="st">"Petal.Length"</span>, <span class="st">"Sepal.Length"</span>, <span class="st">"Petal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb21-14" data-line-number="14">x_train &lt;-<span class="st"> </span><span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(x_train)</a>
<a class="sourceLine" id="cb21-15" data-line-number="15">y_train &lt;-</a>
<a class="sourceLine" id="cb21-16" data-line-number="16"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw">c</span>(<span class="st">"Sepal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb21-17" data-line-number="17">y_train &lt;-<span class="st"> </span><span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(y_train)</a>
<a class="sourceLine" id="cb21-18" data-line-number="18"></a>
<a class="sourceLine" id="cb21-19" data-line-number="19">x_test &lt;-</a>
<a class="sourceLine" id="cb21-20" data-line-number="20"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw">c</span>(<span class="st">"Petal.Length"</span>, <span class="st">"Sepal.Length"</span>, <span class="st">"Petal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb21-21" data-line-number="21">x_test &lt;-<span class="st"> </span><span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(x_test)</a>
<a class="sourceLine" id="cb21-22" data-line-number="22">y_test &lt;-</a>
<a class="sourceLine" id="cb21-23" data-line-number="23"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw">c</span>(<span class="st">"Sepal.Width"</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb21-24" data-line-number="24">y_test &lt;-<span class="st"> </span><span class="kw"><a href="../reference/k_constant.html">k_constant</a></span>(y_test)</a>
<a class="sourceLine" id="cb21-25" data-line-number="25"></a>
<a class="sourceLine" id="cb21-26" data-line-number="26"></a>
<a class="sourceLine" id="cb21-27" data-line-number="27"></a>
<a class="sourceLine" id="cb21-28" data-line-number="28"><span class="co"># Create datasets for training and testing --------------------------------</span></a>
<a class="sourceLine" id="cb21-29" data-line-number="29"></a>
<a class="sourceLine" id="cb21-30" data-line-number="30">train_dataset &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/tensor_slices_dataset">tensor_slices_dataset</a></span>(<span class="kw">list</span> (x_train, y_train)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-31" data-line-number="31"><span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/dataset_batch">dataset_batch</a></span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb21-32" data-line-number="32">test_dataset &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/tensor_slices_dataset">tensor_slices_dataset</a></span>(<span class="kw">list</span> (x_test, y_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-33" data-line-number="33"><span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/dataset_batch">dataset_batch</a></span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb21-34" data-line-number="34"></a>
<a class="sourceLine" id="cb21-35" data-line-number="35"></a>
<a class="sourceLine" id="cb21-36" data-line-number="36"><span class="co"># Create model ------------------------------------------------------------</span></a>
<a class="sourceLine" id="cb21-37" data-line-number="37"></a>
<a class="sourceLine" id="cb21-38" data-line-number="38">iris_regression_model &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">name =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb21-39" data-line-number="39">  <span class="kw"><a href="../reference/keras_model_custom.html">keras_model_custom</a></span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {</a>
<a class="sourceLine" id="cb21-40" data-line-number="40">    self<span class="op">$</span>dense1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">input_shape =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb21-41" data-line-number="41">    self<span class="op">$</span>dropout &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dropout.html">layer_dropout</a></span>(<span class="dt">rate =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb21-42" data-line-number="42">    self<span class="op">$</span>dense2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb21-43" data-line-number="43">    </a>
<a class="sourceLine" id="cb21-44" data-line-number="44">    <span class="cf">function</span> (x, <span class="dt">mask =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb21-45" data-line-number="45">      self<span class="op">$</span><span class="kw">dense1</span>(x) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-46" data-line-number="46"><span class="st">        </span>self<span class="op">$</span><span class="kw">dropout</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-47" data-line-number="47"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense2</span>()</a>
<a class="sourceLine" id="cb21-48" data-line-number="48">    }</a>
<a class="sourceLine" id="cb21-49" data-line-number="49">  })</a>
<a class="sourceLine" id="cb21-50" data-line-number="50">}</a>
<a class="sourceLine" id="cb21-51" data-line-number="51"></a>
<a class="sourceLine" id="cb21-52" data-line-number="52">model &lt;-<span class="st"> </span><span class="kw">iris_regression_model</span>()</a>
<a class="sourceLine" id="cb21-53" data-line-number="53"></a>
<a class="sourceLine" id="cb21-54" data-line-number="54"></a>
<a class="sourceLine" id="cb21-55" data-line-number="55"><span class="co"># Define loss function and optimizer --------------------------------------</span></a>
<a class="sourceLine" id="cb21-56" data-line-number="56"></a>
<a class="sourceLine" id="cb21-57" data-line-number="57">mse_loss &lt;-<span class="st"> </span><span class="cf">function</span>(y_true, y_pred, x) {</a>
<a class="sourceLine" id="cb21-58" data-line-number="58">  mse &lt;-<span class="st"> </span>tf<span class="op">$</span>losses<span class="op">$</span><span class="kw">mean_squared_error</span>(y_true, y_pred)</a>
<a class="sourceLine" id="cb21-59" data-line-number="59">  mse</a>
<a class="sourceLine" id="cb21-60" data-line-number="60">}</a>
<a class="sourceLine" id="cb21-61" data-line-number="61"></a>
<a class="sourceLine" id="cb21-62" data-line-number="62">optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">AdamOptimizer</span>()</a>
<a class="sourceLine" id="cb21-63" data-line-number="63"></a>
<a class="sourceLine" id="cb21-64" data-line-number="64"></a>
<a class="sourceLine" id="cb21-65" data-line-number="65"><span class="co"># Set up checkpointing ----------------------------------------------------</span></a>
<a class="sourceLine" id="cb21-66" data-line-number="66"></a>
<a class="sourceLine" id="cb21-67" data-line-number="67">checkpoint_dir &lt;-<span class="st"> "./checkpoints"</span></a>
<a class="sourceLine" id="cb21-68" data-line-number="68">checkpoint_prefix &lt;-<span class="st"> </span><span class="kw">file.path</span>(checkpoint_dir, <span class="st">"ckpt"</span>)</a>
<a class="sourceLine" id="cb21-69" data-line-number="69">checkpoint &lt;-</a>
<a class="sourceLine" id="cb21-70" data-line-number="70"><span class="st">  </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">Checkpoint</span>(<span class="dt">optimizer =</span> optimizer,</a>
<a class="sourceLine" id="cb21-71" data-line-number="71">                      <span class="dt">model =</span> model)</a>
<a class="sourceLine" id="cb21-72" data-line-number="72"></a>
<a class="sourceLine" id="cb21-73" data-line-number="73">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb21-74" data-line-number="74"></a>
<a class="sourceLine" id="cb21-75" data-line-number="75"><span class="co"># change to TRUE if you want to restore weights</span></a>
<a class="sourceLine" id="cb21-76" data-line-number="76">restore &lt;-<span class="st"> </span><span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb21-77" data-line-number="77"></a>
<a class="sourceLine" id="cb21-78" data-line-number="78"><span class="cf">if</span> (<span class="op">!</span>restore) {</a>
<a class="sourceLine" id="cb21-79" data-line-number="79">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(n_epochs)) {</a>
<a class="sourceLine" id="cb21-80" data-line-number="80">    iter &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/make-iterator">make_iterator_one_shot</a></span>(train_dataset)</a>
<a class="sourceLine" id="cb21-81" data-line-number="81">    total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb21-82" data-line-number="82">    </a>
<a class="sourceLine" id="cb21-83" data-line-number="83">    <span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/until_out_of_range">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb21-84" data-line-number="84">      batch &lt;-<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/iterator_get_next">iterator_get_next</a></span>(iter)</a>
<a class="sourceLine" id="cb21-85" data-line-number="85">      x &lt;-<span class="st"> </span>batch[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb21-86" data-line-number="86">      y &lt;-<span class="st"> </span>batch[[<span class="dv">2</span>]]</a>
<a class="sourceLine" id="cb21-87" data-line-number="87">      </a>
<a class="sourceLine" id="cb21-88" data-line-number="88">      <span class="kw">with</span>(tf<span class="op">$</span><span class="kw">GradientTape</span>() <span class="op">%as%</span><span class="st"> </span>tape, {</a>
<a class="sourceLine" id="cb21-89" data-line-number="89">        preds &lt;-<span class="st"> </span><span class="kw">model</span>(x)</a>
<a class="sourceLine" id="cb21-90" data-line-number="90">        loss &lt;-<span class="st"> </span><span class="kw">mse_loss</span>(y, preds, x)</a>
<a class="sourceLine" id="cb21-91" data-line-number="91">      })</a>
<a class="sourceLine" id="cb21-92" data-line-number="92">      </a>
<a class="sourceLine" id="cb21-93" data-line-number="93">      total_loss &lt;-<span class="st"> </span>total_loss <span class="op">+</span><span class="st"> </span>loss</a>
<a class="sourceLine" id="cb21-94" data-line-number="94">      gradients &lt;-<span class="st"> </span>tape<span class="op">$</span><span class="kw">gradient</span>(loss, model<span class="op">$</span>variables)</a>
<a class="sourceLine" id="cb21-95" data-line-number="95">      </a>
<a class="sourceLine" id="cb21-96" data-line-number="96">      optimizer<span class="op">$</span><span class="kw">apply_gradients</span>(purrr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/purrr/topics/transpose">transpose</a></span>(<span class="kw">list</span>(gradients, model<span class="op">$</span>variables)),</a>
<a class="sourceLine" id="cb21-97" data-line-number="97">                                <span class="dt">global_step =</span> tf<span class="op">$</span>train<span class="op">$</span><span class="kw">get_or_create_global_step</span>())</a>
<a class="sourceLine" id="cb21-98" data-line-number="98">      </a>
<a class="sourceLine" id="cb21-99" data-line-number="99">    })</a>
<a class="sourceLine" id="cb21-100" data-line-number="100">    </a>
<a class="sourceLine" id="cb21-101" data-line-number="101">    <span class="kw">cat</span>(<span class="st">"Total loss (epoch): "</span>, i, <span class="st">": "</span>, <span class="kw">as.numeric</span>(total_loss), <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</a>
<a class="sourceLine" id="cb21-102" data-line-number="102">    </a>
<a class="sourceLine" id="cb21-103" data-line-number="103">    checkpoint<span class="op">$</span><span class="kw">save</span>(<span class="dt">file_prefix =</span> checkpoint_prefix)</a>
<a class="sourceLine" id="cb21-104" data-line-number="104">  }</a>
<a class="sourceLine" id="cb21-105" data-line-number="105">} <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb21-106" data-line-number="106">  checkpoint<span class="op">$</span><span class="kw">restore</span>(tf<span class="op">$</span>train<span class="op">$</span><span class="kw">latest_checkpoint</span>(checkpoint_dir))</a>
<a class="sourceLine" id="cb21-107" data-line-number="107">}</a>
<a class="sourceLine" id="cb21-108" data-line-number="108"></a>
<a class="sourceLine" id="cb21-109" data-line-number="109"></a>
<a class="sourceLine" id="cb21-110" data-line-number="110"><span class="co"># Get model predictions on test set ---------------------------------------</span></a>
<a class="sourceLine" id="cb21-111" data-line-number="111"></a>
<a class="sourceLine" id="cb21-112" data-line-number="112"><span class="kw">model</span>(x_test)</a>
<a class="sourceLine" id="cb21-113" data-line-number="113"></a>
<a class="sourceLine" id="cb21-114" data-line-number="114">iter &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/make-iterator">make_iterator_one_shot</a></span>(test_dataset)</a>
<a class="sourceLine" id="cb21-115" data-line-number="115"><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/until_out_of_range">until_out_of_range</a></span>({</a>
<a class="sourceLine" id="cb21-116" data-line-number="116">  batch &lt;-<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/tfdatasets/topics/iterator_get_next">iterator_get_next</a></span>(iter)</a>
<a class="sourceLine" id="cb21-117" data-line-number="117">  preds &lt;-<span class="st"> </span><span class="kw">model</span>(batch[[<span class="dv">1</span>]])</a>
<a class="sourceLine" id="cb21-118" data-line-number="118">  <span class="kw">print</span>(preds)</a>
<a class="sourceLine" id="cb21-119" data-line-number="119">})</a></code></pre></div>
</div>
<div id="where-to-from-here" class="section level2">
<h2 class="hasAnchor">
<a href="#where-to-from-here" class="anchor"></a>Where to from here</h2>
<p>In this guide, the task - and consequently, the custom model, associated loss and training routine - have been chosen for their simplicity. Visit the <a href="https://blogs.rstudio.com/tensorflow/">TensorFlow for R blog</a> for case studies and paper implementations that use more intricate custom logic.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#requirements">Requirements</a></li>
      <li><a href="#define-a-model">Define a model</a></li>
      <li><a href="#losses-and-optimizers">Losses and optimizers</a></li>
      <li><a href="#use-tfdatasets-to-feed-the-data">Use tfdatasets to feed the data</a></li>
      <li><a href="#training-loop">Training loop</a></li>
      <li><a href="#predictions-on-the-test-set">Predictions on the test set</a></li>
      <li><a href="#saving-and-restoring-model-weights">Saving and restoring model weights</a></li>
      <li><a href="#complete-example">Complete example</a></li>
      <li><a href="#where-to-from-here">Where to from here</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by JJ Allaire, François Chollet,  RStudio,  Google.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
