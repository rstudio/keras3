<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Guide to multi-GPU training for Keras models with TensorFlow.">
<title>Multi-GPU distributed training with TensorFlow • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Fira_Mono-0.4.8/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Multi-GPU distributed training with TensorFlow">
<meta property="og:description" content="Guide to multi-GPU training for Keras models with TensorFlow.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Multi-GPU distributed training with TensorFlow</h1>
                        <h4 data-toc-skip class="author"><a href="https://twitter.com/fchollet" class="external-link">fchollet</a></h4>
            
            <h4 data-toc-skip class="date">Last Modified: 2023-11-21;
Last Rendered: 2023-11-29</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/distributed_training_with_tensorflow.Rmd" class="external-link"><code>vignettes/distributed_training_with_tensorflow.Rmd</code></a></small>
      <div class="d-none name"><code>distributed_training_with_tensorflow.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>There are generally two ways to distribute computation across
multiple devices:</p>
<p><strong>Data parallelism</strong>, where a single model gets
replicated on multiple devices or multiple machines. Each of them
processes different batches of data, then they merge their results.
There exist many variants of this setup, that differ in how the
different model replicas merge results, in whether they stay in sync at
every batch or whether they are more loosely coupled, etc.</p>
<p><strong>Model parallelism</strong>, where different parts of a single
model run on different devices, processing a single batch of data
together. This works best with models that have a naturally-parallel
architecture, such as models that feature multiple branches.</p>
<p>This guide focuses on data parallelism, in particular
<strong>synchronous data parallelism</strong>, where the different
replicas of the model stay in sync after each batch they process.
Synchronicity keeps the model convergence behavior identical to what you
would see for single-device training.</p>
<p>Specifically, this guide teaches you how to use the
<code>tf.distribute</code> API to train Keras models on multiple GPUs,
with minimal changes to your code, on multiple GPUs (typically 2 to 16)
installed on a single machine (single host, multi-device training). This
is the most common setup for researchers and small-scale industry
workflows.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https:/keras.posit.co/">keras3</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow" class="external-link">tensorflow</a></span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##</span></span>
<span><span class="co">## Attaching package: 'tensorflow'</span></span></code></pre>
<pre><code><span><span class="co">## The following objects are masked from 'package:keras3':</span></span>
<span><span class="co">##</span></span>
<span><span class="co">##     set_random_seed, shape</span></span></code></pre>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets" class="external-link">tfdatasets</a></span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##</span></span>
<span><span class="co">## Attaching package: 'tfdatasets'</span></span></code></pre>
<pre><code><span><span class="co">## The following object is masked from 'package:keras3':</span></span>
<span><span class="co">##</span></span>
<span><span class="co">##     shape</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="single-host-multi-device-synchronous-training">Single-host, multi-device synchronous training<a class="anchor" aria-label="anchor" href="#single-host-multi-device-synchronous-training"></a>
</h2>
<p>In this setup, you have one machine with several GPUs on it
(typically 2 to 16). Each device will run a copy of your model (called a
<strong>replica</strong>). For simplicity, in what follows, we’ll assume
we’re dealing with 8 GPUs, at no loss of generality.</p>
<p><strong>How it works</strong></p>
<p>At each step of training:</p>
<ul>
<li>The current batch of data (called <strong>global batch</strong>) is
split into 8 different sub-batches (called <strong>local
batches</strong>). For instance, if the global batch has 512 samples,
each of the 8 local batches will have 64 samples.</li>
<li>Each of the 8 replicas independently processes a local batch: they
run a forward pass, then a backward pass, outputting the gradient of the
weights with respect to the loss of the model on the local batch.</li>
<li>The weight updates originating from local gradients are efficiently
merged across the 8 replicas. Because this is done at the end of every
step, the replicas always stay in sync.</li>
</ul>
<p>In practice, the process of synchronously updating the weights of the
model replicas is handled at the level of each individual weight
variable. This is done through a <strong>mirrored variable</strong>
object.</p>
<p><strong>How to use it</strong></p>
<p>To do single-host, multi-device synchronous training with a Keras
model, you would use the <a href="https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy" class="external-link"><code>tf$distribute$MirroredStrategy</code>
API</a>. Here’s how it works:</p>
<ul>
<li>Instantiate a <code>MirroredStrategy</code>, optionally configuring
which specific devices you want to use (by default the strategy will use
all GPUs available).</li>
<li>Use the strategy object to open a scope, and within this scope,
create all the Keras objects you need that contain variables. Typically,
that means <strong>creating &amp; compiling the model</strong> inside
the distribution scope. In some cases, the first call to
<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> may also create variables, so it’s a good idea to put
your <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> call in the scope as well.</li>
<li>Train the model via <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> as usual.</li>
</ul>
<p>Importantly, we recommend that you use <code>tf.data.Dataset</code>
objects to load data in a multi-device or distributed workflow.</p>
<p>Schematically, it looks like this:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a MirroredStrategy.</span></span>
<span><span class="va">strategy</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">distribute</span><span class="op">$</span><span class="fu">MirroredStrategy</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">'Number of devices: %d'</span>, <span class="va">strategy</span><span class="op">$</span><span class="va">num_replicas_in_sync</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Open a strategy scope.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">startegy</span><span class="op">$</span><span class="fu">scope</span><span class="op">(</span><span class="op">)</span>, <span class="op">{</span></span>
<span>  <span class="co"># Everything that creates variables should be under the strategy scope.</span></span>
<span>  <span class="co"># In general this is only model construction &amp; `compile()`.</span></span>
<span>  <span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">Model</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>  <span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Train the model on all available devices.</span></span>
<span>  <span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_dataset</span>, validation_data<span class="op">=</span><span class="va">val_dataset</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Test the model on all available devices.</span></span>
<span>  <span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/evaluate.html" class="external-link">evaluate</a></span><span class="op">(</span><span class="va">test_dataset</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>Here’s a simple end-to-end runnable example:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">get_compiled_model</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fl">784</span><span class="op">)</span></span>
<span>  <span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">256</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">256</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span>  <span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span></span>
<span>    optimizer <span class="op">=</span> <span class="fu"><a href="../reference/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    loss <span class="op">=</span> <span class="fu"><a href="../reference/loss_sparse_categorical_crossentropy.html">loss_sparse_categorical_crossentropy</a></span><span class="op">(</span>from_logits<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>    metrics<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="../reference/metric_sparse_categorical_accuracy.html">metric_sparse_categorical_accuracy</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">model</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">get_dataset</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">batch_size</span> <span class="op">&lt;-</span> <span class="fl">64</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/multi-assign.html">%&lt;-%</a></span> <span class="fu"><a href="../reference/dataset_mnist.html">dataset_mnist</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">x_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html" class="external-link">array_reshape</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">784</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">x_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html" class="external-link">array_reshape</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">784</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Reserve 10,000 samples for validation.</span></span>
<span>  <span class="va">x_val</span> <span class="op">&lt;-</span> <span class="va">x_train</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10000</span>,<span class="op">]</span></span>
<span>  <span class="va">y_val</span> <span class="op">&lt;-</span> <span class="va">y_train</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10000</span><span class="op">]</span></span>
<span>  <span class="va">x_train</span> <span class="op">=</span> <span class="va">x_train</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10000</span><span class="op">)</span>,<span class="op">]</span></span>
<span>  <span class="va">y_train</span> <span class="op">=</span> <span class="va">y_train</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10000</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span>  <span class="co"># Prepare the training dataset.</span></span>
<span>  <span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html" class="external-link">tensor_slices_dataset</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html" class="external-link">dataset_batch</a></span><span class="op">(</span><span class="va">batch_size</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Prepare the validation dataset.</span></span>
<span>  <span class="va">val_dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">x_val</span>, <span class="va">y_val</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html" class="external-link">tensor_slices_dataset</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html" class="external-link">dataset_batch</a></span><span class="op">(</span><span class="va">batch_size</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Prepare the test dataset.</span></span>
<span>  <span class="va">test_dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html" class="external-link">tensor_slices_dataset</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html" class="external-link">dataset_batch</a></span><span class="op">(</span><span class="va">batch_size</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">train_dataset</span>, <span class="va">val_dataset</span>, <span class="va">test_dataset</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Create a MirroredStrategy.</span></span>
<span><span class="va">strategy</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">distribute</span><span class="op">$</span><span class="fu">MirroredStrategy</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">'Number of devices: %d'</span>, <span class="va">strategy</span><span class="op">$</span><span class="va">num_replicas_in_sync</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Number of devices: 1</span></span></code></pre>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Open a strategy scope.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">strategy</span><span class="op">$</span><span class="fu">scope</span><span class="op">(</span><span class="op">)</span>, <span class="op">{</span></span>
<span>  <span class="co"># Everything that creates variables should be under the strategy scope.</span></span>
<span>  <span class="co"># In general this is only model construction &amp; `compile()`.</span></span>
<span>  <span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">get_compiled_model</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Train the model on all available devices.</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">train_dataset</span>, <span class="va">val_dataset</span>, <span class="va">test_dataset</span><span class="op">)</span> <span class="op"><a href="../reference/multi-assign.html">%&lt;-%</a></span> <span class="fu">get_dataset</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_dataset</span>, epochs<span class="op">=</span><span class="fl">2</span>, validation_data<span class="op">=</span><span class="va">val_dataset</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Test the model on all available devices.</span></span>
<span>  <span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/evaluate.html" class="external-link">evaluate</a></span><span class="op">(</span><span class="va">test_dataset</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 782/782 - 3s - 3ms/step - loss: 2.0840 - sparse_categorical_accuracy: 0.8817 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.9126</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 782/782 - 2s - 3ms/step - loss: 0.4243 - sparse_categorical_accuracy: 0.9337 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.9277</span></span>
<span><span class="co">## 157/157 - 0s - 992us/step - loss: 0.4673 - sparse_categorical_accuracy: 0.9292</span></span></code></pre>
<pre><code><span><span class="co">##            loss compile_metrics</span></span>
<span><span class="co">##        0.467276        0.929200</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="using-callbacks-to-ensure-fault-tolerance">Using callbacks to ensure fault tolerance<a class="anchor" aria-label="anchor" href="#using-callbacks-to-ensure-fault-tolerance"></a>
</h2>
<p>When using distributed training, you should always make sure you have
a strategy to recover from failure (fault tolerance). The simplest way
to handle this is to pass <code>ModelCheckpoint</code> callback to
<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>, to save your model at regular intervals (e.g. every
100 batches or every epoch). You can then restart training from your
saved model.</p>
<p>Here’s a simple example:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Prepare a directory to store all the checkpoints.</span></span>
<span><span class="va">checkpoint_dir</span> <span class="op">&lt;-</span> <span class="st">"./ckpt"</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.exists</a></span><span class="op">(</span><span class="va">checkpoint_dir</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">checkpoint_dir</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">make_or_restore_model</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Either restore the latest model, or create a fresh one</span></span>
<span>  <span class="co"># if there is no checkpoint available.</span></span>
<span>  <span class="va">checkpoints</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="va">checkpoint_dir</span>, full.names<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">checkpoints</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">latest_checkpoint</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">checkpoints</span>, <span class="fl">1</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="../reference/load_model.html">load_model</a></span><span class="op">(</span><span class="va">latest_checkpoint</span><span class="op">)</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="fu">get_compiled_model</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="va">run_training</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">epochs</span><span class="op">=</span><span class="fl">1</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Create a MirroredStrategy.</span></span>
<span>  <span class="va">strategy</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">distribute</span><span class="op">$</span><span class="fu">MirroredStrategy</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Open a strategy scope and create/restore the model</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">strategy</span><span class="op">$</span><span class="fu">scope</span><span class="op">(</span><span class="op">)</span>, <span class="op">{</span></span>
<span>    <span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">make_or_restore_model</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">callbacks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      <span class="co"># This callback saves a SavedModel every epoch</span></span>
<span>      <span class="co"># We include the current epoch in the folder name.</span></span>
<span>      <span class="fu"><a href="../reference/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span></span>
<span>        filepath <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">checkpoint_dir</span>, <span class="st">"/ckpt-{epoch}.keras"</span><span class="op">)</span>,</span>
<span>        save_freq<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span>      <span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span></span>
<span>    <span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span></span>
<span>      <span class="va">train_dataset</span>,</span>
<span>      epochs<span class="op">=</span><span class="va">epochs</span>,</span>
<span>      callbacks<span class="op">=</span><span class="va">callbacks</span>,</span>
<span>      validation_data<span class="op">=</span><span class="va">val_dataset</span>,</span>
<span>      verbose<span class="op">=</span><span class="fl">2</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Running the first time creates the model</span></span>
<span><span class="fu">run_training</span><span class="op">(</span>epochs<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Error in load_model(latest_checkpoint): could not find function "load_model"</span></span></code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Calling the same function again will resume from where we left off</span></span>
<span><span class="fu">run_training</span><span class="op">(</span>epochs<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Error in load_model(latest_checkpoint): could not find function "load_model"</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="tfdata-performance-tips">
<code>tf$data</code> performance tips<a class="anchor" aria-label="anchor" href="#tfdata-performance-tips"></a>
</h2>
<p>When doing distributed training, the efficiency with which you load
data can often become critical. Here are a few tips to make sure your
<code>tf$data</code> pipelines run as fast as possible.</p>
<p><strong>Note about dataset batching</strong></p>
<p>When creating your dataset, make sure it is batched with the global
batch size. For instance, if each of your 8 GPUs is capable of running a
batch of 64 samples, you call use a global batch size of 512.</p>
<p><strong>Calling <code><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html" class="external-link">dataset_cache()</a></code></strong></p>
<p>If you call <code><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html" class="external-link">dataset_cache()</a></code> on a dataset, its data will
be cached after running through the first iteration over the data. Every
subsequent iteration will use the cached data. The cache can be in
memory (default) or to a local file you specify.</p>
<p>This can improve performance when:</p>
<ul>
<li>Your data is not expected to change from iteration to iteration</li>
<li>You are reading data from a remote distributed filesystem</li>
<li>You are reading data from local disk, but your data would fit in
memory and your workflow is significantly IO-bound (e.g. reading &amp;
decoding image files).</li>
</ul>
<p><strong>Calling
<code>dataset_prefetch(buffer_size)</code></strong></p>
<p>You should almost always call
<code>dataset_prefetch(buffer_size)</code> after creating a dataset. It
means your data pipeline will run asynchronously from your model, with
new samples being preprocessed and stored in a buffer while the current
batch samples are used to train the model. The next batch will be
prefetched in GPU memory by the time the current batch is over.</p>
<p>That’s it!</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
