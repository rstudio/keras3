<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Classify speakers using Fast Fourier Transform (FFT) and a 1D Convnet.">
<title>Speaker Recognition • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../deps/Fira_Mono-0.4.7/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Speaker Recognition">
<meta property="og:description" content="Classify speakers using Fast Fourier Transform (FFT) and a 1D Convnet.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Speaker Recognition</h1>
                        <h4 data-toc-skip class="author"><a href="https://twitter.com/fadibadine" class="external-link">Fadi Badine</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/speaker_recognition_using_cnn.Rmd" class="external-link"><code>vignettes/examples/speaker_recognition_using_cnn.Rmd</code></a></small>
      <div class="d-none name"><code>speaker_recognition_using_cnn.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This example demonstrates how to create a model to classify speakers
from the frequency domain representation of speech recordings, obtained
via Fast Fourier Transform (FFT).</p>
<p>It shows the following:</p>
<ul>
<li>How to use <code>tf.data</code> to load, preprocess and feed audio
streams into a model</li>
<li>How to create a 1D convolutional network with residual connections
for audio classification.</li>
</ul>
<p>Our process:</p>
<ul>
<li>We prepare a dataset of speech samples from different speakers, with
the speaker as label.</li>
<li>We add background noise to these samples to augment our data.</li>
<li>We take the FFT of these samples.</li>
<li>We train a 1D convnet to predict the correct speaker given a noisy
FFT speech sample.</li>
</ul>
<p>Note:</p>
<ul>
<li>This example should be run with TensorFlow 2.3 or higher, or
<code>tf-nightly</code>.</li>
<li>The noise samples in the dataset need to be resampled to a sampling
rate of 16000 Hz before using the code in this example. In order to do
this, you will need to have installed <code>ffmpg</code>.</li>
</ul>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>os.environ[<span class="st">"KERAS_BACKEND"</span>] <span class="op">=</span> <span class="st">"tensorflow"</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display, Audio</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co"># Get the data from https://www.kaggle.com/kongaevans/speaker-recognition-dataset/download</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co"># and save it to the 'Downloads' folder in your HOME directory</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>DATASET_ROOT <span class="op">=</span> os.path.join(</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>    os.path.expanduser(<span class="st">"~"</span>), <span class="st">"Downloads/16000_pcm_speeches"</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a><span class="co"># The folders in which we will put the audio samples and the noise samples</span></span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>AUDIO_SUBFOLDER <span class="op">=</span> <span class="st">"audio"</span></span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>NOISE_SUBFOLDER <span class="op">=</span> <span class="st">"noise"</span></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>DATASET_AUDIO_PATH <span class="op">=</span> os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)</span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>DATASET_NOISE_PATH <span class="op">=</span> os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a><span class="co"># Percentage of samples to use for validation</span></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>VALID_SPLIT <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a><span class="co"># Seed to use when shuffling the dataset and the noise</span></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a>SHUFFLE_SEED <span class="op">=</span> <span class="dv">43</span></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a><span class="co"># The sampling rate to use.</span></span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a><span class="co"># This is the one used in all the audio samples.</span></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a><span class="co"># We will resample all the noise to this sampling rate.</span></span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a><span class="co"># This will also be the output size of the audio wave samples</span></span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a><span class="co"># (since all samples are of 1 second long)</span></span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a>SAMPLING_RATE <span class="op">=</span> <span class="dv">16000</span></span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a><span class="co"># The factor to multiply the noise with according to:</span></span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a><span class="co">#   noisy_sample = sample + noise * prop * scale</span></span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a><span class="co">#      where prop = sample_amplitude / noise_amplitude</span></span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a>SCALE <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="data-preparation">Data preparation<a class="anchor" aria-label="anchor" href="#data-preparation"></a>
</h2>
<p>The dataset is composed of 7 folders, divided into 2 groups:</p>
<ul>
<li>Speech samples, with 5 folders for 5 different speakers. Each folder
contains 1500 audio files, each 1 second long and sampled at 16000
Hz.</li>
<li>Background noise samples, with 2 folders and a total of 6 files.
These files are longer than 1 second (and originally not sampled at
16000 Hz, but we will resample them to 16000 Hz). We will use those 6
files to create 354 1-second-long noise samples to be used for
training.</li>
</ul>
<p>Let’s sort these 2 categories into 2 folders:</p>
<ul>
<li>An <code>audio</code> folder which will contain all the per-speaker
speech sample folders</li>
<li>A <code>noise</code> folder which will contain all the noise
samples</li>
</ul>
<p>Before sorting the audio and noise categories into 2 folders, we have
the following directory structure:</p>
<pre><code>main_directory/
...speaker_a/
...speaker_b/
...speaker_c/
...speaker_d/
...speaker_e/
...other/
..._background_noise_/</code></pre>
<p>After sorting, we end up with the following structure:</p>
<pre><code>main_directory/
...audio/
......speaker_a/
......speaker_b/
......speaker_c/
......speaker_d/
......speaker_e/
...noise/
......other/
......_background_noise_/</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># If folder `audio`, does not exist, create it, otherwise do nothing</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="cf">if</span> os.path.exists(DATASET_AUDIO_PATH) <span class="kw">is</span> <span class="va">False</span>:</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    os.makedirs(DATASET_AUDIO_PATH)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co"># If folder `noise`, does not exist, create it, otherwise do nothing</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="cf">if</span> os.path.exists(DATASET_NOISE_PATH) <span class="kw">is</span> <span class="va">False</span>:</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    os.makedirs(DATASET_NOISE_PATH)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="cf">for</span> folder <span class="kw">in</span> os.listdir(DATASET_ROOT):</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    <span class="cf">if</span> os.path.isdir(os.path.join(DATASET_ROOT, folder)):</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>        <span class="cf">if</span> folder <span class="kw">in</span> [AUDIO_SUBFOLDER, NOISE_SUBFOLDER]:</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>            <span class="co"># If folder is `audio` or `noise`, do nothing</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>        <span class="cf">elif</span> folder <span class="kw">in</span> [<span class="st">"other"</span>, <span class="st">"_background_noise_"</span>]:</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>            <span class="co"># If folder is one of the folders that contains noise samples,</span></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>            <span class="co"># move it to the `noise` folder</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>            shutil.move(</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>                os.path.join(DATASET_ROOT, folder),</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>                os.path.join(DATASET_NOISE_PATH, folder),</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>            )</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>            <span class="co"># Otherwise, it should be a speaker folder, then move it to</span></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>            <span class="co"># `audio` folder</span></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>            shutil.move(</span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>                os.path.join(DATASET_ROOT, folder),</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>                os.path.join(DATASET_AUDIO_PATH, folder),</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>            )</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="noise-preparation">Noise preparation<a class="anchor" aria-label="anchor" href="#noise-preparation"></a>
</h2>
<p>In this section:</p>
<ul>
<li>We load all noise samples (which should have been resampled to
16000)</li>
<li>We split those noise samples to chunks of 16000 samples which
correspond to 1 second duration each</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Get the list of all noise files</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>noise_paths <span class="op">=</span> []</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="cf">for</span> subdir <span class="kw">in</span> os.listdir(DATASET_NOISE_PATH):</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    subdir_path <span class="op">=</span> Path(DATASET_NOISE_PATH) <span class="op">/</span> subdir</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    <span class="cf">if</span> os.path.isdir(subdir_path):</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>        noise_paths <span class="op">+=</span> [</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>            os.path.join(subdir_path, filepath)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>            <span class="cf">for</span> filepath <span class="kw">in</span> os.listdir(subdir_path)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>            <span class="cf">if</span> filepath.endswith(<span class="st">".wav"</span>)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>        ]</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>    <span class="st">"Found </span><span class="sc">{}</span><span class="st"> files belonging to </span><span class="sc">{}</span><span class="st"> directories"</span>.<span class="bu">format</span>(</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>        <span class="bu">len</span>(noise_paths), <span class="bu">len</span>(os.listdir(DATASET_NOISE_PATH))</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>    )</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>)</span></code></pre></div>
<p>Resample all noise samples to 16000 Hz</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>command <span class="op">=</span> (</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    <span class="st">"for dir in `ls -1 "</span> <span class="op">+</span> DATASET_NOISE_PATH <span class="op">+</span> <span class="st">"`; do "</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>    <span class="st">"for file in `ls -1 "</span> <span class="op">+</span> DATASET_NOISE_PATH <span class="op">+</span> <span class="st">"/$dir/*.wav`; do "</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>    <span class="st">"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams "</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>    <span class="st">"$file | grep sample_rate | cut -f2 -d=`; "</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    <span class="st">"if [ $sample_rate -ne 16000 ]; then "</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>    <span class="st">"ffmpeg -hide_banner -loglevel panic -y "</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>    <span class="st">"-i $file -ar 16000 temp.wav; "</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    <span class="st">"mv temp.wav $file; "</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>    <span class="st">"fi; done; done"</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>)</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>os.system(command)</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co"># Split noise into chunks of 16,000 steps each</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a><span class="kw">def</span> load_noise_sample(path):</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>    sample, sampling_rate <span class="op">=</span> tf.audio.decode_wav(</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>        tf.io.read_file(path), desired_channels<span class="op">=</span><span class="dv">1</span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>    )</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>    <span class="cf">if</span> sampling_rate <span class="op">==</span> SAMPLING_RATE:</span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a>        <span class="co"># Number of slices of 16000 each that can be generated from the noise sample</span></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a>        slices <span class="op">=</span> <span class="bu">int</span>(sample.shape[<span class="dv">0</span>] <span class="op">/</span> SAMPLING_RATE)</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>        sample <span class="op">=</span> tf.split(sample[: slices <span class="op">*</span> SAMPLING_RATE], slices)</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>        <span class="cf">return</span> sample</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Sampling rate for </span><span class="sc">{}</span><span class="st"> is incorrect. Ignoring it"</span>.<span class="bu">format</span>(path))</span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a>noises <span class="op">=</span> []</span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a><span class="cf">for</span> path <span class="kw">in</span> noise_paths:</span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a>    sample <span class="op">=</span> load_noise_sample(path)</span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a>    <span class="cf">if</span> sample:</span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a>        noises.extend(sample)</span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>noises <span class="op">=</span> tf.stack(noises)</span>
<span id="cb6-36"><a href="#cb6-36" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb6-38"><a href="#cb6-38" tabindex="-1"></a>    <span class="st">"</span><span class="sc">{}</span><span class="st"> noise files were split into </span><span class="sc">{}</span><span class="st"> noise samples where each is </span><span class="sc">{}</span><span class="st"> sec. long"</span>.<span class="bu">format</span>(</span>
<span id="cb6-39"><a href="#cb6-39" tabindex="-1"></a>        <span class="bu">len</span>(noise_paths), noises.shape[<span class="dv">0</span>], noises.shape[<span class="dv">1</span>] <span class="op">//</span> SAMPLING_RATE</span>
<span id="cb6-40"><a href="#cb6-40" tabindex="-1"></a>    )</span>
<span id="cb6-41"><a href="#cb6-41" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="dataset-generation">Dataset generation<a class="anchor" aria-label="anchor" href="#dataset-generation"></a>
</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="kw">def</span> paths_and_labels_to_dataset(audio_paths, labels):</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>    <span class="co">"""Constructs a dataset of audios and labels."""</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>    path_ds <span class="op">=</span> tf.data.Dataset.from_tensor_slices(audio_paths)</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>    audio_ds <span class="op">=</span> path_ds.<span class="bu">map</span>(</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>        <span class="kw">lambda</span> x: path_to_audio(x), num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>    )</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>    label_ds <span class="op">=</span> tf.data.Dataset.from_tensor_slices(labels)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>    <span class="cf">return</span> tf.data.Dataset.<span class="bu">zip</span>((audio_ds, label_ds))</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="kw">def</span> path_to_audio(path):</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>    <span class="co">"""Reads and decodes an audio file."""</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    audio <span class="op">=</span> tf.io.read_file(path)</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>    audio, _ <span class="op">=</span> tf.audio.decode_wav(audio, <span class="dv">1</span>, SAMPLING_RATE)</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    <span class="cf">return</span> audio</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a><span class="kw">def</span> add_noise(audio, noises<span class="op">=</span><span class="va">None</span>, scale<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>    <span class="cf">if</span> noises <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>        <span class="co"># Create a random tensor of the same size as audio ranging from</span></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>        <span class="co"># 0 to the number of noise stream samples that we have.</span></span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>        tf_rnd <span class="op">=</span> tf.random.uniform(</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>            (tf.shape(audio)[<span class="dv">0</span>],), <span class="dv">0</span>, noises.shape[<span class="dv">0</span>], dtype<span class="op">=</span>tf.int32</span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>        )</span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>        noise <span class="op">=</span> tf.gather(noises, tf_rnd, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a>        <span class="co"># Get the amplitude proportion between the audio and the noise</span></span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a>        prop <span class="op">=</span> tf.math.reduce_max(audio, axis<span class="op">=</span><span class="dv">1</span>) <span class="op">/</span> tf.math.reduce_max(</span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>            noise, axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a>        )</span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a>        prop <span class="op">=</span> tf.repeat(</span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a>            tf.expand_dims(prop, axis<span class="op">=</span><span class="dv">1</span>), tf.shape(audio)[<span class="dv">1</span>], axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a>        )</span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a>        <span class="co"># Adding the rescaled noise to audio</span></span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a>        audio <span class="op">=</span> audio <span class="op">+</span> noise <span class="op">*</span> prop <span class="op">*</span> scale</span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a>    <span class="cf">return</span> audio</span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a></span>
<span id="cb7-40"><a href="#cb7-40" tabindex="-1"></a></span>
<span id="cb7-41"><a href="#cb7-41" tabindex="-1"></a><span class="kw">def</span> audio_to_fft(audio):</span>
<span id="cb7-42"><a href="#cb7-42" tabindex="-1"></a>    <span class="co"># Since tf.signal.fft applies FFT on the innermost dimension,</span></span>
<span id="cb7-43"><a href="#cb7-43" tabindex="-1"></a>    <span class="co"># we need to squeeze the dimensions and then expand them again</span></span>
<span id="cb7-44"><a href="#cb7-44" tabindex="-1"></a>    <span class="co"># after FFT</span></span>
<span id="cb7-45"><a href="#cb7-45" tabindex="-1"></a>    audio <span class="op">=</span> tf.squeeze(audio, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-46"><a href="#cb7-46" tabindex="-1"></a>    fft <span class="op">=</span> tf.signal.fft(</span>
<span id="cb7-47"><a href="#cb7-47" tabindex="-1"></a>        tf.cast(tf.<span class="bu">complex</span>(real<span class="op">=</span>audio, imag<span class="op">=</span>tf.zeros_like(audio)), tf.complex64)</span>
<span id="cb7-48"><a href="#cb7-48" tabindex="-1"></a>    )</span>
<span id="cb7-49"><a href="#cb7-49" tabindex="-1"></a>    fft <span class="op">=</span> tf.expand_dims(fft, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb7-50"><a href="#cb7-50" tabindex="-1"></a></span>
<span id="cb7-51"><a href="#cb7-51" tabindex="-1"></a>    <span class="co"># Return the absolute value of the first half of the FFT</span></span>
<span id="cb7-52"><a href="#cb7-52" tabindex="-1"></a>    <span class="co"># which represents the positive frequencies</span></span>
<span id="cb7-53"><a href="#cb7-53" tabindex="-1"></a>    <span class="cf">return</span> tf.math.<span class="bu">abs</span>(fft[:, : (audio.shape[<span class="dv">1</span>] <span class="op">//</span> <span class="dv">2</span>), :])</span>
<span id="cb7-54"><a href="#cb7-54" tabindex="-1"></a></span>
<span id="cb7-55"><a href="#cb7-55" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" tabindex="-1"></a><span class="co"># Get the list of audio file paths along with their corresponding labels</span></span>
<span id="cb7-57"><a href="#cb7-57" tabindex="-1"></a></span>
<span id="cb7-58"><a href="#cb7-58" tabindex="-1"></a>class_names <span class="op">=</span> os.listdir(DATASET_AUDIO_PATH)</span>
<span id="cb7-59"><a href="#cb7-59" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb7-60"><a href="#cb7-60" tabindex="-1"></a>    <span class="st">"Our class names: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(</span>
<span id="cb7-61"><a href="#cb7-61" tabindex="-1"></a>        class_names,</span>
<span id="cb7-62"><a href="#cb7-62" tabindex="-1"></a>    )</span>
<span id="cb7-63"><a href="#cb7-63" tabindex="-1"></a>)</span>
<span id="cb7-64"><a href="#cb7-64" tabindex="-1"></a></span>
<span id="cb7-65"><a href="#cb7-65" tabindex="-1"></a>audio_paths <span class="op">=</span> []</span>
<span id="cb7-66"><a href="#cb7-66" tabindex="-1"></a>labels <span class="op">=</span> []</span>
<span id="cb7-67"><a href="#cb7-67" tabindex="-1"></a><span class="cf">for</span> label, name <span class="kw">in</span> <span class="bu">enumerate</span>(class_names):</span>
<span id="cb7-68"><a href="#cb7-68" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb7-69"><a href="#cb7-69" tabindex="-1"></a>        <span class="st">"Processing speaker </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(</span>
<span id="cb7-70"><a href="#cb7-70" tabindex="-1"></a>            name,</span>
<span id="cb7-71"><a href="#cb7-71" tabindex="-1"></a>        )</span>
<span id="cb7-72"><a href="#cb7-72" tabindex="-1"></a>    )</span>
<span id="cb7-73"><a href="#cb7-73" tabindex="-1"></a>    dir_path <span class="op">=</span> Path(DATASET_AUDIO_PATH) <span class="op">/</span> name</span>
<span id="cb7-74"><a href="#cb7-74" tabindex="-1"></a>    speaker_sample_paths <span class="op">=</span> [</span>
<span id="cb7-75"><a href="#cb7-75" tabindex="-1"></a>        os.path.join(dir_path, filepath)</span>
<span id="cb7-76"><a href="#cb7-76" tabindex="-1"></a>        <span class="cf">for</span> filepath <span class="kw">in</span> os.listdir(dir_path)</span>
<span id="cb7-77"><a href="#cb7-77" tabindex="-1"></a>        <span class="cf">if</span> filepath.endswith(<span class="st">".wav"</span>)</span>
<span id="cb7-78"><a href="#cb7-78" tabindex="-1"></a>    ]</span>
<span id="cb7-79"><a href="#cb7-79" tabindex="-1"></a>    audio_paths <span class="op">+=</span> speaker_sample_paths</span>
<span id="cb7-80"><a href="#cb7-80" tabindex="-1"></a>    labels <span class="op">+=</span> [label] <span class="op">*</span> <span class="bu">len</span>(speaker_sample_paths)</span>
<span id="cb7-81"><a href="#cb7-81" tabindex="-1"></a></span>
<span id="cb7-82"><a href="#cb7-82" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb7-83"><a href="#cb7-83" tabindex="-1"></a>    <span class="st">"Found </span><span class="sc">{}</span><span class="st"> files belonging to </span><span class="sc">{}</span><span class="st"> classes."</span>.<span class="bu">format</span>(</span>
<span id="cb7-84"><a href="#cb7-84" tabindex="-1"></a>        <span class="bu">len</span>(audio_paths), <span class="bu">len</span>(class_names)</span>
<span id="cb7-85"><a href="#cb7-85" tabindex="-1"></a>    )</span>
<span id="cb7-86"><a href="#cb7-86" tabindex="-1"></a>)</span>
<span id="cb7-87"><a href="#cb7-87" tabindex="-1"></a></span>
<span id="cb7-88"><a href="#cb7-88" tabindex="-1"></a><span class="co"># Shuffle</span></span>
<span id="cb7-89"><a href="#cb7-89" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(SHUFFLE_SEED)</span>
<span id="cb7-90"><a href="#cb7-90" tabindex="-1"></a>rng.shuffle(audio_paths)</span>
<span id="cb7-91"><a href="#cb7-91" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(SHUFFLE_SEED)</span>
<span id="cb7-92"><a href="#cb7-92" tabindex="-1"></a>rng.shuffle(labels)</span>
<span id="cb7-93"><a href="#cb7-93" tabindex="-1"></a></span>
<span id="cb7-94"><a href="#cb7-94" tabindex="-1"></a><span class="co"># Split into training and validation</span></span>
<span id="cb7-95"><a href="#cb7-95" tabindex="-1"></a>num_val_samples <span class="op">=</span> <span class="bu">int</span>(VALID_SPLIT <span class="op">*</span> <span class="bu">len</span>(audio_paths))</span>
<span id="cb7-96"><a href="#cb7-96" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Using </span><span class="sc">{}</span><span class="st"> files for training."</span>.<span class="bu">format</span>(<span class="bu">len</span>(audio_paths) <span class="op">-</span> num_val_samples))</span>
<span id="cb7-97"><a href="#cb7-97" tabindex="-1"></a>train_audio_paths <span class="op">=</span> audio_paths[:<span class="op">-</span>num_val_samples]</span>
<span id="cb7-98"><a href="#cb7-98" tabindex="-1"></a>train_labels <span class="op">=</span> labels[:<span class="op">-</span>num_val_samples]</span>
<span id="cb7-99"><a href="#cb7-99" tabindex="-1"></a></span>
<span id="cb7-100"><a href="#cb7-100" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Using </span><span class="sc">{}</span><span class="st"> files for validation."</span>.<span class="bu">format</span>(num_val_samples))</span>
<span id="cb7-101"><a href="#cb7-101" tabindex="-1"></a>valid_audio_paths <span class="op">=</span> audio_paths[<span class="op">-</span>num_val_samples:]</span>
<span id="cb7-102"><a href="#cb7-102" tabindex="-1"></a>valid_labels <span class="op">=</span> labels[<span class="op">-</span>num_val_samples:]</span>
<span id="cb7-103"><a href="#cb7-103" tabindex="-1"></a></span>
<span id="cb7-104"><a href="#cb7-104" tabindex="-1"></a><span class="co"># Create 2 datasets, one for training and the other for validation</span></span>
<span id="cb7-105"><a href="#cb7-105" tabindex="-1"></a>train_ds <span class="op">=</span> paths_and_labels_to_dataset(train_audio_paths, train_labels)</span>
<span id="cb7-106"><a href="#cb7-106" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.shuffle(</span>
<span id="cb7-107"><a href="#cb7-107" tabindex="-1"></a>    buffer_size<span class="op">=</span>BATCH_SIZE <span class="op">*</span> <span class="dv">8</span>, seed<span class="op">=</span>SHUFFLE_SEED</span>
<span id="cb7-108"><a href="#cb7-108" tabindex="-1"></a>).batch(BATCH_SIZE)</span>
<span id="cb7-109"><a href="#cb7-109" tabindex="-1"></a></span>
<span id="cb7-110"><a href="#cb7-110" tabindex="-1"></a>valid_ds <span class="op">=</span> paths_and_labels_to_dataset(valid_audio_paths, valid_labels)</span>
<span id="cb7-111"><a href="#cb7-111" tabindex="-1"></a>valid_ds <span class="op">=</span> valid_ds.shuffle(buffer_size<span class="op">=</span><span class="dv">32</span> <span class="op">*</span> <span class="dv">8</span>, seed<span class="op">=</span>SHUFFLE_SEED).batch(<span class="dv">32</span>)</span>
<span id="cb7-112"><a href="#cb7-112" tabindex="-1"></a></span>
<span id="cb7-113"><a href="#cb7-113" tabindex="-1"></a></span>
<span id="cb7-114"><a href="#cb7-114" tabindex="-1"></a><span class="co"># Add noise to the training set</span></span>
<span id="cb7-115"><a href="#cb7-115" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.<span class="bu">map</span>(</span>
<span id="cb7-116"><a href="#cb7-116" tabindex="-1"></a>    <span class="kw">lambda</span> x, y: (add_noise(x, noises, scale<span class="op">=</span>SCALE), y),</span>
<span id="cb7-117"><a href="#cb7-117" tabindex="-1"></a>    num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE,</span>
<span id="cb7-118"><a href="#cb7-118" tabindex="-1"></a>)</span>
<span id="cb7-119"><a href="#cb7-119" tabindex="-1"></a></span>
<span id="cb7-120"><a href="#cb7-120" tabindex="-1"></a><span class="co"># Transform audio wave to the frequency domain using `audio_to_fft`</span></span>
<span id="cb7-121"><a href="#cb7-121" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.<span class="bu">map</span>(</span>
<span id="cb7-122"><a href="#cb7-122" tabindex="-1"></a>    <span class="kw">lambda</span> x, y: (audio_to_fft(x), y), num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE</span>
<span id="cb7-123"><a href="#cb7-123" tabindex="-1"></a>)</span>
<span id="cb7-124"><a href="#cb7-124" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.prefetch(tf.data.AUTOTUNE)</span>
<span id="cb7-125"><a href="#cb7-125" tabindex="-1"></a></span>
<span id="cb7-126"><a href="#cb7-126" tabindex="-1"></a>valid_ds <span class="op">=</span> valid_ds.<span class="bu">map</span>(</span>
<span id="cb7-127"><a href="#cb7-127" tabindex="-1"></a>    <span class="kw">lambda</span> x, y: (audio_to_fft(x), y), num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE</span>
<span id="cb7-128"><a href="#cb7-128" tabindex="-1"></a>)</span>
<span id="cb7-129"><a href="#cb7-129" tabindex="-1"></a>valid_ds <span class="op">=</span> valid_ds.prefetch(tf.data.AUTOTUNE)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="model-definition">Model Definition<a class="anchor" aria-label="anchor" href="#model-definition"></a>
</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">def</span> residual_block(x, filters, conv_num<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">"relu"</span>):</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    <span class="co"># Shortcut</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>    s <span class="op">=</span> keras.layers.Conv1D(filters, <span class="dv">1</span>, padding<span class="op">=</span><span class="st">"same"</span>)(x)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(conv_num <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>        x <span class="op">=</span> keras.layers.Conv1D(filters, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">"same"</span>)(x)</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>        x <span class="op">=</span> keras.layers.Activation(activation)(x)</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Conv1D(filters, <span class="dv">3</span>, padding<span class="op">=</span><span class="st">"same"</span>)(x)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Add()([x, s])</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Activation(activation)(x)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    <span class="cf">return</span> keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>, strides<span class="op">=</span><span class="dv">2</span>)(x)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="kw">def</span> build_model(input_shape, num_classes):</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    inputs <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>input_shape, name<span class="op">=</span><span class="st">"input"</span>)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    x <span class="op">=</span> residual_block(inputs, <span class="dv">16</span>, <span class="dv">2</span>)</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>    x <span class="op">=</span> residual_block(x, <span class="dv">32</span>, <span class="dv">2</span>)</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>    x <span class="op">=</span> residual_block(x, <span class="dv">64</span>, <span class="dv">3</span>)</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>    x <span class="op">=</span> residual_block(x, <span class="dv">128</span>, <span class="dv">3</span>)</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    x <span class="op">=</span> residual_block(x, <span class="dv">128</span>, <span class="dv">3</span>)</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.AveragePooling1D(pool_size<span class="op">=</span><span class="dv">3</span>, strides<span class="op">=</span><span class="dv">3</span>)(x)</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(x)</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(x)</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(</span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>        num_classes, activation<span class="op">=</span><span class="st">"softmax"</span>, name<span class="op">=</span><span class="st">"output"</span></span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>    )(x)</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a>    <span class="cf">return</span> keras.models.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a></span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a>model <span class="op">=</span> build_model((SAMPLING_RATE <span class="op">//</span> <span class="dv">2</span>, <span class="dv">1</span>), <span class="bu">len</span>(class_names))</span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a></span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a>model.summary()</span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a></span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a><span class="co"># Compile the model using Adam's default learning rate</span></span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">"Adam"</span>,</span>
<span id="cb8-41"><a href="#cb8-41" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb8-42"><a href="#cb8-42" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">"accuracy"</span>],</span>
<span id="cb8-43"><a href="#cb8-43" tabindex="-1"></a>)</span>
<span id="cb8-44"><a href="#cb8-44" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" tabindex="-1"></a><span class="co"># Add callbacks:</span></span>
<span id="cb8-46"><a href="#cb8-46" tabindex="-1"></a><span class="co"># 'EarlyStopping' to stop training when the model is not enhancing anymore</span></span>
<span id="cb8-47"><a href="#cb8-47" tabindex="-1"></a><span class="co"># 'ModelCheckPoint' to always keep the model that has the best val_accuracy</span></span>
<span id="cb8-48"><a href="#cb8-48" tabindex="-1"></a>model_save_filename <span class="op">=</span> <span class="st">"model.keras"</span></span>
<span id="cb8-49"><a href="#cb8-49" tabindex="-1"></a></span>
<span id="cb8-50"><a href="#cb8-50" tabindex="-1"></a>earlystopping_cb <span class="op">=</span> keras.callbacks.EarlyStopping(</span>
<span id="cb8-51"><a href="#cb8-51" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">10</span>, restore_best_weights<span class="op">=</span><span class="va">True</span></span>
<span id="cb8-52"><a href="#cb8-52" tabindex="-1"></a>)</span>
<span id="cb8-53"><a href="#cb8-53" tabindex="-1"></a>mdlcheckpoint_cb <span class="op">=</span> keras.callbacks.ModelCheckpoint(</span>
<span id="cb8-54"><a href="#cb8-54" tabindex="-1"></a>    model_save_filename, monitor<span class="op">=</span><span class="st">"val_accuracy"</span>, save_best_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb8-55"><a href="#cb8-55" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    train_ds,</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>    epochs<span class="op">=</span>EPOCHS,</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>    validation_data<span class="op">=</span>valid_ds,</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    callbacks<span class="op">=</span>[earlystopping_cb, mdlcheckpoint_cb],</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="evaluation">Evaluation<a class="anchor" aria-label="anchor" href="#evaluation"></a>
</h2>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="bu">print</span>(model.evaluate(valid_ds))</span></code></pre></div>
<p>We get ~ 98% validation accuracy.</p>
</div>
<div class="section level2">
<h2 id="demonstration">Demonstration<a class="anchor" aria-label="anchor" href="#demonstration"></a>
</h2>
<p>Let’s take some samples and:</p>
<ul>
<li>Predict the speaker</li>
<li>Compare the prediction with the real speaker</li>
<li>Listen to the audio to see that despite the samples being noisy, the
model is still pretty accurate</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>SAMPLES_TO_DISPLAY <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>test_ds <span class="op">=</span> paths_and_labels_to_dataset(valid_audio_paths, valid_labels)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>test_ds <span class="op">=</span> test_ds.shuffle(buffer_size<span class="op">=</span>BATCH_SIZE <span class="op">*</span> <span class="dv">8</span>, seed<span class="op">=</span>SHUFFLE_SEED).batch(</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>    BATCH_SIZE</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>)</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>test_ds <span class="op">=</span> test_ds.<span class="bu">map</span>(</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>    <span class="kw">lambda</span> x, y: (add_noise(x, noises, scale<span class="op">=</span>SCALE), y),</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>    num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE,</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>)</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a><span class="cf">for</span> audios, labels <span class="kw">in</span> test_ds.take(<span class="dv">1</span>):</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>    <span class="co"># Get the signal FFT</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>    ffts <span class="op">=</span> audio_to_fft(audios)</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>    <span class="co"># Predict</span></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>    y_pred <span class="op">=</span> model.predict(ffts)</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a>    <span class="co"># Take random samples</span></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a>    rnd <span class="op">=</span> np.random.randint(<span class="dv">0</span>, BATCH_SIZE, SAMPLES_TO_DISPLAY)</span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>    audios <span class="op">=</span> audios.numpy()[rnd, :, :]</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>    labels <span class="op">=</span> labels.numpy()[rnd]</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>    y_pred <span class="op">=</span> np.argmax(y_pred, axis<span class="op">=-</span><span class="dv">1</span>)[rnd]</span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a>    <span class="cf">for</span> index <span class="kw">in</span> <span class="bu">range</span>(SAMPLES_TO_DISPLAY):</span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>        <span class="co"># For every sample, print the true and predicted label</span></span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>        <span class="co"># as well as run the voice with the noise</span></span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a>            <span class="st">"Speaker:</span><span class="ch">\33</span><span class="sc">{}</span><span class="st"> </span><span class="sc">{}</span><span class="ch">\33</span><span class="st">[0m</span><span class="ch">\t</span><span class="st">Predicted:</span><span class="ch">\33</span><span class="sc">{}</span><span class="st"> </span><span class="sc">{}</span><span class="ch">\33</span><span class="st">[0m"</span>.<span class="bu">format</span>(</span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a>                <span class="st">"[92m"</span> <span class="cf">if</span> labels[index] <span class="op">==</span> y_pred[index] <span class="cf">else</span> <span class="st">"[91m"</span>,</span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a>                class_names[labels[index]],</span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a>                <span class="st">"[92m"</span> <span class="cf">if</span> labels[index] <span class="op">==</span> y_pred[index] <span class="cf">else</span> <span class="st">"[91m"</span>,</span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a>                class_names[y_pred[index]],</span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a>            )</span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a>        )</span>
<span id="cb11-35"><a href="#cb11-35" tabindex="-1"></a>        display(Audio(audios[index, :, :].squeeze(), rate<span class="op">=</span>SAMPLING_RATE))</span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
