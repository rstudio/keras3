<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Timeseries classification from scratch • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Timeseries classification from scratch">
<meta property="og:description" content="Training a timeseries classifier from scratch on the FordA dataset from the UCR/UEA archive.">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">keras</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.13.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    </li>
    <li>
      <a href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    </li>
    <li>
      <a href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Guides (New for TF 2.6)</li>
    <li>
      <a href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    </li>
    <li>
      <a href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    </li>
    <li>
      <a href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    </li>
    <li>
      <a href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    </li>
    <li>
      <a href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    </li>
    <li>
      <a href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    </li>
    <li>
      <a href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Functional API in Depth</a>
    </li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li>
      <a href="../../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/eager_guide.html">Eager Execution</a>
    </li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
    <li>
      <a href="../../articles/custom_models.html">Custom Models</a>
    </li>
    <li>
      <a href="../../articles/saving_serializing.html">Saving and serializing</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/keras/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Timeseries classification from scratch</h1>
                        <h4 data-toc-skip class="author"><a href="https://github.com/hfawaz/" class="external-link">hfawaz</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/timeseries_classification_from_scratch.Rmd" class="external-link"><code>vignettes/examples/timeseries_classification_from_scratch.Rmd</code></a></small>
      <div class="hidden name"><code>timeseries_classification_from_scratch.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This example shows how to do timeseries classification from scratch,
starting from raw CSV timeseries files on disk. We demonstrate the
workflow on the FordA dataset from the <a href="https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/" class="external-link">UCR/UEA
archive</a>.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-the-data-the-forda-dataset">Load the data: the FordA dataset<a class="anchor" aria-label="anchor" href="#load-the-data-the-forda-dataset"></a>
</h2>
<div class="section level3">
<h3 id="dataset-description">Dataset description<a class="anchor" aria-label="anchor" href="#dataset-description"></a>
</h3>
<p>The dataset we are using here is called FordA. The data comes from
the UCR archive. The dataset contains 3601 training instances and
another 1320 testing instances. Each timeseries corresponds to a
measurement of engine noise captured by a motor sensor. For this task,
the goal is to automatically detect the presence of a specific issue
with the engine. The problem is a balanced binary classification task.
The full description of this dataset can be found <a href="http://www.j-wichard.de/publications/FordPaper.pdf" class="external-link">here</a>.</p>
</div>
<div class="section level3">
<h3 id="read-the-tsv-data">Read the TSV data<a class="anchor" aria-label="anchor" href="#read-the-tsv-data"></a>
</h3>
<p>We will use the <code>FordA_TRAIN</code> file for training and the
<code>FordA_TEST</code> file for testing. The simplicity of this dataset
allows us to demonstrate effectively how to use ConvNets for timeseries
classification. In this file, the first column corresponds to the
label.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="kw">def</span> readucr(filename):</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    data <span class="op">=</span> np.loadtxt(filename, delimiter<span class="op">=</span><span class="st">"</span><span class="ch">\t</span><span class="st">"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    y <span class="op">=</span> data[:, <span class="dv">0</span>]</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    x <span class="op">=</span> data[:, <span class="dv">1</span>:]</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>    <span class="cf">return</span> x, y.astype(<span class="bu">int</span>)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>root_url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/"</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>x_train, y_train <span class="op">=</span> readucr(root_url <span class="op">+</span> <span class="st">"FordA_TRAIN.tsv"</span>)</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>x_test, y_test <span class="op">=</span> readucr(root_url <span class="op">+</span> <span class="st">"FordA_TEST.tsv"</span>)</span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="visualize-the-data">Visualize the data<a class="anchor" aria-label="anchor" href="#visualize-the-data"></a>
</h2>
<p>Here we visualize one timeseries example for each class in the
dataset.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>classes <span class="op">=</span> np.unique(np.concatenate((y_train, y_test), axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>plt.figure()</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="cf">for</span> c <span class="kw">in</span> classes:</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>    c_x_train <span class="op">=</span> x_train[y_train <span class="op">==</span> c]</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    plt.plot(c_x_train[<span class="dv">0</span>], label<span class="op">=</span><span class="st">"class "</span> <span class="op">+</span> <span class="bu">str</span>(c))</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"best"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>plt.show()</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>plt.close()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="standardize-the-data">Standardize the data<a class="anchor" aria-label="anchor" href="#standardize-the-data"></a>
</h2>
<p>Our timeseries are already in a single length (500). However, their
values are usually in various ranges. This is not ideal for a neural
network; in general we should seek to make the input values normalized.
For this specific dataset, the data is already z-normalized: each
timeseries sample has a mean equal to zero and a standard deviation
equal to one. This type of normalization is very common for timeseries
classification problems, see <a href="https://link.springer.com/article/10.1007/s10618-016-0483-9" class="external-link">Bagnall
et al. (2016)</a>.</p>
<p>Note that the timeseries data used here are univariate, meaning we
only have one channel per timeseries example. We will therefore
transform the timeseries into a multivariate one with one channel using
a simple reshaping via numpy. This will allow us to construct a model
that is easily applicable to multivariate time series.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>x_train <span class="op">=</span> x_train.reshape((x_train.shape[<span class="dv">0</span>], x_train.shape[<span class="dv">1</span>], <span class="dv">1</span>))</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>x_test <span class="op">=</span> x_test.reshape((x_test.shape[<span class="dv">0</span>], x_test.shape[<span class="dv">1</span>], <span class="dv">1</span>))</span></code></pre></div>
<p>Finally, in order to use
<code>sparse_categorical_crossentropy</code>, we will have to count the
number of classes beforehand.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="bu">len</span>(np.unique(y_train))</span></code></pre></div>
<p>Now we shuffle the training set because we will be using the
<code>validation_split</code> option later when training.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>idx <span class="op">=</span> np.random.permutation(<span class="bu">len</span>(x_train))</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>x_train <span class="op">=</span> x_train[idx]</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>y_train <span class="op">=</span> y_train[idx]</span></code></pre></div>
<p>Standardize the labels to positive integers. The expected labels will
then be 0 and 1.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>y_train[y_train <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>y_test[y_test <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="build-a-model">Build a model<a class="anchor" aria-label="anchor" href="#build-a-model"></a>
</h2>
<p>We build a Fully Convolutional Neural Network originally proposed in
<a href="https://arxiv.org/abs/1611.06455" class="external-link">this paper</a>. The
implementation is based on the TF 2 version provided <a href="https://github.com/hfawaz/dl-4-tsc/" class="external-link">here</a>. The following
hyperparameters (kernel_size, filters, the usage of BatchNorm) were
found via random search using <a href="https://github.com/keras-team/keras-tuner" class="external-link">KerasTuner</a>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">def</span> make_model(input_shape):</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    input_layer <span class="op">=</span> keras.layers.Input(input_shape)</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>    conv1 <span class="op">=</span> keras.layers.Conv1D(filters<span class="op">=</span><span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="st">"same"</span>)(</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>        input_layer</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>    )</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    conv1 <span class="op">=</span> keras.layers.BatchNormalization()(conv1)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>    conv1 <span class="op">=</span> keras.layers.ReLU()(conv1)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    conv2 <span class="op">=</span> keras.layers.Conv1D(filters<span class="op">=</span><span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="st">"same"</span>)(</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>        conv1</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>    )</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>    conv2 <span class="op">=</span> keras.layers.BatchNormalization()(conv2)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    conv2 <span class="op">=</span> keras.layers.ReLU()(conv2)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    conv3 <span class="op">=</span> keras.layers.Conv1D(filters<span class="op">=</span><span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="st">"same"</span>)(</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>        conv2</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>    )</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>    conv3 <span class="op">=</span> keras.layers.BatchNormalization()(conv3)</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    conv3 <span class="op">=</span> keras.layers.ReLU()(conv3)</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    gap <span class="op">=</span> keras.layers.GlobalAveragePooling1D()(conv3)</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>    output_layer <span class="op">=</span> keras.layers.Dense(num_classes, activation<span class="op">=</span><span class="st">"softmax"</span>)(gap)</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>    <span class="cf">return</span> keras.models.Model(inputs<span class="op">=</span>input_layer, outputs<span class="op">=</span>output_layer)</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>model <span class="op">=</span> make_model(input_shape<span class="op">=</span>x_train.shape[<span class="dv">1</span>:])</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a>keras.utils.plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="train-the-model">Train the model<a class="anchor" aria-label="anchor" href="#train-the-model"></a>
</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>callbacks <span class="op">=</span> [</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    keras.callbacks.ModelCheckpoint(</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>        <span class="st">"best_model.keras"</span>, save_best_only<span class="op">=</span><span class="va">True</span>, monitor<span class="op">=</span><span class="st">"val_loss"</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>    ),</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    keras.callbacks.ReduceLROnPlateau(</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>        monitor<span class="op">=</span><span class="st">"val_loss"</span>, factor<span class="op">=</span><span class="fl">0.5</span>, patience<span class="op">=</span><span class="dv">20</span>, min_lr<span class="op">=</span><span class="fl">0.0001</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>    ),</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">"val_loss"</span>, patience<span class="op">=</span><span class="dv">50</span>, verbose<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>]</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">"sparse_categorical_accuracy"</span>],</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>)</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>    x_train,</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>    y_train,</span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>    callbacks<span class="op">=</span>callbacks,</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="evaluate-model-on-test-data">Evaluate model on test data<a class="anchor" aria-label="anchor" href="#evaluate-model-on-test-data"></a>
</h2>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>model <span class="op">=</span> keras.models.load_model(<span class="st">"best_model.keras"</span>)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>test_loss, test_acc <span class="op">=</span> model.evaluate(x_test, y_test)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test accuracy"</span>, test_acc)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test loss"</span>, test_loss)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="plot-the-models-training-and-validation-loss">Plot the model’s training and validation loss<a class="anchor" aria-label="anchor" href="#plot-the-models-training-and-validation-loss"></a>
</h2>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>metric <span class="op">=</span> <span class="st">"sparse_categorical_accuracy"</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>plt.figure()</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>plt.plot(history.history[metric])</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>plt.plot(history.history[<span class="st">"val_"</span> <span class="op">+</span> metric])</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>plt.title(<span class="st">"model "</span> <span class="op">+</span> metric)</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>plt.ylabel(metric, fontsize<span class="op">=</span><span class="st">"large"</span>)</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>plt.xlabel(<span class="st">"epoch"</span>, fontsize<span class="op">=</span><span class="st">"large"</span>)</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>plt.legend([<span class="st">"train"</span>, <span class="st">"val"</span>], loc<span class="op">=</span><span class="st">"best"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>plt.show()</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>plt.close()</span></code></pre></div>
<p>We can see how the training accuracy reaches almost 0.95 after 100
epochs. However, by observing the validation accuracy we can see how the
network still needs training until it reaches almost 0.97 for both the
validation and the training accuracy after 200 epochs. Beyond the 200th
epoch, if we continue on training, the validation accuracy will start
decreasing while the training accuracy will continue on increasing: the
model starts overfitting.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
