<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>variational_autoencoder_deconv • keras</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">Keras for R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Getting Started</li>
    <li>
      <a href="../../articles/sequential_model.html">Guide to the Sequential Model</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Guide to the Functional API</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/keras">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>variational_autoencoder_deconv</h1>
            
          </div>

    
    
<div class="contents">
<div class="source-ref">
<p><span class="caption">Source: </span><a href="https://github.com/rstudio/keras/blob/master/vignettes/examples/variational_autoencoder_deconv.R" class="uri">https://github.com/rstudio/keras/blob/master/vignettes/examples/variational_autoencoder_deconv.R</a></p>
</div>
<p>This script demonstrates how to build a variational autoencoder with Keras and deconvolution layers. Reference: “Auto-Encoding Variational Bayes” <a href="https://arxiv.org/abs/1312.6114" class="uri">https://arxiv.org/abs/1312.6114</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(keras)
K &lt;-<span class="st"> </span>keras<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/backend">backend</a></span>()

#### Parameterization ####

<span class="co"># input image dimensions</span>
img_rows &lt;-<span class="st"> </span>28L
img_cols &lt;-<span class="st"> </span>28L
<span class="co"># color channels (1 = grayscale, 3 = RGB)</span>
img_chns &lt;-<span class="st"> </span>1L

<span class="co"># number of convolutional filters to use</span>
filters &lt;-<span class="st"> </span>64L

<span class="co"># convolution kernel size</span>
num_conv &lt;-<span class="st"> </span>3L

latent_dim &lt;-<span class="st"> </span>2L
intermediate_dim &lt;-<span class="st"> </span>128L
epsilon_std &lt;-<span class="st"> </span><span class="fl">1.0</span>

<span class="co"># training parameters</span>
batch_size &lt;-<span class="st"> </span>100L
epochs &lt;-<span class="st"> </span>5L


#### Model Construction ####

original_img_size &lt;-<span class="st"> </span><span class="kw">c</span>(img_rows, img_cols, img_chns)

x &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> <span class="kw">c</span>(original_img_size))

conv_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(
  x,
  <span class="dt">filters =</span> img_chns,
  <span class="dt">kernel_size =</span> <span class="kw">c</span>(2L, 2L),
  <span class="dt">strides =</span> <span class="kw">c</span>(1L, 1L),
  <span class="dt">padding =</span> <span class="st">"same"</span>,
  <span class="dt">activation =</span> <span class="st">"relu"</span>
)

conv_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(
  conv_<span class="dv">1</span>,
  <span class="dt">filters =</span> filters,
  <span class="dt">kernel_size =</span> <span class="kw">c</span>(2L, 2L),
  <span class="dt">strides =</span> <span class="kw">c</span>(2L, 2L),
  <span class="dt">padding =</span> <span class="st">"same"</span>,
  <span class="dt">activation =</span> <span class="st">"relu"</span>
)

conv_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(
  conv_<span class="dv">2</span>,
  <span class="dt">filters =</span> filters,
  <span class="dt">kernel_size =</span> <span class="kw">c</span>(num_conv, num_conv),
  <span class="dt">strides =</span> <span class="kw">c</span>(1L, 1L),
  <span class="dt">padding =</span> <span class="st">"same"</span>,
  <span class="dt">activation =</span> <span class="st">"relu"</span>
)

conv_<span class="dv">4</span> &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(
  conv_<span class="dv">3</span>,
  <span class="dt">filters =</span> filters,
  <span class="dt">kernel_size =</span> <span class="kw">c</span>(num_conv, num_conv),
  <span class="dt">strides =</span> <span class="kw">c</span>(1L, 1L),
  <span class="dt">padding =</span> <span class="st">"same"</span>,
  <span class="dt">activation =</span> <span class="st">"relu"</span>
)

flat &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_flatten.html">layer_flatten</a></span>(conv_<span class="dv">4</span>)
hidden &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(flat, <span class="dt">units =</span> intermediate_dim, <span class="dt">activation =</span> <span class="st">"relu"</span>)

z_mean &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(hidden, <span class="dt">units =</span> latent_dim)
z_log_var &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(hidden, <span class="dt">units =</span> latent_dim)

sampling &lt;-<span class="st"> </span><span class="cf">function</span>(args) {
  z_mean &lt;-<span class="st"> </span>args[, <span class="dv">0</span><span class="op">:</span>(latent_dim <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)]
  z_log_var &lt;-<span class="st"> </span>args[, latent_dim<span class="op">:</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>latent_dim <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)]
  
  epsilon &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">random_normal</span>(
    <span class="dt">shape =</span> <span class="kw">c</span>(K<span class="op">$</span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes_linetype_size_shape">shape</a></span>(z_mean)[[<span class="dv">1</span>]]),
    <span class="dt">mean =</span> <span class="dv">0</span>.,
    <span class="dt">stddev =</span> epsilon_std
  )
  z_mean <span class="op">+</span><span class="st"> </span>K<span class="op">$</span><span class="kw">exp</span>(z_log_var) <span class="op">*</span><span class="st"> </span>epsilon
}

z &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_concatenate.html">layer_concatenate</a></span>(<span class="kw">list</span>(z_mean, z_log_var)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/layer_lambda.html">layer_lambda</a></span>(sampling)

output_shape &lt;-<span class="st"> </span><span class="kw">c</span>(batch_size, 14L, 14L, filters)

decoder_hidden &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> intermediate_dim, <span class="dt">activation =</span> <span class="st">"relu"</span>)
decoder_upsample &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="kw">prod</span>(output_shape[<span class="op">-</span><span class="dv">1</span>]), <span class="dt">activation =</span> <span class="st">"relu"</span>)

decoder_reshape &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_reshape.html">layer_reshape</a></span>(<span class="dt">target_shape =</span> output_shape[<span class="op">-</span><span class="dv">1</span>])
decoder_deconv_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d_transpose.html">layer_conv_2d_transpose</a></span>(
  <span class="dt">filters =</span> filters,
  <span class="dt">kernel_size =</span> <span class="kw">c</span>(num_conv, num_conv),
  <span class="dt">strides =</span> <span class="kw">c</span>(1L, 1L),
  <span class="dt">padding =</span> <span class="st">"same"</span>,
  <span class="dt">activation =</span> <span class="st">"relu"</span>
)

decoder_deconv_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d_transpose.html">layer_conv_2d_transpose</a></span>(
  <span class="dt">filters =</span> filters,
  <span class="dt">kernel_size =</span> <span class="kw">c</span>(num_conv, num_conv),
  <span class="dt">strides =</span> <span class="kw">c</span>(1L, 1L),
  <span class="dt">padding =</span> <span class="st">"same"</span>,
  <span class="dt">activation =</span> <span class="st">"relu"</span>
)

decoder_deconv_3_upsample &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d_transpose.html">layer_conv_2d_transpose</a></span>(
  <span class="dt">filters =</span> filters,
  <span class="dt">kernel_size =</span> <span class="kw">c</span>(3L, 3L),
  <span class="dt">strides =</span> <span class="kw">c</span>(2L, 2L),
  <span class="dt">padding =</span> <span class="st">"valid"</span>,
  <span class="dt">activation =</span> <span class="st">"relu"</span>
)

decoder_mean_squash &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(
  <span class="dt">filters =</span> img_chns,
  <span class="dt">kernel_size =</span> <span class="kw">c</span>(2L, 2L),
  <span class="dt">strides =</span> <span class="kw">c</span>(1L, 1L),
  <span class="dt">padding =</span> <span class="st">"valid"</span>,
  <span class="dt">activation =</span> <span class="st">"sigmoid"</span>
)

hidden_decoded &lt;-<span class="st"> </span><span class="kw">decoder_hidden</span>(z)
up_decoded &lt;-<span class="st"> </span><span class="kw">decoder_upsample</span>(hidden_decoded)
reshape_decoded &lt;-<span class="st"> </span><span class="kw">decoder_reshape</span>(up_decoded)
deconv_1_decoded &lt;-<span class="st"> </span><span class="kw">decoder_deconv_1</span>(reshape_decoded)
deconv_2_decoded &lt;-<span class="st"> </span><span class="kw">decoder_deconv_2</span>(deconv_1_decoded)
x_decoded_relu &lt;-<span class="st"> </span><span class="kw">decoder_deconv_3_upsample</span>(deconv_2_decoded)
x_decoded_mean_squash &lt;-<span class="st"> </span><span class="kw">decoder_mean_squash</span>(x_decoded_relu)

<span class="co"># custom loss function</span>
vae_loss &lt;-<span class="st"> </span><span class="cf">function</span>(x, x_decoded_mean_squash) {
  x &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">flatten</span>(x)
  x_decoded_mean_squash &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">flatten</span>(x_decoded_mean_squash)
  xent_loss &lt;-<span class="st"> </span><span class="fl">1.0</span> <span class="op">*</span><span class="st"> </span>img_rows <span class="op">*</span><span class="st"> </span>img_cols <span class="op">*</span>
<span class="st">    </span><span class="kw"><a href="../../reference/loss_mean_squared_error.html">loss_binary_crossentropy</a></span>(x, x_decoded_mean_squash)
  kl_loss &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>K<span class="op">$</span><span class="kw">mean</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>z_log_var <span class="op">-</span><span class="st"> </span>K<span class="op">$</span><span class="kw">square</span>(z_mean) <span class="op">-</span>
<span class="st">                           </span>K<span class="op">$</span><span class="kw">exp</span>(z_log_var), <span class="dt">axis =</span> <span class="op">-</span>1L)
  K<span class="op">$</span><span class="kw">mean</span>(xent_loss <span class="op">+</span><span class="st"> </span>kl_loss)
}

## variational autoencoder
vae &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(x, x_decoded_mean_squash)
vae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/compile.html">compile</a></span>(<span class="dt">optimizer =</span> <span class="st">"rmsprop"</span>, <span class="dt">loss =</span> vae_loss)
<span class="kw">summary</span>(vae)

## encoder: model to project inputs on the latent space
encoder &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(x, z_mean)

## build a digit generator that can sample from the learned distribution
gen_decoder_input &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> latent_dim)
gen_hidden_decoded &lt;-<span class="st"> </span><span class="kw">decoder_hidden</span>(gen_decoder_input)
gen_up_decoded &lt;-<span class="st"> </span><span class="kw">decoder_upsample</span>(gen_hidden_decoded)
gen_reshape_decoded &lt;-<span class="st"> </span><span class="kw">decoder_reshape</span>(gen_up_decoded)
gen_deconv_1_decoded &lt;-<span class="st"> </span><span class="kw">decoder_deconv_1</span>(gen_reshape_decoded)
gen_deconv_2_decoded &lt;-<span class="st"> </span><span class="kw">decoder_deconv_2</span>(gen_deconv_1_decoded)
gen_x_decoded_relu &lt;-<span class="st"> </span><span class="kw">decoder_deconv_3_upsample</span>(gen_deconv_2_decoded)
gen_x_decoded_mean_squash &lt;-<span class="st"> </span><span class="kw">decoder_mean_squash</span>(gen_x_decoded_relu)
generator &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(gen_decoder_input, gen_x_decoded_mean_squash)


#### Data Preparation ####

mnist &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/dataset_mnist.html">dataset_mnist</a></span>()
data &lt;-<span class="st"> </span><span class="kw">lapply</span>(mnist, <span class="cf">function</span>(m) {
  <span class="kw">array</span>(m<span class="op">$</span>x <span class="op">/</span><span class="st"> </span><span class="dv">255</span>, <span class="dt">dim =</span> <span class="kw">c</span>(<span class="kw">dim</span>(m<span class="op">$</span>x)[<span class="dv">1</span>], original_img_size))
})
x_train &lt;-<span class="st"> </span>data<span class="op">$</span>train
x_test &lt;-<span class="st"> </span>data<span class="op">$</span>test


#### Model Fitting ####

vae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/fit.html">fit</a></span>(
  x_train, x_train, 
  <span class="dt">shuffle =</span> <span class="ot">TRUE</span>, 
  <span class="dt">epochs =</span> epochs, 
  <span class="dt">batch_size =</span> batch_size, 
  <span class="dt">validation_data =</span> <span class="kw">list</span>(x_test, x_test)
)


#### Visualizations ####

<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)

## display a 2D plot of the digit classes in the latent space
x_test_encoded &lt;-<span class="st"> </span><span class="kw">predict</span>(encoder, x_test, <span class="dt">batch_size =</span> batch_size)
x_test_encoded <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/reexports.html">as_data_frame</a></span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span>(<span class="dt">class =</span> <span class="kw">as.factor</span>(mnist<span class="op">$</span>test<span class="op">$</span>y)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> V1, <span class="dt">y =</span> V2, <span class="dt">colour =</span> class)) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_point">geom_point</a></span>()

## display a 2D manifold of the digits
n &lt;-<span class="st"> </span><span class="dv">15</span>  <span class="co"># figure with 15x15 digits</span>
digit_size &lt;-<span class="st"> </span><span class="dv">28</span>

<span class="co"># we will sample n points within [-4, 4] standard deviations</span>
grid_x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> n)
grid_y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> n)

rows &lt;-<span class="st"> </span><span class="ot">NULL</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(grid_x)){
  column &lt;-<span class="st"> </span><span class="ot">NULL</span>
  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(grid_y)){
    z_sample &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(grid_x[i], grid_y[j]), <span class="dt">ncol =</span> <span class="dv">2</span>)
    column &lt;-<span class="st"> </span><span class="kw">rbind</span>(column, <span class="kw">predict</span>(generator, z_sample) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol =</span> digit_size))
  }
  rows &lt;-<span class="st"> </span><span class="kw">cbind</span>(rows, column)
}
rows <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.raster</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>()</code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by JJ Allaire, François Chollet,  RStudio,  Google.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
