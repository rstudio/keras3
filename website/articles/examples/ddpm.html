<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Generating images of flowers with denoising diffusion probabilistic models.">
<title>Denoising Diffusion Probabilistic Model • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../deps/JetBrains_Mono-0.4.7/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Denoising Diffusion Probabilistic Model">
<meta property="og:description" content="Generating images of flowers with denoising diffusion probabilistic models.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Denoising Diffusion Probabilistic Model</h1>
                        <h4 data-toc-skip class="author"><a href="https://twitter.com/A_K_Nain" class="external-link">A_K_Nain</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/ddpm.Rmd" class="external-link"><code>vignettes/examples/ddpm.Rmd</code></a></small>
      <div class="d-none name"><code>ddpm.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Generative modeling experienced tremendous growth in the last five
years. Models like VAEs, GANs, and flow-based models proved to be a
great success in generating high-quality content, especially images.
Diffusion models are a new type of generative model that has proven to
be better than previous approaches.</p>
<p>Diffusion models are inspired by non-equilibrium thermodynamics, and
they learn to generate by denoising. Learning by denoising consists of
two processes, each of which is a Markov Chain. These are:</p>
<ol style="list-style-type: decimal">
<li><p>The forward process: In the forward process, we slowly add random
noise to the data in a series of time steps
<code>(t1, t2, ..., tn )</code>. Samples at the current time step are
drawn from a Gaussian distribution where the mean of the distribution is
conditioned on the sample at the previous time step, and the variance of
the distribution follows a fixed schedule. At the end of the forward
process, the samples end up with a pure noise distribution.</p></li>
<li><p>The reverse process: During the reverse process, we try to undo
the added noise at every time step. We start with the pure noise
distribution (the last step of the forward process) and try to denoise
the samples in the backward direction
<code>(tn, tn-1, ..., t1)</code>.</p></li>
</ol>
<p>We implement the <a href="https://arxiv.org/abs/2006.11239" class="external-link">Denoising
Diffusion Probabilistic Models</a> paper or DDPMs for short in this code
example. It was the first paper demonstrating the use of diffusion
models for generating high-quality images. The authors proved that a
certain parameterization of diffusion models reveals an equivalence with
denoising score matching over multiple noise levels during training and
with annealed Langevin dynamics during sampling that generates the best
quality results.</p>
<p>This paper replicates both the Markov chains (forward process and
reverse process) involved in the diffusion process but for images. The
forward process is fixed and gradually adds Gaussian noise to the images
according to a fixed variance schedule denoted by beta in the paper.
This is what the diffusion process looks like in case of images: (image
-&gt; noise::noise -&gt; image)</p>
<div class="float">
<img src="https://imgur.com/Yn7tho9.gif" alt="diffusion process gif"><div class="figcaption">diffusion process gif</div>
</div>
<p>The paper describes two algorithms, one for training the model, and
the other for sampling from the trained model. Training is performed by
optimizing the usual variational bound on negative log-likelihood. The
objective function is further simplified, and the network is treated as
a noise prediction network. Once optimized, we can sample from the
network to generate new images from noise samples. Here is an overview
of both algorithms as presented in the paper:</p>
<div class="float">
<img src="https://i.imgur.com/S7KH5hZ.png" alt="ddpms"><div class="figcaption">ddpms</div>
</div>
<p><strong>Note:</strong> DDPM is just one way of implementing a
diffusion model. Also, the sampling algorithm in the DDPM replicates the
complete Markov chain. Hence it’s slow in generating new samples
compared to other generative models like GANs. Lots of research efforts
have been made to address this issue. One such example is Denoising
Diffusion Implicit Models, or DDIM for short, where the authors replaced
the Markov chain with a non-Markovian process to sample faster. You can
find the code example for DDIM <a href="https://keras.io/examples/generative/ddim/" class="external-link">here</a></p>
<p>Implementing a DDPM model is simple. We define a model that takes two
inputs: Images and the randomly sampled time steps. At each training
step, we perform the following operations to train our model:</p>
<ol style="list-style-type: decimal">
<li>Sample random noise to be added to the inputs.</li>
<li>Apply the forward process to diffuse the inputs with the sampled
noise.</li>
<li>Your model takes these noisy samples as inputs and outputs the noise
prediction for each time step.</li>
<li>Given true noise and predicted noise, we calculate the loss
values</li>
<li>We then calculate the gradients and update the model weights.</li>
</ol>
<p>Given that our model knows how to denoise a noisy sample at a given
time step, we can leverage this idea to generate new samples, starting
from a pure noise distribution.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># Requires TensorFlow &gt;=2.11 for the GroupNormalization layer.</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">import</span> tensorflow_datasets <span class="im">as</span> tfds</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="hyperparameters">Hyperparameters<a class="anchor" aria-label="anchor" href="#hyperparameters"></a>
</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Just for the sake of demonstration</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>total_timesteps <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>norm_groups <span class="op">=</span> <span class="dv">8</span>  <span class="co"># Number of groups used in GroupNormalization layer</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">2e-4</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>img_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>img_channels <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>clip_min <span class="op">=</span> <span class="op">-</span><span class="fl">1.0</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>clip_max <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>first_conv_channels <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>channel_multiplier <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>]</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>widths <span class="op">=</span> [first_conv_channels <span class="op">*</span> mult <span class="cf">for</span> mult <span class="kw">in</span> channel_multiplier]</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>has_attention <span class="op">=</span> [<span class="va">False</span>, <span class="va">False</span>, <span class="va">True</span>, <span class="va">True</span>]</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>num_res_blocks <span class="op">=</span> <span class="dv">2</span>  <span class="co"># Number of residual blocks</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>dataset_name <span class="op">=</span> <span class="st">"oxford_flowers102"</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>splits <span class="op">=</span> [<span class="st">"train"</span>]</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="dataset">Dataset<a class="anchor" aria-label="anchor" href="#dataset"></a>
</h2>
<p>We use the <a href="https://www.tensorflow.org/datasets/catalog/oxford_flowers102" class="external-link">Oxford
Flowers 102</a> dataset for generating images of flowers. In terms of
preprocessing, we use center cropping for resizing the images to the
desired image size, and we rescale the pixel values in the range
<code>[-1.0, 1.0]</code>. This is in line with the range of the pixel
values that was applied by the authors of the <a href="https://arxiv.org/abs/2006.11239" class="external-link">DDPMs paper</a>. For augmenting
training data, we randomly flip the images left/right.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>(ds,) <span class="op">=</span> tfds.load(</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    dataset_name, split<span class="op">=</span>splits, with_info<span class="op">=</span><span class="va">False</span>, shuffle_files<span class="op">=</span><span class="va">True</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="kw">def</span> augment(img):</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    <span class="co">"""Flips an image left/right randomly."""</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    <span class="cf">return</span> tf.image.random_flip_left_right(img)</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="kw">def</span> resize_and_rescale(img, size):</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    <span class="co">"""Resize the image to the desired size first and then</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co">    rescale the pixel values in the range [-1.0, 1.0].</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co">        img: Image tensor</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">        size: Desired image size for resizing</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="co">        Resized and rescaled image tensor</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>    height <span class="op">=</span> tf.shape(img)[<span class="dv">0</span>]</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>    width <span class="op">=</span> tf.shape(img)[<span class="dv">1</span>]</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>    crop_size <span class="op">=</span> tf.minimum(height, width)</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>    img <span class="op">=</span> tf.image.crop_to_bounding_box(</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>        img,</span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a>        (height <span class="op">-</span> crop_size) <span class="op">//</span> <span class="dv">2</span>,</span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a>        (width <span class="op">-</span> crop_size) <span class="op">//</span> <span class="dv">2</span>,</span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a>        crop_size,</span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a>        crop_size,</span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a>    )</span>
<span id="cb3-34"><a href="#cb3-34" tabindex="-1"></a></span>
<span id="cb3-35"><a href="#cb3-35" tabindex="-1"></a>    <span class="co"># Resize</span></span>
<span id="cb3-36"><a href="#cb3-36" tabindex="-1"></a>    img <span class="op">=</span> tf.cast(img, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb3-37"><a href="#cb3-37" tabindex="-1"></a>    img <span class="op">=</span> tf.image.resize(img, size<span class="op">=</span>size, antialias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-38"><a href="#cb3-38" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" tabindex="-1"></a>    <span class="co"># Rescale the pixel values</span></span>
<span id="cb3-40"><a href="#cb3-40" tabindex="-1"></a>    img <span class="op">=</span> img <span class="op">/</span> <span class="fl">127.5</span> <span class="op">-</span> <span class="fl">1.0</span></span>
<span id="cb3-41"><a href="#cb3-41" tabindex="-1"></a>    img <span class="op">=</span> tf.clip_by_value(img, clip_min, clip_max)</span>
<span id="cb3-42"><a href="#cb3-42" tabindex="-1"></a>    <span class="cf">return</span> img</span>
<span id="cb3-43"><a href="#cb3-43" tabindex="-1"></a></span>
<span id="cb3-44"><a href="#cb3-44" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" tabindex="-1"></a><span class="kw">def</span> train_preprocessing(x):</span>
<span id="cb3-46"><a href="#cb3-46" tabindex="-1"></a>    img <span class="op">=</span> x[<span class="st">"image"</span>]</span>
<span id="cb3-47"><a href="#cb3-47" tabindex="-1"></a>    img <span class="op">=</span> resize_and_rescale(img, size<span class="op">=</span>(img_size, img_size))</span>
<span id="cb3-48"><a href="#cb3-48" tabindex="-1"></a>    img <span class="op">=</span> augment(img)</span>
<span id="cb3-49"><a href="#cb3-49" tabindex="-1"></a>    <span class="cf">return</span> img</span>
<span id="cb3-50"><a href="#cb3-50" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" tabindex="-1"></a></span>
<span id="cb3-52"><a href="#cb3-52" tabindex="-1"></a>train_ds <span class="op">=</span> (</span>
<span id="cb3-53"><a href="#cb3-53" tabindex="-1"></a>    ds.<span class="bu">map</span>(train_preprocessing, num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE)</span>
<span id="cb3-54"><a href="#cb3-54" tabindex="-1"></a>    .batch(batch_size, drop_remainder<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-55"><a href="#cb3-55" tabindex="-1"></a>    .shuffle(batch_size <span class="op">*</span> <span class="dv">2</span>)</span>
<span id="cb3-56"><a href="#cb3-56" tabindex="-1"></a>    .prefetch(tf.data.AUTOTUNE)</span>
<span id="cb3-57"><a href="#cb3-57" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="gaussian-diffusion-utilities">Gaussian diffusion utilities<a class="anchor" aria-label="anchor" href="#gaussian-diffusion-utilities"></a>
</h2>
<p>We define the forward process and the reverse process as a separate
utility. Most of the code in this utility has been borrowed from the
original implementation with some slight modifications.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="kw">class</span> GaussianDiffusion:</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>    <span class="co">"""Gaussian diffusion utility.</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co">        beta_start: Start value of the scheduled variance</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co">        beta_end: End value of the scheduled variance</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co">        timesteps: Number of time steps in the forward process</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>        beta_start<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>        beta_end<span class="op">=</span><span class="fl">0.02</span>,</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>        timesteps<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>        clip_min<span class="op">=-</span><span class="fl">1.0</span>,</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>        clip_max<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>    ):</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>        <span class="va">self</span>.beta_start <span class="op">=</span> beta_start</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>        <span class="va">self</span>.beta_end <span class="op">=</span> beta_end</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>        <span class="va">self</span>.timesteps <span class="op">=</span> timesteps</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>        <span class="va">self</span>.clip_min <span class="op">=</span> clip_min</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>        <span class="va">self</span>.clip_max <span class="op">=</span> clip_max</span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>        <span class="co"># Define the linear variance schedule</span></span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>        <span class="va">self</span>.betas <span class="op">=</span> betas <span class="op">=</span> np.linspace(</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>            beta_start,</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>            beta_end,</span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>            timesteps,</span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>            dtype<span class="op">=</span>np.float64,  <span class="co"># Using float64 for better precision</span></span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a>        )</span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>        <span class="va">self</span>.num_timesteps <span class="op">=</span> <span class="bu">int</span>(timesteps)</span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a>        alphas <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> betas</span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a>        alphas_cumprod <span class="op">=</span> np.cumprod(alphas, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a>        alphas_cumprod_prev <span class="op">=</span> np.append(<span class="fl">1.0</span>, alphas_cumprod[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a>        <span class="va">self</span>.betas <span class="op">=</span> tf.constant(betas, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a>        <span class="va">self</span>.alphas_cumprod <span class="op">=</span> tf.constant(alphas_cumprod, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb4-39"><a href="#cb4-39" tabindex="-1"></a>        <span class="va">self</span>.alphas_cumprod_prev <span class="op">=</span> tf.constant(</span>
<span id="cb4-40"><a href="#cb4-40" tabindex="-1"></a>            alphas_cumprod_prev, dtype<span class="op">=</span>tf.float32</span>
<span id="cb4-41"><a href="#cb4-41" tabindex="-1"></a>        )</span>
<span id="cb4-42"><a href="#cb4-42" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" tabindex="-1"></a>        <span class="co"># Calculations for diffusion q(x_t | x_{t-1}) and others</span></span>
<span id="cb4-44"><a href="#cb4-44" tabindex="-1"></a>        <span class="va">self</span>.sqrt_alphas_cumprod <span class="op">=</span> tf.constant(</span>
<span id="cb4-45"><a href="#cb4-45" tabindex="-1"></a>            np.sqrt(alphas_cumprod), dtype<span class="op">=</span>tf.float32</span>
<span id="cb4-46"><a href="#cb4-46" tabindex="-1"></a>        )</span>
<span id="cb4-47"><a href="#cb4-47" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" tabindex="-1"></a>        <span class="va">self</span>.sqrt_one_minus_alphas_cumprod <span class="op">=</span> tf.constant(</span>
<span id="cb4-49"><a href="#cb4-49" tabindex="-1"></a>            np.sqrt(<span class="fl">1.0</span> <span class="op">-</span> alphas_cumprod), dtype<span class="op">=</span>tf.float32</span>
<span id="cb4-50"><a href="#cb4-50" tabindex="-1"></a>        )</span>
<span id="cb4-51"><a href="#cb4-51" tabindex="-1"></a></span>
<span id="cb4-52"><a href="#cb4-52" tabindex="-1"></a>        <span class="va">self</span>.log_one_minus_alphas_cumprod <span class="op">=</span> tf.constant(</span>
<span id="cb4-53"><a href="#cb4-53" tabindex="-1"></a>            np.log(<span class="fl">1.0</span> <span class="op">-</span> alphas_cumprod), dtype<span class="op">=</span>tf.float32</span>
<span id="cb4-54"><a href="#cb4-54" tabindex="-1"></a>        )</span>
<span id="cb4-55"><a href="#cb4-55" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" tabindex="-1"></a>        <span class="va">self</span>.sqrt_recip_alphas_cumprod <span class="op">=</span> tf.constant(</span>
<span id="cb4-57"><a href="#cb4-57" tabindex="-1"></a>            np.sqrt(<span class="fl">1.0</span> <span class="op">/</span> alphas_cumprod), dtype<span class="op">=</span>tf.float32</span>
<span id="cb4-58"><a href="#cb4-58" tabindex="-1"></a>        )</span>
<span id="cb4-59"><a href="#cb4-59" tabindex="-1"></a>        <span class="va">self</span>.sqrt_recipm1_alphas_cumprod <span class="op">=</span> tf.constant(</span>
<span id="cb4-60"><a href="#cb4-60" tabindex="-1"></a>            np.sqrt(<span class="fl">1.0</span> <span class="op">/</span> alphas_cumprod <span class="op">-</span> <span class="dv">1</span>), dtype<span class="op">=</span>tf.float32</span>
<span id="cb4-61"><a href="#cb4-61" tabindex="-1"></a>        )</span>
<span id="cb4-62"><a href="#cb4-62" tabindex="-1"></a></span>
<span id="cb4-63"><a href="#cb4-63" tabindex="-1"></a>        <span class="co"># Calculations for posterior q(x_{t-1} | x_t, x_0)</span></span>
<span id="cb4-64"><a href="#cb4-64" tabindex="-1"></a>        posterior_variance <span class="op">=</span> (</span>
<span id="cb4-65"><a href="#cb4-65" tabindex="-1"></a>            betas <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">-</span> alphas_cumprod_prev) <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">-</span> alphas_cumprod)</span>
<span id="cb4-66"><a href="#cb4-66" tabindex="-1"></a>        )</span>
<span id="cb4-67"><a href="#cb4-67" tabindex="-1"></a>        <span class="va">self</span>.posterior_variance <span class="op">=</span> tf.constant(</span>
<span id="cb4-68"><a href="#cb4-68" tabindex="-1"></a>            posterior_variance, dtype<span class="op">=</span>tf.float32</span>
<span id="cb4-69"><a href="#cb4-69" tabindex="-1"></a>        )</span>
<span id="cb4-70"><a href="#cb4-70" tabindex="-1"></a></span>
<span id="cb4-71"><a href="#cb4-71" tabindex="-1"></a>        <span class="co"># Log calculation clipped because the posterior variance is 0 at the beginning</span></span>
<span id="cb4-72"><a href="#cb4-72" tabindex="-1"></a>        <span class="co"># of the diffusion chain</span></span>
<span id="cb4-73"><a href="#cb4-73" tabindex="-1"></a>        <span class="va">self</span>.posterior_log_variance_clipped <span class="op">=</span> tf.constant(</span>
<span id="cb4-74"><a href="#cb4-74" tabindex="-1"></a>            np.log(np.maximum(posterior_variance, <span class="fl">1e-20</span>)), dtype<span class="op">=</span>tf.float32</span>
<span id="cb4-75"><a href="#cb4-75" tabindex="-1"></a>        )</span>
<span id="cb4-76"><a href="#cb4-76" tabindex="-1"></a></span>
<span id="cb4-77"><a href="#cb4-77" tabindex="-1"></a>        <span class="va">self</span>.posterior_mean_coef1 <span class="op">=</span> tf.constant(</span>
<span id="cb4-78"><a href="#cb4-78" tabindex="-1"></a>            betas <span class="op">*</span> np.sqrt(alphas_cumprod_prev) <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">-</span> alphas_cumprod),</span>
<span id="cb4-79"><a href="#cb4-79" tabindex="-1"></a>            dtype<span class="op">=</span>tf.float32,</span>
<span id="cb4-80"><a href="#cb4-80" tabindex="-1"></a>        )</span>
<span id="cb4-81"><a href="#cb4-81" tabindex="-1"></a></span>
<span id="cb4-82"><a href="#cb4-82" tabindex="-1"></a>        <span class="va">self</span>.posterior_mean_coef2 <span class="op">=</span> tf.constant(</span>
<span id="cb4-83"><a href="#cb4-83" tabindex="-1"></a>            (<span class="fl">1.0</span> <span class="op">-</span> alphas_cumprod_prev)</span>
<span id="cb4-84"><a href="#cb4-84" tabindex="-1"></a>            <span class="op">*</span> np.sqrt(alphas)</span>
<span id="cb4-85"><a href="#cb4-85" tabindex="-1"></a>            <span class="op">/</span> (<span class="fl">1.0</span> <span class="op">-</span> alphas_cumprod),</span>
<span id="cb4-86"><a href="#cb4-86" tabindex="-1"></a>            dtype<span class="op">=</span>tf.float32,</span>
<span id="cb4-87"><a href="#cb4-87" tabindex="-1"></a>        )</span>
<span id="cb4-88"><a href="#cb4-88" tabindex="-1"></a></span>
<span id="cb4-89"><a href="#cb4-89" tabindex="-1"></a>    <span class="kw">def</span> _extract(<span class="va">self</span>, a, t, x_shape):</span>
<span id="cb4-90"><a href="#cb4-90" tabindex="-1"></a>        <span class="co">"""Extract some coefficients at specified timesteps,</span></span>
<span id="cb4-91"><a href="#cb4-91" tabindex="-1"></a><span class="co">        then reshape to [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.</span></span>
<span id="cb4-92"><a href="#cb4-92" tabindex="-1"></a></span>
<span id="cb4-93"><a href="#cb4-93" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb4-94"><a href="#cb4-94" tabindex="-1"></a><span class="co">            a: Tensor to extract from</span></span>
<span id="cb4-95"><a href="#cb4-95" tabindex="-1"></a><span class="co">            t: Timestep for which the coefficients are to be extracted</span></span>
<span id="cb4-96"><a href="#cb4-96" tabindex="-1"></a><span class="co">            x_shape: Shape of the current batched samples</span></span>
<span id="cb4-97"><a href="#cb4-97" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-98"><a href="#cb4-98" tabindex="-1"></a>        batch_size <span class="op">=</span> x_shape[<span class="dv">0</span>]</span>
<span id="cb4-99"><a href="#cb4-99" tabindex="-1"></a>        out <span class="op">=</span> tf.gather(a, t)</span>
<span id="cb4-100"><a href="#cb4-100" tabindex="-1"></a>        <span class="cf">return</span> tf.reshape(out, [batch_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb4-101"><a href="#cb4-101" tabindex="-1"></a></span>
<span id="cb4-102"><a href="#cb4-102" tabindex="-1"></a>    <span class="kw">def</span> q_mean_variance(<span class="va">self</span>, x_start, t):</span>
<span id="cb4-103"><a href="#cb4-103" tabindex="-1"></a>        <span class="co">"""Extracts the mean, and the variance at current timestep.</span></span>
<span id="cb4-104"><a href="#cb4-104" tabindex="-1"></a></span>
<span id="cb4-105"><a href="#cb4-105" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb4-106"><a href="#cb4-106" tabindex="-1"></a><span class="co">            x_start: Initial sample (before the first diffusion step)</span></span>
<span id="cb4-107"><a href="#cb4-107" tabindex="-1"></a><span class="co">            t: Current timestep</span></span>
<span id="cb4-108"><a href="#cb4-108" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-109"><a href="#cb4-109" tabindex="-1"></a>        x_start_shape <span class="op">=</span> tf.shape(x_start)</span>
<span id="cb4-110"><a href="#cb4-110" tabindex="-1"></a>        mean <span class="op">=</span> (</span>
<span id="cb4-111"><a href="#cb4-111" tabindex="-1"></a>            <span class="va">self</span>._extract(<span class="va">self</span>.sqrt_alphas_cumprod, t, x_start_shape) <span class="op">*</span> x_start</span>
<span id="cb4-112"><a href="#cb4-112" tabindex="-1"></a>        )</span>
<span id="cb4-113"><a href="#cb4-113" tabindex="-1"></a>        variance <span class="op">=</span> <span class="va">self</span>._extract(<span class="fl">1.0</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod, t, x_start_shape)</span>
<span id="cb4-114"><a href="#cb4-114" tabindex="-1"></a>        log_variance <span class="op">=</span> <span class="va">self</span>._extract(</span>
<span id="cb4-115"><a href="#cb4-115" tabindex="-1"></a>            <span class="va">self</span>.log_one_minus_alphas_cumprod, t, x_start_shape</span>
<span id="cb4-116"><a href="#cb4-116" tabindex="-1"></a>        )</span>
<span id="cb4-117"><a href="#cb4-117" tabindex="-1"></a>        <span class="cf">return</span> mean, variance, log_variance</span>
<span id="cb4-118"><a href="#cb4-118" tabindex="-1"></a></span>
<span id="cb4-119"><a href="#cb4-119" tabindex="-1"></a>    <span class="kw">def</span> q_sample(<span class="va">self</span>, x_start, t, noise):</span>
<span id="cb4-120"><a href="#cb4-120" tabindex="-1"></a>        <span class="co">"""Diffuse the data.</span></span>
<span id="cb4-121"><a href="#cb4-121" tabindex="-1"></a></span>
<span id="cb4-122"><a href="#cb4-122" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb4-123"><a href="#cb4-123" tabindex="-1"></a><span class="co">            x_start: Initial sample (before the first diffusion step)</span></span>
<span id="cb4-124"><a href="#cb4-124" tabindex="-1"></a><span class="co">            t: Current timestep</span></span>
<span id="cb4-125"><a href="#cb4-125" tabindex="-1"></a><span class="co">            noise: Gaussian noise to be added at the current timestep</span></span>
<span id="cb4-126"><a href="#cb4-126" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb4-127"><a href="#cb4-127" tabindex="-1"></a><span class="co">            Diffused samples at timestep `t`</span></span>
<span id="cb4-128"><a href="#cb4-128" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-129"><a href="#cb4-129" tabindex="-1"></a>        x_start_shape <span class="op">=</span> tf.shape(x_start)</span>
<span id="cb4-130"><a href="#cb4-130" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb4-131"><a href="#cb4-131" tabindex="-1"></a>            <span class="va">self</span>._extract(<span class="va">self</span>.sqrt_alphas_cumprod, t, tf.shape(x_start))</span>
<span id="cb4-132"><a href="#cb4-132" tabindex="-1"></a>            <span class="op">*</span> x_start</span>
<span id="cb4-133"><a href="#cb4-133" tabindex="-1"></a>            <span class="op">+</span> <span class="va">self</span>._extract(</span>
<span id="cb4-134"><a href="#cb4-134" tabindex="-1"></a>                <span class="va">self</span>.sqrt_one_minus_alphas_cumprod, t, x_start_shape</span>
<span id="cb4-135"><a href="#cb4-135" tabindex="-1"></a>            )</span>
<span id="cb4-136"><a href="#cb4-136" tabindex="-1"></a>            <span class="op">*</span> noise</span>
<span id="cb4-137"><a href="#cb4-137" tabindex="-1"></a>        )</span>
<span id="cb4-138"><a href="#cb4-138" tabindex="-1"></a></span>
<span id="cb4-139"><a href="#cb4-139" tabindex="-1"></a>    <span class="kw">def</span> predict_start_from_noise(<span class="va">self</span>, x_t, t, noise):</span>
<span id="cb4-140"><a href="#cb4-140" tabindex="-1"></a>        x_t_shape <span class="op">=</span> tf.shape(x_t)</span>
<span id="cb4-141"><a href="#cb4-141" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb4-142"><a href="#cb4-142" tabindex="-1"></a>            <span class="va">self</span>._extract(<span class="va">self</span>.sqrt_recip_alphas_cumprod, t, x_t_shape) <span class="op">*</span> x_t</span>
<span id="cb4-143"><a href="#cb4-143" tabindex="-1"></a>            <span class="op">-</span> <span class="va">self</span>._extract(<span class="va">self</span>.sqrt_recipm1_alphas_cumprod, t, x_t_shape)</span>
<span id="cb4-144"><a href="#cb4-144" tabindex="-1"></a>            <span class="op">*</span> noise</span>
<span id="cb4-145"><a href="#cb4-145" tabindex="-1"></a>        )</span>
<span id="cb4-146"><a href="#cb4-146" tabindex="-1"></a></span>
<span id="cb4-147"><a href="#cb4-147" tabindex="-1"></a>    <span class="kw">def</span> q_posterior(<span class="va">self</span>, x_start, x_t, t):</span>
<span id="cb4-148"><a href="#cb4-148" tabindex="-1"></a>        <span class="co">"""Compute the mean and variance of the diffusion</span></span>
<span id="cb4-149"><a href="#cb4-149" tabindex="-1"></a><span class="co">        posterior q(x_{t-1} | x_t, x_0).</span></span>
<span id="cb4-150"><a href="#cb4-150" tabindex="-1"></a></span>
<span id="cb4-151"><a href="#cb4-151" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb4-152"><a href="#cb4-152" tabindex="-1"></a><span class="co">            x_start: Stating point(sample) for the posterior computation</span></span>
<span id="cb4-153"><a href="#cb4-153" tabindex="-1"></a><span class="co">            x_t: Sample at timestep `t`</span></span>
<span id="cb4-154"><a href="#cb4-154" tabindex="-1"></a><span class="co">            t: Current timestep</span></span>
<span id="cb4-155"><a href="#cb4-155" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb4-156"><a href="#cb4-156" tabindex="-1"></a><span class="co">            Posterior mean and variance at current timestep</span></span>
<span id="cb4-157"><a href="#cb4-157" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-158"><a href="#cb4-158" tabindex="-1"></a></span>
<span id="cb4-159"><a href="#cb4-159" tabindex="-1"></a>        x_t_shape <span class="op">=</span> tf.shape(x_t)</span>
<span id="cb4-160"><a href="#cb4-160" tabindex="-1"></a>        posterior_mean <span class="op">=</span> (</span>
<span id="cb4-161"><a href="#cb4-161" tabindex="-1"></a>            <span class="va">self</span>._extract(<span class="va">self</span>.posterior_mean_coef1, t, x_t_shape) <span class="op">*</span> x_start</span>
<span id="cb4-162"><a href="#cb4-162" tabindex="-1"></a>            <span class="op">+</span> <span class="va">self</span>._extract(<span class="va">self</span>.posterior_mean_coef2, t, x_t_shape) <span class="op">*</span> x_t</span>
<span id="cb4-163"><a href="#cb4-163" tabindex="-1"></a>        )</span>
<span id="cb4-164"><a href="#cb4-164" tabindex="-1"></a>        posterior_variance <span class="op">=</span> <span class="va">self</span>._extract(</span>
<span id="cb4-165"><a href="#cb4-165" tabindex="-1"></a>            <span class="va">self</span>.posterior_variance, t, x_t_shape</span>
<span id="cb4-166"><a href="#cb4-166" tabindex="-1"></a>        )</span>
<span id="cb4-167"><a href="#cb4-167" tabindex="-1"></a>        posterior_log_variance_clipped <span class="op">=</span> <span class="va">self</span>._extract(</span>
<span id="cb4-168"><a href="#cb4-168" tabindex="-1"></a>            <span class="va">self</span>.posterior_log_variance_clipped, t, x_t_shape</span>
<span id="cb4-169"><a href="#cb4-169" tabindex="-1"></a>        )</span>
<span id="cb4-170"><a href="#cb4-170" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb4-171"><a href="#cb4-171" tabindex="-1"></a>            posterior_mean,</span>
<span id="cb4-172"><a href="#cb4-172" tabindex="-1"></a>            posterior_variance,</span>
<span id="cb4-173"><a href="#cb4-173" tabindex="-1"></a>            posterior_log_variance_clipped,</span>
<span id="cb4-174"><a href="#cb4-174" tabindex="-1"></a>        )</span>
<span id="cb4-175"><a href="#cb4-175" tabindex="-1"></a></span>
<span id="cb4-176"><a href="#cb4-176" tabindex="-1"></a>    <span class="kw">def</span> p_mean_variance(<span class="va">self</span>, pred_noise, x, t, clip_denoised<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb4-177"><a href="#cb4-177" tabindex="-1"></a>        x_recon <span class="op">=</span> <span class="va">self</span>.predict_start_from_noise(x, t<span class="op">=</span>t, noise<span class="op">=</span>pred_noise)</span>
<span id="cb4-178"><a href="#cb4-178" tabindex="-1"></a>        <span class="cf">if</span> clip_denoised:</span>
<span id="cb4-179"><a href="#cb4-179" tabindex="-1"></a>            x_recon <span class="op">=</span> tf.clip_by_value(x_recon, <span class="va">self</span>.clip_min, <span class="va">self</span>.clip_max)</span>
<span id="cb4-180"><a href="#cb4-180" tabindex="-1"></a></span>
<span id="cb4-181"><a href="#cb4-181" tabindex="-1"></a>        (</span>
<span id="cb4-182"><a href="#cb4-182" tabindex="-1"></a>            model_mean,</span>
<span id="cb4-183"><a href="#cb4-183" tabindex="-1"></a>            posterior_variance,</span>
<span id="cb4-184"><a href="#cb4-184" tabindex="-1"></a>            posterior_log_variance,</span>
<span id="cb4-185"><a href="#cb4-185" tabindex="-1"></a>        ) <span class="op">=</span> <span class="va">self</span>.q_posterior(x_start<span class="op">=</span>x_recon, x_t<span class="op">=</span>x, t<span class="op">=</span>t)</span>
<span id="cb4-186"><a href="#cb4-186" tabindex="-1"></a>        <span class="cf">return</span> model_mean, posterior_variance, posterior_log_variance</span>
<span id="cb4-187"><a href="#cb4-187" tabindex="-1"></a></span>
<span id="cb4-188"><a href="#cb4-188" tabindex="-1"></a>    <span class="kw">def</span> p_sample(<span class="va">self</span>, pred_noise, x, t, clip_denoised<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb4-189"><a href="#cb4-189" tabindex="-1"></a>        <span class="co">"""Sample from the diffuison model.</span></span>
<span id="cb4-190"><a href="#cb4-190" tabindex="-1"></a></span>
<span id="cb4-191"><a href="#cb4-191" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb4-192"><a href="#cb4-192" tabindex="-1"></a><span class="co">            pred_noise: Noise predicted by the diffusion model</span></span>
<span id="cb4-193"><a href="#cb4-193" tabindex="-1"></a><span class="co">            x: Samples at a given timestep for which the noise was predicted</span></span>
<span id="cb4-194"><a href="#cb4-194" tabindex="-1"></a><span class="co">            t: Current timestep</span></span>
<span id="cb4-195"><a href="#cb4-195" tabindex="-1"></a><span class="co">            clip_denoised (bool): Whether to clip the predicted noise</span></span>
<span id="cb4-196"><a href="#cb4-196" tabindex="-1"></a><span class="co">                within the specified range or not.</span></span>
<span id="cb4-197"><a href="#cb4-197" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-198"><a href="#cb4-198" tabindex="-1"></a>        model_mean, _, model_log_variance <span class="op">=</span> <span class="va">self</span>.p_mean_variance(</span>
<span id="cb4-199"><a href="#cb4-199" tabindex="-1"></a>            pred_noise, x<span class="op">=</span>x, t<span class="op">=</span>t, clip_denoised<span class="op">=</span>clip_denoised</span>
<span id="cb4-200"><a href="#cb4-200" tabindex="-1"></a>        )</span>
<span id="cb4-201"><a href="#cb4-201" tabindex="-1"></a>        noise <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>x.shape, dtype<span class="op">=</span>x.dtype)</span>
<span id="cb4-202"><a href="#cb4-202" tabindex="-1"></a>        <span class="co"># No noise when t == 0</span></span>
<span id="cb4-203"><a href="#cb4-203" tabindex="-1"></a>        nonzero_mask <span class="op">=</span> tf.reshape(</span>
<span id="cb4-204"><a href="#cb4-204" tabindex="-1"></a>            <span class="dv">1</span> <span class="op">-</span> tf.cast(tf.equal(t, <span class="dv">0</span>), tf.float32), [tf.shape(x)[<span class="dv">0</span>], <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb4-205"><a href="#cb4-205" tabindex="-1"></a>        )</span>
<span id="cb4-206"><a href="#cb4-206" tabindex="-1"></a>        <span class="cf">return</span> (</span>
<span id="cb4-207"><a href="#cb4-207" tabindex="-1"></a>            model_mean <span class="op">+</span> nonzero_mask <span class="op">*</span> tf.exp(<span class="fl">0.5</span> <span class="op">*</span> model_log_variance) <span class="op">*</span> noise</span>
<span id="cb4-208"><a href="#cb4-208" tabindex="-1"></a>        )</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="network-architecture">Network architecture<a class="anchor" aria-label="anchor" href="#network-architecture"></a>
</h2>
<p>U-Net, originally developed for semantic segmentation, is an
architecture that is widely used for implementing diffusion models but
with some slight modifications:</p>
<ol style="list-style-type: decimal">
<li>The network accepts two inputs: Image and time step</li>
<li>Self-attention between the convolution blocks once we reach a
specific resolution (16x16 in the paper)</li>
<li>Group Normalization instead of weight normalization</li>
</ol>
<p>We implement most of the things as used in the original paper. We use
the <code>swish</code> activation function throughout the network. We
use the variance scaling kernel initializer.</p>
<p>The only difference here is the number of groups used for the
<code>GroupNormalization</code> layer. For the flowers dataset, we found
that a value of <code>groups=8</code> produces better results compared
to the default value of <code>groups=32</code>. Dropout is optional and
should be used where chances of over fitting is high. In the paper, the
authors used dropout only when training on CIFAR10.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Kernel initializer to use</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="kw">def</span> kernel_init(scale):</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    scale <span class="op">=</span> <span class="bu">max</span>(scale, <span class="fl">1e-10</span>)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    <span class="cf">return</span> keras.initializers.VarianceScaling(</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>        scale, mode<span class="op">=</span><span class="st">"fan_avg"</span>, distribution<span class="op">=</span><span class="st">"uniform"</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    )</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="kw">class</span> AttentionBlock(layers.Layer):</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>    <span class="co">"""Applies self-attention.</span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a><span class="co">        units: Number of units in the dense layers</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="co">        groups: Number of groups to be used for GroupNormalization layer</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, units, groups<span class="op">=</span><span class="dv">8</span>, <span class="op">**</span>kwargs):</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>        <span class="va">self</span>.units <span class="op">=</span> units</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>        <span class="va">self</span>.groups <span class="op">=</span> groups</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>        <span class="va">self</span>.norm <span class="op">=</span> layers.GroupNormalization(groups<span class="op">=</span>groups)</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a>        <span class="va">self</span>.query <span class="op">=</span> layers.Dense(units, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>))</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>        <span class="va">self</span>.key <span class="op">=</span> layers.Dense(units, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>))</span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a>        <span class="va">self</span>.value <span class="op">=</span> layers.Dense(units, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>))</span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a>        <span class="va">self</span>.proj <span class="op">=</span> layers.Dense(units, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">0.0</span>))</span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a>        batch_size <span class="op">=</span> tf.shape(inputs)[<span class="dv">0</span>]</span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a>        height <span class="op">=</span> tf.shape(inputs)[<span class="dv">1</span>]</span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a>        width <span class="op">=</span> tf.shape(inputs)[<span class="dv">2</span>]</span>
<span id="cb5-32"><a href="#cb5-32" tabindex="-1"></a>        scale <span class="op">=</span> tf.cast(<span class="va">self</span>.units, tf.float32) <span class="op">**</span> (<span class="op">-</span><span class="fl">0.5</span>)</span>
<span id="cb5-33"><a href="#cb5-33" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" tabindex="-1"></a>        inputs <span class="op">=</span> <span class="va">self</span>.norm(inputs)</span>
<span id="cb5-35"><a href="#cb5-35" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.query(inputs)</span>
<span id="cb5-36"><a href="#cb5-36" tabindex="-1"></a>        k <span class="op">=</span> <span class="va">self</span>.key(inputs)</span>
<span id="cb5-37"><a href="#cb5-37" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.value(inputs)</span>
<span id="cb5-38"><a href="#cb5-38" tabindex="-1"></a></span>
<span id="cb5-39"><a href="#cb5-39" tabindex="-1"></a>        attn_score <span class="op">=</span> tf.einsum(<span class="st">"bhwc, bHWc-&gt;bhwHW"</span>, q, k) <span class="op">*</span> scale</span>
<span id="cb5-40"><a href="#cb5-40" tabindex="-1"></a>        attn_score <span class="op">=</span> tf.reshape(</span>
<span id="cb5-41"><a href="#cb5-41" tabindex="-1"></a>            attn_score, [batch_size, height, width, height <span class="op">*</span> width]</span>
<span id="cb5-42"><a href="#cb5-42" tabindex="-1"></a>        )</span>
<span id="cb5-43"><a href="#cb5-43" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" tabindex="-1"></a>        attn_score <span class="op">=</span> tf.nn.softmax(attn_score, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-45"><a href="#cb5-45" tabindex="-1"></a>        attn_score <span class="op">=</span> tf.reshape(</span>
<span id="cb5-46"><a href="#cb5-46" tabindex="-1"></a>            attn_score, [batch_size, height, width, height, width]</span>
<span id="cb5-47"><a href="#cb5-47" tabindex="-1"></a>        )</span>
<span id="cb5-48"><a href="#cb5-48" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" tabindex="-1"></a>        proj <span class="op">=</span> tf.einsum(<span class="st">"bhwHW,bHWc-&gt;bhwc"</span>, attn_score, v)</span>
<span id="cb5-50"><a href="#cb5-50" tabindex="-1"></a>        proj <span class="op">=</span> <span class="va">self</span>.proj(proj)</span>
<span id="cb5-51"><a href="#cb5-51" tabindex="-1"></a>        <span class="cf">return</span> inputs <span class="op">+</span> proj</span>
<span id="cb5-52"><a href="#cb5-52" tabindex="-1"></a></span>
<span id="cb5-53"><a href="#cb5-53" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" tabindex="-1"></a><span class="kw">class</span> TimeEmbedding(layers.Layer):</span>
<span id="cb5-55"><a href="#cb5-55" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim, <span class="op">**</span>kwargs):</span>
<span id="cb5-56"><a href="#cb5-56" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb5-57"><a href="#cb5-57" tabindex="-1"></a>        <span class="va">self</span>.dim <span class="op">=</span> dim</span>
<span id="cb5-58"><a href="#cb5-58" tabindex="-1"></a>        <span class="va">self</span>.half_dim <span class="op">=</span> dim <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb5-59"><a href="#cb5-59" tabindex="-1"></a>        <span class="va">self</span>.emb <span class="op">=</span> math.log(<span class="dv">10000</span>) <span class="op">/</span> (<span class="va">self</span>.half_dim <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb5-60"><a href="#cb5-60" tabindex="-1"></a>        <span class="va">self</span>.emb <span class="op">=</span> tf.exp(tf.<span class="bu">range</span>(<span class="va">self</span>.half_dim, dtype<span class="op">=</span>tf.float32) <span class="op">*</span> <span class="op">-</span><span class="va">self</span>.emb)</span>
<span id="cb5-61"><a href="#cb5-61" tabindex="-1"></a></span>
<span id="cb5-62"><a href="#cb5-62" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb5-63"><a href="#cb5-63" tabindex="-1"></a>        inputs <span class="op">=</span> tf.cast(inputs, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb5-64"><a href="#cb5-64" tabindex="-1"></a>        emb <span class="op">=</span> inputs[:, <span class="va">None</span>] <span class="op">*</span> <span class="va">self</span>.emb[<span class="va">None</span>, :]</span>
<span id="cb5-65"><a href="#cb5-65" tabindex="-1"></a>        emb <span class="op">=</span> tf.concat([tf.sin(emb), tf.cos(emb)], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-66"><a href="#cb5-66" tabindex="-1"></a>        <span class="cf">return</span> emb</span>
<span id="cb5-67"><a href="#cb5-67" tabindex="-1"></a></span>
<span id="cb5-68"><a href="#cb5-68" tabindex="-1"></a></span>
<span id="cb5-69"><a href="#cb5-69" tabindex="-1"></a><span class="kw">def</span> ResidualBlock(width, groups<span class="op">=</span><span class="dv">8</span>, activation_fn<span class="op">=</span>keras.activations.swish):</span>
<span id="cb5-70"><a href="#cb5-70" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">apply</span>(inputs):</span>
<span id="cb5-71"><a href="#cb5-71" tabindex="-1"></a>        x, t <span class="op">=</span> inputs</span>
<span id="cb5-72"><a href="#cb5-72" tabindex="-1"></a>        input_width <span class="op">=</span> x.shape[<span class="dv">3</span>]</span>
<span id="cb5-73"><a href="#cb5-73" tabindex="-1"></a></span>
<span id="cb5-74"><a href="#cb5-74" tabindex="-1"></a>        <span class="cf">if</span> input_width <span class="op">==</span> width:</span>
<span id="cb5-75"><a href="#cb5-75" tabindex="-1"></a>            residual <span class="op">=</span> x</span>
<span id="cb5-76"><a href="#cb5-76" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb5-77"><a href="#cb5-77" tabindex="-1"></a>            residual <span class="op">=</span> layers.Conv2D(</span>
<span id="cb5-78"><a href="#cb5-78" tabindex="-1"></a>                width, kernel_size<span class="op">=</span><span class="dv">1</span>, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>)</span>
<span id="cb5-79"><a href="#cb5-79" tabindex="-1"></a>            )(x)</span>
<span id="cb5-80"><a href="#cb5-80" tabindex="-1"></a></span>
<span id="cb5-81"><a href="#cb5-81" tabindex="-1"></a>        temb <span class="op">=</span> activation_fn(t)</span>
<span id="cb5-82"><a href="#cb5-82" tabindex="-1"></a>        temb <span class="op">=</span> layers.Dense(width, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>))(temb)[</span>
<span id="cb5-83"><a href="#cb5-83" tabindex="-1"></a>            :, <span class="va">None</span>, <span class="va">None</span>, :</span>
<span id="cb5-84"><a href="#cb5-84" tabindex="-1"></a>        ]</span>
<span id="cb5-85"><a href="#cb5-85" tabindex="-1"></a></span>
<span id="cb5-86"><a href="#cb5-86" tabindex="-1"></a>        x <span class="op">=</span> layers.GroupNormalization(groups<span class="op">=</span>groups)(x)</span>
<span id="cb5-87"><a href="#cb5-87" tabindex="-1"></a>        x <span class="op">=</span> activation_fn(x)</span>
<span id="cb5-88"><a href="#cb5-88" tabindex="-1"></a>        x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb5-89"><a href="#cb5-89" tabindex="-1"></a>            width,</span>
<span id="cb5-90"><a href="#cb5-90" tabindex="-1"></a>            kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb5-91"><a href="#cb5-91" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb5-92"><a href="#cb5-92" tabindex="-1"></a>            kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>),</span>
<span id="cb5-93"><a href="#cb5-93" tabindex="-1"></a>        )(x)</span>
<span id="cb5-94"><a href="#cb5-94" tabindex="-1"></a></span>
<span id="cb5-95"><a href="#cb5-95" tabindex="-1"></a>        x <span class="op">=</span> layers.Add()([x, temb])</span>
<span id="cb5-96"><a href="#cb5-96" tabindex="-1"></a>        x <span class="op">=</span> layers.GroupNormalization(groups<span class="op">=</span>groups)(x)</span>
<span id="cb5-97"><a href="#cb5-97" tabindex="-1"></a>        x <span class="op">=</span> activation_fn(x)</span>
<span id="cb5-98"><a href="#cb5-98" tabindex="-1"></a></span>
<span id="cb5-99"><a href="#cb5-99" tabindex="-1"></a>        x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb5-100"><a href="#cb5-100" tabindex="-1"></a>            width,</span>
<span id="cb5-101"><a href="#cb5-101" tabindex="-1"></a>            kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb5-102"><a href="#cb5-102" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb5-103"><a href="#cb5-103" tabindex="-1"></a>            kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">0.0</span>),</span>
<span id="cb5-104"><a href="#cb5-104" tabindex="-1"></a>        )(x)</span>
<span id="cb5-105"><a href="#cb5-105" tabindex="-1"></a>        x <span class="op">=</span> layers.Add()([x, residual])</span>
<span id="cb5-106"><a href="#cb5-106" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb5-107"><a href="#cb5-107" tabindex="-1"></a></span>
<span id="cb5-108"><a href="#cb5-108" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">apply</span></span>
<span id="cb5-109"><a href="#cb5-109" tabindex="-1"></a></span>
<span id="cb5-110"><a href="#cb5-110" tabindex="-1"></a></span>
<span id="cb5-111"><a href="#cb5-111" tabindex="-1"></a><span class="kw">def</span> DownSample(width):</span>
<span id="cb5-112"><a href="#cb5-112" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">apply</span>(x):</span>
<span id="cb5-113"><a href="#cb5-113" tabindex="-1"></a>        x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb5-114"><a href="#cb5-114" tabindex="-1"></a>            width,</span>
<span id="cb5-115"><a href="#cb5-115" tabindex="-1"></a>            kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb5-116"><a href="#cb5-116" tabindex="-1"></a>            strides<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb5-117"><a href="#cb5-117" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb5-118"><a href="#cb5-118" tabindex="-1"></a>            kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>),</span>
<span id="cb5-119"><a href="#cb5-119" tabindex="-1"></a>        )(x)</span>
<span id="cb5-120"><a href="#cb5-120" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb5-121"><a href="#cb5-121" tabindex="-1"></a></span>
<span id="cb5-122"><a href="#cb5-122" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">apply</span></span>
<span id="cb5-123"><a href="#cb5-123" tabindex="-1"></a></span>
<span id="cb5-124"><a href="#cb5-124" tabindex="-1"></a></span>
<span id="cb5-125"><a href="#cb5-125" tabindex="-1"></a><span class="kw">def</span> UpSample(width, interpolation<span class="op">=</span><span class="st">"nearest"</span>):</span>
<span id="cb5-126"><a href="#cb5-126" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">apply</span>(x):</span>
<span id="cb5-127"><a href="#cb5-127" tabindex="-1"></a>        x <span class="op">=</span> layers.UpSampling2D(size<span class="op">=</span><span class="dv">2</span>, interpolation<span class="op">=</span>interpolation)(x)</span>
<span id="cb5-128"><a href="#cb5-128" tabindex="-1"></a>        x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb5-129"><a href="#cb5-129" tabindex="-1"></a>            width,</span>
<span id="cb5-130"><a href="#cb5-130" tabindex="-1"></a>            kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb5-131"><a href="#cb5-131" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb5-132"><a href="#cb5-132" tabindex="-1"></a>            kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>),</span>
<span id="cb5-133"><a href="#cb5-133" tabindex="-1"></a>        )(x)</span>
<span id="cb5-134"><a href="#cb5-134" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb5-135"><a href="#cb5-135" tabindex="-1"></a></span>
<span id="cb5-136"><a href="#cb5-136" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">apply</span></span>
<span id="cb5-137"><a href="#cb5-137" tabindex="-1"></a></span>
<span id="cb5-138"><a href="#cb5-138" tabindex="-1"></a></span>
<span id="cb5-139"><a href="#cb5-139" tabindex="-1"></a><span class="kw">def</span> TimeMLP(units, activation_fn<span class="op">=</span>keras.activations.swish):</span>
<span id="cb5-140"><a href="#cb5-140" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">apply</span>(inputs):</span>
<span id="cb5-141"><a href="#cb5-141" tabindex="-1"></a>        temb <span class="op">=</span> layers.Dense(</span>
<span id="cb5-142"><a href="#cb5-142" tabindex="-1"></a>            units, activation<span class="op">=</span>activation_fn, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>)</span>
<span id="cb5-143"><a href="#cb5-143" tabindex="-1"></a>        )(inputs)</span>
<span id="cb5-144"><a href="#cb5-144" tabindex="-1"></a>        temb <span class="op">=</span> layers.Dense(units, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>))(temb)</span>
<span id="cb5-145"><a href="#cb5-145" tabindex="-1"></a>        <span class="cf">return</span> temb</span>
<span id="cb5-146"><a href="#cb5-146" tabindex="-1"></a></span>
<span id="cb5-147"><a href="#cb5-147" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">apply</span></span>
<span id="cb5-148"><a href="#cb5-148" tabindex="-1"></a></span>
<span id="cb5-149"><a href="#cb5-149" tabindex="-1"></a></span>
<span id="cb5-150"><a href="#cb5-150" tabindex="-1"></a><span class="kw">def</span> build_model(</span>
<span id="cb5-151"><a href="#cb5-151" tabindex="-1"></a>    img_size,</span>
<span id="cb5-152"><a href="#cb5-152" tabindex="-1"></a>    img_channels,</span>
<span id="cb5-153"><a href="#cb5-153" tabindex="-1"></a>    widths,</span>
<span id="cb5-154"><a href="#cb5-154" tabindex="-1"></a>    has_attention,</span>
<span id="cb5-155"><a href="#cb5-155" tabindex="-1"></a>    num_res_blocks<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb5-156"><a href="#cb5-156" tabindex="-1"></a>    norm_groups<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb5-157"><a href="#cb5-157" tabindex="-1"></a>    interpolation<span class="op">=</span><span class="st">"nearest"</span>,</span>
<span id="cb5-158"><a href="#cb5-158" tabindex="-1"></a>    activation_fn<span class="op">=</span>keras.activations.swish,</span>
<span id="cb5-159"><a href="#cb5-159" tabindex="-1"></a>):</span>
<span id="cb5-160"><a href="#cb5-160" tabindex="-1"></a>    image_input <span class="op">=</span> layers.Input(</span>
<span id="cb5-161"><a href="#cb5-161" tabindex="-1"></a>        shape<span class="op">=</span>(img_size, img_size, img_channels), name<span class="op">=</span><span class="st">"image_input"</span></span>
<span id="cb5-162"><a href="#cb5-162" tabindex="-1"></a>    )</span>
<span id="cb5-163"><a href="#cb5-163" tabindex="-1"></a>    time_input <span class="op">=</span> keras.Input(shape<span class="op">=</span>(), dtype<span class="op">=</span>tf.int64, name<span class="op">=</span><span class="st">"time_input"</span>)</span>
<span id="cb5-164"><a href="#cb5-164" tabindex="-1"></a></span>
<span id="cb5-165"><a href="#cb5-165" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb5-166"><a href="#cb5-166" tabindex="-1"></a>        first_conv_channels,</span>
<span id="cb5-167"><a href="#cb5-167" tabindex="-1"></a>        kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb5-168"><a href="#cb5-168" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb5-169"><a href="#cb5-169" tabindex="-1"></a>        kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">1.0</span>),</span>
<span id="cb5-170"><a href="#cb5-170" tabindex="-1"></a>    )(image_input)</span>
<span id="cb5-171"><a href="#cb5-171" tabindex="-1"></a></span>
<span id="cb5-172"><a href="#cb5-172" tabindex="-1"></a>    temb <span class="op">=</span> TimeEmbedding(dim<span class="op">=</span>first_conv_channels <span class="op">*</span> <span class="dv">4</span>)(time_input)</span>
<span id="cb5-173"><a href="#cb5-173" tabindex="-1"></a>    temb <span class="op">=</span> TimeMLP(units<span class="op">=</span>first_conv_channels <span class="op">*</span> <span class="dv">4</span>, activation_fn<span class="op">=</span>activation_fn)(</span>
<span id="cb5-174"><a href="#cb5-174" tabindex="-1"></a>        temb</span>
<span id="cb5-175"><a href="#cb5-175" tabindex="-1"></a>    )</span>
<span id="cb5-176"><a href="#cb5-176" tabindex="-1"></a></span>
<span id="cb5-177"><a href="#cb5-177" tabindex="-1"></a>    skips <span class="op">=</span> [x]</span>
<span id="cb5-178"><a href="#cb5-178" tabindex="-1"></a></span>
<span id="cb5-179"><a href="#cb5-179" tabindex="-1"></a>    <span class="co"># DownBlock</span></span>
<span id="cb5-180"><a href="#cb5-180" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(widths)):</span>
<span id="cb5-181"><a href="#cb5-181" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_res_blocks):</span>
<span id="cb5-182"><a href="#cb5-182" tabindex="-1"></a>            x <span class="op">=</span> ResidualBlock(</span>
<span id="cb5-183"><a href="#cb5-183" tabindex="-1"></a>                widths[i], groups<span class="op">=</span>norm_groups, activation_fn<span class="op">=</span>activation_fn</span>
<span id="cb5-184"><a href="#cb5-184" tabindex="-1"></a>            )([x, temb])</span>
<span id="cb5-185"><a href="#cb5-185" tabindex="-1"></a>            <span class="cf">if</span> has_attention[i]:</span>
<span id="cb5-186"><a href="#cb5-186" tabindex="-1"></a>                x <span class="op">=</span> AttentionBlock(widths[i], groups<span class="op">=</span>norm_groups)(x)</span>
<span id="cb5-187"><a href="#cb5-187" tabindex="-1"></a>            skips.append(x)</span>
<span id="cb5-188"><a href="#cb5-188" tabindex="-1"></a></span>
<span id="cb5-189"><a href="#cb5-189" tabindex="-1"></a>        <span class="cf">if</span> widths[i] <span class="op">!=</span> widths[<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb5-190"><a href="#cb5-190" tabindex="-1"></a>            x <span class="op">=</span> DownSample(widths[i])(x)</span>
<span id="cb5-191"><a href="#cb5-191" tabindex="-1"></a>            skips.append(x)</span>
<span id="cb5-192"><a href="#cb5-192" tabindex="-1"></a></span>
<span id="cb5-193"><a href="#cb5-193" tabindex="-1"></a>    <span class="co"># MiddleBlock</span></span>
<span id="cb5-194"><a href="#cb5-194" tabindex="-1"></a>    x <span class="op">=</span> ResidualBlock(</span>
<span id="cb5-195"><a href="#cb5-195" tabindex="-1"></a>        widths[<span class="op">-</span><span class="dv">1</span>], groups<span class="op">=</span>norm_groups, activation_fn<span class="op">=</span>activation_fn</span>
<span id="cb5-196"><a href="#cb5-196" tabindex="-1"></a>    )([x, temb])</span>
<span id="cb5-197"><a href="#cb5-197" tabindex="-1"></a>    x <span class="op">=</span> AttentionBlock(widths[<span class="op">-</span><span class="dv">1</span>], groups<span class="op">=</span>norm_groups)(x)</span>
<span id="cb5-198"><a href="#cb5-198" tabindex="-1"></a>    x <span class="op">=</span> ResidualBlock(</span>
<span id="cb5-199"><a href="#cb5-199" tabindex="-1"></a>        widths[<span class="op">-</span><span class="dv">1</span>], groups<span class="op">=</span>norm_groups, activation_fn<span class="op">=</span>activation_fn</span>
<span id="cb5-200"><a href="#cb5-200" tabindex="-1"></a>    )([x, temb])</span>
<span id="cb5-201"><a href="#cb5-201" tabindex="-1"></a></span>
<span id="cb5-202"><a href="#cb5-202" tabindex="-1"></a>    <span class="co"># UpBlock</span></span>
<span id="cb5-203"><a href="#cb5-203" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="bu">len</span>(widths))):</span>
<span id="cb5-204"><a href="#cb5-204" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_res_blocks <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb5-205"><a href="#cb5-205" tabindex="-1"></a>            x <span class="op">=</span> layers.Concatenate(axis<span class="op">=-</span><span class="dv">1</span>)([x, skips.pop()])</span>
<span id="cb5-206"><a href="#cb5-206" tabindex="-1"></a>            x <span class="op">=</span> ResidualBlock(</span>
<span id="cb5-207"><a href="#cb5-207" tabindex="-1"></a>                widths[i], groups<span class="op">=</span>norm_groups, activation_fn<span class="op">=</span>activation_fn</span>
<span id="cb5-208"><a href="#cb5-208" tabindex="-1"></a>            )([x, temb])</span>
<span id="cb5-209"><a href="#cb5-209" tabindex="-1"></a>            <span class="cf">if</span> has_attention[i]:</span>
<span id="cb5-210"><a href="#cb5-210" tabindex="-1"></a>                x <span class="op">=</span> AttentionBlock(widths[i], groups<span class="op">=</span>norm_groups)(x)</span>
<span id="cb5-211"><a href="#cb5-211" tabindex="-1"></a></span>
<span id="cb5-212"><a href="#cb5-212" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb5-213"><a href="#cb5-213" tabindex="-1"></a>            x <span class="op">=</span> UpSample(widths[i], interpolation<span class="op">=</span>interpolation)(x)</span>
<span id="cb5-214"><a href="#cb5-214" tabindex="-1"></a></span>
<span id="cb5-215"><a href="#cb5-215" tabindex="-1"></a>    <span class="co"># End block</span></span>
<span id="cb5-216"><a href="#cb5-216" tabindex="-1"></a>    x <span class="op">=</span> layers.GroupNormalization(groups<span class="op">=</span>norm_groups)(x)</span>
<span id="cb5-217"><a href="#cb5-217" tabindex="-1"></a>    x <span class="op">=</span> activation_fn(x)</span>
<span id="cb5-218"><a href="#cb5-218" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb5-219"><a href="#cb5-219" tabindex="-1"></a>        <span class="dv">3</span>, (<span class="dv">3</span>, <span class="dv">3</span>), padding<span class="op">=</span><span class="st">"same"</span>, kernel_initializer<span class="op">=</span>kernel_init(<span class="fl">0.0</span>)</span>
<span id="cb5-220"><a href="#cb5-220" tabindex="-1"></a>    )(x)</span>
<span id="cb5-221"><a href="#cb5-221" tabindex="-1"></a>    <span class="cf">return</span> keras.Model([image_input, time_input], x, name<span class="op">=</span><span class="st">"unet"</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h2>
<p>We follow the same setup for training the diffusion model as
described in the paper. We use <code>Adam</code> optimizer with a
learning rate of <code>2e-4</code>. We use EMA on model parameters with
a decay factor of 0.999. We treat our model as noise prediction network
i.e. at every training step, we input a batch of images and
corresponding time steps to our UNet, and the network outputs the noise
as predictions.</p>
<p>The only difference is that we aren’t using the Kernel Inception
Distance (KID) or Frechet Inception Distance (FID) for evaluating the
quality of generated samples during training. This is because both these
metrics are compute heavy and are skipped for the brevity of
implementation.</p>
<p><strong>Note: </strong> We are using mean squared error as the loss
function which is aligned with the paper, and theoretically makes sense.
In practice, though, it is also common to use mean absolute error or
Huber loss as the loss function.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="kw">class</span> DiffusionModel(keras.Model):</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, network, ema_network, timesteps, gdf_util, ema<span class="op">=</span><span class="fl">0.999</span>):</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>        <span class="va">self</span>.network <span class="op">=</span> network</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>        <span class="va">self</span>.ema_network <span class="op">=</span> ema_network</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>        <span class="va">self</span>.timesteps <span class="op">=</span> timesteps</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>        <span class="va">self</span>.gdf_util <span class="op">=</span> gdf_util</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>        <span class="va">self</span>.ema <span class="op">=</span> ema</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>    <span class="kw">def</span> train_step(<span class="va">self</span>, images):</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>        <span class="co"># 1. Get the batch size</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>        batch_size <span class="op">=</span> tf.shape(images)[<span class="dv">0</span>]</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>        <span class="co"># 2. Sample timesteps uniformly</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>        t <span class="op">=</span> tf.random.uniform(</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>            minval<span class="op">=</span><span class="dv">0</span>, maxval<span class="op">=</span><span class="va">self</span>.timesteps, shape<span class="op">=</span>(batch_size,), dtype<span class="op">=</span>tf.int64</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>        )</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>            <span class="co"># 3. Sample random noise to be added to the images in the batch</span></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a>            noise <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>tf.shape(images), dtype<span class="op">=</span>images.dtype)</span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>            <span class="co"># 4. Diffuse the images with noise</span></span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>            images_t <span class="op">=</span> <span class="va">self</span>.gdf_util.q_sample(images, t, noise)</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a>            <span class="co"># 5. Pass the diffused images and time steps to the network</span></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a>            pred_noise <span class="op">=</span> <span class="va">self</span>.network([images_t, t], training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a>            <span class="co"># 6. Calculate the loss</span></span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a>            loss <span class="op">=</span> <span class="va">self</span>.loss(noise, pred_noise)</span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a>        <span class="co"># 7. Get the gradients</span></span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a>        gradients <span class="op">=</span> tape.gradient(loss, <span class="va">self</span>.network.trainable_weights)</span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>        <span class="co"># 8. Update the weights of the network</span></span>
<span id="cb6-36"><a href="#cb6-36" tabindex="-1"></a>        <span class="va">self</span>.optimizer.apply_gradients(</span>
<span id="cb6-37"><a href="#cb6-37" tabindex="-1"></a>            <span class="bu">zip</span>(gradients, <span class="va">self</span>.network.trainable_weights)</span>
<span id="cb6-38"><a href="#cb6-38" tabindex="-1"></a>        )</span>
<span id="cb6-39"><a href="#cb6-39" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" tabindex="-1"></a>        <span class="co"># 9. Updates the weight values for the network with EMA weights</span></span>
<span id="cb6-41"><a href="#cb6-41" tabindex="-1"></a>        <span class="cf">for</span> weight, ema_weight <span class="kw">in</span> <span class="bu">zip</span>(</span>
<span id="cb6-42"><a href="#cb6-42" tabindex="-1"></a>            <span class="va">self</span>.network.weights, <span class="va">self</span>.ema_network.weights</span>
<span id="cb6-43"><a href="#cb6-43" tabindex="-1"></a>        ):</span>
<span id="cb6-44"><a href="#cb6-44" tabindex="-1"></a>            ema_weight.assign(<span class="va">self</span>.ema <span class="op">*</span> ema_weight <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.ema) <span class="op">*</span> weight)</span>
<span id="cb6-45"><a href="#cb6-45" tabindex="-1"></a></span>
<span id="cb6-46"><a href="#cb6-46" tabindex="-1"></a>        <span class="co"># 10. Return loss values</span></span>
<span id="cb6-47"><a href="#cb6-47" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"loss"</span>: loss}</span>
<span id="cb6-48"><a href="#cb6-48" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" tabindex="-1"></a>    <span class="kw">def</span> generate_images(<span class="va">self</span>, num_images<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb6-50"><a href="#cb6-50" tabindex="-1"></a>        <span class="co"># 1. Randomly sample noise (starting point for reverse process)</span></span>
<span id="cb6-51"><a href="#cb6-51" tabindex="-1"></a>        samples <span class="op">=</span> tf.random.normal(</span>
<span id="cb6-52"><a href="#cb6-52" tabindex="-1"></a>            shape<span class="op">=</span>(num_images, img_size, img_size, img_channels),</span>
<span id="cb6-53"><a href="#cb6-53" tabindex="-1"></a>            dtype<span class="op">=</span>tf.float32,</span>
<span id="cb6-54"><a href="#cb6-54" tabindex="-1"></a>        )</span>
<span id="cb6-55"><a href="#cb6-55" tabindex="-1"></a>        <span class="co"># 2. Sample from the model iteratively</span></span>
<span id="cb6-56"><a href="#cb6-56" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="dv">0</span>, <span class="va">self</span>.timesteps)):</span>
<span id="cb6-57"><a href="#cb6-57" tabindex="-1"></a>            tt <span class="op">=</span> tf.cast(tf.fill(num_images, t), dtype<span class="op">=</span>tf.int64)</span>
<span id="cb6-58"><a href="#cb6-58" tabindex="-1"></a>            pred_noise <span class="op">=</span> <span class="va">self</span>.ema_network.predict(</span>
<span id="cb6-59"><a href="#cb6-59" tabindex="-1"></a>                [samples, tt], verbose<span class="op">=</span><span class="dv">0</span>, batch_size<span class="op">=</span>num_images</span>
<span id="cb6-60"><a href="#cb6-60" tabindex="-1"></a>            )</span>
<span id="cb6-61"><a href="#cb6-61" tabindex="-1"></a>            samples <span class="op">=</span> <span class="va">self</span>.gdf_util.p_sample(</span>
<span id="cb6-62"><a href="#cb6-62" tabindex="-1"></a>                pred_noise, samples, tt, clip_denoised<span class="op">=</span><span class="va">True</span></span>
<span id="cb6-63"><a href="#cb6-63" tabindex="-1"></a>            )</span>
<span id="cb6-64"><a href="#cb6-64" tabindex="-1"></a>        <span class="co"># 3. Return generated samples</span></span>
<span id="cb6-65"><a href="#cb6-65" tabindex="-1"></a>        <span class="cf">return</span> samples</span>
<span id="cb6-66"><a href="#cb6-66" tabindex="-1"></a></span>
<span id="cb6-67"><a href="#cb6-67" tabindex="-1"></a>    <span class="kw">def</span> plot_images(</span>
<span id="cb6-68"><a href="#cb6-68" tabindex="-1"></a>        <span class="va">self</span>, epoch<span class="op">=</span><span class="va">None</span>, logs<span class="op">=</span><span class="va">None</span>, num_rows<span class="op">=</span><span class="dv">2</span>, num_cols<span class="op">=</span><span class="dv">8</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>)</span>
<span id="cb6-69"><a href="#cb6-69" tabindex="-1"></a>    ):</span>
<span id="cb6-70"><a href="#cb6-70" tabindex="-1"></a>        <span class="co">"""Utility to plot images using the diffusion model during training."""</span></span>
<span id="cb6-71"><a href="#cb6-71" tabindex="-1"></a>        generated_samples <span class="op">=</span> <span class="va">self</span>.generate_images(num_images<span class="op">=</span>num_rows <span class="op">*</span> num_cols)</span>
<span id="cb6-72"><a href="#cb6-72" tabindex="-1"></a>        generated_samples <span class="op">=</span> (</span>
<span id="cb6-73"><a href="#cb6-73" tabindex="-1"></a>            tf.clip_by_value(generated_samples <span class="op">*</span> <span class="fl">127.5</span> <span class="op">+</span> <span class="fl">127.5</span>, <span class="fl">0.0</span>, <span class="fl">255.0</span>)</span>
<span id="cb6-74"><a href="#cb6-74" tabindex="-1"></a>            .numpy()</span>
<span id="cb6-75"><a href="#cb6-75" tabindex="-1"></a>            .astype(np.uint8)</span>
<span id="cb6-76"><a href="#cb6-76" tabindex="-1"></a>        )</span>
<span id="cb6-77"><a href="#cb6-77" tabindex="-1"></a></span>
<span id="cb6-78"><a href="#cb6-78" tabindex="-1"></a>        _, ax <span class="op">=</span> plt.subplots(num_rows, num_cols, figsize<span class="op">=</span>figsize)</span>
<span id="cb6-79"><a href="#cb6-79" tabindex="-1"></a>        <span class="cf">for</span> i, image <span class="kw">in</span> <span class="bu">enumerate</span>(generated_samples):</span>
<span id="cb6-80"><a href="#cb6-80" tabindex="-1"></a>            <span class="cf">if</span> num_rows <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb6-81"><a href="#cb6-81" tabindex="-1"></a>                ax[i].imshow(image)</span>
<span id="cb6-82"><a href="#cb6-82" tabindex="-1"></a>                ax[i].axis(<span class="st">"off"</span>)</span>
<span id="cb6-83"><a href="#cb6-83" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb6-84"><a href="#cb6-84" tabindex="-1"></a>                ax[i <span class="op">//</span> num_cols, i <span class="op">%</span> num_cols].imshow(image)</span>
<span id="cb6-85"><a href="#cb6-85" tabindex="-1"></a>                ax[i <span class="op">//</span> num_cols, i <span class="op">%</span> num_cols].axis(<span class="st">"off"</span>)</span>
<span id="cb6-86"><a href="#cb6-86" tabindex="-1"></a></span>
<span id="cb6-87"><a href="#cb6-87" tabindex="-1"></a>        plt.tight_layout()</span>
<span id="cb6-88"><a href="#cb6-88" tabindex="-1"></a>        plt.show()</span>
<span id="cb6-89"><a href="#cb6-89" tabindex="-1"></a></span>
<span id="cb6-90"><a href="#cb6-90" tabindex="-1"></a></span>
<span id="cb6-91"><a href="#cb6-91" tabindex="-1"></a><span class="co"># Build the unet model</span></span>
<span id="cb6-92"><a href="#cb6-92" tabindex="-1"></a>network <span class="op">=</span> build_model(</span>
<span id="cb6-93"><a href="#cb6-93" tabindex="-1"></a>    img_size<span class="op">=</span>img_size,</span>
<span id="cb6-94"><a href="#cb6-94" tabindex="-1"></a>    img_channels<span class="op">=</span>img_channels,</span>
<span id="cb6-95"><a href="#cb6-95" tabindex="-1"></a>    widths<span class="op">=</span>widths,</span>
<span id="cb6-96"><a href="#cb6-96" tabindex="-1"></a>    has_attention<span class="op">=</span>has_attention,</span>
<span id="cb6-97"><a href="#cb6-97" tabindex="-1"></a>    num_res_blocks<span class="op">=</span>num_res_blocks,</span>
<span id="cb6-98"><a href="#cb6-98" tabindex="-1"></a>    norm_groups<span class="op">=</span>norm_groups,</span>
<span id="cb6-99"><a href="#cb6-99" tabindex="-1"></a>    activation_fn<span class="op">=</span>keras.activations.swish,</span>
<span id="cb6-100"><a href="#cb6-100" tabindex="-1"></a>)</span>
<span id="cb6-101"><a href="#cb6-101" tabindex="-1"></a>ema_network <span class="op">=</span> build_model(</span>
<span id="cb6-102"><a href="#cb6-102" tabindex="-1"></a>    img_size<span class="op">=</span>img_size,</span>
<span id="cb6-103"><a href="#cb6-103" tabindex="-1"></a>    img_channels<span class="op">=</span>img_channels,</span>
<span id="cb6-104"><a href="#cb6-104" tabindex="-1"></a>    widths<span class="op">=</span>widths,</span>
<span id="cb6-105"><a href="#cb6-105" tabindex="-1"></a>    has_attention<span class="op">=</span>has_attention,</span>
<span id="cb6-106"><a href="#cb6-106" tabindex="-1"></a>    num_res_blocks<span class="op">=</span>num_res_blocks,</span>
<span id="cb6-107"><a href="#cb6-107" tabindex="-1"></a>    norm_groups<span class="op">=</span>norm_groups,</span>
<span id="cb6-108"><a href="#cb6-108" tabindex="-1"></a>    activation_fn<span class="op">=</span>keras.activations.swish,</span>
<span id="cb6-109"><a href="#cb6-109" tabindex="-1"></a>)</span>
<span id="cb6-110"><a href="#cb6-110" tabindex="-1"></a>ema_network.set_weights(</span>
<span id="cb6-111"><a href="#cb6-111" tabindex="-1"></a>    network.get_weights()</span>
<span id="cb6-112"><a href="#cb6-112" tabindex="-1"></a>)  <span class="co"># Initially the weights are the same</span></span>
<span id="cb6-113"><a href="#cb6-113" tabindex="-1"></a></span>
<span id="cb6-114"><a href="#cb6-114" tabindex="-1"></a><span class="co"># Get an instance of the Gaussian Diffusion utilities</span></span>
<span id="cb6-115"><a href="#cb6-115" tabindex="-1"></a>gdf_util <span class="op">=</span> GaussianDiffusion(timesteps<span class="op">=</span>total_timesteps)</span>
<span id="cb6-116"><a href="#cb6-116" tabindex="-1"></a></span>
<span id="cb6-117"><a href="#cb6-117" tabindex="-1"></a><span class="co"># Get the model</span></span>
<span id="cb6-118"><a href="#cb6-118" tabindex="-1"></a>model <span class="op">=</span> DiffusionModel(</span>
<span id="cb6-119"><a href="#cb6-119" tabindex="-1"></a>    network<span class="op">=</span>network,</span>
<span id="cb6-120"><a href="#cb6-120" tabindex="-1"></a>    ema_network<span class="op">=</span>ema_network,</span>
<span id="cb6-121"><a href="#cb6-121" tabindex="-1"></a>    gdf_util<span class="op">=</span>gdf_util,</span>
<span id="cb6-122"><a href="#cb6-122" tabindex="-1"></a>    timesteps<span class="op">=</span>total_timesteps,</span>
<span id="cb6-123"><a href="#cb6-123" tabindex="-1"></a>)</span>
<span id="cb6-124"><a href="#cb6-124" tabindex="-1"></a></span>
<span id="cb6-125"><a href="#cb6-125" tabindex="-1"></a><span class="co"># Compile the model</span></span>
<span id="cb6-126"><a href="#cb6-126" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb6-127"><a href="#cb6-127" tabindex="-1"></a>    loss<span class="op">=</span>keras.losses.MeanSquaredError(),</span>
<span id="cb6-128"><a href="#cb6-128" tabindex="-1"></a>    optimizer<span class="op">=</span>keras.optimizers.Adam(learning_rate<span class="op">=</span>learning_rate),</span>
<span id="cb6-129"><a href="#cb6-129" tabindex="-1"></a>    jit_compile<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-130"><a href="#cb6-130" tabindex="-1"></a>)</span>
<span id="cb6-131"><a href="#cb6-131" tabindex="-1"></a></span>
<span id="cb6-132"><a href="#cb6-132" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb6-133"><a href="#cb6-133" tabindex="-1"></a>model.fit(</span>
<span id="cb6-134"><a href="#cb6-134" tabindex="-1"></a>    train_ds,</span>
<span id="cb6-135"><a href="#cb6-135" tabindex="-1"></a>    epochs<span class="op">=</span>num_epochs,</span>
<span id="cb6-136"><a href="#cb6-136" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb6-137"><a href="#cb6-137" tabindex="-1"></a>    callbacks<span class="op">=</span>[keras.callbacks.LambdaCallback(on_epoch_end<span class="op">=</span>model.plot_images)],</span>
<span id="cb6-138"><a href="#cb6-138" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="results">Results<a class="anchor" aria-label="anchor" href="#results"></a>
</h2>
<p>We trained this model for 800 epochs on a V100 GPU, and each epoch
took almost 8 seconds to finish. We load those weights here, and we
generate a few samples starting from pure noise.</p>
<p>curl -LO <a href="https://github.com/AakashKumarNain/ddpms/releases/download/v3.0.0/checkpoints.zip" class="external-link uri">https://github.com/AakashKumarNain/ddpms/releases/download/v3.0.0/checkpoints.zip</a>
unzip -qq checkpoints.zip</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Load the model weights</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>model.ema_network.load_weights(<span class="st">"checkpoints/diffusion_model_checkpoint"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co"># Generate and plot some samples</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>model.plot_images(num_rows<span class="op">=</span><span class="dv">4</span>, num_cols<span class="op">=</span><span class="dv">8</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>We successfully implemented and trained a diffusion model exactly in
the same fashion as implemented by the authors of the DDPMs paper. You
can find the original implementation <a href="https://github.com/hojonathanho/diffusion" class="external-link">here</a>.</p>
<p>There are a few things that you can try to improve the model:</p>
<ol style="list-style-type: decimal">
<li><p>Increasing the width of each block. A bigger model can learn to
denoise in fewer epochs, though you may have to take care of
overfitting.</p></li>
<li><p>We implemented the linear schedule for variance scheduling. You
can implement other schemes like cosine scheduling and compare the
performance.</p></li>
</ol>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<ol style="list-style-type: decimal">
<li><a href="https://arxiv.org/abs/2006.11239" class="external-link">Denoising Diffusion
Probabilistic Models</a></li>
<li><a href="https://github.com/hojonathanho/diffusion" class="external-link">Author’s
implementation</a></li>
<li><a href="https://magic-with-latents.github.io/latent/posts/ddpms/part3/" class="external-link">A
deep dive into DDPMs</a></li>
<li><a href="https://keras.io/examples/generative/ddim/" class="external-link">Denoising
Diffusion Implicit Models</a></li>
<li><a href="https://huggingface.co/blog/annotated-diffusion" class="external-link">Annotated
Diffusion Model</a></li>
<li><a href="https://www.youtube.com/watch?v=XTs7M6TSK9I&amp;t=14s" class="external-link">AIAIART</a></li>
</ol>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
