<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>pretrained_word_embeddings • keras</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">Keras for R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Getting Started</li>
    <li>
      <a href="../../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li>
      <a href="../../articles/sequential_model.html">Guide to the Sequential Model</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Guide to the Functional API</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
<li>
  <a href="https://github.com/rstudio/keras">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>pretrained_word_embeddings</h1>
            
          </div>

    
    
<div class="contents">
<div class="source-ref">
<p><span class="caption">Source: </span><a href="https://github.com/rstudio/keras/blob/master/vignettes/examples/pretrained_word_embeddings.R" class="uri">https://github.com/rstudio/keras/blob/master/vignettes/examples/pretrained_word_embeddings.R</a></p>
</div>
<p>This script loads pre-trained word embeddings (GloVe embeddings) into a frozen Keras Embedding layer, and uses it to train a text classification model on the 20 Newsgroup dataset (classication of newsgroup messages into 20 different categories).</p>
<p>GloVe embedding data can be found at: <a href="http://nlp.stanford.edu/data/glove.6B.zip" class="uri">http://nlp.stanford.edu/data/glove.6B.zip</a> (source page: <a href="http://nlp.stanford.edu/projects/glove/" class="uri">http://nlp.stanford.edu/projects/glove/</a>)</p>
<p>20 Newsgroup data can be found at: <a href="http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html" class="uri">http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html</a></p>
<p>IMPORTANT NOTE: This example does yet work correctly. The code executes fine and appears to mimic the Python code upon which it is based however it achieves only half the training accuracy that the Python code does so there is clearly a subtle difference.</p>
<p>We need to investigate this further before formally adding to the list of examples</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(keras)

GLOVE_DIR &lt;-<span class="st"> 'glove.6B'</span>
TEXT_DATA_DIR &lt;-<span class="st"> '20_newsgroup'</span>
MAX_SEQUENCE_LENGTH &lt;-<span class="st"> </span><span class="dv">1000</span>
MAX_NUM_WORDS &lt;-<span class="st"> </span><span class="dv">20000</span>
EMBEDDING_DIM &lt;-<span class="st"> </span><span class="dv">100</span>
VALIDATION_SPLIT &lt;-<span class="st"> </span><span class="fl">0.2</span>

<span class="co"># download data if necessary</span>
download_data &lt;-<span class="st"> </span><span class="cf">function</span>(data_dir, url_path, data_file) {
  <span class="cf">if</span> (<span class="op">!</span><span class="kw">dir.exists</span>(data_dir)) {
    <span class="kw">download.file</span>(<span class="kw">paste0</span>(url_path, data_file), data_file, <span class="dt">mode =</span> <span class="st">"wb"</span>)
    <span class="cf">if</span> (tools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/tools/topics/fileutils">file_ext</a></span>(data_file) <span class="op">==</span><span class="st"> "zip"</span>)
      <span class="kw">unzip</span>(data_file, <span class="dt">exdir =</span> tools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/tools/topics/fileutils">file_path_sans_ext</a></span>(data_file))
    <span class="cf">else</span>
      <span class="kw">untar</span>(data_file)
    <span class="kw">unlink</span>(data_file)
  }
}
<span class="kw">download_data</span>(GLOVE_DIR, <span class="st">'http://nlp.stanford.edu/data/'</span>, <span class="st">'glove.6B.zip'</span>)
<span class="kw">download_data</span>(TEXT_DATA_DIR, <span class="st">"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/"</span>, <span class="st">"news20.tar.gz"</span>)

<span class="co"># first, build index mapping words in the embeddings set</span>
<span class="co"># to their embedding vector</span>

<span class="kw">cat</span>(<span class="st">'Indexing word vectors.</span><span class="ch">\n</span><span class="st">'</span>)

embeddings_index &lt;-<span class="st"> </span><span class="kw">new.env</span>(<span class="dt">parent =</span> <span class="kw">emptyenv</span>())
lines &lt;-<span class="st"> </span><span class="kw">readLines</span>(<span class="kw">file.path</span>(GLOVE_DIR, <span class="st">'glove.6B.100d.txt'</span>))
<span class="cf">for</span> (line <span class="cf">in</span> lines) {
  values &lt;-<span class="st"> </span><span class="kw">strsplit</span>(line, <span class="st">' '</span>, <span class="dt">fixed =</span> <span class="ot">TRUE</span>)[[<span class="dv">1</span>]]
  word &lt;-<span class="st"> </span>values[[<span class="dv">1</span>]]
  coefs &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(values[<span class="op">-</span><span class="dv">1</span>])
  embeddings_index[[word]] &lt;-<span class="st"> </span>coefs
}

<span class="kw">cat</span>(<span class="kw">sprintf</span>(<span class="st">'Found %s word vectors.</span><span class="ch">\n</span><span class="st">'</span>, <span class="kw">length</span>(embeddings_index)))

<span class="co"># second, prepare text samples and their labels</span>
<span class="kw">cat</span>(<span class="st">'Processing text dataset</span><span class="ch">\n</span><span class="st">'</span>)

texts &lt;-<span class="st"> </span><span class="kw">character</span>()  <span class="co"># text samples</span>
labels &lt;-<span class="st"> </span><span class="kw">integer</span>() <span class="co"># label ids</span>
labels_index &lt;-<span class="st"> </span><span class="kw">list</span>()  <span class="co"># dictionary: label name to numeric id</span>

<span class="cf">for</span> (name <span class="cf">in</span> <span class="kw">list.files</span>(TEXT_DATA_DIR)) {
  path &lt;-<span class="st"> </span><span class="kw">file.path</span>(TEXT_DATA_DIR, name)
  <span class="cf">if</span> (<span class="kw">file_test</span>(<span class="st">"-d"</span>, path)) {
    label_id &lt;-<span class="st"> </span><span class="kw">length</span>(labels_index)
    labels_index[[name]] &lt;-<span class="st"> </span>label_id
    <span class="cf">for</span> (fname <span class="cf">in</span> <span class="kw">list.files</span>(path)) {
      <span class="cf">if</span> (<span class="kw">grepl</span>(<span class="st">"^[0-9]+$"</span>, fname)) {
        fpath &lt;-<span class="st"> </span><span class="kw">file.path</span>(path, fname)
        t &lt;-<span class="st"> </span><span class="kw">readLines</span>(fpath, <span class="dt">encoding =</span> <span class="st">"latin1"</span>)
        t &lt;-<span class="st"> </span><span class="kw">paste</span>(t, <span class="dt">collapse =</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)
        i &lt;-<span class="st"> </span><span class="kw">regexpr</span>(<span class="dt">pattern =</span> <span class="st">'</span><span class="ch">\n\n</span><span class="st">'</span>, t, <span class="dt">fixed =</span> <span class="ot">TRUE</span>)[[<span class="dv">1</span>]]
        <span class="cf">if</span> (i <span class="op">!=</span><span class="st"> </span><span class="op">-</span>1L)
          t &lt;-<span class="st"> </span><span class="kw">substring</span>(t, i)
        texts &lt;-<span class="st"> </span><span class="kw">c</span>(texts, t)
        labels &lt;-<span class="st"> </span><span class="kw">c</span>(labels, label_id)
      }
    }
  }
}

<span class="kw">cat</span>(<span class="kw">sprintf</span>(<span class="st">'Found %s texts.</span><span class="ch">\n</span><span class="st">'</span>, <span class="kw">length</span>(texts)))

<span class="co"># finally, vectorize the text samples into a 2D integer tensor</span>
tokenizer &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/text_tokenizer.html">text_tokenizer</a></span>(<span class="dt">num_words=</span>MAX_NUM_WORDS)
tokenizer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/fit_text_tokenizer.html">fit_text_tokenizer</a></span>(texts)

<span class="co"># save the tokenizer in case we want to use it again</span>
<span class="co"># for prediction within another R session, see:</span>
<span class="co"># https://keras.rstudio.com/reference/save_text_tokenizer.html</span>
<span class="kw"><a href="../../reference/save_text_tokenizer.html">save_text_tokenizer</a></span>(tokenizer, <span class="st">"tokenizer"</span>)

sequences &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/texts_to_sequences.html">texts_to_sequences</a></span>(tokenizer, texts)

word_index &lt;-<span class="st"> </span>tokenizer<span class="op">$</span>word_index
<span class="kw">cat</span>(<span class="kw">sprintf</span>(<span class="st">'Found %s unique tokens.</span><span class="ch">\n</span><span class="st">'</span>, <span class="kw">length</span>(word_index)))

data &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/pad_sequences.html">pad_sequences</a></span>(sequences, <span class="dt">maxlen=</span>MAX_SEQUENCE_LENGTH)
labels &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/to_categorical.html">to_categorical</a></span>(labels)

<span class="kw">cat</span>(<span class="st">'Shape of data tensor: '</span>, <span class="kw">dim</span>(data), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)
<span class="kw">cat</span>(<span class="st">'Shape of label tensor: '</span>, <span class="kw">dim</span>(labels), <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)

<span class="co"># split the data into a training set and a validation set</span>
indices &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(data)
indices &lt;-<span class="st"> </span><span class="kw">sample</span>(indices)
data &lt;-<span class="st"> </span>data[indices,]
labels &lt;-<span class="st"> </span>labels[indices,]
num_validation_samples &lt;-<span class="st"> </span><span class="kw">as.integer</span>(VALIDATION_SPLIT <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(data))

x_train &lt;-<span class="st"> </span>data[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span>num_validation_samples),]
y_train &lt;-<span class="st"> </span>labels[<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span>num_validation_samples),]
x_val &lt;-<span class="st"> </span>data[<span class="dv">1</span><span class="op">:</span>num_validation_samples,]
y_val &lt;-<span class="st"> </span>labels[<span class="dv">1</span><span class="op">:</span>num_validation_samples,]

<span class="kw">cat</span>(<span class="st">'Preparing embedding matrix.</span><span class="ch">\n</span><span class="st">'</span>)

<span class="co"># prepare embedding matrix</span>
num_words &lt;-<span class="st"> </span><span class="kw">min</span>(MAX_NUM_WORDS, <span class="kw">length</span>(word_index) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)
prepare_embedding_matrix &lt;-<span class="st"> </span><span class="cf">function</span>() {
  embedding_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(0L, <span class="dt">nrow =</span> num_words, <span class="dt">ncol =</span> EMBEDDING_DIM)
  <span class="cf">for</span> (word <span class="cf">in</span> <span class="kw">names</span>(word_index)) {
    index &lt;-<span class="st"> </span>word_index[[word]]
    <span class="cf">if</span> (index <span class="op">&gt;=</span><span class="st"> </span>MAX_NUM_WORDS)
      <span class="cf">next</span>
    embedding_vector &lt;-<span class="st"> </span>embeddings_index[[word]]
    <span class="cf">if</span> (<span class="op">!</span><span class="kw">is.null</span>(embedding_vector)) {
      <span class="co"># words not found in embedding index will be all-zeros.</span>
      embedding_matrix[index,] &lt;-<span class="st"> </span>embedding_vector
    }
  }
  embedding_matrix
}

embedding_matrix &lt;-<span class="st"> </span><span class="kw">prepare_embedding_matrix</span>()

<span class="co"># load pre-trained word embeddings into an Embedding layer</span>
<span class="co"># note that we set trainable = False so as to keep the embeddings fixed</span>
embedding_layer &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_embedding.html">layer_embedding</a></span>(
  <span class="dt">input_dim =</span> num_words,
  <span class="dt">output_dim =</span> EMBEDDING_DIM,
  <span class="dt">weights =</span> <span class="kw">list</span>(embedding_matrix),
  <span class="dt">input_length =</span> MAX_SEQUENCE_LENGTH,
  <span class="dt">trainable =</span> <span class="ot">FALSE</span>
)
                           
<span class="kw">cat</span>(<span class="st">'Training model</span><span class="ch">\n</span><span class="st">'</span>)

<span class="co"># train a 1D convnet with global maxpooling</span>
sequence_input &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> <span class="kw">list</span>(MAX_SEQUENCE_LENGTH), <span class="dt">dtype=</span><span class="st">'int32'</span>)

preds &lt;-<span class="st"> </span>sequence_input <span class="op">%&gt;%</span>
<span class="st">  </span>embedding_layer <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_conv_1d.html">layer_conv_1d</a></span>(<span class="dt">filters =</span> <span class="dv">128</span>, <span class="dt">kernel_size =</span> <span class="dv">5</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_max_pooling_1d.html">layer_max_pooling_1d</a></span>(<span class="dt">pool_size =</span> <span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_conv_1d.html">layer_conv_1d</a></span>(<span class="dt">filters =</span> <span class="dv">128</span>, <span class="dt">kernel_size =</span> <span class="dv">5</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_max_pooling_1d.html">layer_max_pooling_1d</a></span>(<span class="dt">pool_size =</span> <span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_conv_1d.html">layer_conv_1d</a></span>(<span class="dt">filters =</span> <span class="dv">128</span>, <span class="dt">kernel_size =</span> <span class="dv">5</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_max_pooling_1d.html">layer_max_pooling_1d</a></span>(<span class="dt">pool_size =</span> <span class="dv">35</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_flatten.html">layer_flatten</a></span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="dv">128</span>, <span class="dt">activation =</span> <span class="st">'relu'</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> <span class="kw">length</span>(labels_index), <span class="dt">activation =</span> <span class="st">'softmax'</span>)


model &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(sequence_input, preds)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/compile.html">compile</a></span>(
  <span class="dt">loss =</span> <span class="st">'categorical_crossentropy'</span>,
  <span class="dt">optimizer =</span> <span class="st">'rmsprop'</span>,
  <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">'acc'</span>)  
)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/fit.html">fit</a></span>(
  x_train, y_train,
  <span class="dt">batch_size =</span> <span class="dv">128</span>,
  <span class="dt">epochs =</span> <span class="dv">10</span>,
  <span class="dt">validation_data =</span> <span class="kw">list</span>(x_val, y_val)
)</code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by JJ Allaire, François Chollet,  RStudio,  Google.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
