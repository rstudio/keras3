<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>variational_autoencoder • keras</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">Keras for R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Getting Started</li>
    <li>
      <a href="../../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li>
      <a href="../../articles/sequential_model.html">Guide to the Sequential Model</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Guide to the Functional API</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
<li>
  <a href="https://github.com/rstudio/keras">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>variational_autoencoder</h1>
            
          </div>

    
    
<div class="contents">
<div class="source-ref">
<p><span class="caption">Source: </span><a href="https://github.com/rstudio/keras/blob/master/vignettes/examples/variational_autoencoder.R" class="uri">https://github.com/rstudio/keras/blob/master/vignettes/examples/variational_autoencoder.R</a></p>
</div>
<p>This script demonstrates how to build a variational autoencoder with Keras. Reference: “Auto-Encoding Variational Bayes” <a href="https://arxiv.org/abs/1312.6114" class="uri">https://arxiv.org/abs/1312.6114</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(keras)
K &lt;-<span class="st"> </span>keras<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/keras/topics/backend">backend</a></span>()

<span class="co"># Parameters --------------------------------------------------------------</span>

batch_size &lt;-<span class="st"> </span>100L
original_dim &lt;-<span class="st"> </span>784L
latent_dim &lt;-<span class="st"> </span>2L
intermediate_dim &lt;-<span class="st"> </span>256L
epochs &lt;-<span class="st"> </span>50L
epsilon_std &lt;-<span class="st"> </span><span class="fl">1.0</span>

<span class="co"># Model definition --------------------------------------------------------</span>

x &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> <span class="kw">c</span>(original_dim))
h &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(x, intermediate_dim, <span class="dt">activation =</span> <span class="st">"relu"</span>)
z_mean &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(h, latent_dim)
z_log_var &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(h, latent_dim)

sampling &lt;-<span class="st"> </span><span class="cf">function</span>(arg){
  z_mean &lt;-<span class="st"> </span>arg[, <span class="dv">1</span><span class="op">:</span>(latent_dim)]
  z_log_var &lt;-<span class="st"> </span>arg[, (latent_dim <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">:</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>latent_dim)]
  
  epsilon &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/k_random_normal.html">k_random_normal</a></span>(
    <span class="dt">shape =</span> <span class="kw">c</span>(<span class="kw"><a href="../../reference/k_shape.html">k_shape</a></span>(z_mean)[[<span class="dv">1</span>]]), 
    <span class="dt">mean=</span><span class="dv">0</span>.,
    <span class="dt">stddev=</span>epsilon_std
  )
  
  z_mean <span class="op">+</span><span class="st"> </span><span class="kw"><a href="../../reference/k_exp.html">k_exp</a></span>(z_log_var<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>epsilon
}

<span class="co"># note that "output_shape" isn't necessary with the TensorFlow backend</span>
z &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_concatenate.html">layer_concatenate</a></span>(<span class="kw">list</span>(z_mean, z_log_var)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="../../reference/layer_lambda.html">layer_lambda</a></span>(sampling)

<span class="co"># we instantiate these layers separately so as to reuse them later</span>
decoder_h &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> intermediate_dim, <span class="dt">activation =</span> <span class="st">"relu"</span>)
decoder_mean &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_dense.html">layer_dense</a></span>(<span class="dt">units =</span> original_dim, <span class="dt">activation =</span> <span class="st">"sigmoid"</span>)
h_decoded &lt;-<span class="st"> </span><span class="kw">decoder_h</span>(z)
x_decoded_mean &lt;-<span class="st"> </span><span class="kw">decoder_mean</span>(h_decoded)

<span class="co"># end-to-end autoencoder</span>
vae &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(x, x_decoded_mean)

<span class="co"># encoder, from inputs to latent space</span>
encoder &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(x, z_mean)

<span class="co"># generator, from latent space to reconstructed inputs</span>
decoder_input &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> latent_dim)
h_decoded_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">decoder_h</span>(decoder_input)
x_decoded_mean_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">decoder_mean</span>(h_decoded_<span class="dv">2</span>)
generator &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(decoder_input, x_decoded_mean_<span class="dv">2</span>)


vae_loss &lt;-<span class="st"> </span><span class="cf">function</span>(x, x_decoded_mean){
  xent_loss &lt;-<span class="st"> </span>(original_dim<span class="op">/</span><span class="fl">1.0</span>)<span class="op">*</span><span class="kw"><a href="../../reference/loss_mean_squared_error.html">loss_binary_crossentropy</a></span>(x, x_decoded_mean)
  kl_loss &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">0.5</span><span class="op">*</span><span class="kw"><a href="../../reference/k_mean.html">k_mean</a></span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>z_log_var <span class="op">-</span><span class="st"> </span><span class="kw"><a href="../../reference/k_square.html">k_square</a></span>(z_mean) <span class="op">-</span><span class="st"> </span><span class="kw"><a href="../../reference/k_exp.html">k_exp</a></span>(z_log_var), <span class="dt">axis =</span> <span class="op">-</span>1L)
  xent_loss <span class="op">+</span><span class="st"> </span>kl_loss
}

vae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/compile.html">compile</a></span>(<span class="dt">optimizer =</span> <span class="st">"rmsprop"</span>, <span class="dt">loss =</span> vae_loss)


<span class="co"># Data preparation --------------------------------------------------------</span>

mnist &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/dataset_mnist.html">dataset_mnist</a></span>()
x_train &lt;-<span class="st"> </span>mnist<span class="op">$</span>train<span class="op">$</span>x<span class="op">/</span><span class="dv">255</span>
x_test &lt;-<span class="st"> </span>mnist<span class="op">$</span>test<span class="op">$</span>x<span class="op">/</span><span class="dv">255</span>
x_train &lt;-<span class="st"> </span>x_train <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">apply</span>(<span class="dv">1</span>, as.numeric) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">t</span>()
x_test &lt;-<span class="st"> </span>x_test <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">apply</span>(<span class="dv">1</span>, as.numeric) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">t</span>()


<span class="co"># Model training ----------------------------------------------------------</span>

vae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/fit.html">fit</a></span>(
  x_train, x_train, 
  <span class="dt">shuffle =</span> <span class="ot">TRUE</span>, 
  <span class="dt">epochs =</span> epochs, 
  <span class="dt">batch_size =</span> batch_size, 
  <span class="dt">validation_data =</span> <span class="kw">list</span>(x_test, x_test)
)


<span class="co"># Visualizations ----------------------------------------------------------</span>

<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
x_test_encoded &lt;-<span class="st"> </span><span class="kw">predict</span>(encoder, x_test, <span class="dt">batch_size =</span> batch_size)

x_test_encoded <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/reexports.html">as_data_frame</a></span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span>(<span class="dt">class =</span> <span class="kw">as.factor</span>(mnist<span class="op">$</span>test<span class="op">$</span>y)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> V1, <span class="dt">y =</span> V2, <span class="dt">colour =</span> class)) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_point">geom_point</a></span>()

<span class="co"># display a 2D manifold of the digits</span>
n &lt;-<span class="st"> </span><span class="dv">15</span>  <span class="co"># figure with 15x15 digits</span>
digit_size &lt;-<span class="st"> </span><span class="dv">28</span>

<span class="co"># we will sample n points within [-4, 4] standard deviations</span>
grid_x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> n)
grid_y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> n)

rows &lt;-<span class="st"> </span><span class="ot">NULL</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(grid_x)){
  column &lt;-<span class="st"> </span><span class="ot">NULL</span>
  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(grid_y)){
    z_sample &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(grid_x[i], grid_y[j]), <span class="dt">ncol =</span> <span class="dv">2</span>)
    column &lt;-<span class="st"> </span><span class="kw">rbind</span>(column, <span class="kw">predict</span>(generator, z_sample) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol =</span> <span class="dv">28</span>) )
  }
  rows &lt;-<span class="st"> </span><span class="kw">cbind</span>(rows, column)
}
rows <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.raster</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>()</code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by JJ Allaire, François Chollet,  RStudio,  Google.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
