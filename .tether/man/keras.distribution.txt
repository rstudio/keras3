DataParallel(
  device_mesh=None,
  devices=None,
  auto_shard_dataset=True
)
DeviceMesh(
  shape,
  axis_names,
  devices=None
)
distribute_tensor(tensor, layout)
distribution()
initialize(
  job_addresses=None,
  num_processes=None,
  process_id=None
)
LayoutMap(device_mesh)
list_devices(device_type=None)
ModelParallel(
  *,
  layout_map=None,
  batch_dim_name=None,
  auto_shard_dataset=True,
  **kwargs
)
set_distribution(value)
TensorLayout(axes, device_mesh=None)

