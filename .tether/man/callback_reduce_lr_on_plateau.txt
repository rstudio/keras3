Help on class ReduceLROnPlateau in module keras.src.callbacks.reduce_lr_on_plateau:

class ReduceLROnPlateau(keras.src.callbacks.callback.Callback)
 |  ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0, **kwargs)
 |
 |  Reduce learning rate when a metric has stopped improving.
 |
 |  Models often benefit from reducing the learning rate by a factor
 |  of 2-10 once learning stagnates. This callback monitors a
 |  quantity and if no improvement is seen for a 'patience' number
 |  of epochs, the learning rate is reduced.
 |
 |  Example:
 |
 |  ```python
 |  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
 |                                patience=5, min_lr=0.001)
 |  model.fit(x_train, y_train, callbacks=[reduce_lr])
 |  ```
 |
 |  Args:
 |      monitor: String. Quantity to be monitored.
 |      factor: Float. Factor by which the learning rate will be reduced.
 |          `new_lr = lr * factor`.
 |      patience: Integer. Number of epochs with no improvement after which
 |          learning rate will be reduced.
 |      verbose: Integer. 0: quiet, 1: update messages.
 |      mode: String. One of `{'auto', 'min', 'max'}`. In `'min'` mode,
 |          the learning rate will be reduced when the
 |          quantity monitored has stopped decreasing; in `'max'` mode it will
 |          be reduced when the quantity monitored has stopped increasing; in
 |          `'auto'` mode, the direction is automatically inferred from the name
 |          of the monitored quantity.
 |      min_delta: Float. Threshold for measuring the new optimum, to only focus
 |          on significant changes.
 |      cooldown: Integer. Number of epochs to wait before resuming normal
 |          operation after the learning rate has been reduced.
 |      min_lr: Float. Lower bound on the learning rate.
 |
 |  Method resolution order:
 |      ReduceLROnPlateau
 |      keras.src.callbacks.callback.Callback
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  __init__(
 |    self,
 |    monitor='val_loss',
 |    factor=0.1,
 |    patience=10,
 |    verbose=0,
 |    mode='auto',
 |    min_delta=0.0001,
 |    cooldown=0,
 |    min_lr=0,
 |    **kwargs
 |  )
 |      Initialize self.  See help(type(self)) for accurate signature.
 |
 |  in_cooldown(self)
 |
 |  on_epoch_end(
 |    self,
 |    epoch,
 |    logs=None
 |  )
 |      Called at the end of an epoch.
 |
 |      Subclasses should override for any actions to run. This function should
 |      only be called during TRAIN mode.
 |
 |      Args:
 |          epoch: Integer, index of epoch.
 |          logs: Dict, metric results for this training epoch, and for the
 |            validation epoch if validation is performed. Validation result
 |            keys are prefixed with `val_`. For training epoch, the values of
 |            the `Model`'s metrics are returned. Example:
 |            `{'loss': 0.2, 'accuracy': 0.7}`.
 |
 |  on_train_begin(self, logs=None)
 |      Called at the beginning of training.
 |
 |      Subclasses should override for any actions to run.
 |
 |      Args:
 |          logs: Dict. Currently no data is passed to this argument for this
 |            method but that may change in the future.
 |
