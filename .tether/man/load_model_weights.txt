__signature__
keras.Model.load_weights(
  self,
  filepath,
  skip_mismatch=False,
  **kwargs
)
__doc__
Load the weights from a single file or sharded files.

Weights are loaded based on the network's topology. This means the
architecture should be the same as when the weights were saved. Note
that layers that don't have weights are not taken into account in the
topological ordering, so adding or removing layers is fine as long as
they don't have weights.

**Partial weight loading**

If you have modified your model, for instance by adding a new layer
(with weights) or by changing the shape of the weights of a layer, you
can choose to ignore errors and continue loading by setting
`skip_mismatch=True`. In this case any layer with mismatching weights
will be skipped. A warning will be displayed for each skipped layer.

**Sharding**

When loading sharded weights, it is important to specify `filepath` that
ends with `*.weights.json` which is used as the configuration file.
Additionally, the sharded files `*_xxxxx.weights.h5` must be in the same
directory as the configuration file.

Args:
    filepath: `str` or `pathlib.Path` object. Path where the weights
        will be saved.  When sharding, the filepath must end in
        `.weights.json`.
    skip_mismatch: Boolean, whether to skip loading of layers where
        there is a mismatch in the number of weights, or a mismatch in
        the shape of the weights.

Example:

```python
# Load the weights in a single file.
model.load_weights("model.weights.h5")

# Load the weights in sharded files.
model.load_weights("model.weights.json")
```

