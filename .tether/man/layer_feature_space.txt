Help on class FeatureSpace in module keras.src.layers.preprocessing.feature_space:

class FeatureSpace(keras.src.layers.layer.Layer)
 |  FeatureSpace(features, output_mode='concat', crosses=None, crossing_dim=32, hashing_dim=32, num_discretization_bins=32, name=None)
 |
 |  One-stop utility for preprocessing and encoding structured data.
 |
 |  Arguments:
 |      feature_names: Dict mapping the names of your features to their
 |          type specification, e.g. `{"my_feature": "integer_categorical"}`
 |          or `{"my_feature": FeatureSpace.integer_categorical()}`.
 |          For a complete list of all supported types, see
 |          "Available feature types" paragraph below.
 |      output_mode: One of `"concat"` or `"dict"`. In concat mode, all
 |          features get concatenated together into a single vector.
 |          In dict mode, the FeatureSpace returns a dict of individually
 |          encoded features (with the same keys as the input dict keys).
 |      crosses: List of features to be crossed together, e.g.
 |          `crosses=[("feature_1", "feature_2")]`. The features will be
 |          "crossed" by hashing their combined value into
 |          a fixed-length vector.
 |      crossing_dim: Default vector size for hashing crossed features.
 |          Defaults to `32`.
 |      hashing_dim: Default vector size for hashing features of type
 |          `"integer_hashed"` and `"string_hashed"`. Defaults to `32`.
 |      num_discretization_bins: Default number of bins to be used for
 |          discretizing features of type `"float_discretized"`.
 |          Defaults to `32`.
 |
 |  **Available feature types:**
 |
 |  Note that all features can be referred to by their string name,
 |  e.g. `"integer_categorical"`. When using the string name, the default
 |  argument values are used.
 |
 |  ```python
 |  # Plain float values.
 |  FeatureSpace.float(name=None)
 |
 |  # Float values to be preprocessed via featurewise standardization
 |  # (i.e. via a `keras.layers.Normalization` layer).
 |  FeatureSpace.float_normalized(name=None)
 |
 |  # Float values to be preprocessed via linear rescaling
 |  # (i.e. via a `keras.layers.Rescaling` layer).
 |  FeatureSpace.float_rescaled(scale=1., offset=0., name=None)
 |
 |  # Float values to be discretized. By default, the discrete
 |  # representation will then be one-hot encoded.
 |  FeatureSpace.float_discretized(
 |      num_bins, bin_boundaries=None, output_mode="one_hot", name=None)
 |
 |  # Integer values to be indexed. By default, the discrete
 |  # representation will then be one-hot encoded.
 |  FeatureSpace.integer_categorical(
 |      max_tokens=None, num_oov_indices=1, output_mode="one_hot", name=None)
 |
 |  # String values to be indexed. By default, the discrete
 |  # representation will then be one-hot encoded.
 |  FeatureSpace.string_categorical(
 |      max_tokens=None, num_oov_indices=1, output_mode="one_hot", name=None)
 |
 |  # Integer values to be hashed into a fixed number of bins.
 |  # By default, the discrete representation will then be one-hot encoded.
 |  FeatureSpace.integer_hashed(num_bins, output_mode="one_hot", name=None)
 |
 |  # String values to be hashed into a fixed number of bins.
 |  # By default, the discrete representation will then be one-hot encoded.
 |  FeatureSpace.string_hashed(num_bins, output_mode="one_hot", name=None)
 |  ```
 |
 |  Examples:
 |
 |  **Basic usage with a dict of input data:**
 |
 |  ```python
 |  raw_data = {
 |      "float_values": [0.0, 0.1, 0.2, 0.3],
 |      "string_values": ["zero", "one", "two", "three"],
 |      "int_values": [0, 1, 2, 3],
 |  }
 |  dataset = tf.data.Dataset.from_tensor_slices(raw_data)
 |
 |  feature_space = FeatureSpace(
 |      features={
 |          "float_values": "float_normalized",
 |          "string_values": "string_categorical",
 |          "int_values": "integer_categorical",
 |      },
 |      crosses=[("string_values", "int_values")],
 |      output_mode="concat",
 |  )
 |  # Before you start using the FeatureSpace,
 |  # you must `adapt()` it on some data.
 |  feature_space.adapt(dataset)
 |
 |  # You can call the FeatureSpace on a dict of data (batched or unbatched).
 |  output_vector = feature_space(raw_data)
 |  ```
 |
 |  **Basic usage with `tf.data`:**
 |
 |  ```python
 |  # Unlabeled data
 |  preprocessed_ds = unlabeled_dataset.map(feature_space)
 |
 |  # Labeled data
 |  preprocessed_ds = labeled_dataset.map(lambda x, y: (feature_space(x), y))
 |  ```
 |
 |  **Basic usage with the Keras Functional API:**
 |
 |  ```python
 |  # Retrieve a dict Keras Input objects
 |  inputs = feature_space.get_inputs()
 |  # Retrieve the corresponding encoded Keras tensors
 |  encoded_features = feature_space.get_encoded_features()
 |  # Build a Functional model
 |  outputs = keras.layers.Dense(1, activation="sigmoid")(encoded_features)
 |  model = keras.Model(inputs, outputs)
 |  ```
 |
 |  **Customizing each feature or feature cross:**
 |
 |  ```python
 |  feature_space = FeatureSpace(
 |      features={
 |          "float_values": FeatureSpace.float_normalized(),
 |          "string_values": FeatureSpace.string_categorical(max_tokens=10),
 |          "int_values": FeatureSpace.integer_categorical(max_tokens=10),
 |      },
 |      crosses=[
 |          FeatureSpace.cross(("string_values", "int_values"), crossing_dim=32)
 |      ],
 |      output_mode="concat",
 |  )
 |  ```
 |
 |  **Returning a dict of integer-encoded features:**
 |
 |  ```python
 |  feature_space = FeatureSpace(
 |      features={
 |          "string_values": FeatureSpace.string_categorical(output_mode="int"),
 |          "int_values": FeatureSpace.integer_categorical(output_mode="int"),
 |      },
 |      crosses=[
 |          FeatureSpace.cross(
 |              feature_names=("string_values", "int_values"),
 |              crossing_dim=32,
 |              output_mode="int",
 |          )
 |      ],
 |      output_mode="dict",
 |  )
 |  ```
 |
 |  **Specifying your own Keras preprocessing layer:**
 |
 |  ```python
 |  # Let's say that one of the features is a short text paragraph that
 |  # we want to encode as a vector (one vector per paragraph) via TF-IDF.
 |  data = {
 |      "text": ["1st string", "2nd string", "3rd string"],
 |  }
 |
 |  # There's a Keras layer for this: TextVectorization.
 |  custom_layer = layers.TextVectorization(output_mode="tf_idf")
 |
 |  # We can use FeatureSpace.feature to create a custom feature
 |  # that will use our preprocessing layer.
 |  feature_space = FeatureSpace(
 |      features={
 |          "text": FeatureSpace.feature(
 |              preprocessor=custom_layer, dtype="string", output_mode="float"
 |          ),
 |      },
 |      output_mode="concat",
 |  )
 |  feature_space.adapt(tf.data.Dataset.from_tensor_slices(data))
 |  output_vector = feature_space(data)
 |  ```
 |
 |  **Retrieving the underlying Keras preprocessing layers:**
 |
 |  ```python
 |  # The preprocessing layer of each feature is available in `.preprocessors`.
 |  preprocessing_layer = feature_space.preprocessors["feature1"]
 |
 |  # The crossing layer of each feature cross is available in `.crossers`.
 |  # It's an instance of keras.layers.HashedCrossing.
 |  crossing_layer = feature_space.crossers["feature1_X_feature2"]
 |  ```
 |
 |  **Saving and reloading a FeatureSpace:**
 |
 |  ```python
 |  feature_space.save("featurespace.keras")
 |  reloaded_feature_space = keras.models.load_model("featurespace.keras")
 |  ```
 |
 |  Method resolution order:
 |      FeatureSpace
 |      keras.src.layers.layer.Layer
 |      keras.src.backend.tensorflow.layer.TFLayer
 |      keras.src.backend.tensorflow.trackable.KerasAutoTrackable
 |      tensorflow.python.trackable.autotrackable.AutoTrackable
 |      tensorflow.python.trackable.base.Trackable
 |      keras.src.ops.operation.Operation
 |      builtins.object
 |
 |  Methods defined here:
 |
 |  __call__(self, data)
 |      Call self as a function.
 |
 |  __init__(
 |    self,
 |    features,
 |    output_mode='concat',
 |    crosses=None,
 |    crossing_dim=32,
 |    hashing_dim=32,
 |    num_discretization_bins=32,
 |    name=None
 |  )
 |      Initialize self.  See help(type(self)) for accurate signature.
 |
 |  adapt(self, dataset)
 |
 |  build_from_config(self, config)
 |      Builds the layer's states with the supplied config dict.
 |
 |      By default, this method calls the `build(config["input_shape"])` method,
 |      which creates weights based on the layer's input shape in the supplied
 |      config. If your config contains other information needed to load the
 |      layer's state, you should override this method.
 |
 |      Args:
 |          config: Dict containing the input shape associated with this layer.
 |
 |  get_build_config(self)
 |      Returns a dictionary with the layer's input shape.
 |
 |      This method returns a config dict that can be used by
 |      `build_from_config(config)` to create all states (e.g. Variables and
 |      Lookup tables) needed by the layer.
 |
 |      By default, the config only contains the input shape that the layer
 |      was built with. If you're writing a custom layer that creates state in
 |      an unusual way, you should override this method to make sure this state
 |      is already created when Keras attempts to load its value upon model
 |      loading.
 |
 |      Returns:
 |          A dict containing the input shape associated with the layer.
 |
 |  get_config(self)
 |      Returns the config of the object.
 |
 |      An object config is a Python dictionary (serializable)
 |      containing the information needed to re-instantiate it.
 |
 |  get_encoded_features(self)
 |
 |  get_inputs(self)
 |
 |  load_own_variables(self, store)
 |      Loads the state of the layer.
 |
 |      You can override this method to take full control of how the state of
 |      the layer is loaded upon calling `keras.models.load_model()`.
 |
 |      Args:
 |          store: Dict from which the state of the model will be loaded.
 |
 |  save(self, filepath)
 |      Save the `FeatureSpace` instance to a `.keras` file.
 |
 |      You can reload it via `keras.models.load_model()`:
 |
 |      ```python
 |      feature_space.save("featurespace.keras")
 |      reloaded_fs = keras.models.load_model("featurespace.keras")
 |      ```
 |
 |  save_own_variables(self, store)
 |      Saves the state of the layer.
 |
 |      You can override this method to take full control of how the state of
 |      the layer is saved upon calling `model.save()`.
 |
 |      Args:
 |          store: Dict where the state of the model will be saved.
 |
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |
 |  cross(feature_names, crossing_dim, output_mode='one_hot') from builtins.type
 |
 |  feature(dtype, preprocessor, output_mode) from builtins.type
 |
 |  float(name=None) from builtins.type
 |
 |  float_discretized(num_bins, bin_boundaries=None, output_mode='one_hot', name=None) from builtins.type
 |
 |  float_normalized(name=None) from builtins.type
 |
 |  float_rescaled(scale=1.0, offset=0.0, name=None) from builtins.type
 |
 |  from_config(config) from builtins.type
 |      Creates a layer from its config.
 |
 |      This method is the reverse of `get_config`,
 |      capable of instantiating the same layer from the config
 |      dictionary. It does not handle layer connectivity
 |      (handled by Network), nor weights (handled by `set_weights`).
 |
 |      Args:
 |          config: A Python dictionary, typically the
 |              output of get_config.
 |
 |      Returns:
 |          A layer instance.
 |
 |  integer_categorical(max_tokens=None, num_oov_indices=1, output_mode='one_hot', name=None) from builtins.type
 |
 |  integer_hashed(num_bins, output_mode='one_hot', name=None) from builtins.type
 |
 |  string_categorical(max_tokens=None, num_oov_indices=1, output_mode='one_hot', name=None) from builtins.type
 |
 |  string_hashed(num_bins, output_mode='one_hot', name=None) from builtins.type
 |
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |
 |  __annotations__ = {}
 |

