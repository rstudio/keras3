<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>deep_dream.R • keras</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">Keras for R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Getting Started</li>
    <li>
      <a href="../../articles/sequential_model.html">Guide to the Sequential Model</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Guide to the Functional API</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/tensorboard.html">TensorBoard Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Backend Functions</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/keras">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>deep_dream.R</h1>
            
          </div>

    
    
<div class="contents">
<p>Deep Dreaming in Keras.</p>
<p>It is preferable to run this script on GPU, for speed.</p>
<p>Example results: <a href="http://i.imgur.com/FX6ROg9.jpg" class="uri">http://i.imgur.com/FX6ROg9.jpg</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(keras)
<span class="kw">library</span>(tensorflow)
<span class="kw">library</span>(purrr)
<span class="kw">library</span>(R6)
K &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/backend.html">backend</a></span>()

<span class="co"># Function Definitions ----------------------------------------------------</span>

preprocess_image &lt;-<span class="st"> </span><span class="cf">function</span>(image_path, height, width){
  <span class="kw"><a href="../../reference/image_load.html">image_load</a></span>(image_path, <span class="dt">target_size =</span> <span class="kw">c</span>(height, width)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw"><a href="../../reference/image_to_array.html">image_to_array</a></span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">array</span>(<span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="kw">dim</span>(.))) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw"><a href="../../reference/imagenet_preprocess_input.html">imagenet_preprocess_input</a></span>()
}

deprocess_image &lt;-<span class="st"> </span><span class="cf">function</span>(x){
  x &lt;-<span class="st"> </span>x[<span class="dv">1</span>,,,]
  <span class="co"># Remove zero-center by mean pixel</span>
  x[,,<span class="dv">1</span>] &lt;-<span class="st"> </span>x[,,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="fl">103.939</span>
  x[,,<span class="dv">2</span>] &lt;-<span class="st"> </span>x[,,<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="fl">116.779</span>
  x[,,<span class="dv">3</span>] &lt;-<span class="st"> </span>x[,,<span class="dv">3</span>] <span class="op">+</span><span class="st"> </span><span class="fl">123.68</span>
  <span class="co"># 'BGR'-&gt;'RGB'</span>
  x &lt;-<span class="st"> </span>x[,,<span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">1</span>)]
  <span class="co"># clip to interval 0, 255</span>
  x[x <span class="op">&gt;</span><span class="st"> </span><span class="dv">255</span>] &lt;-<span class="st"> </span><span class="dv">255</span>
  x[x <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>] &lt;-<span class="st"> </span><span class="dv">0</span>
  x[] &lt;-<span class="st"> </span><span class="kw">as.integer</span>(x)<span class="op">/</span><span class="dv">255</span>
  x
}

<span class="co"># calculates the total variation loss</span>
<span class="co"># https://en.wikipedia.org/wiki/Total_variation_denoising</span>
total_variation_loss &lt;-<span class="st"> </span><span class="cf">function</span>(x, h, w){
  
  y_ij  &lt;-<span class="st"> </span>x[,<span class="dv">0</span><span class="op">:</span>(h <span class="op">-</span><span class="st"> </span>2L), <span class="dv">0</span><span class="op">:</span>(w <span class="op">-</span><span class="st"> </span>2L),]
  y_i1j &lt;-<span class="st"> </span>x[,<span class="dv">1</span><span class="op">:</span>(h <span class="op">-</span><span class="st"> </span>1L), <span class="dv">0</span><span class="op">:</span>(w <span class="op">-</span><span class="st"> </span>2L),]
  y_ij1 &lt;-<span class="st"> </span>x[,<span class="dv">0</span><span class="op">:</span>(h <span class="op">-</span><span class="st"> </span>2L), <span class="dv">1</span><span class="op">:</span>(w <span class="op">-</span><span class="st"> </span>1L),]
  
  a &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">square</span>(y_ij <span class="op">-</span><span class="st"> </span>y_i1j)
  b &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">square</span>(y_ij <span class="op">-</span><span class="st"> </span>y_ij1)
  K<span class="op">$</span><span class="kw">sum</span>(K<span class="op">$</span><span class="kw">pow</span>(a <span class="op">+</span><span class="st"> </span>b, <span class="fl">1.25</span>))
}


<span class="co"># Parameters --------------------------------------------------------</span>

<span class="co"># some settings we found interesting</span>
saved_settings =<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">bad_trip =</span> <span class="kw">list</span>(
    <span class="dt">features =</span> <span class="kw">list</span>(
      <span class="dt">block4_conv1 =</span> <span class="fl">0.05</span>,
      <span class="dt">block4_conv2 =</span> <span class="fl">0.01</span>,
      <span class="dt">block4_conv3 =</span> <span class="fl">0.01</span>
    ),
    <span class="dt">continuity =</span> <span class="fl">0.1</span>,
    <span class="dt">dream_l2 =</span> <span class="fl">0.8</span>,
    <span class="dt">jitter =</span>  <span class="dv">5</span>
  ),
  <span class="dt">dreamy =</span> <span class="kw">list</span>(
    <span class="dt">features =</span> <span class="kw">list</span>(
      <span class="dt">block5_conv1 =</span> <span class="fl">0.05</span>,
      <span class="dt">block5_conv2 =</span> <span class="fl">0.02</span>
    ),
    <span class="dt">continuity =</span> <span class="fl">0.1</span>,
    <span class="dt">dream_l2 =</span> <span class="fl">0.02</span>,
    <span class="dt">jitter =</span> <span class="dv">0</span>
  )
)

<span class="co"># the settings we will use in this experiment</span>
img_height &lt;-<span class="st"> </span>600L
img_width &lt;-<span class="st"> </span>600L
img_size &lt;-<span class="st"> </span><span class="kw">c</span>(img_height, img_width, <span class="dv">3</span>)
settings &lt;-<span class="st"> </span>saved_settings<span class="op">$</span>dreamy
image &lt;-<span class="st"> </span><span class="kw">preprocess_image</span>(<span class="st">"deep_dream.jpg"</span>, img_height, img_width)

<span class="co"># Model definition --------------------------------------------------------</span>

<span class="co"># this will contain our generated image</span>
dream &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">batch_shape =</span> <span class="kw">c</span>(<span class="dv">1</span>, img_size))

<span class="co"># build the VGG16 network with our placeholder</span>
<span class="co"># the model will be loaded with pre-trained ImageNet weights</span>
model &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/application_vgg.html">application_vgg16</a></span>(<span class="dt">input_tensor =</span> dream, <span class="dt">weights =</span> <span class="st">"imagenet"</span>,
                           <span class="dt">include_top =</span> <span class="ot">FALSE</span>)


<span class="co"># get the symbolic outputs of each "key" layer (we gave them unique names).</span>
layer_dict &lt;-<span class="st"> </span>model<span class="op">$</span>layers
<span class="kw">names</span>(layer_dict) &lt;-<span class="st"> </span><span class="kw">map_chr</span>(layer_dict ,<span class="op">~</span>.x<span class="op">$</span>name)

<span class="co"># define the loss</span>
loss &lt;-<span class="st"> </span>tf<span class="op">$</span><span class="kw">Variable</span>(<span class="fl">0.0</span>)
<span class="cf">for</span>(layer_name <span class="cf">in</span> <span class="kw">names</span>(settings<span class="op">$</span>features)){
  <span class="co"># add the L2 norm of the features of a layer to the loss</span>
  coeff &lt;-<span class="st"> </span>settings<span class="op">$</span>features[[layer_name]]
  x &lt;-<span class="st"> </span>layer_dict[[layer_name]]<span class="op">$</span>output
  out_shape &lt;-<span class="st"> </span>layer_dict[[layer_name]]<span class="op">$</span>output_shape <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()
  <span class="co"># we avoid border artifacts by only involving non-border pixels in the loss</span>
  loss &lt;-<span class="st"> </span>loss <span class="op">-</span><span class="st"> </span>
<span class="st">    </span>coeff<span class="op">*</span>K<span class="op">$</span><span class="kw">sum</span>(K<span class="op">$</span><span class="kw">square</span>(x[,<span class="dv">3</span><span class="op">:</span>(out_shape[<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span><span class="dv">2</span>), <span class="dv">3</span><span class="op">:</span>(out_shape[<span class="dv">3</span>] <span class="op">-</span><span class="st"> </span><span class="dv">2</span>),])) <span class="op">/</span><span class="st"> </span>
<span class="st">    </span><span class="kw">prod</span>(out_shape[<span class="op">-</span><span class="dv">1</span>])
}

<span class="co"># add continuity loss (gives image local coherence, can result in an artful blur)</span>
loss &lt;-<span class="st"> </span>loss <span class="op">+</span><span class="st"> </span>settings<span class="op">$</span>continuity<span class="op">*</span>
<span class="st">  </span><span class="kw">total_variation_loss</span>(<span class="dt">x =</span> dream, img_height, img_width)<span class="op">/</span>
<span class="st">  </span><span class="kw">prod</span>(img_size)
<span class="co"># add image L2 norm to loss (prevents pixels from taking very high values, makes image darker)</span>
loss &lt;-<span class="st"> </span>loss <span class="op">+</span><span class="st"> </span>settings<span class="op">$</span>dream_l2<span class="op">*</span>K<span class="op">$</span><span class="kw">sum</span>(K<span class="op">$</span><span class="kw">square</span>(dream))<span class="op">/</span><span class="kw">prod</span>(img_size)

<span class="co"># feel free to further modify the loss as you see fit, to achieve new effects...</span>

<span class="co"># compute the gradients of the dream wrt the loss</span>
grads &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">gradients</span>(loss, dream)[[<span class="dv">1</span>]] 

f_outputs &lt;-<span class="st"> </span>K<span class="op">$</span><span class="st">`</span><span class="dt">function</span><span class="st">`</span>(<span class="kw">list</span>(dream), <span class="kw">list</span>(loss,grads))

eval_loss_and_grads &lt;-<span class="st"> </span><span class="cf">function</span>(image){
  <span class="kw">dim</span>(image) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, img_size)
  outs &lt;-<span class="st"> </span><span class="kw">f_outputs</span>(<span class="kw">list</span>(image))
  <span class="kw">list</span>(
    <span class="dt">loss_value =</span> outs[[<span class="dv">1</span>]],
    <span class="dt">grad_values =</span> <span class="kw">as.numeric</span>(outs[[<span class="dv">2</span>]])
  )
}

<span class="co"># Loss and gradients evaluator.</span>
<span class="co"># </span>
<span class="co"># This Evaluator class makes it possible</span>
<span class="co"># to compute loss and gradients in one pass</span>
<span class="co"># while retrieving them via two separate functions,</span>
<span class="co"># "loss" and "grads". This is done because scipy.optimize</span>
<span class="co"># requires separate functions for loss and gradients,</span>
<span class="co"># but computing them separately would be inefficient.</span>
Evaluator &lt;-<span class="st"> </span><span class="kw">R6Class</span>(
  <span class="st">"Evaluator"</span>,
  <span class="dt">public =</span> <span class="kw">list</span>(
    
    <span class="dt">loss_value =</span> <span class="ot">NULL</span>,
    <span class="dt">grad_values =</span> <span class="ot">NULL</span>,
    
    <span class="dt">initialize =</span> <span class="cf">function</span>() {
      self<span class="op">$</span>loss_value &lt;-<span class="st"> </span><span class="ot">NULL</span>
      self<span class="op">$</span>grad_values &lt;-<span class="st"> </span><span class="ot">NULL</span>
    },
    
    <span class="dt">loss =</span> <span class="cf">function</span>(x){
      loss_and_grad &lt;-<span class="st"> </span><span class="kw">eval_loss_and_grads</span>(x)
      self<span class="op">$</span>loss_value &lt;-<span class="st"> </span>loss_and_grad<span class="op">$</span>loss_value
      self<span class="op">$</span>grad_values &lt;-<span class="st"> </span>loss_and_grad<span class="op">$</span>grad_values
      self<span class="op">$</span>loss_value
    },
    
    <span class="dt">grads =</span> <span class="cf">function</span>(x){
      grad_values &lt;-<span class="st"> </span>self<span class="op">$</span>grad_values
      self<span class="op">$</span>loss_value &lt;-<span class="st"> </span><span class="ot">NULL</span>
      self<span class="op">$</span>grad_values &lt;-<span class="st"> </span><span class="ot">NULL</span>
      grad_values
    }
      
  )
)

evaluator &lt;-<span class="st"> </span>Evaluator<span class="op">$</span><span class="kw">new</span>()

<span class="co"># Run optimization (L-BFGS) over the pixels of the generated image</span>
<span class="co"># so as to minimize the loss</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>){
  
  <span class="co"># add random jitter to initial image</span>
  random_jitter &lt;-<span class="st"> </span>settings<span class="op">$</span>jitter<span class="op">*</span><span class="dv">2</span><span class="op">*</span>(<span class="kw">runif</span>(<span class="kw">prod</span>(img_size)) <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">array</span>(<span class="dt">dim =</span> <span class="kw">c</span>(<span class="dv">1</span>, img_size))
  image &lt;-<span class="st"> </span>image <span class="op">+</span><span class="st"> </span>random_jitter

  <span class="co"># Run L-BFGS</span>
  opt &lt;-<span class="st"> </span><span class="kw">optim</span>(
    <span class="kw">as.numeric</span>(image), <span class="dt">fn =</span> evaluator<span class="op">$</span>loss, <span class="dt">gr =</span> evaluator<span class="op">$</span>grads, 
    <span class="dt">method =</span> <span class="st">"L-BFGS-B"</span>,
    <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">maxit =</span> <span class="dv">2</span>)
    )
  
  <span class="co"># Print loss value</span>
  <span class="kw">print</span>(opt<span class="op">$</span>value)
  
  <span class="co"># decode the image</span>
  image &lt;-<span class="st"> </span>opt<span class="op">$</span>par
  <span class="kw">dim</span>(image) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, img_size)
  image &lt;-<span class="st"> </span>image <span class="op">-</span><span class="st"> </span>random_jitter

  <span class="co"># plot</span>
  im &lt;-<span class="st"> </span><span class="kw">deprocess_image</span>(image)
  <span class="kw">plot</span>(<span class="kw">as.raster</span>(im))
  
}</code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by JJ Allaire, François Chollet, <a href="https://www.rstudio.com"><img src="http://tidyverse.org/rstudio-logo.svg" height="24"></a>,  Google.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
