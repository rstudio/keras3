[{"path":"https://keras.posit.co/articles/custom_train_step_in_jax.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Customizing what happens in `fit()` with JAX","text":"’re supervised learning, can use fit() everything works smoothly. need take control every little detail, can write training loop entirely scratch. need custom training algorithm, still want benefit convenient features fit(), callbacks, built-distribution support, step fusing? core principle Keras progressive disclosure complexity. always able get lower-level workflows gradual way. shouldn’t fall cliff high-level functionality doesn’t exactly match use case. able gain control small details retaining commensurate amount high-level convenience. need customize fit() , override training step function Model class. function called fit() every batch data. able call fit() usual – running learning algorithm. Note pattern prevent building models Functional API. can whether ’re building Sequential models, Functional API models, subclassed models. Let’s see works.","code":""},{"path":"https://keras.posit.co/articles/custom_train_step_in_jax.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Customizing what happens in `fit()` with JAX","text":"","code":"import os  # This guide can only be run with the JAX backend. os.environ[\"KERAS_BACKEND\"] = \"jax\"  import jax import keras import numpy as np"},{"path":"https://keras.posit.co/articles/custom_train_step_in_jax.html","id":"a-first-simple-example","dir":"Articles","previous_headings":"","what":"A first simple example","title":"Customizing what happens in `fit()` with JAX","text":"Let’s start simple example: create new class subclasses keras.Model. implement fully-stateless compute_loss_and_updates() method compute loss well updated values non-trainable variables model. Internally, calls stateless_call() built-compute_loss(). implement fully-stateless train_step() method compute current metric values (including loss) well updated values trainable variables, optimizer variables, metric variables. Note can also take account sample_weight argument : Unpacking data x, y, sample_weight = data Passing sample_weight compute_loss() Passing sample_weight alongside y y_pred metrics stateless_update_state() Let’s try :","code":"class CustomModel(keras.Model):     def compute_loss_and_updates(         self,         trainable_variables,         non_trainable_variables,         x,         y,         training=False,     ):         y_pred, non_trainable_variables = self.stateless_call(             trainable_variables,             non_trainable_variables,             x,             training=training,         )         loss = self.compute_loss(x, y, y_pred)         return loss, (y_pred, non_trainable_variables)      def train_step(self, state, data):         (             trainable_variables,             non_trainable_variables,             optimizer_variables,             metrics_variables,         ) = state         x, y = data          # Get the gradient function.         grad_fn = jax.value_and_grad(             self.compute_loss_and_updates, has_aux=True         )          # Compute the gradients.         (loss, (y_pred, non_trainable_variables)), grads = grad_fn(             trainable_variables,             non_trainable_variables,             x,             y,             training=True,         )          # Update trainable variables and optimizer variables.         (             trainable_variables,             optimizer_variables,         ) = self.optimizer.stateless_apply(             optimizer_variables, grads, trainable_variables         )          # Update metrics.         new_metrics_vars = []         for metric in self.metrics:             this_metric_vars = metrics_variables[                 len(new_metrics_vars) : len(new_metrics_vars)                 + len(metric.variables)             ]             if metric.name == \"loss\":                 this_metric_vars = metric.stateless_update_state(                     this_metric_vars, loss                 )             else:                 this_metric_vars = metric.stateless_update_state(                     this_metric_vars, y, y_pred                 )             logs = metric.stateless_result(this_metric_vars)             new_metrics_vars += this_metric_vars          # Return metric logs and updated state variables.         state = (             trainable_variables,             non_trainable_variables,             optimizer_variables,             new_metrics_vars,         )         return logs, state # Construct and compile an instance of CustomModel inputs = keras.Input(shape=(32,)) outputs = keras.layers.Dense(1)(inputs) model = CustomModel(inputs, outputs) model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])  # Just use `fit` as usual x = np.random.random((1000, 32)) y = np.random.random((1000, 1)) model.fit(x, y, epochs=3)"},{"path":"https://keras.posit.co/articles/custom_train_step_in_jax.html","id":"going-lower-level","dir":"Articles","previous_headings":"","what":"Going lower-level","title":"Customizing what happens in `fit()` with JAX","text":"Naturally, just skip passing loss function compile(), instead everything manually train_step. Likewise metrics. ’s lower-level example, uses compile() configure optimizer:","code":"class CustomModel(keras.Model):     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)         self.loss_tracker = keras.metrics.Mean(name=\"loss\")         self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")         self.loss_fn = keras.losses.MeanSquaredError()      def compute_loss_and_updates(         self,         trainable_variables,         non_trainable_variables,         x,         y,         training=False,     ):         y_pred, non_trainable_variables = self.stateless_call(             trainable_variables,             non_trainable_variables,             x,             training=training,         )         loss = self.loss_fn(y, y_pred)         return loss, (y_pred, non_trainable_variables)      def train_step(self, state, data):         (             trainable_variables,             non_trainable_variables,             optimizer_variables,             metrics_variables,         ) = state         x, y = data          # Get the gradient function.         grad_fn = jax.value_and_grad(             self.compute_loss_and_updates, has_aux=True         )          # Compute the gradients.         (loss, (y_pred, non_trainable_variables)), grads = grad_fn(             trainable_variables,             non_trainable_variables,             x,             y,             training=True,         )          # Update trainable variables and optimizer variables.         (             trainable_variables,             optimizer_variables,         ) = self.optimizer.stateless_apply(             optimizer_variables, grads, trainable_variables         )          # Update metrics.         loss_tracker_vars = metrics_variables[             : len(self.loss_tracker.variables)         ]         mae_metric_vars = metrics_variables[len(self.loss_tracker.variables) :]          loss_tracker_vars = self.loss_tracker.stateless_update_state(             loss_tracker_vars, loss         )         mae_metric_vars = self.mae_metric.stateless_update_state(             mae_metric_vars, y, y_pred         )          logs = {}         logs[self.loss_tracker.name] = self.loss_tracker.stateless_result(             loss_tracker_vars         )         logs[self.mae_metric.name] = self.mae_metric.stateless_result(             mae_metric_vars         )          new_metrics_vars = loss_tracker_vars + mae_metric_vars          # Return metric logs and updated state variables.         state = (             trainable_variables,             non_trainable_variables,             optimizer_variables,             new_metrics_vars,         )         return logs, state      @property     def metrics(self):         # We list our `Metric` objects here so that `reset_states()` can be         # called automatically at the start of each epoch         # or at the start of `evaluate()`.         return [self.loss_tracker, self.mae_metric]   # Construct an instance of CustomModel inputs = keras.Input(shape=(32,)) outputs = keras.layers.Dense(1)(inputs) model = CustomModel(inputs, outputs)  # We don't passs a loss or metrics here. model.compile(optimizer=\"adam\")  # Just use `fit` as usual -- you can use callbacks, etc. x = np.random.random((1000, 32)) y = np.random.random((1000, 1)) model.fit(x, y, epochs=5)"},{"path":"https://keras.posit.co/articles/custom_train_step_in_jax.html","id":"providing-your-own-evaluation-step","dir":"Articles","previous_headings":"","what":"Providing your own evaluation step","title":"Customizing what happens in `fit()` with JAX","text":"want calls model.evaluate()? override test_step exactly way. ’s looks like: ’s !","code":"class CustomModel(keras.Model):     def test_step(self, state, data):         # Unpack the data.         x, y = data         (             trainable_variables,             non_trainable_variables,             metrics_variables,         ) = state          # Compute predictions and loss.         y_pred, non_trainable_variables = self.stateless_call(             trainable_variables,             non_trainable_variables,             x,             training=False,         )         loss = self.compute_loss(x, y, y_pred)          # Update metrics.         new_metrics_vars = []         for metric in self.metrics:             this_metric_vars = metrics_variables[                 len(new_metrics_vars) : len(new_metrics_vars)                 + len(metric.variables)             ]             if metric.name == \"loss\":                 this_metric_vars = metric.stateless_update_state(                     this_metric_vars, loss                 )             else:                 this_metric_vars = metric.stateless_update_state(                     this_metric_vars, y, y_pred                 )             logs = metric.stateless_result(this_metric_vars)             new_metrics_vars += this_metric_vars          # Return metric logs and updated state variables.         state = (             trainable_variables,             non_trainable_variables,             new_metrics_vars,         )         return logs, state   # Construct an instance of CustomModel inputs = keras.Input(shape=(32,)) outputs = keras.layers.Dense(1)(inputs) model = CustomModel(inputs, outputs) model.compile(loss=\"mse\", metrics=[\"mae\"])  # Evaluate with our custom test_step x = np.random.random((1000, 32)) y = np.random.random((1000, 1)) model.evaluate(x, y)"},{"path":"https://keras.posit.co/articles/custom_train_step_in_tensorflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Customizing what happens in `fit()` with TensorFlow","text":"’re supervised learning, can use fit() everything works smoothly. need take control every little detail, can write training loop entirely scratch. need custom training algorithm, still want benefit convenient features fit(), callbacks, built-distribution support, step fusing? core principle Keras progressive disclosure complexity. always able get lower-level workflows gradual way. shouldn’t fall cliff high-level functionality doesn’t exactly match use case. able gain control small details retaining commensurate amount high-level convenience. need customize fit() , override training step function Model class. function called fit() every batch data. able call fit() usual – running learning algorithm. Note pattern prevent building models Functional API. can whether ’re building Sequential models, Functional API models, subclassed models. Let’s see works.","code":""},{"path":"https://keras.posit.co/articles/custom_train_step_in_tensorflow.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Customizing what happens in `fit()` with TensorFlow","text":"","code":"library(reticulate) library(tensorflow, exclude = c(\"set_random_seed\", \"shape\")) library(keras3)"},{"path":"https://keras.posit.co/articles/custom_train_step_in_tensorflow.html","id":"a-first-simple-example","dir":"Articles","previous_headings":"","what":"A first simple example","title":"Customizing what happens in `fit()` with TensorFlow","text":"Let’s start simple example: create new class subclasses Model. just override method train_step(self, data). return dictionary mapping metric names (including loss) current value. input argument data gets passed fit training data: pass arrays, calling fit(x, y, ...), data list (x, y) pass tf_dataset, calling fit(dataset, ...), data gets yielded dataset batch. body train_step() method, implement regular training update, similar already familiar . Importantly, compute loss via self.compute_loss(), wraps loss(es) function(s) passed compile(). Similarly, call metric$update_state(y, y_pred) metrics self$metrics, update state metrics passed compile(), query results self$metrics end retrieve current value. Let’s try :","code":"CustomModel <- new_model_class(   \"CustomModel\",   train_step = function(data) {     c(x, y, sample_weight) %<-% unpack_x_y_sample_weight(data)      with(tf$GradientTape() %as% tape, {       y_pred <- self(x, training = TRUE)       loss <- self$compute_loss(y = y, y_pred = y_pred,                                 sample_weight = sample_weight)     })      # Compute gradients     trainable_vars <- self$trainable_variables     gradients <- tape$gradient(loss, trainable_vars)      # Update weights     self$optimizer$apply(gradients, trainable_vars)      # Update metrics (includes the metric that tracks the loss)     for (metric in self$metrics) {       if (metric$name == \"loss\")         metric$update_state(loss)       else         metric$update_state(y, y_pred)     }      # Return a dict mapping metric names to current value     metrics <- lapply(self$metrics, function(m) m$result())     metrics <- setNames(metrics, sapply(self$metrics, function(m) m$name))     metrics   } ) # Construct and compile an instance of CustomModel inputs <- keras_input(shape = 32) outputs <- layer_dense(inputs, 1) model <- CustomModel(inputs, outputs) model |> compile(optimizer = \"adam\", loss = \"mse\", metrics = \"mae\")  # Just use `fit` as usual x <- random_normal(c(1000, 32)) y <- random_normal(c(1000, 1)) model |> fit(x, y, epochs = 3) ## Epoch 1/3 ## 32/32 - 1s - 22ms/step - loss: 2.9118 - mae: 1.3597 ## Epoch 2/3 ## 32/32 - 0s - 1ms/step - loss: 2.6026 - mae: 1.2856 ## Epoch 3/3 ## 32/32 - 0s - 1ms/step - loss: 2.3378 - mae: 1.2193"},{"path":"https://keras.posit.co/articles/custom_train_step_in_tensorflow.html","id":"going-lower-level","dir":"Articles","previous_headings":"","what":"Going lower-level","title":"Customizing what happens in `fit()` with TensorFlow","text":"Naturally, just skip passing loss function compile(), instead everything manually train_step. Likewise metrics. ’s lower-level example, uses compile() configure optimizer: start creating Metric instances track loss MAE score (__init__()). implement custom train_step() updates state metrics (calling update_state() ), query (via result()) return current average value, displayed progress bar pass callback. Note need call reset_states() metrics epoch! Otherwise calling result() return average since start training, whereas usually work per-epoch averages. Thankfully, framework can us: just list metric want reset metrics property model. model call reset_states() object listed beginning fit() epoch beginning call evaluate().","code":"CustomModel <- new_model_class(   \"CustomModel\",   initialize = function(...) {     super$initialize(...)     self$loss_tracker <- metric_mean(name = \"loss\")     self$mae_metric <- metric_mean_absolute_error(name = \"mae\")     self$loss_fn <- loss_mean_squared_error()   },   train_step = function(data) {     c(x, y, sample_weight) %<-% unpack_x_y_sample_weight(data)      with(tf$GradientTape() %as% tape, {       y_pred <- self(x, training = TRUE)       loss <- self$loss_fn(y, y_pred, sample_weight = sample_weight)     })      # Compute gradients     trainable_vars <- self$trainable_variables     gradients <- tape$gradient(loss, trainable_vars)      # Update weights     self$optimizer$apply(gradients, trainable_vars)      # Compute our own metrics     self$loss_tracker$update_state(loss)     self$mae_metric$update_state(y, y_pred)      # Return a dict mapping metric names to current value     list(       loss = self$loss_tracker$result(),       mae = self$mae_metric$result()     )   },   metrics = mark_active(function() {     # We list our `Metric` objects here so that `reset_states()` can be     # called automatically at the start of each epoch     # or at the start of `evaluate()`.     list(self$loss_tracker, self$mae_metric)   }) )   # Construct and compile an instance of CustomModel inputs <- keras_input(shape = 32) outputs <- layer_dense(inputs, 1) model <- CustomModel(inputs, outputs)  # We don't pass a loss or metrics here. model |> compile(optimizer = \"adam\")  # Just use `fit` as usual x <- random_normal(c(1000, 32)) y <- random_normal(c(1000, 1)) model |> fit(x, y, epochs = 3) ## Epoch 1/3 ## 32/32 - 1s - 19ms/step - loss: 2.6540 - mae: 1.2901 ## Epoch 2/3 ## 32/32 - 0s - 1ms/step - loss: 2.4139 - mae: 1.2303 ## Epoch 3/3 ## 32/32 - 0s - 1ms/step - loss: 2.2080 - mae: 1.1761"},{"path":"https://keras.posit.co/articles/custom_train_step_in_tensorflow.html","id":"supporting-sample_weight-class_weight","dir":"Articles","previous_headings":"","what":"Supporting sample_weight & class_weight","title":"Customizing what happens in `fit()` with TensorFlow","text":"may noticed first basic example didn’t make mention sample weighting. want support fit() arguments sample_weight class_weight, ’d simply following: Unpack sample_weight data argument Pass compute_loss & update_state (course, also just apply manually don’t rely compile() losses & metrics) ’s .","code":"CustomModel <- new_model_class(   \"CustomModel\",   train_step = function(data) {     c(x, y, sample_weight) %<-% unpack_x_y_sample_weight(data)      with(tf$GradientTape() %as% tape, {       y_pred <- self(x, training = TRUE)       loss <- self$compute_loss(y = y, y_pred = y_pred,                                 sample_weight = sample_weight)     })      # Compute gradients     trainable_vars <- self$trainable_variables     gradients <- tape$gradient(loss, trainable_vars)      # Update weights     self$optimizer$apply_gradients(zip_lists(gradients, trainable_vars))      # Update metrics (includes the metric that tracks the loss)     for (metric in self$metrics) {       if (metric$name == \"loss\") {         metric$update_state(loss)       } else {         metric$update_state(y, y_pred, sample_weight = sample_weight)       }     }      # Return a dict mapping metric names to current value     metrics <- lapply(self$metrics, function(m) m$result())     metrics <- setNames(metrics, sapply(self$metrics, function(m) m$name))     metrics   } )   # Construct and compile an instance of CustomModel inputs <- keras_input(shape = 32) outputs <- layer_dense(inputs, units = 1) model <- CustomModel(inputs, outputs) model |> compile(optimizer = \"adam\", loss = \"mse\", metrics = \"mae\")  # You can now use sample_weight argument x <- random_normal(c(1000, 32)) y <- random_normal(c(1000, 1)) sw <- random_normal(c(1000, 1)) model |> fit(x, y, sample_weight = sw, epochs = 3) ## Epoch 1/3 ## 32/32 - 1s - 24ms/step - loss: 0.1607 - mae: 1.3018 ## Epoch 2/3 ## 32/32 - 0s - 1ms/step - loss: 0.1452 - mae: 1.2999 ## Epoch 3/3 ## 32/32 - 0s - 1ms/step - loss: 0.1335 - mae: 1.2986"},{"path":"https://keras.posit.co/articles/custom_train_step_in_tensorflow.html","id":"providing-your-own-evaluation-step","dir":"Articles","previous_headings":"","what":"Providing your own evaluation step","title":"Customizing what happens in `fit()` with TensorFlow","text":"want calls model.evaluate()? override test_step exactly way. ’s looks like:","code":"CustomModel <- new_model_class(   \"CustomModel\",   test_step = function(data) {     # Unpack the data     c(x, y, sw) %<-% unpack_x_y_sample_weight(data)     # Compute predictions     y_pred = self(x, training = FALSE)     # Updates the metrics tracking the loss     self$compute_loss(y = y, y_pred = y_pred, sample_weight = sw)     # Update the metrics.     for (metric in self$metrics) {       if (metric$name != \"loss\") {         metric$update_state(y, y_pred, sample_weight = sw)       }     }     # Return a dict mapping metric names to current value.     # Note that it will include the loss (tracked in self.metrics).     metrics <- lapply(self$metrics, function(m) m$result())     metrics <- setNames(metrics, sapply(self$metrics, function(m) m$name))     metrics   } )  # Construct an instance of CustomModel inputs <- keras_input(shape = 32) outputs <- layer_dense(inputs, 1) model <- CustomModel(inputs, outputs) model |> compile(loss = \"mse\", metrics = \"mae\")  # Evaluate with our custom test_step x <- random_normal(c(1000, 32)) y <- random_normal(c(1000, 1)) model |> evaluate(x, y) ## 32/32 - 0s - 10ms/step - loss: 0.0000e+00 - mae: 1.3947 ## $loss ## [1] 0 ## ## $mae ## [1] 1.394695"},{"path":"https://keras.posit.co/articles/custom_train_step_in_tensorflow.html","id":"wrapping-up-an-end-to-end-gan-example","dir":"Articles","previous_headings":"","what":"Wrapping up: an end-to-end GAN example","title":"Customizing what happens in `fit()` with TensorFlow","text":"Let’s walk end--end example leverages everything just learned. Let’s consider: generator network meant generate 28x28x1 images. discriminator network meant classify 28x28x1 images two classes (“fake” “real”). One optimizer . loss function train discriminator. ’s feature-complete GAN class, overriding compile() use signature, implementing entire GAN algorithm 17 lines train_step: Let’s test-drive : ideas behind deep learning simple, implementation painful?","code":"# Create the discriminator discriminator <-   keras_model_sequential(name = \"discriminator\", input_shape = c(28, 28, 1)) |>    layer_conv_2d(filters = 64, kernel_size = c(3, 3),                 strides = c(2, 2),  padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>    layer_conv_2d(filters = 128, kernel_size = c(3, 3),                 strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>    layer_global_max_pooling_2d() |>   layer_dense(units = 1)   # Create the generator latent_dim <- 128 generator <-   keras_model_sequential(name = \"generator\", input_shape = latent_dim) |>    layer_dense(7 * 7 * 128) |>   layer_activation_leaky_relu(negative_slope = 0.2) |>    layer_reshape(target_shape = c(7, 7, 128)) |>    layer_conv_2d_transpose(filters = 128, kernel_size = c(4, 4),                           strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>    layer_conv_2d_transpose(filters = 128, kernel_size = c(4, 4),                           strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>    layer_conv_2d(filters = 1, kernel_size = c(7, 7), padding = \"same\",                 activation = \"sigmoid\") GAN <- Model(   classname = \"GAN\",    initialize = function(discriminator, generator, latent_dim, ...) {     super$initialize(...)     self$discriminator <- discriminator     self$generator <- generator     self$latent_dim <- as.integer(latent_dim)     self$d_loss_tracker <- metric_mean(name = \"d_loss\")     self$g_loss_tracker <- metric_mean(name = \"g_loss\")   },    compile = function(d_optimizer, g_optimizer, loss_fn, ...) {     super$compile(...)     self$d_optimizer <- d_optimizer     self$g_optimizer <- g_optimizer     self$loss_fn <- loss_fn   },   metrics = active_property(function() {     list(self$d_loss_tracker, self$g_loss_tracker)   }),    train_step = function(real_images) {      # Sample random points in the latent space     batch_size <- shape(real_images)[[1]]     random_latent_vectors <-       tf$random$normal(shape(batch_size, self$latent_dim))      # Decode them to fake images     generated_images <- self$generator(random_latent_vectors)      # Combine them with real images     combined_images <- op_concatenate(list(generated_images,                                            real_images))      # Assemble labels discriminating real from fake images     labels <- op_concatenate(list(op_ones(c(batch_size, 1)),                                   op_zeros(c(batch_size, 1))))      # Add random noise to the labels - important trick!     labels %<>% `+`(tf$random$uniform(shape(.), maxval = 0.05))      # Train the discriminator     with(tf$GradientTape() %as% tape, {       predictions <- self$discriminator(combined_images)       d_loss <- self$loss_fn(labels, predictions)     })     grads <- tape$gradient(d_loss, self$discriminator$trainable_weights)     self$d_optimizer$apply_gradients(       zip_lists(grads, self$discriminator$trainable_weights))      # Sample random points in the latent space     random_latent_vectors <-       tf$random$normal(shape(batch_size, self$latent_dim))      # Assemble labels that say \"all real images\"     misleading_labels <- op_zeros(c(batch_size, 1))      # Train the generator (note that we should *not* update the weights     # of the discriminator)!     with(tf$GradientTape() %as% tape, {       predictions <- self$discriminator(self$generator(random_latent_vectors))       g_loss <- self$loss_fn(misleading_labels, predictions)     })     grads <- tape$gradient(g_loss, self$generator$trainable_weights)     self$g_optimizer$apply_gradients(       zip_lists(grads, self$generator$trainable_weights))      list(d_loss = d_loss, g_loss = g_loss)   } ) batch_size <- 64 c(c(x_train, .), c(x_test, .)) %<-% dataset_mnist() all_digits <- op_concatenate(list(x_train, x_test)) all_digits <- op_reshape(all_digits, c(-1, 28, 28, 1)) dataset <- all_digits |>   tfdatasets::tensor_slices_dataset() |>   tfdatasets::dataset_map(\\(x) op_cast(x, \"float32\") / 255) |>   tfdatasets::dataset_shuffle(buffer_size = 1024) |>   tfdatasets::dataset_batch(batch_size = batch_size)  gan <- GAN(discriminator = discriminator,            generator = generator,            latent_dim = latent_dim)  gan |> compile(   d_optimizer = optimizer_adam(learning_rate = 0.0003),   g_optimizer = optimizer_adam(learning_rate = 0.0003),   loss_fn = loss_binary_crossentropy(from_logits = TRUE) )  # To limit the execution time, we only train on 100 batches. You can train on # the entire dataset. You will need about 20 epochs to get nice results. gan |> fit(   tfdatasets::dataset_take(dataset, 100),   epochs = 1 ) ## 100/100 - 5s - 54ms/step - d_loss: 0.0000e+00 - g_loss: 0.0000e+00"},{"path":"https://keras.posit.co/articles/custom_train_step_in_torch.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Customizing what happens in `fit()` with PyTorch","text":"’re supervised learning, can use fit() everything works smoothly. need take control every little detail, can write training loop entirely scratch. need custom training algorithm, still want benefit convenient features fit(), callbacks, built-distribution support, step fusing? core principle Keras progressive disclosure complexity. always able get lower-level workflows gradual way. shouldn’t fall cliff high-level functionality doesn’t exactly match use case. able gain control small details retaining commensurate amount high-level convenience. need customize fit() , override training step function Model class. function called fit() every batch data. able call fit() usual – running learning algorithm. Note pattern prevent building models Functional API. can whether ’re building Sequential models, Functional API models, subclassed models. Let’s see works.","code":""},{"path":"https://keras.posit.co/articles/custom_train_step_in_torch.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Customizing what happens in `fit()` with PyTorch","text":"","code":"import os  # This guide can only be run with the torch backend. os.environ[\"KERAS_BACKEND\"] = \"torch\"  import torch import keras from keras import layers import numpy as np"},{"path":"https://keras.posit.co/articles/custom_train_step_in_torch.html","id":"a-first-simple-example","dir":"Articles","previous_headings":"","what":"A first simple example","title":"Customizing what happens in `fit()` with PyTorch","text":"Let’s start simple example: create new class subclasses keras.Model. just override method train_step(self, data). return dictionary mapping metric names (including loss) current value. input argument data gets passed fit training data: pass NumPy arrays, calling fit(x, y, ...), data tuple (x, y) pass torch.utils.data.DataLoader tf.data.Dataset, calling fit(dataset, ...), data gets yielded dataset batch. body train_step() method, implement regular training update, similar already familiar . Importantly, compute loss via self.compute_loss(), wraps loss(es) function(s) passed compile(). Similarly, call metric.update_state(y, y_pred) metrics self.metrics, update state metrics passed compile(), query results self.metrics end retrieve current value. Let’s try :","code":"class CustomModel(keras.Model):     def train_step(self, data):         # Unpack the data. Its structure depends on your model and         # on what you pass to `fit()`.         x, y = data          # Call torch.nn.Module.zero_grad() to clear the leftover gradients         # for the weights from the previous train step.         self.zero_grad()          # Compute loss         y_pred = self(x, training=True)  # Forward pass         loss = self.compute_loss(y=y, y_pred=y_pred)          # Call torch.Tensor.backward() on the loss to compute gradients         # for the weights.         loss.backward()          trainable_weights = [v for v in self.trainable_weights]         gradients = [v.value.grad for v in trainable_weights]          # Update weights         with torch.no_grad():             self.optimizer.apply(gradients, trainable_weights)          # Update metrics (includes the metric that tracks the loss)         for metric in self.metrics:             if metric.name == \"loss\":                 metric.update_state(loss)             else:                 metric.update_state(y, y_pred)          # Return a dict mapping metric names to current value         # Note that it will include the loss (tracked in self.metrics).         return {m.name: m.result() for m in self.metrics} # Construct and compile an instance of CustomModel inputs = keras.Input(shape=(32,)) outputs = keras.layers.Dense(1)(inputs) model = CustomModel(inputs, outputs) model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])  # Just use `fit` as usual x = np.random.random((1000, 32)) y = np.random.random((1000, 1)) model.fit(x, y, epochs=3)"},{"path":"https://keras.posit.co/articles/custom_train_step_in_torch.html","id":"going-lower-level","dir":"Articles","previous_headings":"","what":"Going lower-level","title":"Customizing what happens in `fit()` with PyTorch","text":"Naturally, just skip passing loss function compile(), instead everything manually train_step. Likewise metrics. ’s lower-level example, uses compile() configure optimizer: start creating Metric instances track loss MAE score (__init__()). implement custom train_step() updates state metrics (calling update_state() ), query (via result()) return current average value, displayed progress bar pass callback. Note need call reset_states() metrics epoch! Otherwise calling result() return average since start training, whereas usually work per-epoch averages. Thankfully, framework can us: just list metric want reset metrics property model. model call reset_states() object listed beginning fit() epoch beginning call evaluate().","code":"class CustomModel(keras.Model):     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)         self.loss_tracker = keras.metrics.Mean(name=\"loss\")         self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")         self.loss_fn = keras.losses.MeanSquaredError()      def train_step(self, data):         x, y = data          # Call torch.nn.Module.zero_grad() to clear the leftover gradients         # for the weights from the previous train step.         self.zero_grad()          # Compute loss         y_pred = self(x, training=True)  # Forward pass         loss = self.loss_fn(y, y_pred)          # Call torch.Tensor.backward() on the loss to compute gradients         # for the weights.         loss.backward()          trainable_weights = [v for v in self.trainable_weights]         gradients = [v.value.grad for v in trainable_weights]          # Update weights         with torch.no_grad():             self.optimizer.apply(gradients, trainable_weights)          # Compute our own metrics         self.loss_tracker.update_state(loss)         self.mae_metric.update_state(y, y_pred)         return {             \"loss\": self.loss_tracker.result(),             \"mae\": self.mae_metric.result(),         }      @property     def metrics(self):         # We list our `Metric` objects here so that `reset_states()` can be         # called automatically at the start of each epoch         # or at the start of `evaluate()`.         return [self.loss_tracker, self.mae_metric]   # Construct an instance of CustomModel inputs = keras.Input(shape=(32,)) outputs = keras.layers.Dense(1)(inputs) model = CustomModel(inputs, outputs)  # We don't passs a loss or metrics here. model.compile(optimizer=\"adam\")  # Just use `fit` as usual -- you can use callbacks, etc. x = np.random.random((1000, 32)) y = np.random.random((1000, 1)) model.fit(x, y, epochs=5)"},{"path":"https://keras.posit.co/articles/custom_train_step_in_torch.html","id":"supporting-sample_weight-class_weight","dir":"Articles","previous_headings":"","what":"Supporting sample_weight & class_weight","title":"Customizing what happens in `fit()` with PyTorch","text":"may noticed first basic example didn’t make mention sample weighting. want support fit() arguments sample_weight class_weight, ’d simply following: Unpack sample_weight data argument Pass compute_loss & update_state (course, also just apply manually don’t rely compile() losses & metrics) ’s .","code":"class CustomModel(keras.Model):     def train_step(self, data):         # Unpack the data. Its structure depends on your model and         # on what you pass to `fit()`.         if len(data) == 3:             x, y, sample_weight = data         else:             sample_weight = None             x, y = data          # Call torch.nn.Module.zero_grad() to clear the leftover gradients         # for the weights from the previous train step.         self.zero_grad()          # Compute loss         y_pred = self(x, training=True)  # Forward pass         loss = self.compute_loss(             y=y,             y_pred=y_pred,             sample_weight=sample_weight,         )          # Call torch.Tensor.backward() on the loss to compute gradients         # for the weights.         loss.backward()          trainable_weights = [v for v in self.trainable_weights]         gradients = [v.value.grad for v in trainable_weights]          # Update weights         with torch.no_grad():             self.optimizer.apply(gradients, trainable_weights)          # Update metrics (includes the metric that tracks the loss)         for metric in self.metrics:             if metric.name == \"loss\":                 metric.update_state(loss)             else:                 metric.update_state(y, y_pred, sample_weight=sample_weight)          # Return a dict mapping metric names to current value         # Note that it will include the loss (tracked in self.metrics).         return {m.name: m.result() for m in self.metrics}   # Construct and compile an instance of CustomModel inputs = keras.Input(shape=(32,)) outputs = keras.layers.Dense(1)(inputs) model = CustomModel(inputs, outputs) model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])  # You can now use sample_weight argument x = np.random.random((1000, 32)) y = np.random.random((1000, 1)) sw = np.random.random((1000, 1)) model.fit(x, y, sample_weight=sw, epochs=3)"},{"path":"https://keras.posit.co/articles/custom_train_step_in_torch.html","id":"providing-your-own-evaluation-step","dir":"Articles","previous_headings":"","what":"Providing your own evaluation step","title":"Customizing what happens in `fit()` with PyTorch","text":"want calls model.evaluate()? override test_step exactly way. ’s looks like:","code":"class CustomModel(keras.Model):     def test_step(self, data):         # Unpack the data         x, y = data         # Compute predictions         y_pred = self(x, training=False)         # Updates the metrics tracking the loss         loss = self.compute_loss(y=y, y_pred=y_pred)         # Update the metrics.         for metric in self.metrics:             if metric.name == \"loss\":                 metric.update_state(loss)             else:                 metric.update_state(y, y_pred)         # Return a dict mapping metric names to current value.         # Note that it will include the loss (tracked in self.metrics).         return {m.name: m.result() for m in self.metrics}   # Construct an instance of CustomModel inputs = keras.Input(shape=(32,)) outputs = keras.layers.Dense(1)(inputs) model = CustomModel(inputs, outputs) model.compile(loss=\"mse\", metrics=[\"mae\"])  # Evaluate with our custom test_step x = np.random.random((1000, 32)) y = np.random.random((1000, 1)) model.evaluate(x, y)"},{"path":"https://keras.posit.co/articles/custom_train_step_in_torch.html","id":"wrapping-up-an-end-to-end-gan-example","dir":"Articles","previous_headings":"","what":"Wrapping up: an end-to-end GAN example","title":"Customizing what happens in `fit()` with PyTorch","text":"Let’s walk end--end example leverages everything just learned. Let’s consider: generator network meant generate 28x28x1 images. discriminator network meant classify 28x28x1 images two classes (“fake” “real”). One optimizer . loss function train discriminator. ’s feature-complete GAN class, overriding compile() use signature, implementing entire GAN algorithm 17 lines train_step: Let’s test-drive : ideas behind deep learning simple, implementation painful?","code":"# Create the discriminator discriminator = keras.Sequential(     [         keras.Input(shape=(28, 28, 1)),         layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),         layers.LeakyReLU(negative_slope=0.2),         layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),         layers.LeakyReLU(negative_slope=0.2),         layers.GlobalMaxPooling2D(),         layers.Dense(1),     ],     name=\"discriminator\", )  # Create the generator latent_dim = 128 generator = keras.Sequential(     [         keras.Input(shape=(latent_dim,)),         # We want to generate 128 coefficients to reshape into a 7x7x128 map         layers.Dense(7 * 7 * 128),         layers.LeakyReLU(negative_slope=0.2),         layers.Reshape((7, 7, 128)),         layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),         layers.LeakyReLU(negative_slope=0.2),         layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),         layers.LeakyReLU(negative_slope=0.2),         layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),     ],     name=\"generator\", ) class GAN(keras.Model):     def __init__(self, discriminator, generator, latent_dim):         super().__init__()         self.discriminator = discriminator         self.generator = generator         self.latent_dim = latent_dim         self.d_loss_tracker = keras.metrics.Mean(name=\"d_loss\")         self.g_loss_tracker = keras.metrics.Mean(name=\"g_loss\")         self.seed_generator = keras.random.SeedGenerator(1337)         self.built = True      @property     def metrics(self):         return [self.d_loss_tracker, self.g_loss_tracker]      def compile(self, d_optimizer, g_optimizer, loss_fn):         super().compile()         self.d_optimizer = d_optimizer         self.g_optimizer = g_optimizer         self.loss_fn = loss_fn      def train_step(self, real_images):         if isinstance(real_images, tuple):             real_images = real_images[0]         # Sample random points in the latent space         batch_size = real_images.shape[0]         random_latent_vectors = keras.random.normal(             shape=(batch_size, self.latent_dim), seed=self.seed_generator         )          # Decode them to fake images         generated_images = self.generator(random_latent_vectors)          # Combine them with real images         real_images = torch.tensor(real_images)         combined_images = torch.concat([generated_images, real_images], axis=0)          # Assemble labels discriminating real from fake images         labels = torch.concat(             [torch.ones((batch_size, 1)), torch.zeros((batch_size, 1))], axis=0         )         # Add random noise to the labels - important trick!         labels += 0.05 * keras.random.uniform(             labels.shape, seed=self.seed_generator         )          # Train the discriminator         self.zero_grad()         predictions = self.discriminator(combined_images)         d_loss = self.loss_fn(labels, predictions)         d_loss.backward()         grads = [v.value.grad for v in self.discriminator.trainable_weights]         with torch.no_grad():             self.d_optimizer.apply(grads, self.discriminator.trainable_weights)          # Sample random points in the latent space         random_latent_vectors = keras.random.normal(             shape=(batch_size, self.latent_dim), seed=self.seed_generator         )          # Assemble labels that say \"all real images\"         misleading_labels = torch.zeros((batch_size, 1))          # Train the generator (note that we should *not* update the weights         # of the discriminator)!         self.zero_grad()         predictions = self.discriminator(self.generator(random_latent_vectors))         g_loss = self.loss_fn(misleading_labels, predictions)         grads = g_loss.backward()         grads = [v.value.grad for v in self.generator.trainable_weights]         with torch.no_grad():             self.g_optimizer.apply(grads, self.generator.trainable_weights)          # Update metrics and return their value.         self.d_loss_tracker.update_state(d_loss)         self.g_loss_tracker.update_state(g_loss)         return {             \"d_loss\": self.d_loss_tracker.result(),             \"g_loss\": self.g_loss_tracker.result(),         } # Prepare the dataset. We use both the training & test MNIST digits. batch_size = 64 (x_train, _), (x_test, _) = keras.datasets.mnist.load_data() all_digits = np.concatenate([x_train, x_test]) all_digits = all_digits.astype(\"float32\") / 255.0 all_digits = np.reshape(all_digits, (-1, 28, 28, 1))  # Create a TensorDataset dataset = torch.utils.data.TensorDataset(     torch.from_numpy(all_digits), torch.from_numpy(all_digits) ) # Create a DataLoader dataloader = torch.utils.data.DataLoader(     dataset, batch_size=batch_size, shuffle=True )  gan = GAN(     discriminator=discriminator, generator=generator, latent_dim=latent_dim ) gan.compile(     d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),     g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),     loss_fn=keras.losses.BinaryCrossentropy(from_logits=True), )  gan.fit(dataloader, epochs=1)"},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Customizing Saving and Serialization","text":"guide covers advanced methods can customized Keras saving. users, methods outlined primary Serialize, save, export guide sufficient.","code":""},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"apis","dir":"Articles","previous_headings":"Introduction","what":"APIs","title":"Customizing Saving and Serialization","text":"cover following APIs: save_assets() load_assets() save_own_variables() load_own_variables() get_build_config() build_from_config() get_compile_config() compile_from_config() restoring model, get executed following order: build_from_config() compile_from_config() load_own_variables() load_assets()","code":""},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Customizing Saving and Serialization","text":"","code":"import os import numpy as np import keras"},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"state-saving-customization","dir":"Articles","previous_headings":"","what":"State saving customization","title":"Customizing Saving and Serialization","text":"methods determine state model’s layers saved calling model.save(). can override take full control state saving process.","code":""},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"save_own_variables-and-load_own_variables","dir":"Articles","previous_headings":"State saving customization","what":"save_own_variables() and load_own_variables()","title":"Customizing Saving and Serialization","text":"methods save load state variables layer model.save() keras.models.load_model() called, respectively. default, state variables saved loaded weights layer (trainable non-trainable). default implementation save_own_variables(): store used methods dictionary can populated layer variables. Let’s take look example customizing . Example:","code":"def save_own_variables(self, store):     all_vars = self._trainable_weights + self._non_trainable_weights     for i, v in enumerate(all_vars):         store[f\"{i}\"] = v.numpy() @keras.utils.register_keras_serializable(package=\"my_custom_package\") class LayerWithCustomVariable(keras.layers.Dense):     def __init__(self, units, **kwargs):         super().__init__(units, **kwargs)         self.my_variable = keras.Variable(             np.random.random((units,)), name=\"my_variable\", dtype=\"float32\"         )      def save_own_variables(self, store):         super().save_own_variables(store)         # Stores the value of the variable upon saving         store[\"variables\"] = self.my_variable.numpy()      def load_own_variables(self, store):         # Assigns the value of the variable upon loading         self.my_variable.assign(store[\"variables\"])         # Load the remaining weights         for i, v in enumerate(self.weights):             v.assign(store[f\"{i}\"])         # Note: You must specify how all variables (including layer weights)         # are loaded in `load_own_variables.`      def call(self, inputs):         dense_out = super().call(inputs)         return dense_out + self.my_variable   model = keras.Sequential([LayerWithCustomVariable(1)])  ref_input = np.random.random((8, 10)) ref_output = np.random.random((8, 10)) model.compile(optimizer=\"adam\", loss=\"mean_squared_error\") model.fit(ref_input, ref_output)  model.save(\"custom_vars_model.keras\") restored_model = keras.models.load_model(\"custom_vars_model.keras\")  np.testing.assert_allclose(     model.layers[0].my_variable.numpy(),     restored_model.layers[0].my_variable.numpy(), )"},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"save_assets-and-load_assets","dir":"Articles","previous_headings":"State saving customization","what":"save_assets() and load_assets()","title":"Customizing Saving and Serialization","text":"methods can added model class definition store load additional information model needs. example, NLP domain layers TextVectorization layers IndexLookup layers may need store associated vocabulary (lookup table) text file upon saving. Let’s take basics workflow simple file assets.txt. Example:","code":"@keras.saving.register_keras_serializable(package=\"my_custom_package\") class LayerWithCustomAssets(keras.layers.Dense):     def __init__(self, vocab=None, *args, **kwargs):         super().__init__(*args, **kwargs)         self.vocab = vocab      def save_assets(self, inner_path):         # Writes the vocab (sentence) to text file at save time.         with open(os.path.join(inner_path, \"vocabulary.txt\"), \"w\") as f:             f.write(self.vocab)      def load_assets(self, inner_path):         # Reads the vocab (sentence) from text file at load time.         with open(os.path.join(inner_path, \"vocabulary.txt\"), \"r\") as f:             text = f.read()         self.vocab = text.replace(\"<unk>\", \"little\")   model = keras.Sequential(     [LayerWithCustomAssets(vocab=\"Mary had a <unk> lamb.\", units=5)] )  x = np.random.random((10, 10)) y = model(x)  model.save(\"custom_assets_model.keras\") restored_model = keras.models.load_model(\"custom_assets_model.keras\")  np.testing.assert_string_equal(     restored_model.layers[0].vocab, \"Mary had a little lamb.\" )"},{"path":[]},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"get_build_config-and-build_from_config","dir":"Articles","previous_headings":"build and compile saving customization","what":"get_build_config() and build_from_config()","title":"Customizing Saving and Serialization","text":"methods work together save layer’s built states restore upon loading. default, includes build config dictionary layer’s input shape, overriding methods can used include Variables Lookup Tables can useful restore built model. Example:","code":"@keras.saving.register_keras_serializable(package=\"my_custom_package\") class LayerWithCustomBuild(keras.layers.Layer):     def __init__(self, units=32, **kwargs):         super().__init__(**kwargs)         self.units = units      def call(self, inputs):         return keras.ops.matmul(inputs, self.w) + self.b      def get_config(self):         return dict(units=self.units, **super().get_config())      def build(self, input_shape, layer_init):         # Note the overriding of `build()` to add an extra argument.         # Therefore, we will need to manually call build with `layer_init` argument         # before the first execution of `call()`.         super().build(input_shape)         self._input_shape = input_shape         self.w = self.add_weight(             shape=(input_shape[-1], self.units),             initializer=layer_init,             trainable=True,         )         self.b = self.add_weight(             shape=(self.units,),             initializer=layer_init,             trainable=True,         )         self.layer_init = layer_init      def get_build_config(self):         build_config = {             \"layer_init\": self.layer_init,             \"input_shape\": self._input_shape,         }  # Stores our initializer for `build()`         return build_config      def build_from_config(self, config):         # Calls `build()` with the parameters at loading time         self.build(config[\"input_shape\"], config[\"layer_init\"])   custom_layer = LayerWithCustomBuild(units=16) custom_layer.build(input_shape=(8,), layer_init=\"random_normal\")  model = keras.Sequential(     [         custom_layer,         keras.layers.Dense(1, activation=\"sigmoid\"),     ] )  x = np.random.random((16, 8)) y = model(x)  model.save(\"custom_build_model.keras\") restored_model = keras.models.load_model(\"custom_build_model.keras\")  np.testing.assert_equal(restored_model.layers[0].layer_init, \"random_normal\") np.testing.assert_equal(restored_model.built, True)"},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"get_compile_config-and-compile_from_config","dir":"Articles","previous_headings":"build and compile saving customization","what":"get_compile_config() and compile_from_config()","title":"Customizing Saving and Serialization","text":"methods work together save information model compiled (optimizers, losses, etc.) restore re-compile model information. Overriding methods can useful compiling restored model custom optimizers, custom losses, etc., need deserialized prior calling model.compile compile_from_config(). Let’s take look example . Example:","code":"@keras.saving.register_keras_serializable(package=\"my_custom_package\") def small_square_sum_loss(y_true, y_pred):     loss = keras.ops.square(y_pred - y_true)     loss = loss / 10.0     loss = keras.ops.sum(loss, axis=1)     return loss   @keras.saving.register_keras_serializable(package=\"my_custom_package\") def mean_pred(y_true, y_pred):     return keras.ops.mean(y_pred)   @keras.saving.register_keras_serializable(package=\"my_custom_package\") class ModelWithCustomCompile(keras.Model):     def __init__(self, **kwargs):         super().__init__(**kwargs)         self.dense1 = keras.layers.Dense(8, activation=\"relu\")         self.dense2 = keras.layers.Dense(4, activation=\"softmax\")      def call(self, inputs):         x = self.dense1(inputs)         return self.dense2(x)      def compile(self, optimizer, loss_fn, metrics):         super().compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)         self.model_optimizer = optimizer         self.loss_fn = loss_fn         self.loss_metrics = metrics      def get_compile_config(self):         # These parameters will be serialized at saving time.         return {             \"model_optimizer\": self.model_optimizer,             \"loss_fn\": self.loss_fn,             \"metric\": self.loss_metrics,         }      def compile_from_config(self, config):         # Deserializes the compile parameters (important, since many are custom)         optimizer = keras.utils.deserialize_keras_object(config[\"model_optimizer\"])         loss_fn = keras.utils.deserialize_keras_object(config[\"loss_fn\"])         metrics = keras.utils.deserialize_keras_object(config[\"metric\"])          # Calls compile with the deserialized parameters         self.compile(optimizer=optimizer, loss_fn=loss_fn, metrics=metrics)   model = ModelWithCustomCompile() model.compile(     optimizer=\"SGD\", loss_fn=small_square_sum_loss, metrics=[\"accuracy\", mean_pred] )  x = np.random.random((4, 8)) y = np.random.random((4,))  model.fit(x, y)  model.save(\"custom_compile_model.keras\") restored_model = keras.models.load_model(\"custom_compile_model.keras\")  np.testing.assert_equal(model.model_optimizer, restored_model.model_optimizer) np.testing.assert_equal(model.loss_fn, restored_model.loss_fn) np.testing.assert_equal(model.loss_metrics, restored_model.loss_metrics)"},{"path":"https://keras.posit.co/articles/customizing_saving_and_serialization.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Customizing Saving and Serialization","text":"Using methods learned tutorial allows wide variety use cases, allowing saving loading complex models exotic assets state elements. recap: save_own_variables load_own_variables determine states saved loaded. save_assets load_assets can added store load additional information model needs. get_build_config build_from_config save restore model’s built states. get_compile_config compile_from_config save restore model’s compiled states.","code":""},{"path":"https://keras.posit.co/articles/distributed_training_with_jax.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Multi-GPU distributed training with JAX","text":"generally two ways distribute computation across multiple devices: Data parallelism, single model gets replicated multiple devices multiple machines. processes different batches data, merge results. exist many variants setup, differ different model replicas merge results, whether stay sync every batch whether loosely coupled, etc. Model parallelism, different parts single model run different devices, processing single batch data together. works best models naturally-parallel architecture, models feature multiple branches. guide focuses data parallelism, particular synchronous data parallelism, different replicas model stay sync batch process. Synchronicity keeps model convergence behavior identical see single-device training. Specifically, guide teaches use jax.sharding APIs train Keras models, minimal changes code, multiple GPUs TPUS (typically 2 16) installed single machine (single host, multi-device training). common setup researchers small-scale industry workflows.","code":""},{"path":"https://keras.posit.co/articles/distributed_training_with_jax.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Multi-GPU distributed training with JAX","text":"Let’s start defining function creates model train, function creates dataset train (MNIST case).","code":"import os  os.environ[\"KERAS_BACKEND\"] = \"jax\"  import jax import numpy as np import tensorflow as tf import keras  from jax.experimental import mesh_utils from jax.sharding import Mesh from jax.sharding import NamedSharding from jax.sharding import PartitionSpec as P   def get_model():     # Make a simple convnet with batch normalization and dropout.     inputs = keras.Input(shape=(28, 28, 1))     x = keras.layers.Rescaling(1.0 / 255.0)(inputs)     x = keras.layers.Conv2D(         filters=12, kernel_size=3, padding=\"same\", use_bias=False     )(x)     x = keras.layers.BatchNormalization(scale=False, center=True)(x)     x = keras.layers.ReLU()(x)     x = keras.layers.Conv2D(         filters=24,         kernel_size=6,         use_bias=False,         strides=2,     )(x)     x = keras.layers.BatchNormalization(scale=False, center=True)(x)     x = keras.layers.ReLU()(x)     x = keras.layers.Conv2D(         filters=32,         kernel_size=6,         padding=\"same\",         strides=2,         name=\"large_k\",     )(x)     x = keras.layers.BatchNormalization(scale=False, center=True)(x)     x = keras.layers.ReLU()(x)     x = keras.layers.GlobalAveragePooling2D()(x)     x = keras.layers.Dense(256, activation=\"relu\")(x)     x = keras.layers.Dropout(0.5)(x)     outputs = keras.layers.Dense(10)(x)     model = keras.Model(inputs, outputs)     return model   def get_datasets():     # Load the data and split it between train and test sets     (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()      # Scale images to the [0, 1] range     x_train = x_train.astype(\"float32\")     x_test = x_test.astype(\"float32\")     # Make sure images have shape (28, 28, 1)     x_train = np.expand_dims(x_train, -1)     x_test = np.expand_dims(x_test, -1)     print(\"x_train shape:\", x_train.shape)     print(x_train.shape[0], \"train samples\")     print(x_test.shape[0], \"test samples\")      # Create TF Datasets     train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))     eval_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))     return train_data, eval_data"},{"path":"https://keras.posit.co/articles/distributed_training_with_jax.html","id":"single-host-multi-device-synchronous-training","dir":"Articles","previous_headings":"","what":"Single-host, multi-device synchronous training","title":"Multi-GPU distributed training with JAX","text":"setup, one machine several GPUs TPUs (typically 2 16). device run copy model (called replica). simplicity, follows, ’ll assume ’re dealing 8 GPUs, loss generality. works step training: current batch data (called global batch) split 8 different sub-batches (called local batches). instance, global batch 512 samples, 8 local batches 64 samples. 8 replicas independently processes local batch: run forward pass, backward pass, outputting gradient weights respect loss model local batch. weight updates originating local gradients efficiently merged across 8 replicas. done end every step, replicas always stay sync. practice, process synchronously updating weights model replicas handled level individual weight variable. done using jax.sharding.NamedSharding configured replicate variables. use single-host, multi-device synchronous training Keras model, use jax.sharding features. ’s works: first create device mesh using mesh_utils.create_device_mesh. specify want replicate model optimizer variables across devices using spec axis. specify want shard data across devices using spec splits along batch dimension. use jax.device_put replicate model optimizer variables across devices. happens beginning. training loop, batch process, use jax.device_put split batch across devices invoking train step. ’s flow, step split utility function: ’s !","code":"# Config num_epochs = 2 batch_size = 64  train_data, eval_data = get_datasets() train_data = train_data.batch(batch_size, drop_remainder=True)  model = get_model() optimizer = keras.optimizers.Adam(1e-3) loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Initialize all state with .build() (one_batch, one_batch_labels) = next(iter(train_data)) model.build(one_batch) optimizer.build(model.trainable_variables)   # This is the loss function that will be differentiated. # Keras provides a pure functional forward pass: model.stateless_call def compute_loss(trainable_variables, non_trainable_variables, x, y):     y_pred, updated_non_trainable_variables = model.stateless_call(         trainable_variables, non_trainable_variables, x     )     loss_value = loss(y, y_pred)     return loss_value, updated_non_trainable_variables   # Function to compute gradients compute_gradients = jax.value_and_grad(compute_loss, has_aux=True)   # Training step, Keras provides a pure functional optimizer.stateless_apply @jax.jit def train_step(train_state, x, y):     (         trainable_variables,         non_trainable_variables,         optimizer_variables,     ) = train_state     (loss_value, non_trainable_variables), grads = compute_gradients(         trainable_variables, non_trainable_variables, x, y     )      trainable_variables, optimizer_variables = optimizer.stateless_apply(         optimizer_variables, grads, trainable_variables     )      return loss_value, (         trainable_variables,         non_trainable_variables,         optimizer_variables,     )   # Replicate the model and optimizer variable on all devices def get_replicated_train_state(devices):     # All variables will be replicated on all devices     var_mesh = Mesh(devices, axis_names=(\"_\"))     # In NamedSharding, axes not mentioned are replicated (all axes here)     var_replication = NamedSharding(var_mesh, P())      # Apply the distribution settings to the model variables     trainable_variables = jax.device_put(         model.trainable_variables, var_replication     )     non_trainable_variables = jax.device_put(         model.non_trainable_variables, var_replication     )     optimizer_variables = jax.device_put(optimizer.variables, var_replication)      # Combine all state in a tuple     return (trainable_variables, non_trainable_variables, optimizer_variables)   num_devices = len(jax.local_devices()) print(f\"Running on {num_devices} devices: {jax.local_devices()}\") devices = mesh_utils.create_device_mesh((num_devices,))  # Data will be split along the batch axis data_mesh = Mesh(devices, axis_names=(\"batch\",))  # naming axes of the mesh data_sharding = NamedSharding(     data_mesh,     P(         \"batch\",     ), )  # naming axes of the sharded partition  # Display data sharding x, y = next(iter(train_data)) sharded_x = jax.device_put(x.numpy(), data_sharding) print(\"Data sharding\") jax.debug.visualize_array_sharding(jax.numpy.reshape(sharded_x, [-1, 28 * 28]))  train_state = get_replicated_train_state(devices)  # Custom training loop for epoch in range(num_epochs):     data_iter = iter(train_data)     for data in data_iter:         x, y = data         sharded_x = jax.device_put(x.numpy(), data_sharding)         loss_value, train_state = train_step(train_state, sharded_x, y.numpy())     print(\"Epoch\", epoch, \"loss:\", loss_value)  # Post-processing model state update to write them back into the model trainable_variables, non_trainable_variables, optimizer_variables = train_state for variable, value in zip(model.trainable_variables, trainable_variables):     variable.assign(value) for variable, value in zip(     model.non_trainable_variables, non_trainable_variables ):     variable.assign(value)"},{"path":"https://keras.posit.co/articles/distributed_training_with_tensorflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Multi-GPU distributed training with TensorFlow","text":"generally two ways distribute computation across multiple devices: Data parallelism, single model gets replicated multiple devices multiple machines. processes different batches data, merge results. exist many variants setup, differ different model replicas merge results, whether stay sync every batch whether loosely coupled, etc. Model parallelism, different parts single model run different devices, processing single batch data together. works best models naturally-parallel architecture, models feature multiple branches. guide focuses data parallelism, particular synchronous data parallelism, different replicas model stay sync batch process. Synchronicity keeps model convergence behavior identical see single-device training. Specifically, guide teaches use tf.distribute API train Keras models multiple GPUs, minimal changes code, multiple GPUs (typically 2 16) installed single machine (single host, multi-device training). common setup researchers small-scale industry workflows.","code":""},{"path":"https://keras.posit.co/articles/distributed_training_with_tensorflow.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Multi-GPU distributed training with TensorFlow","text":"","code":"library(keras3) library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(tfdatasets, exclude = \"shape\")"},{"path":"https://keras.posit.co/articles/distributed_training_with_tensorflow.html","id":"single-host-multi-device-synchronous-training","dir":"Articles","previous_headings":"","what":"Single-host, multi-device synchronous training","title":"Multi-GPU distributed training with TensorFlow","text":"setup, one machine several GPUs (typically 2 16). device run copy model (called replica). simplicity, follows, ’ll assume ’re dealing 8 GPUs, loss generality. works step training: current batch data (called global batch) split 8 different sub-batches (called local batches). instance, global batch 512 samples, 8 local batches 64 samples. 8 replicas independently processes local batch: run forward pass, backward pass, outputting gradient weights respect loss model local batch. weight updates originating local gradients efficiently merged across 8 replicas. done end every step, replicas always stay sync. practice, process synchronously updating weights model replicas handled level individual weight variable. done mirrored variable object. use single-host, multi-device synchronous training Keras model, use tf$distribute$MirroredStrategy API. ’s works: Instantiate MirroredStrategy, optionally configuring specific devices want use (default strategy use GPUs available). Use strategy object open scope, within scope, create Keras objects need contain variables. Typically, means creating & compiling model inside distribution scope. cases, first call fit() may also create variables, ’s good idea put fit() call scope well. Train model via fit() usual. Importantly, recommend use tf.data.Dataset objects load data multi-device distributed workflow. Schematically, looks like : ’s simple end--end runnable example:","code":"# Create a MirroredStrategy. strategy <- tf$distribute$MirroredStrategy() cat(sprintf('Number of devices: %d\\n', strategy$num_replicas_in_sync))  # Open a strategy scope. with(startegy$scope(), {   # Everything that creates variables should be under the strategy scope.   # In general this is only model construction & `compile()`.   model <- Model(...)   model |> compile(...)    # Train the model on all available devices.   model |> fit(train_dataset, validation_data=val_dataset, ...)    # Test the model on all available devices.   model |> evaluate(test_dataset) }) get_compiled_model <- function() {   inputs <- keras_input(shape = 784)   outputs <- inputs |>     layer_dense(units = 256, activation = \"relu\") |>     layer_dense(units = 256, activation = \"relu\") |>     layer_dense(units = 10)   model <- keras_model(inputs, outputs)   model |> compile(     optimizer = optimizer_adam(),     loss = loss_sparse_categorical_crossentropy(from_logits = TRUE),     metrics = list(metric_sparse_categorical_accuracy()),      # XLA compilation is temporarily disabled due to a bug     # https://github.com/keras-team/keras/issues/19005     jit_compile = FALSE   )   model }  get_dataset <- function(batch_size = 64) {    c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()   x_train <- array_reshape(x_train, c(-1, 784))   x_test <- array_reshape(x_test, c(-1, 784))    # Reserve 10,000 samples for validation.   val_i <- sample.int(nrow(x_train), 10000)   x_val <- x_train[val_i,]   y_val <- y_train[val_i]   x_train = x_train[-val_i,]   y_train = y_train[-val_i]    # Prepare the training dataset.   train_dataset <- list(x_train, y_train) |>     tensor_slices_dataset() |>     dataset_batch(batch_size)    # Prepare the validation dataset.   val_dataset <- list(x_val, y_val) |>     tensor_slices_dataset() |>     dataset_batch(batch_size)    # Prepare the test dataset.   test_dataset <- list(x_test, y_test) |>     tensor_slices_dataset() |>     dataset_batch(batch_size)    list(train_dataset, val_dataset, test_dataset) }  # Create a MirroredStrategy. strategy <- tf$distribute$MirroredStrategy() cat(sprintf('Number of devices: %d\\n', strategy$num_replicas_in_sync)) ## Number of devices: 2 # Open a strategy scope. with(strategy$scope(), {   # Everything that creates variables should be under the strategy scope.   # In general this is only model construction & `compile()`.   model <- get_compiled_model()    c(train_dataset, val_dataset, test_dataset) %<-% get_dataset()    # Train the model on all available devices.   model |> fit(train_dataset, epochs = 2, validation_data = val_dataset)    # Test the model on all available devices.   model |> evaluate(test_dataset)  }) ## Epoch 1/2 ## 782/782 - 6s - 7ms/step - loss: 2.9028 - sparse_categorical_accuracy: 0.8634 - val_loss: 1.0579 - val_sparse_categorical_accuracy: 0.9140 ## Epoch 2/2 ## 782/782 - 3s - 4ms/step - loss: 0.6231 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.7157 - val_sparse_categorical_accuracy: 0.9168 ## 157/157 - 0s - 2ms/step - loss: 0.7382 - sparse_categorical_accuracy: 0.9134 ## $loss ## [1] 0.7382208 ## ## $sparse_categorical_accuracy ## [1] 0.9134"},{"path":"https://keras.posit.co/articles/distributed_training_with_tensorflow.html","id":"using-callbacks-to-ensure-fault-tolerance","dir":"Articles","previous_headings":"","what":"Using callbacks to ensure fault tolerance","title":"Multi-GPU distributed training with TensorFlow","text":"using distributed training, always make sure strategy recover failure (fault tolerance). simplest way handle pass ModelCheckpoint callback fit(), save model regular intervals (e.g. every 100 batches every epoch). can restart training saved model. ’s simple example:","code":"# Prepare a directory to store all the checkpoints. checkpoint_dir <- \"./ckpt\" if (!dir.exists(checkpoint_dir)) {   dir.create(checkpoint_dir) }  make_or_restore_model <- function() {   # Either restore the latest model, or create a fresh one   # if there is no checkpoint available.   checkpoints <- list.files(checkpoint_dir, #pattern = \"ckpt-.*\\\\.keras\",                             full.names = TRUE)    if (length(checkpoints) > 0) {     checkpoint_epochs <- as.integer(sub(\"ckpt-([0-9]+)\\\\.keras\", \"\\\\1\",                                         basename(checkpoints)))     latest_checkpoint <- checkpoints[which.max(checkpoint_epochs)]     load_model(latest_checkpoint)   } else {     get_compiled_model()   } }    run_training <- function(epochs = 1) {   # Create a MirroredStrategy.   strategy <- tf$distribute$MirroredStrategy()    # Open a strategy scope and create/restore the model   with(strategy$scope(), {     model <- make_or_restore_model()      callbacks <- list(       # This callback saves a SavedModel every epoch       # We include the current epoch in the folder name.       callback_model_checkpoint(         filepath = paste0(checkpoint_dir, \"/ckpt-{epoch}.keras\"),         save_freq = \"epoch\"       ))      model |> fit(       train_dataset,       epochs = epochs,       callbacks = callbacks,       validation_data = val_dataset,       verbose = 2     )   }) }  # Running the first time creates the model run_training(epochs = 1) ## 782/782 - 5s - 7ms/step - loss: 3.2545 - sparse_categorical_accuracy: 0.8585 - val_loss: 0.9734 - val_sparse_categorical_accuracy: 0.9046 # Calling the same function again will resume from where we left off run_training(epochs = 1) ## 782/782 - 3s - 4ms/step - loss: 0.6964 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.7399 - val_sparse_categorical_accuracy: 0.9138"},{"path":"https://keras.posit.co/articles/distributed_training_with_tensorflow.html","id":"tfdata-performance-tips","dir":"Articles","previous_headings":"","what":"tf$data performance tips","title":"Multi-GPU distributed training with TensorFlow","text":"distributed training, efficiency load data can often become critical. tips make sure tf$data pipelines run fast possible. Note dataset batching creating dataset, make sure batched global batch size. instance, 8 GPUs capable running batch 64 samples, call use global batch size 512. Calling dataset_cache() call dataset_cache() dataset, data cached running first iteration data. Every subsequent iteration use cached data. cache can memory (default) local file specify. can improve performance : data expected change iteration iteration reading data remote distributed filesystem reading data local disk, data fit memory workflow significantly IO-bound (e.g. reading & decoding image files). Calling dataset_prefetch(buffer_size) almost always call dataset_prefetch(buffer_size) creating dataset. means data pipeline run asynchronously model, new samples preprocessed stored buffer current batch samples used train model. next batch prefetched GPU memory time current batch . ’s !","code":""},{"path":"https://keras.posit.co/articles/distributed_training_with_torch.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Multi-GPU distributed training with PyTorch","text":"generally two ways distribute computation across multiple devices: Data parallelism, single model gets replicated multiple devices multiple machines. processes different batches data, merge results. exist many variants setup, differ different model replicas merge results, whether stay sync every batch whether loosely coupled, etc. Model parallelism, different parts single model run different devices, processing single batch data together. works best models naturally-parallel architecture, models feature multiple branches. guide focuses data parallelism, particular synchronous data parallelism, different replicas model stay sync batch process. Synchronicity keeps model convergence behavior identical see single-device training. Specifically, guide teaches use PyTorch’s DistributedDataParallel module wrapper train Keras, minimal changes code, multiple GPUs (typically 2 16) installed single machine (single host, multi-device training). common setup researchers small-scale industry workflows.","code":""},{"path":"https://keras.posit.co/articles/distributed_training_with_torch.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Multi-GPU distributed training with PyTorch","text":"Let’s start defining function creates model train, function creates dataset train (MNIST case). Next, let’s define simple PyTorch training loop targets GPU (note calls .cuda()).","code":"import os  os.environ[\"KERAS_BACKEND\"] = \"torch\"  import torch import numpy as np import keras   def get_model():     # Make a simple convnet with batch normalization and dropout.     inputs = keras.Input(shape=(28, 28, 1))     x = keras.layers.Rescaling(1.0 / 255.0)(inputs)     x = keras.layers.Conv2D(         filters=12, kernel_size=3, padding=\"same\", use_bias=False     )(x)     x = keras.layers.BatchNormalization(scale=False, center=True)(x)     x = keras.layers.ReLU()(x)     x = keras.layers.Conv2D(         filters=24,         kernel_size=6,         use_bias=False,         strides=2,     )(x)     x = keras.layers.BatchNormalization(scale=False, center=True)(x)     x = keras.layers.ReLU()(x)     x = keras.layers.Conv2D(         filters=32,         kernel_size=6,         padding=\"same\",         strides=2,         name=\"large_k\",     )(x)     x = keras.layers.BatchNormalization(scale=False, center=True)(x)     x = keras.layers.ReLU()(x)     x = keras.layers.GlobalAveragePooling2D()(x)     x = keras.layers.Dense(256, activation=\"relu\")(x)     x = keras.layers.Dropout(0.5)(x)     outputs = keras.layers.Dense(10)(x)     model = keras.Model(inputs, outputs)     return model   def get_dataset():     # Load the data and split it between train and test sets     (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()      # Scale images to the [0, 1] range     x_train = x_train.astype(\"float32\")     x_test = x_test.astype(\"float32\")     # Make sure images have shape (28, 28, 1)     x_train = np.expand_dims(x_train, -1)     x_test = np.expand_dims(x_test, -1)     print(\"x_train shape:\", x_train.shape)      # Create a TensorDataset     dataset = torch.utils.data.TensorDataset(         torch.from_numpy(x_train), torch.from_numpy(y_train)     )     return dataset def train_model(model, dataloader, num_epochs, optimizer, loss_fn):     for epoch in range(num_epochs):         running_loss = 0.0         running_loss_count = 0         for batch_idx, (inputs, targets) in enumerate(dataloader):             inputs = inputs.cuda(non_blocking=True)             targets = targets.cuda(non_blocking=True)              # Forward pass             outputs = model(inputs)             loss = loss_fn(outputs, targets)              # Backward and optimize             optimizer.zero_grad()             loss.backward()             optimizer.step()              running_loss += loss.item()             running_loss_count += 1          # Print loss statistics         print(             f\"Epoch {epoch + 1}/{num_epochs}, \"             f\"Loss: {running_loss / running_loss_count}\"         )"},{"path":"https://keras.posit.co/articles/distributed_training_with_torch.html","id":"single-host-multi-device-synchronous-training","dir":"Articles","previous_headings":"","what":"Single-host, multi-device synchronous training","title":"Multi-GPU distributed training with PyTorch","text":"setup, one machine several GPUs (typically 2 16). device run copy model (called replica). simplicity, follows, ’ll assume ’re dealing 8 GPUs, loss generality. works step training: current batch data (called global batch) split 8 different sub-batches (called local batches). instance, global batch 512 samples, 8 local batches 64 samples. 8 replicas independently processes local batch: run forward pass, backward pass, outputting gradient weights respect loss model local batch. weight updates originating local gradients efficiently merged across 8 replicas. done end every step, replicas always stay sync. practice, process synchronously updating weights model replicas handled level individual weight variable. done mirrored variable object. use single-host, multi-device synchronous training Keras model, use torch.nn.parallel.DistributedDataParallel module wrapper. ’s works: use torch.multiprocessing.start_processes start multiple Python processes, one per device. process run per_device_launch_fn function. uses torch.distributed.init_process_group torch.cuda.set_device configure device used process. uses torch.utils.data.distributed.DistributedSampler torch.utils.data.DataLoader turn data distributed data loader. also uses torch.nn.parallel.DistributedDataParallel turn model distributed PyTorch module. calls train_model function. train_model function run process, model using separate device process. ’s flow, step split utility function: Time start multiple processes: ’s !","code":"# Config num_gpu = torch.cuda.device_count() num_epochs = 2 batch_size = 64 print(f\"Running on {num_gpu} GPUs\")   def setup_device(current_gpu_index, num_gpus):     # Device setup     os.environ[\"MASTER_ADDR\"] = \"localhost\"     os.environ[\"MASTER_PORT\"] = \"56492\"     device = torch.device(\"cuda:{}\".format(current_gpu_index))     torch.distributed.init_process_group(         backend=\"nccl\",         init_method=\"env://\",         world_size=num_gpus,         rank=current_gpu_index,     )     torch.cuda.set_device(device)   def cleanup():     torch.distributed.destroy_process_group()   def prepare_dataloader(dataset, current_gpu_index, num_gpus, batch_size):     sampler = torch.utils.data.distributed.DistributedSampler(         dataset,         num_replicas=num_gpus,         rank=current_gpu_index,         shuffle=False,     )     dataloader = torch.utils.data.DataLoader(         dataset,         sampler=sampler,         batch_size=batch_size,         shuffle=False,     )     return dataloader   def per_device_launch_fn(current_gpu_index, num_gpu):     # Setup the process groups     setup_device(current_gpu_index, num_gpu)      dataset = get_dataset()     model = get_model()      # prepare the dataloader     dataloader = prepare_dataloader(         dataset, current_gpu_index, num_gpu, batch_size     )      # Instantiate the torch optimizer     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)      # Instantiate the torch loss function     loss_fn = torch.nn.CrossEntropyLoss()      # Put model on device     model = model.to(current_gpu_index)     ddp_model = torch.nn.parallel.DistributedDataParallel(         model, device_ids=[current_gpu_index], output_device=current_gpu_index     )      train_model(ddp_model, dataloader, num_epochs, optimizer, loss_fn)      cleanup() if __name__ == \"__main__\":     # We use the \"fork\" method rather than \"spawn\" to support notebooks     torch.multiprocessing.start_processes(         per_device_launch_fn,         args=(num_gpu,),         nprocs=num_gpu,         join=True,         start_method=\"fork\",     )"},{"path":"https://keras.posit.co/articles/distribution.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Distributed training with Keras 3","text":"Keras distribution API new interface designed facilitate distributed deep learning across variety backends like JAX, TensorFlow PyTorch. powerful API introduces suite tools enabling data model parallelism, allowing efficient scaling deep learning models multiple accelerators hosts. Whether leveraging power GPUs TPUs, API provides streamlined approach initializing distributed environments, defining device meshes, orchestrating layout tensors across computational resources. classes like DataParallel ModelParallel, abstracts complexity involved parallel computation, making easier developers accelerate machine learning workflows.","code":""},{"path":"https://keras.posit.co/articles/distribution.html","id":"how-it-works","dir":"Articles","previous_headings":"","what":"How it works","title":"Distributed training with Keras 3","text":"Keras distribution API provides global programming model allows developers compose applications operate tensors global context (working single device) automatically managing distribution across many devices. API leverages underlying framework (e.g. JAX) distribute program tensors according sharding directives procedure called single program, multiple data (SPMD) expansion. decoupling application sharding directives, API enables running application single device, multiple devices, even multiple clients, preserving global semantics.","code":""},{"path":"https://keras.posit.co/articles/distribution.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Distributed training with Keras 3","text":"","code":"# This guide assumes there are 8 GPUs available for testing. If you don't have # 8 gpus available locally, you can set the following envvar to # make xla initialize the CPU as 8 devices, to enable local testing Sys.setenv(\"CUDA_VISIBLE_DEVICES\" = \"\") Sys.setenv(\"XLA_FLAGS\" = \"--xla_force_host_platform_device_count=8\") library(keras3)  # The distribution API is only implemented for the JAX backend for now. use_backend(\"jax\") jax <- reticulate::import(\"jax\")  library(tfdatasets, exclude = \"shape\") # For dataset input."},{"path":"https://keras.posit.co/articles/distribution.html","id":"devicemesh-and-tensorlayout","dir":"Articles","previous_headings":"","what":"DeviceMesh and TensorLayout","title":"Distributed training with Keras 3","text":"keras$distribution$DeviceMesh class Keras distribution API represents cluster computational devices configured distributed computation. aligns similar concepts jax.sharding.Mesh tf.dtensor.Mesh, ’s used map physical devices logical mesh structure. TensorLayout class specifies tensors distributed across DeviceMesh, detailing sharding tensors along specified axes correspond names axes DeviceMesh. can find detailed concept explainers TensorFlow DTensor guide.","code":"# Retrieve the local available gpu devices. devices <- jax$devices() # \"gpu\" str(devices) ## List of 8 ##  $ :TFRT_CPU_0 ##  $ :TFRT_CPU_1 ##  $ :TFRT_CPU_2 ##  $ :TFRT_CPU_3 ##  $ :TFRT_CPU_4 ##  $ :TFRT_CPU_5 ##  $ :TFRT_CPU_6 ##  $ :TFRT_CPU_7 # Define a 2x4 device mesh with data and model parallel axes mesh <- keras$distribution$DeviceMesh(   shape = shape(2, 4),   axis_names = list(\"data\", \"model\"),   devices = devices )  # A 2D layout, which describes how a tensor is distributed across the # mesh. The layout can be visualized as a 2D grid with \"model\" as rows and # \"data\" as columns, and it is a [4, 2] grid when it mapped to the physical # devices on the mesh. layout_2d <- keras$distribution$TensorLayout(   axes = c(\"model\", \"data\"),   device_mesh = mesh )  # A 4D layout which could be used for data parallelism of an image input. replicated_layout_4d <- keras$distribution$TensorLayout(   axes = list(\"data\", NULL, NULL, NULL),   device_mesh = mesh )"},{"path":"https://keras.posit.co/articles/distribution.html","id":"distribution","dir":"Articles","previous_headings":"","what":"Distribution","title":"Distributed training with Keras 3","text":"Distribution class Keras serves foundational abstract class designed developing custom distribution strategies. encapsulates core logic needed distribute model’s variables, input data, intermediate computations across device mesh. end user, won’t interact directly class, subclasses like DataParallel ModelParallel.","code":""},{"path":"https://keras.posit.co/articles/distribution.html","id":"dataparallel","dir":"Articles","previous_headings":"","what":"DataParallel","title":"Distributed training with Keras 3","text":"DataParallel class Keras distribution API designed data parallelism strategy distributed training, model weights replicated across devices DeviceMesh, device processes portion input data. sample usage class.","code":"# Create DataParallel with list of devices. # As a shortcut, the devices can be skipped, # and Keras will detect all local available devices. # E.g. data_parallel <- DataParallel() data_parallel <- keras$distribution$DataParallel(devices = devices)  # Or you can choose to create DataParallel with a 1D `DeviceMesh`. mesh_1d <- keras$distribution$DeviceMesh(   shape = shape(8),   axis_names = list(\"data\"),   devices = devices ) data_parallel <- keras$distribution$DataParallel(device_mesh = mesh_1d)  inputs <- random_normal(c(128, 28, 28, 1)) labels <- random_normal(c(128, 10)) dataset <- tensor_slices_dataset(c(inputs, labels)) |>   dataset_batch(16)  # Set the global distribution. keras$distribution$set_distribution(data_parallel)  # Note that all the model weights from here on are replicated to # all the devices of the `DeviceMesh`. This includes the RNG # state, optimizer states, metrics, etc. The dataset fed into `model |> fit()` or # `model |> evaluate()` will be split evenly on the batch dimension, and sent to # all the devices. You don't have to do any manual aggregation of losses, # since all the computation happens in a global context. inputs <- keras_input(shape = c(28, 28, 1)) outputs <- inputs |>   layer_flatten() |>   layer_dense(units = 200, use_bias = FALSE, activation = \"relu\") |>   layer_dropout(0.4) |>   layer_dense(units = 10, activation = \"softmax\")  model <- keras_model(inputs = inputs, outputs = outputs)  model |> compile(loss = \"mse\") model |> fit(dataset, epochs = 3) ## Epoch 1/3 ## 8/8 - 0s - 40ms/step - loss: 1.0604 ## Epoch 2/3 ## 8/8 - 0s - 5ms/step - loss: 0.9732 ## Epoch 3/3 ## 8/8 - 0s - 5ms/step - loss: 0.9253 model |> evaluate(dataset) ## 8/8 - 0s - 7ms/step - loss: 0.8825 ## $loss ## [1] 0.8825469"},{"path":"https://keras.posit.co/articles/distribution.html","id":"modelparallel-and-layoutmap","dir":"Articles","previous_headings":"","what":"ModelParallel and LayoutMap","title":"Distributed training with Keras 3","text":"ModelParallel mostly useful model weights large fit single accelerator. setting allows spit model weights activation tensors across devices DeviceMesh, enable horizontal scaling large models. Unlike DataParallel model weights fully replicated, weights layout ModelParallel usually need customization best performances. introduce LayoutMap let specify TensorLayout weights intermediate tensors global perspective. LayoutMap dict-like object maps string TensorLayout instances. behaves differently normal dict string key treated regex retrieving value. class allows define naming schema TensorLayout retrieve corresponding TensorLayout instance. Typically, key used query variable$path attribute, identifier variable. shortcut, list axis names also allowed inserting value, converted TensorLayout. LayoutMap can also optionally contain DeviceMesh populate TensorLayout$device_mesh set. retrieving layout key, isn’t exact match, existing keys layout map treated regex matched input key . multiple matches, ValueError raised. matches found, NULL returned. also easy change mesh structure tune computation data parallel model parallel. can adjusting shape mesh. changes needed code.","code":"mesh_2d <- keras$distribution$DeviceMesh(   shape = shape(2, 4),   axis_names = c(\"data\", \"model\"),   devices = devices ) layout_map  <- keras$distribution$LayoutMap(mesh_2d)  # The rule below means that for any weights that match with d1/kernel, it # will be sharded with model dimensions (4 devices), same for the d1/bias. # All other weights will be fully replicated. layout_map[\"d1/kernel\"] <- tuple(NULL, \"model\") layout_map[\"d1/bias\"] <- tuple(\"model\")  # You can also set the layout for the layer output like layout_map[\"d2/output\"] <- tuple(\"data\", NULL)  model_parallel <- keras$distribution$ModelParallel(   mesh_2d, layout_map, batch_dim_name = \"data\" )  keras$distribution$set_distribution(model_parallel)  inputs <- layer_input(shape = c(28, 28, 1)) outputs <- inputs |>   layer_flatten() |>   layer_dense(units = 200, use_bias = FALSE,               activation = \"relu\", name = \"d1\") |>   layer_dropout(0.4) |>   layer_dense(units = 10,               activation = \"softmax\",               name = \"d2\")  model <- keras_model(inputs = inputs, outputs = outputs)  # The data will be sharded across the \"data\" dimension of the method, which # has 2 devices. model |> compile(loss = \"mse\") model |> fit(dataset, epochs = 3) ## Epoch 1/3 ## 8/8 - 0s - 30ms/step - loss: 1.0650 ## Epoch 2/3 ## 8/8 - 0s - 4ms/step - loss: 0.9721 ## Epoch 3/3 ## 8/8 - 0s - 4ms/step - loss: 0.9290 model |> evaluate(dataset) ## 8/8 - 0s - 7ms/step - loss: 0.8810 ## $loss ## [1] 0.8810369 full_data_parallel_mesh <- keras$distribution$DeviceMesh(   shape = shape(8, 1),   axis_names = list(\"data\", \"model\"),   devices = devices ) more_data_parallel_mesh <- keras$distribution$DeviceMesh(   shape = shape(4, 2),   axis_names = list(\"data\", \"model\"),   devices = devices ) more_model_parallel_mesh <- keras$distribution$DeviceMesh(   shape = shape(2, 4),   axis_names = list(\"data\", \"model\"),   devices = devices ) full_model_parallel_mesh <- keras$distribution$DeviceMesh(   shape = shape(1, 8),   axis_names = list(\"data\", \"model\"),   devices = devices )"},{"path":"https://keras.posit.co/articles/distribution.html","id":"further-reading","dir":"Articles","previous_headings":"ModelParallel and LayoutMap","what":"Further reading","title":"Distributed training with Keras 3","text":"JAX Distributed arrays automatic parallelization JAX sharding module TensorFlow Distributed training DTensors TensorFlow DTensor concepts Using DTensors tf.keras","code":""},{"path":"https://keras.posit.co/articles/examples/autoencoder.html","id":"introduction","dir":"Articles > Examples","previous_headings":"","what":"Introduction","title":"Convolutional autoencoder for image denoising","text":"example demonstrates implement deep convolutional autoencoder image denoising, mapping noisy digits images MNIST dataset clean digits images. implementation based original blog post titled Building Autoencoders Keras François Chollet.","code":""},{"path":"https://keras.posit.co/articles/examples/autoencoder.html","id":"setup","dir":"Articles > Examples","previous_headings":"","what":"Setup","title":"Convolutional autoencoder for image denoising","text":"","code":"library(keras3)  # Normalizes the supplied array and reshapes it. preprocess <- function(array) {   array_reshape(array/255, c(dim(array)[1], 28, 28, 1)) }  # Adds random noise to each image in the supplied array. noise <- function(array) {   noise_factor <- 0.4   noisy_array <- array + noise_factor * random_normal(dim(array))   op_clip(noisy_array, 0.0, 1.0) }  display <- function(array1, array2) {   n <- 2   indices <- sample.int(dim(array1)[1], n)   images1 <- as.array(array1)[indices, , , ]   images2 <- as.array(array2)[indices, , , ]    par(mfrow = c(2, n), mar = c(0, 0, 0, 0))   for (i in seq_len(n)) {     plot(as.raster(images1[i, , ]))     plot(as.raster(images2[i, , ]))   } }"},{"path":"https://keras.posit.co/articles/examples/autoencoder.html","id":"prepare-the-data","dir":"Articles > Examples","previous_headings":"","what":"Prepare the data","title":"Convolutional autoencoder for image denoising","text":"","code":"# Since we only need images from the dataset to encode and decode, we # won't use the labels. c(c(train_data, .), c(test_data, .)) %<-% dataset_mnist()  # Normalize and reshape the data train_data <- preprocess(train_data) test_data <- preprocess(test_data)  # Create a copy of the data with added noise noisy_train_data <- noise(train_data) noisy_test_data <- noise(test_data)  # Display the train data and a version of it with added noise display(train_data, noisy_train_data)"},{"path":"https://keras.posit.co/articles/examples/autoencoder.html","id":"build-the-autoencoder","dir":"Articles > Examples","previous_headings":"","what":"Build the autoencoder","title":"Convolutional autoencoder for image denoising","text":"going use Functional API build convolutional autoencoder. Now can train autoencoder using train_data input data target. Notice setting validation data using format. Let’s predict test dataset display original image together prediction autoencoder. Notice predictions pretty close original images, although quite . Now know autoencoder works, let’s retrain using noisy data input clean data target. want autoencoder learn denoise images. Let’s now predict noisy data display results autoencoder. Notice autoencoder amazing job removing noise input images.","code":"input <- keras_input(shape = c(28, 28, 1))  # Encoder enc <- input |>   layer_conv_2d(filters = 32, kernel_size = c(3, 3),                 activation = \"relu\", padding = \"same\") |>   layer_max_pooling_2d(pool_size = c(2, 2), padding = \"same\") |>   layer_conv_2d(filters = 32, kernel_size = c(3, 3),                 activation = \"relu\", padding = \"same\") |>   layer_max_pooling_2d(pool_size = c(2, 2), padding = \"same\")  # Decoder dec <- enc |>   layer_conv_2d_transpose(filters = 32, kernel_size = c(3, 3), strides = 2,                           activation = \"relu\", padding = \"same\") |>   layer_conv_2d_transpose(filters = 32, kernel_size = c(3, 3), strides = 2,                           activation = \"relu\", padding = \"same\") |>   layer_conv_2d(filters = 1, kernel_size = c(3, 3),                 activation = \"sigmoid\", padding = \"same\")  # Autoencoder autoencoder <- keras_model(input, dec) autoencoder |> compile(optimizer = \"adam\", loss = \"binary_crossentropy\") autoencoder |> summary() ## Model: \"functional_1\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ input_layer (InputLayer)        │ (None, 28, 28, 1)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_1 (Conv2D)               │ (None, 28, 28, 32)     │           320 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d_1 (MaxPooling2D)  │ (None, 14, 14, 32)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 14, 14, 32)     │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 7, 7, 32)       │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_1              │ (None, 14, 14, 32)     │         9,248 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose                │ (None, 28, 28, 32)     │         9,248 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_2 (Conv2D)               │ (None, 28, 28, 1)      │           289 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 28,353 (110.75 KB) ##  Trainable params: 28,353 (110.75 KB) ##  Non-trainable params: 0 (0.00 B) autoencoder |> fit(   x = train_data,   y = train_data,   epochs = 50,   batch_size = 128,   shuffle = TRUE,   validation_data = list(test_data, test_data), ) ## Epoch 1/50 ## 469/469 - 5s - 10ms/step - loss: 0.1322 - val_loss: 0.0736 ## Epoch 2/50 ## 469/469 - 1s - 3ms/step - loss: 0.0721 - val_loss: 0.0698 ## Epoch 3/50 ## 469/469 - 1s - 3ms/step - loss: 0.0695 - val_loss: 0.0681 ## Epoch 4/50 ## 469/469 - 1s - 3ms/step - loss: 0.0682 - val_loss: 0.0671 ## Epoch 5/50 ## 469/469 - 1s - 3ms/step - loss: 0.0673 - val_loss: 0.0665 ## Epoch 6/50 ## 469/469 - 1s - 3ms/step - loss: 0.0667 - val_loss: 0.0660 ## Epoch 7/50 ## 469/469 - 1s - 3ms/step - loss: 0.0663 - val_loss: 0.0656 ## Epoch 8/50 ## 469/469 - 1s - 3ms/step - loss: 0.0659 - val_loss: 0.0652 ## Epoch 9/50 ## 469/469 - 1s - 3ms/step - loss: 0.0655 - val_loss: 0.0649 ## Epoch 10/50 ## 469/469 - 1s - 3ms/step - loss: 0.0652 - val_loss: 0.0646 ## Epoch 11/50 ## 469/469 - 1s - 3ms/step - loss: 0.0650 - val_loss: 0.0644 ## Epoch 12/50 ## 469/469 - 1s - 3ms/step - loss: 0.0647 - val_loss: 0.0642 ## Epoch 13/50 ## 469/469 - 1s - 3ms/step - loss: 0.0645 - val_loss: 0.0640 ## Epoch 14/50 ## 469/469 - 1s - 3ms/step - loss: 0.0643 - val_loss: 0.0638 ## Epoch 15/50 ## 469/469 - 1s - 3ms/step - loss: 0.0642 - val_loss: 0.0636 ## Epoch 16/50 ## 469/469 - 1s - 3ms/step - loss: 0.0640 - val_loss: 0.0635 ## Epoch 17/50 ## 469/469 - 1s - 3ms/step - loss: 0.0639 - val_loss: 0.0634 ## Epoch 18/50 ## 469/469 - 1s - 3ms/step - loss: 0.0638 - val_loss: 0.0633 ## Epoch 19/50 ## 469/469 - 1s - 3ms/step - loss: 0.0636 - val_loss: 0.0631 ## Epoch 20/50 ## 469/469 - 1s - 3ms/step - loss: 0.0635 - val_loss: 0.0631 ## Epoch 21/50 ## 469/469 - 1s - 3ms/step - loss: 0.0634 - val_loss: 0.0630 ## Epoch 22/50 ## 469/469 - 1s - 3ms/step - loss: 0.0634 - val_loss: 0.0629 ## Epoch 23/50 ## 469/469 - 1s - 3ms/step - loss: 0.0633 - val_loss: 0.0628 ## Epoch 24/50 ## 469/469 - 1s - 3ms/step - loss: 0.0632 - val_loss: 0.0628 ## Epoch 25/50 ## 469/469 - 1s - 3ms/step - loss: 0.0631 - val_loss: 0.0627 ## Epoch 26/50 ## 469/469 - 1s - 3ms/step - loss: 0.0631 - val_loss: 0.0626 ## Epoch 27/50 ## 469/469 - 1s - 3ms/step - loss: 0.0630 - val_loss: 0.0626 ## Epoch 28/50 ## 469/469 - 1s - 3ms/step - loss: 0.0629 - val_loss: 0.0625 ## Epoch 29/50 ## 469/469 - 1s - 3ms/step - loss: 0.0629 - val_loss: 0.0625 ## Epoch 30/50 ## 469/469 - 1s - 3ms/step - loss: 0.0628 - val_loss: 0.0624 ## Epoch 31/50 ## 469/469 - 1s - 3ms/step - loss: 0.0628 - val_loss: 0.0624 ## Epoch 32/50 ## 469/469 - 1s - 3ms/step - loss: 0.0627 - val_loss: 0.0623 ## Epoch 33/50 ## 469/469 - 1s - 3ms/step - loss: 0.0627 - val_loss: 0.0623 ## Epoch 34/50 ## 469/469 - 1s - 3ms/step - loss: 0.0627 - val_loss: 0.0623 ## Epoch 35/50 ## 469/469 - 1s - 3ms/step - loss: 0.0626 - val_loss: 0.0622 ## Epoch 36/50 ## 469/469 - 1s - 3ms/step - loss: 0.0626 - val_loss: 0.0622 ## Epoch 37/50 ## 469/469 - 1s - 3ms/step - loss: 0.0626 - val_loss: 0.0622 ## Epoch 38/50 ## 469/469 - 1s - 3ms/step - loss: 0.0625 - val_loss: 0.0622 ## Epoch 39/50 ## 469/469 - 1s - 3ms/step - loss: 0.0625 - val_loss: 0.0621 ## Epoch 40/50 ## 469/469 - 1s - 3ms/step - loss: 0.0625 - val_loss: 0.0621 ## Epoch 41/50 ## 469/469 - 1s - 3ms/step - loss: 0.0624 - val_loss: 0.0621 ## Epoch 42/50 ## 469/469 - 1s - 3ms/step - loss: 0.0624 - val_loss: 0.0621 ## Epoch 43/50 ## 469/469 - 1s - 3ms/step - loss: 0.0624 - val_loss: 0.0620 ## Epoch 44/50 ## 469/469 - 1s - 3ms/step - loss: 0.0624 - val_loss: 0.0620 ## Epoch 45/50 ## 469/469 - 1s - 3ms/step - loss: 0.0623 - val_loss: 0.0620 ## Epoch 46/50 ## 469/469 - 1s - 3ms/step - loss: 0.0623 - val_loss: 0.0620 ## Epoch 47/50 ## 469/469 - 1s - 3ms/step - loss: 0.0623 - val_loss: 0.0619 ## Epoch 48/50 ## 469/469 - 1s - 3ms/step - loss: 0.0623 - val_loss: 0.0619 ## Epoch 49/50 ## 469/469 - 1s - 3ms/step - loss: 0.0622 - val_loss: 0.0619 ## Epoch 50/50 ## 469/469 - 1s - 3ms/step - loss: 0.0622 - val_loss: 0.0619 predictions <- autoencoder |> predict(test_data) ## 313/313 - 1s - 2ms/step display(test_data, predictions) autoencoder |> fit(   x = noisy_train_data,   y = train_data,   epochs = 100,   batch_size = 128,   shuffle = TRUE,   validation_data = list(noisy_test_data, test_data), ) ## Epoch 1/100 ## 469/469 - 1s - 3ms/step - loss: 0.0998 - val_loss: 0.0928 ## Epoch 2/100 ## 469/469 - 1s - 3ms/step - loss: 0.0925 - val_loss: 0.0908 ## Epoch 3/100 ## 469/469 - 1s - 3ms/step - loss: 0.0910 - val_loss: 0.0898 ## Epoch 4/100 ## 469/469 - 1s - 3ms/step - loss: 0.0900 - val_loss: 0.0890 ## Epoch 5/100 ## 469/469 - 1s - 3ms/step - loss: 0.0893 - val_loss: 0.0883 ## Epoch 6/100 ## 469/469 - 1s - 3ms/step - loss: 0.0888 - val_loss: 0.0877 ## Epoch 7/100 ## 469/469 - 1s - 3ms/step - loss: 0.0883 - val_loss: 0.0873 ## Epoch 8/100 ## 469/469 - 1s - 3ms/step - loss: 0.0879 - val_loss: 0.0870 ## Epoch 9/100 ## 469/469 - 1s - 3ms/step - loss: 0.0876 - val_loss: 0.0868 ## Epoch 10/100 ## 469/469 - 1s - 3ms/step - loss: 0.0873 - val_loss: 0.0866 ## Epoch 11/100 ## 469/469 - 1s - 3ms/step - loss: 0.0871 - val_loss: 0.0863 ## Epoch 12/100 ## 469/469 - 1s - 3ms/step - loss: 0.0869 - val_loss: 0.0861 ## Epoch 13/100 ## 469/469 - 1s - 3ms/step - loss: 0.0867 - val_loss: 0.0860 ## Epoch 14/100 ## 469/469 - 1s - 3ms/step - loss: 0.0865 - val_loss: 0.0858 ## Epoch 15/100 ## 469/469 - 1s - 3ms/step - loss: 0.0864 - val_loss: 0.0857 ## Epoch 16/100 ## 469/469 - 1s - 3ms/step - loss: 0.0862 - val_loss: 0.0855 ## Epoch 17/100 ## 469/469 - 1s - 3ms/step - loss: 0.0861 - val_loss: 0.0854 ## Epoch 18/100 ## 469/469 - 1s - 3ms/step - loss: 0.0860 - val_loss: 0.0853 ## Epoch 19/100 ## 469/469 - 1s - 3ms/step - loss: 0.0859 - val_loss: 0.0852 ## Epoch 20/100 ## 469/469 - 1s - 3ms/step - loss: 0.0858 - val_loss: 0.0852 ## Epoch 21/100 ## 469/469 - 1s - 3ms/step - loss: 0.0857 - val_loss: 0.0851 ## Epoch 22/100 ## 469/469 - 1s - 3ms/step - loss: 0.0856 - val_loss: 0.0850 ## Epoch 23/100 ## 469/469 - 1s - 3ms/step - loss: 0.0855 - val_loss: 0.0850 ## Epoch 24/100 ## 469/469 - 1s - 3ms/step - loss: 0.0855 - val_loss: 0.0849 ## Epoch 25/100 ## 469/469 - 1s - 3ms/step - loss: 0.0854 - val_loss: 0.0849 ## Epoch 26/100 ## 469/469 - 1s - 3ms/step - loss: 0.0854 - val_loss: 0.0848 ## Epoch 27/100 ## 469/469 - 1s - 3ms/step - loss: 0.0853 - val_loss: 0.0848 ## Epoch 28/100 ## 469/469 - 1s - 3ms/step - loss: 0.0853 - val_loss: 0.0847 ## Epoch 29/100 ## 469/469 - 1s - 3ms/step - loss: 0.0852 - val_loss: 0.0847 ## Epoch 30/100 ## 469/469 - 1s - 3ms/step - loss: 0.0852 - val_loss: 0.0847 ## Epoch 31/100 ## 469/469 - 1s - 3ms/step - loss: 0.0851 - val_loss: 0.0847 ## Epoch 32/100 ## 469/469 - 1s - 3ms/step - loss: 0.0851 - val_loss: 0.0846 ## Epoch 33/100 ## 469/469 - 1s - 3ms/step - loss: 0.0851 - val_loss: 0.0846 ## Epoch 34/100 ## 469/469 - 1s - 3ms/step - loss: 0.0850 - val_loss: 0.0846 ## Epoch 35/100 ## 469/469 - 1s - 3ms/step - loss: 0.0850 - val_loss: 0.0845 ## Epoch 36/100 ## 469/469 - 1s - 3ms/step - loss: 0.0850 - val_loss: 0.0845 ## Epoch 37/100 ## 469/469 - 1s - 3ms/step - loss: 0.0849 - val_loss: 0.0845 ## Epoch 38/100 ## 469/469 - 1s - 3ms/step - loss: 0.0849 - val_loss: 0.0845 ## Epoch 39/100 ## 469/469 - 1s - 3ms/step - loss: 0.0849 - val_loss: 0.0845 ## Epoch 40/100 ## 469/469 - 1s - 3ms/step - loss: 0.0849 - val_loss: 0.0844 ## Epoch 41/100 ## 469/469 - 1s - 3ms/step - loss: 0.0848 - val_loss: 0.0844 ## Epoch 42/100 ## 469/469 - 1s - 3ms/step - loss: 0.0848 - val_loss: 0.0844 ## Epoch 43/100 ## 469/469 - 1s - 3ms/step - loss: 0.0848 - val_loss: 0.0844 ## Epoch 44/100 ## 469/469 - 1s - 3ms/step - loss: 0.0848 - val_loss: 0.0844 ## Epoch 45/100 ## 469/469 - 1s - 3ms/step - loss: 0.0847 - val_loss: 0.0843 ## Epoch 46/100 ## 469/469 - 1s - 3ms/step - loss: 0.0847 - val_loss: 0.0843 ## Epoch 47/100 ## 469/469 - 1s - 3ms/step - loss: 0.0847 - val_loss: 0.0843 ## Epoch 48/100 ## 469/469 - 1s - 3ms/step - loss: 0.0847 - val_loss: 0.0843 ## Epoch 49/100 ## 469/469 - 1s - 3ms/step - loss: 0.0847 - val_loss: 0.0843 ## Epoch 50/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0843 ## Epoch 51/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0842 ## Epoch 52/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0842 ## Epoch 53/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0842 ## Epoch 54/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0842 ## Epoch 55/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0842 ## Epoch 56/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0842 ## Epoch 57/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0842 ## Epoch 58/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0842 ## Epoch 59/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0842 ## Epoch 60/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 61/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 62/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 63/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0841 ## Epoch 64/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0841 ## Epoch 65/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0841 ## Epoch 66/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0841 ## Epoch 67/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 68/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 69/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 70/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 71/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 72/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 73/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 74/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 75/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 76/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 77/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 78/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 79/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 80/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 81/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 82/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 83/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 84/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 85/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 86/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 87/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 88/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 89/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 90/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 91/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 92/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 93/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 94/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 95/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 96/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 97/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 98/100 ## 469/469 - 1s - 3ms/step - loss: 0.0841 - val_loss: 0.0839 ## Epoch 99/100 ## 469/469 - 1s - 3ms/step - loss: 0.0841 - val_loss: 0.0839 ## Epoch 100/100 ## 469/469 - 1s - 3ms/step - loss: 0.0841 - val_loss: 0.0839 predictions <- autoencoder |> predict(noisy_test_data) ## 313/313 - 0s - 581us/step display(noisy_test_data, predictions)"},{"path":"https://keras.posit.co/articles/examples/mnist_convnet.html","id":"setup","dir":"Articles > Examples","previous_headings":"","what":"Setup","title":"Simple MNIST convnet","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/examples/mnist_convnet.html","id":"prepare-the-data","dir":"Articles > Examples","previous_headings":"","what":"Prepare the data","title":"Simple MNIST convnet","text":"","code":"# Model / data parameters num_classes <- 10 input_shape <- c(28, 28, 1)  # Load the data and split it between train and test sets c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()  # Scale images to the [0, 1] range x_train <- x_train / 255 x_test <- x_test / 255 # Make sure images have shape (28, 28, 1) x_train <- op_expand_dims(x_train, -1) x_test <- op_expand_dims(x_test, -1)   dim(x_train) ## [1] 60000    28    28     1 dim(x_test) ## [1] 10000    28    28     1 # convert class vectors to binary class matrices y_train <- to_categorical(y_train, num_classes) y_test <- to_categorical(y_test, num_classes)"},{"path":"https://keras.posit.co/articles/examples/mnist_convnet.html","id":"build-the-model","dir":"Articles > Examples","previous_headings":"","what":"Build the model","title":"Simple MNIST convnet","text":"","code":"model <- keras_model_sequential(input_shape = input_shape) model |>   layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = \"relu\") |>   layer_max_pooling_2d(pool_size = c(2, 2)) |>   layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = \"relu\") |>   layer_max_pooling_2d(pool_size = c(2, 2)) |>   layer_flatten() |>   layer_dropout(rate = 0.5) |>   layer_dense(units = num_classes, activation = \"softmax\")  summary(model) ## Model: \"sequential\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ conv2d_1 (Conv2D)               │ (None, 26, 26, 32)     │           320 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d_1 (MaxPooling2D)  │ (None, 13, 13, 32)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 11, 11, 64)     │        18,496 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 5, 5, 64)       │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ flatten (Flatten)               │ (None, 1600)           │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout (Dropout)               │ (None, 1600)           │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense (Dense)                   │ (None, 10)             │        16,010 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 34,826 (136.04 KB) ##  Trainable params: 34,826 (136.04 KB) ##  Non-trainable params: 0 (0.00 B)"},{"path":"https://keras.posit.co/articles/examples/mnist_convnet.html","id":"train-the-model","dir":"Articles > Examples","previous_headings":"","what":"Train the model","title":"Simple MNIST convnet","text":"","code":"batch_size <- 128 epochs <- 15  model |> compile(   loss = \"categorical_crossentropy\",   optimizer = \"adam\",   metrics = \"accuracy\" )  model |> fit(   x_train, y_train,   batch_size = batch_size,   epochs = epochs,   validation_split = 0.1 ) ## Epoch 1/15 ## 422/422 - 4s - 11ms/step - accuracy: 0.8845 - loss: 0.3815 - val_accuracy: 0.9783 - val_loss: 0.0810 ## Epoch 2/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9644 - loss: 0.1151 - val_accuracy: 0.9863 - val_loss: 0.0548 ## Epoch 3/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9735 - loss: 0.0838 - val_accuracy: 0.9880 - val_loss: 0.0455 ## Epoch 4/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9781 - loss: 0.0689 - val_accuracy: 0.9893 - val_loss: 0.0413 ## Epoch 5/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9811 - loss: 0.0608 - val_accuracy: 0.9907 - val_loss: 0.0373 ## Epoch 6/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9824 - loss: 0.0561 - val_accuracy: 0.9908 - val_loss: 0.0359 ## Epoch 7/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9848 - loss: 0.0487 - val_accuracy: 0.9917 - val_loss: 0.0328 ## Epoch 8/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9845 - loss: 0.0484 - val_accuracy: 0.9915 - val_loss: 0.0334 ## Epoch 9/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9859 - loss: 0.0439 - val_accuracy: 0.9923 - val_loss: 0.0320 ## Epoch 10/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9868 - loss: 0.0405 - val_accuracy: 0.9925 - val_loss: 0.0319 ## Epoch 11/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9874 - loss: 0.0387 - val_accuracy: 0.9920 - val_loss: 0.0317 ## Epoch 12/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9882 - loss: 0.0367 - val_accuracy: 0.9925 - val_loss: 0.0301 ## Epoch 13/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9879 - loss: 0.0361 - val_accuracy: 0.9928 - val_loss: 0.0281 ## Epoch 14/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9889 - loss: 0.0332 - val_accuracy: 0.9930 - val_loss: 0.0284 ## Epoch 15/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9897 - loss: 0.0311 - val_accuracy: 0.9925 - val_loss: 0.0293"},{"path":"https://keras.posit.co/articles/examples/mnist_convnet.html","id":"evaluate-the-trained-model","dir":"Articles > Examples","previous_headings":"","what":"Evaluate the trained model","title":"Simple MNIST convnet","text":"","code":"score <- model |> evaluate(x_test, y_test, verbose = 0) score ## $accuracy ## [1] 0.9911 ## ## $loss ## [1] 0.02564374"},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"introduction","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Introduction","title":"Text classification from scratch","text":"example shows text classification starting raw text (set text files disk). demonstrate workflow IMDB sentiment classification dataset (unprocessed version). use [layer_text_vectorization()] word splitting & indexing.","code":""},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"setup","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Setup","title":"Text classification from scratch","text":"","code":"options(conflicts.policy = \"strict\") library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(tfdatasets, exclude = \"shape\") library(keras3) use_virtualenv(\"r-keras\")"},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"load-the-data-imdb-movie-review-sentiment-classification","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Load the data: IMDB movie review sentiment classification","title":"Text classification from scratch","text":"Let’s download data inspect structure. aclImdb folder contains train test subfolder: aclImdb/train/pos aclImdb/train/neg folders contain text files, represents one review (either positive negative): interested pos neg subfolders, let’s delete subfolder text files : can use utility text_dataset_from_directory() generate labeled tf_dataset object set text files disk filed class-specific folders. Let’s use generate training, validation, test datasets. validation training datasets generated two subsets train directory, 20% samples going validation dataset 80% going training dataset. validation dataset addition test dataset useful tuning hyperparameters, model architecture, test dataset used. putting model real world however, retrained using available training data (without creating validation dataset), performance maximized. using validation_split subset arguments, make sure either specify random seed, pass shuffle=FALSE, validation & training splits get overlap. Let’s preview samples:","code":"if (!dir.exists(\"datasets/aclImdb\")) {   dir.create(\"datasets\")   download.file(     \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",     \"datasets/aclImdb_v1.tar.gz\"   )   untar(\"datasets/aclImdb_v1.tar.gz\", exdir = \"datasets\")   unlink(\"datasets/aclImdb/train/unsup\", recursive = TRUE) } head(list.files(\"datasets/aclImdb/test\")) ## [1] \"labeledBow.feat\" \"neg\"             \"pos\"             \"urls_neg.txt\" ## [5] \"urls_pos.txt\" head(list.files(\"datasets/aclImdb/train\")) ## [1] \"labeledBow.feat\" \"neg\"             \"pos\"             \"unsupBow.feat\" ## [5] \"urls_neg.txt\"    \"urls_pos.txt\" cat(readLines(\"datasets/aclImdb/train/pos/6248_7.txt\")) ## Being an Austrian myself this has been a straight knock in my face. Fortunately I don't live nowhere near the place where this movie takes place but unfortunately it portrays everything that the rest of Austria hates about Viennese people (or people close to that region). And it is very easy to read that this is exactly the directors intention: to let your head sink into your hands and say \"Oh my god, how can THAT be possible!\". No, not with me, the (in my opinion) totally exaggerated uncensored swinger club scene is not necessary, I watch porn, sure, but in this context I was rather disgusted than put in the right context.<br /><br />This movie tells a story about how misled people who suffer from lack of education or bad company try to survive and live in a world of redundancy and boring horizons. A girl who is treated like a whore by her super-jealous boyfriend (and still keeps coming back), a female teacher who discovers her masochism by putting the life of her super-cruel \"lover\" on the line, an old couple who has an almost mathematical daily cycle (she is the \"official replacement\" of his ex wife), a couple that has just divorced and has the ex husband suffer under the acts of his former wife obviously having a relationship with her masseuse and finally a crazy hitchhiker who asks her drivers the most unusual questions and stretches their nerves by just being super-annoying.<br /><br />After having seen it you feel almost nothing. You're not even shocked, sad, depressed or feel like doing anything... Maybe that's why I gave it 7 points, it made me react in a way I never reacted before. If that's good or bad is up to you! unlink(\"datasets/aclImdb/train/unsup\", recursive = TRUE) batch_size <- 32  raw_train_ds <- text_dataset_from_directory(   \"datasets/aclImdb/train\",   batch_size = batch_size,   validation_split = 0.2,   subset = \"training\",   seed = 1337 ) ## Found 25000 files belonging to 2 classes. ## Using 20000 files for training. raw_val_ds <- text_dataset_from_directory(   \"datasets/aclImdb/train\",   batch_size = batch_size,   validation_split = 0.2,   subset = \"validation\",   seed = 1337 ) ## Found 25000 files belonging to 2 classes. ## Using 5000 files for validation. raw_test_ds <- text_dataset_from_directory(   \"datasets/aclImdb/test\",   batch_size = batch_size ) ## Found 25000 files belonging to 2 classes. cat(\"Number of batches in raw_train_ds:\", length(raw_train_ds), \"\\n\") ## Number of batches in raw_train_ds: 625 cat(\"Number of batches in raw_val_ds:\", length(raw_val_ds), \"\\n\") ## Number of batches in raw_val_ds: 157 cat(\"Number of batches in raw_test_ds:\", length(raw_test_ds), \"\\n\") ## Number of batches in raw_test_ds: 782 # It's important to take a look at your raw data to ensure your normalization # and tokenization will work as expected. We can do that by taking a few # examples from the training set and looking at them. # This is one of the places where eager execution shines: # we can just evaluate these tensors using .numpy() # instead of needing to evaluate them in a Session/Graph context. batch <- iter_next(as_iterator(raw_train_ds)) str(batch) ## List of 2 ##  $ :<tf.Tensor: shape=(32), dtype=string, numpy=…> ##  $ :<tf.Tensor: shape=(32), dtype=int32, numpy=…> c(text_batch, label_batch) %<-% batch for (i in 1:3) {   print(text_batch[i])   print(label_batch[i]) } ## tf.Tensor(b\"I have read the novel Reaper of Ben Mezrich a fews years ago and last night I accidentally came to see this adaption.<br /><br />Although it's been years since I read the story the first time, the differences between the novel and the movie are humongous. Very important elements, which made the whole thing plausible are just written out or changed to bad.<br /><br />If the plot sounds interesting to you: go and get the novel. Its much, much, much better.<br /><br />Still 4 out of 10 since it was hard to stop watching because of the great basic plot by Ben Mezrich.\", shape=(), dtype=string) ## tf.Tensor(0, shape=(), dtype=int32) ## tf.Tensor(b'After seeing all the Jesse James, Quantrill, jayhawkers,etc films in the fifties, it is quite a thrill to see this film with a new perspective by director Ang Lee. The scene of the attack of Lawrence, Kansas is awesome. The romantic relationship between Jewel and Toby Mcguire turns out to be one of the best parts and Jonathan Rhys-Meyers is outstanding as the bad guy. All the time this film makes you feel the horror of war, and the desperate situation of the main characters who do not know if they are going to survive the next hours. Definitely worth seeing.', shape=(), dtype=string) ## tf.Tensor(1, shape=(), dtype=int32) ## tf.Tensor(b'AG was an excellent presentation of drama, suspense and thriller that is so rare to American TV. Sheriff Lucas gave many a viewer the willies. We rooted for Caleb as he strove to resist the overtures of Sheriff Lucas. We became engrossed and fearful upon learning of the unthinkable connection between these two characters. The manipulations which weekly gave cause to fear what Lucas would do next were truly surprising. This show lived up to the \"Gothic\" moniker in ways American entertainment has so seldom attempted, much less mastered. The suits definitely made a big mistake in not supporting this show. This show puts shame to the current glut of \"reality\" shows- which are so less than satisfying viewing.The call for a DVD box set is well based. This show is quality viewing for a discerning market hungry for quality viewing. A public that is tiring of over-saturation of mind-numbing reality fare will welcome this gem of real storytelling. Bring on the DVD box set!!', shape=(), dtype=string) ## tf.Tensor(1, shape=(), dtype=int32)"},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"prepare-the-data","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Prepare the data","title":"Text classification from scratch","text":"particular, remove <br /> tags.","code":"# Having looked at our data above, we see that the raw text contains HTML break # tags of the form '<br />'. These tags will not be removed by the default # standardizer (which doesn't strip HTML). Because of this, we will need to # create a custom standardization function. custom_standardization_fn <- function(string_tensor) {   string_tensor |>     tf$strings$lower() |> # convert to all lowercase     tf$strings$regex_replace(\"<br />\", \" \") |> # remove '<br />' HTML tag     tf$strings$regex_replace(\"[[:punct:]]\", \"\") # remove punctuation }   # Model constants. max_features <- 20000 embedding_dim <- 128 sequence_length <- 500  # Now that we have our custom standardization, we can instantiate our text # vectorization layer. We are using this layer to normalize, split, and map # strings to integers, so we set our 'output_mode' to 'int'. # Note that we're using the default split function, # and the custom standardization defined above. # We also set an explicit maximum sequence length, since the CNNs later in our # model won't support ragged sequences. vectorize_layer <- layer_text_vectorization(   standardize = custom_standardization_fn,   max_tokens = max_features,   output_mode = \"int\",   output_sequence_length = sequence_length, )  # Now that the vectorize_layer has been created, call `adapt` on a text-only # dataset to create the vocabulary. You don't have to batch, but for very large # datasets this means you're not keeping spare copies of the dataset in memory.  # Let's make a text-only dataset (no labels): text_ds <- raw_train_ds |>   dataset_map(\\(x, y) x) # Let's call `adapt`: vectorize_layer |> adapt(text_ds)"},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"two-options-to-vectorize-the-data","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Two options to vectorize the data","title":"Text classification from scratch","text":"2 ways can use text vectorization layer: Option 1: Make part model, obtain model processes raw strings, like : Option 2: Apply text dataset obtain dataset word indices, feed model expects integer sequences inputs. important difference two option 2 enables asynchronous CPU processing buffering data training GPU. ’re training model GPU, probably want go option get best performance. . export model production, ’d ship model accepts raw strings input, like code snippet option 1 . can done training. last section.","code":"text_input <- keras_input(shape = c(1L), dtype = \"string\", name = 'text') x <- text_input |>   vectorize_layer() |>   layer_embedding(max_features + 1, embedding_dim) vectorize_text <- function(text, label) {   text <- text |>     op_expand_dims(-1) |>     vectorize_layer()   list(text, label) }  # Vectorize the data. train_ds <- raw_train_ds |> dataset_map(vectorize_text) val_ds   <- raw_val_ds   |> dataset_map(vectorize_text) test_ds  <- raw_test_ds  |> dataset_map(vectorize_text)  # Do async prefetching / buffering of the data for best performance on GPU. train_ds <- train_ds |>   dataset_cache() |>   dataset_prefetch(buffer_size = 10) val_ds <- val_ds |>   dataset_cache() |>   dataset_prefetch(buffer_size = 10) test_ds <- test_ds |>   dataset_cache() |>   dataset_prefetch(buffer_size = 10)"},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"build-a-model","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Build a model","title":"Text classification from scratch","text":"choose simple 1D convnet starting Embedding layer.","code":"# A integer input for vocab indices. inputs <- keras_input(shape = c(NA), dtype = \"int64\")  predictions <- inputs |>   # Next, we add a layer to map those vocab indices into a space of dimensionality   # 'embedding_dim'.   layer_embedding(max_features, embedding_dim) |>   layer_dropout(0.5) |>   # Conv1D + global max pooling   layer_conv_1d(128, 7, padding = \"valid\", activation = \"relu\", strides = 3) |>   layer_conv_1d(128, 7, padding = \"valid\", activation = \"relu\", strides = 3) |>   layer_global_max_pooling_1d() |>   # We add a vanilla hidden layer:   layer_dense(128, activation = \"relu\") |>   layer_dropout(0.5) |>   # We project onto a single unit output layer, and squash it with a sigmoid:   layer_dense(1, activation = \"sigmoid\", name = \"predictions\")  model <- keras_model(inputs, predictions)  summary(model) ## Model: \"functional_1\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ input_layer (InputLayer)        │ (None, None)           │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ embedding_1 (Embedding)         │ (None, None, 128)      │     2,560,000 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout_1 (Dropout)             │ (None, None, 128)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv1d_1 (Conv1D)               │ (None, None, 128)      │       114,816 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv1d (Conv1D)                 │ (None, None, 128)      │       114,816 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ global_max_pooling1d            │ (None, 128)            │             0 │ ## │ (GlobalMaxPooling1D)            │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense (Dense)                   │ (None, 128)            │        16,512 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout (Dropout)               │ (None, 128)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ predictions (Dense)             │ (None, 1)              │           129 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 2,806,273 (10.71 MB) ##  Trainable params: 2,806,273 (10.71 MB) ##  Non-trainable params: 0 (0.00 B) # Compile the model with binary crossentropy loss and an adam optimizer. model |> compile(loss = \"binary_crossentropy\",                  optimizer = \"adam\",                  metrics = \"accuracy\")"},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"train-the-model","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Train the model","title":"Text classification from scratch","text":"","code":"epochs <- 3  # Fit the model using the train and test datasets. model |> fit(train_ds, validation_data = val_ds, epochs = epochs) ## Epoch 1/3 ## 625/625 - 6s - 10ms/step - accuracy: 0.7310 - loss: 0.4883 - val_accuracy: 0.8676 - val_loss: 0.3192 ## Epoch 2/3 ## 625/625 - 2s - 3ms/step - accuracy: 0.9114 - loss: 0.2256 - val_accuracy: 0.8704 - val_loss: 0.3190 ## Epoch 3/3 ## 625/625 - 2s - 3ms/step - accuracy: 0.9581 - loss: 0.1147 - val_accuracy: 0.8698 - val_loss: 0.3550"},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"evaluate-the-model-on-the-test-set","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Evaluate the model on the test set","title":"Text classification from scratch","text":"","code":"model |> evaluate(test_ds) ## 782/782 - 1s - 2ms/step - accuracy: 0.8649 - loss: 0.3641 ## $accuracy ## [1] 0.86488 ## ## $loss ## [1] 0.3641175"},{"path":"https://keras.posit.co/articles/examples/nlp/text_classification_from_scratch.html","id":"make-an-end-to-end-model","dir":"Articles > Examples > Nlp","previous_headings":"","what":"Make an end-to-end model","title":"Text classification from scratch","text":"want obtain model capable processing raw strings, can simply create new model (using weights just trained):","code":"# A string input inputs <- keras_input(shape = c(1), dtype = \"string\") # Turn strings into vocab indices indices <- vectorize_layer(inputs) # Turn vocab indices into predictions outputs <- model(indices)  # Our end to end model end_to_end_model <- keras_model(inputs, outputs) end_to_end_model |> compile(   loss = \"binary_crossentropy\",   optimizer = \"adam\",   metrics = c(\"accuracy\") )  # Test it with `raw_test_ds`, which yields raw strings end_to_end_model |> evaluate(raw_test_ds) ## 782/782 - 4s - 5ms/step - accuracy: 0.8649 - loss: 0.3638 ## $accuracy ## [1] 0.86488 ## ## $loss ## [1] 0.3637652"},{"path":"https://keras.posit.co/articles/examples/oxford_pets_image_segmentation.html","id":"download-the-data","dir":"Articles > Examples","previous_headings":"","what":"Download the data","title":"Image segmentation with a U-Net-like architecture","text":"","code":"options(timeout = 5000) download.file(   \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\",   \"datasets/images.tar.gz\" ) download.file(   \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\",   \"datasets/annotations.tar.gz\" )  untar(\"datasets/images.tar.gz\", exdir = \"datasets\") untar(\"datasets/annotations.tar.gz\", exdir = \"datasets\")"},{"path":"https://keras.posit.co/articles/examples/oxford_pets_image_segmentation.html","id":"prepare-paths-of-input-images-and-target-segmentation-masks","dir":"Articles > Examples","previous_headings":"","what":"Prepare paths of input images and target segmentation masks","title":"Image segmentation with a U-Net-like architecture","text":"","code":"library(keras3) input_dir <- \"datasets/images/\" target_dir <- \"datasets/annotations/trimaps/\" img_size <- c(160, 160) num_classes <- 3 batch_size <- 32  input_img_paths <- fs::dir_ls(input_dir, glob = \"*.jpg\") |> sort() target_img_paths <- fs::dir_ls(target_dir, glob = \"*.png\") |> sort()  cat(\"Number of samples:\", length(input_img_paths), \"\\n\") ## Number of samples: 7390 for (i in 1:10) {   cat(input_img_paths[i], \"|\", target_img_paths[i], \"\\n\") } ## datasets/images/Abyssinian_1.jpg | datasets/annotations/trimaps/Abyssinian_1.png ## datasets/images/Abyssinian_10.jpg | datasets/annotations/trimaps/Abyssinian_10.png ## datasets/images/Abyssinian_100.jpg | datasets/annotations/trimaps/Abyssinian_100.png ## datasets/images/Abyssinian_101.jpg | datasets/annotations/trimaps/Abyssinian_101.png ## datasets/images/Abyssinian_102.jpg | datasets/annotations/trimaps/Abyssinian_102.png ## datasets/images/Abyssinian_103.jpg | datasets/annotations/trimaps/Abyssinian_103.png ## datasets/images/Abyssinian_104.jpg | datasets/annotations/trimaps/Abyssinian_104.png ## datasets/images/Abyssinian_105.jpg | datasets/annotations/trimaps/Abyssinian_105.png ## datasets/images/Abyssinian_106.jpg | datasets/annotations/trimaps/Abyssinian_106.png ## datasets/images/Abyssinian_107.jpg | datasets/annotations/trimaps/Abyssinian_107.png"},{"path":"https://keras.posit.co/articles/examples/oxford_pets_image_segmentation.html","id":"what-does-one-input-image-and-corresponding-segmentation-mask-look-like","dir":"Articles > Examples","previous_headings":"","what":"What does one input image and corresponding segmentation mask look like?","title":"Image segmentation with a U-Net-like architecture","text":"","code":"# Display input image #10 input_img_paths[10] |>   jpeg::readJPEG() |>   as.raster() |>   plot() target_img_paths[10] |>   png::readPNG() |>   magrittr::multiply_by(255)|>   as.raster(max = 3) |>   plot()"},{"path":"https://keras.posit.co/articles/examples/oxford_pets_image_segmentation.html","id":"prepare-dataset-to-load-vectorize-batches-of-data","dir":"Articles > Examples","previous_headings":"","what":"Prepare dataset to load & vectorize batches of data","title":"Image segmentation with a U-Net-like architecture","text":"","code":"library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(tfdatasets, exclude = \"shape\")   # Returns a tf_dataset get_dataset <- function(batch_size, img_size, input_img_paths, target_img_paths,                         max_dataset_len = NULL) {    img_size <- as.integer(img_size)    load_img_masks <- function(input_img_path, target_img_path) {     input_img <- input_img_path |>       tf$io$read_file() |>       tf$io$decode_jpeg(channels = 3) |>       tf$image$resize(img_size) |>       tf$image$convert_image_dtype(\"float32\")      target_img <- target_img_path |>       tf$io$read_file() |>       tf$io$decode_png(channels = 1) |>       tf$image$resize(img_size, method = \"nearest\") |>       tf$image$convert_image_dtype(\"uint8\")      # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:     target_img <- target_img - 1L      list(input_img, target_img)   }    if (!is.null(max_dataset_len)) {     input_img_paths <- input_img_paths[1:max_dataset_len]     target_img_paths <- target_img_paths[1:max_dataset_len]   }    list(input_img_paths, target_img_paths) |>     tensor_slices_dataset() |>     dataset_map(load_img_masks, num_parallel_calls = tf$data$AUTOTUNE)|>     dataset_batch(batch_size) }"},{"path":"https://keras.posit.co/articles/examples/oxford_pets_image_segmentation.html","id":"prepare-u-net-xception-style-model","dir":"Articles > Examples","previous_headings":"","what":"Prepare U-Net Xception-style model","title":"Image segmentation with a U-Net-like architecture","text":"","code":"get_model <- function(img_size, num_classes) {    inputs <- keras_input(shape = c(img_size, 3))    ### [First half of the network: downsampling inputs] ###    # Entry block   x <- inputs |>     layer_conv_2d(filters = 32, kernel_size = 3, strides = 2, padding = \"same\") |>     layer_batch_normalization() |>     layer_activation(\"relu\")    previous_block_activation <- x  # Set aside residual    for (filters in c(64, 128, 256)) {     x <- x |>       layer_activation(\"relu\") |>       layer_separable_conv_2d(filters = filters, kernel_size = 3, padding = \"same\") |>       layer_batch_normalization() |>        layer_activation(\"relu\") |>       layer_separable_conv_2d(filters = filters, kernel_size = 3, padding = \"same\") |>       layer_batch_normalization() |>        layer_max_pooling_2d(pool_size = 3, strides = 2, padding = \"same\")      residual <- previous_block_activation |>       layer_conv_2d(filters = filters, kernel_size = 1, strides = 2, padding = \"same\")      x <- layer_add(x, residual)  # Add back residual     previous_block_activation <- x  # Set aside next residual   }    ### [Second half of the network: upsampling inputs] ###    for (filters in c(256, 128, 64, 32)) {     x <- x |>       layer_activation(\"relu\") |>       layer_conv_2d_transpose(filters = filters, kernel_size = 3, padding = \"same\") |>       layer_batch_normalization() |>        layer_activation(\"relu\") |>       layer_conv_2d_transpose(filters = filters, kernel_size = 3, padding = \"same\") |>       layer_batch_normalization() |>        layer_upsampling_2d(size = 2)      # Project residual     residual <- previous_block_activation |>       layer_upsampling_2d(size = 2) |>       layer_conv_2d(filters = filters, kernel_size = 1, padding = \"same\")      x <- layer_add(x, residual)     # Add back residual     previous_block_activation <- x  # Set aside next residual   }    # Add a per-pixel classification layer   outputs <- x |>     layer_conv_2d(num_classes, 3, activation = \"softmax\", padding = \"same\")    # Define the model   keras_model(inputs, outputs) }  # Build model model <- get_model(img_size, num_classes) summary(model) ## Model: \"functional_1\" ## ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━┓ ## ┃ Layer (type)      ┃ Output Shape    ┃   Param # ┃ Connected to   ┃ Trai… ┃ ## ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━┩ ## │ input_layer       │ (None, 160,     │         0 │ -              │   -   │ ## │ (InputLayer)      │ 160, 3)         │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d (Conv2D)   │ (None, 80, 80,  │       896 │ input_layer[0… │   Y   │ ## │                   │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       128 │ conv2d[0][0]   │   Y   │ ## │ (BatchNormalizat… │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation        │ (None, 80, 80,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_2      │ (None, 80, 80,  │         0 │ activation[0]… │   -   │ ## │ (Activation)      │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 80, 80,  │     2,400 │ activation_2[… │   Y   │ ## │ (SeparableConv2D) │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       256 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_1      │ (None, 80, 80,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d  │ (None, 80, 80,  │     4,736 │ activation_1[… │   Y   │ ## │ (SeparableConv2D) │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       256 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ max_pooling2d     │ (None, 40, 40,  │         0 │ batch_normali… │   -   │ ## │ (MaxPooling2D)    │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_1 (Conv2D) │ (None, 40, 40,  │     2,112 │ activation[0]… │   Y   │ ## │                   │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add (Add)         │ (None, 40, 40,  │         0 │ max_pooling2d… │   -   │ ## │                   │ 64)             │           │ conv2d_1[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_4      │ (None, 40, 40,  │         0 │ add[0][0]      │   -   │ ## │ (Activation)      │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 40, 40,  │     8,896 │ activation_4[… │   Y   │ ## │ (SeparableConv2D) │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 40, 40,  │       512 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_3      │ (None, 40, 40,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 40, 40,  │    17,664 │ activation_3[… │   Y   │ ## │ (SeparableConv2D) │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 40, 40,  │       512 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ max_pooling2d_1   │ (None, 20, 20,  │         0 │ batch_normali… │   -   │ ## │ (MaxPooling2D)    │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_2 (Conv2D) │ (None, 20, 20,  │     8,320 │ add[0][0]      │   Y   │ ## │                   │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_1 (Add)       │ (None, 20, 20,  │         0 │ max_pooling2d… │   -   │ ## │                   │ 128)            │           │ conv2d_2[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_6      │ (None, 20, 20,  │         0 │ add_1[0][0]    │   -   │ ## │ (Activation)      │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 20, 20,  │    34,176 │ activation_6[… │   Y   │ ## │ (SeparableConv2D) │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 20, 20,  │     1,024 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_5      │ (None, 20, 20,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 20, 20,  │    68,096 │ activation_5[… │   Y   │ ## │ (SeparableConv2D) │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 20, 20,  │     1,024 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ max_pooling2d_2   │ (None, 10, 10,  │         0 │ batch_normali… │   -   │ ## │ (MaxPooling2D)    │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_3 (Conv2D) │ (None, 10, 10,  │    33,024 │ add_1[0][0]    │   Y   │ ## │                   │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_2 (Add)       │ (None, 10, 10,  │         0 │ max_pooling2d… │   -   │ ## │                   │ 256)            │           │ conv2d_3[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_8      │ (None, 10, 10,  │         0 │ add_2[0][0]    │   -   │ ## │ (Activation)      │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 10, 10,  │   590,080 │ activation_8[… │   Y   │ ## │ (Conv2DTranspose) │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 10, 10,  │     1,024 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_7      │ (None, 10, 10,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose  │ (None, 10, 10,  │   590,080 │ activation_7[… │   Y   │ ## │ (Conv2DTranspose) │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 10, 10,  │     1,024 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_1   │ (None, 20, 20,  │         0 │ add_2[0][0]    │   -   │ ## │ (UpSampling2D)    │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d     │ (None, 20, 20,  │         0 │ batch_normali… │   -   │ ## │ (UpSampling2D)    │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_4 (Conv2D) │ (None, 20, 20,  │    65,792 │ up_sampling2d… │   Y   │ ## │                   │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_3 (Add)       │ (None, 20, 20,  │         0 │ up_sampling2d… │   -   │ ## │                   │ 256)            │           │ conv2d_4[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_10     │ (None, 20, 20,  │         0 │ add_3[0][0]    │   -   │ ## │ (Activation)      │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 20, 20,  │   295,040 │ activation_10… │   Y   │ ## │ (Conv2DTranspose) │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 20, 20,  │       512 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_9      │ (None, 20, 20,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 20, 20,  │   147,584 │ activation_9[… │   Y   │ ## │ (Conv2DTranspose) │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 20, 20,  │       512 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_3   │ (None, 40, 40,  │         0 │ add_3[0][0]    │   -   │ ## │ (UpSampling2D)    │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_2   │ (None, 40, 40,  │         0 │ batch_normali… │   -   │ ## │ (UpSampling2D)    │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_5 (Conv2D) │ (None, 40, 40,  │    32,896 │ up_sampling2d… │   Y   │ ## │                   │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_4 (Add)       │ (None, 40, 40,  │         0 │ up_sampling2d… │   -   │ ## │                   │ 128)            │           │ conv2d_5[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_12     │ (None, 40, 40,  │         0 │ add_4[0][0]    │   -   │ ## │ (Activation)      │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 40, 40,  │    73,792 │ activation_12… │   Y   │ ## │ (Conv2DTranspose) │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 40, 40,  │       256 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_11     │ (None, 40, 40,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 40, 40,  │    36,928 │ activation_11… │   Y   │ ## │ (Conv2DTranspose) │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 40, 40,  │       256 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_5   │ (None, 80, 80,  │         0 │ add_4[0][0]    │   -   │ ## │ (UpSampling2D)    │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_4   │ (None, 80, 80,  │         0 │ batch_normali… │   -   │ ## │ (UpSampling2D)    │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_6 (Conv2D) │ (None, 80, 80,  │     8,256 │ up_sampling2d… │   Y   │ ## │                   │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_5 (Add)       │ (None, 80, 80,  │         0 │ up_sampling2d… │   -   │ ## │                   │ 64)             │           │ conv2d_6[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_14     │ (None, 80, 80,  │         0 │ add_5[0][0]    │   -   │ ## │ (Activation)      │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 80, 80,  │    18,464 │ activation_14… │   Y   │ ## │ (Conv2DTranspose) │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       128 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_13     │ (None, 80, 80,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 80, 80,  │     9,248 │ activation_13… │   Y   │ ## │ (Conv2DTranspose) │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       128 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_7   │ (None, 160,     │         0 │ add_5[0][0]    │   -   │ ## │ (UpSampling2D)    │ 160, 64)        │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_6   │ (None, 160,     │         0 │ batch_normali… │   -   │ ## │ (UpSampling2D)    │ 160, 32)        │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_7 (Conv2D) │ (None, 160,     │     2,080 │ up_sampling2d… │   Y   │ ## │                   │ 160, 32)        │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_6 (Add)       │ (None, 160,     │         0 │ up_sampling2d… │   -   │ ## │                   │ 160, 32)        │           │ conv2d_7[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_8 (Conv2D) │ (None, 160,     │       867 │ add_6[0][0]    │   Y   │ ## │                   │ 160, 3)         │           │                │       │ ## └───────────────────┴─────────────────┴───────────┴────────────────┴───────┘ ##  Total params: 2,058,979 (7.85 MB) ##  Trainable params: 2,055,203 (7.84 MB) ##  Non-trainable params: 3,776 (14.75 KB)"},{"path":"https://keras.posit.co/articles/examples/oxford_pets_image_segmentation.html","id":"set-aside-a-validation-split","dir":"Articles > Examples","previous_headings":"","what":"Set aside a validation split","title":"Image segmentation with a U-Net-like architecture","text":"","code":"# Split our img paths into a training and a validation set val_samples <- 1000 val_samples <- sample.int(length(input_img_paths), val_samples)  train_input_img_paths <- input_img_paths[-val_samples] train_target_img_paths <- target_img_paths[-val_samples]  val_input_img_paths <- input_img_paths[val_samples] val_target_img_paths <- target_img_paths[val_samples]  # Instantiate dataset for each split # Limit input files in `max_dataset_len` for faster epoch training time. # Remove the `max_dataset_len` arg when running with full dataset. train_dataset <- get_dataset(   batch_size,   img_size,   train_input_img_paths,   train_target_img_paths,   max_dataset_len = 1000 ) valid_dataset <- get_dataset(   batch_size, img_size, val_input_img_paths, val_target_img_paths )"},{"path":"https://keras.posit.co/articles/examples/oxford_pets_image_segmentation.html","id":"train-the-model","dir":"Articles > Examples","previous_headings":"","what":"Train the model","title":"Image segmentation with a U-Net-like architecture","text":"","code":"# Configure the model for training. # We use the \"sparse\" version of categorical_crossentropy # because our target data is integers. model |> compile(   optimizer = optimizer_adam(1e-4),   loss = \"sparse_categorical_crossentropy\" )  callbacks <- list(   callback_model_checkpoint(     \"models/oxford_segmentation.keras\", save_best_only = TRUE   ) )  # Train the model, doing validation at the end of each epoch. epochs <- 50 model |> fit(     train_dataset,     epochs=epochs,     validation_data=valid_dataset,     callbacks=callbacks,     verbose=2 ) ## Epoch 1/50 ## 32/32 - 32s - 986ms/step - loss: 1.3044 - val_loss: 1.5502 ## Epoch 2/50 ## 32/32 - 2s - 60ms/step - loss: 0.8717 - val_loss: 1.9567 ## Epoch 3/50 ## 32/32 - 2s - 60ms/step - loss: 0.7695 - val_loss: 2.1948 ## Epoch 4/50 ## 32/32 - 2s - 60ms/step - loss: 0.7080 - val_loss: 2.4837 ## Epoch 5/50 ## 32/32 - 2s - 64ms/step - loss: 0.6689 - val_loss: 2.7751 ## Epoch 6/50 ## 32/32 - 2s - 61ms/step - loss: 0.6378 - val_loss: 3.1156 ## Epoch 7/50 ## 32/32 - 2s - 60ms/step - loss: 0.6129 - val_loss: 3.3611 ## Epoch 8/50 ## 32/32 - 2s - 60ms/step - loss: 0.5917 - val_loss: 3.5193 ## Epoch 9/50 ## 32/32 - 2s - 62ms/step - loss: 0.5723 - val_loss: 3.6237 ## Epoch 10/50 ## 32/32 - 2s - 62ms/step - loss: 0.5538 - val_loss: 3.7209 ## Epoch 11/50 ## 32/32 - 2s - 60ms/step - loss: 0.5352 - val_loss: 3.8216 ## Epoch 12/50 ## 32/32 - 2s - 61ms/step - loss: 0.5161 - val_loss: 3.9090 ## Epoch 13/50 ## 32/32 - 2s - 60ms/step - loss: 0.4958 - val_loss: 4.0158 ## Epoch 14/50 ## 32/32 - 2s - 60ms/step - loss: 0.4739 - val_loss: 4.0756 ## Epoch 15/50 ## 32/32 - 2s - 60ms/step - loss: 0.4501 - val_loss: 4.0083 ## Epoch 16/50 ## 32/32 - 2s - 60ms/step - loss: 0.4243 - val_loss: 3.7728 ## Epoch 17/50 ## 32/32 - 2s - 60ms/step - loss: 0.3971 - val_loss: 3.3484 ## Epoch 18/50 ## 32/32 - 2s - 61ms/step - loss: 0.3696 - val_loss: 2.6909 ## Epoch 19/50 ## 32/32 - 2s - 60ms/step - loss: 0.3428 - val_loss: 1.9726 ## Epoch 20/50 ## 32/32 - 2s - 65ms/step - loss: 0.3178 - val_loss: 1.4081 ## Epoch 21/50 ## 32/32 - 2s - 65ms/step - loss: 0.2954 - val_loss: 1.1136 ## Epoch 22/50 ## 32/32 - 2s - 65ms/step - loss: 0.2764 - val_loss: 1.0246 ## Epoch 23/50 ## 32/32 - 2s - 61ms/step - loss: 0.2610 - val_loss: 1.0390 ## Epoch 24/50 ## 32/32 - 2s - 60ms/step - loss: 0.2507 - val_loss: 1.1001 ## Epoch 25/50 ## 32/32 - 2s - 60ms/step - loss: 0.2525 - val_loss: 1.1915 ## Epoch 26/50 ## 32/32 - 2s - 61ms/step - loss: 0.2961 - val_loss: 1.2296 ## Epoch 27/50 ## 32/32 - 2s - 61ms/step - loss: 0.3545 - val_loss: 1.2625 ## Epoch 28/50 ## 32/32 - 2s - 65ms/step - loss: 0.3326 - val_loss: 0.9711 ## Epoch 29/50 ## 32/32 - 2s - 60ms/step - loss: 0.3302 - val_loss: 1.0251 ## Epoch 30/50 ## 32/32 - 2s - 60ms/step - loss: 0.3163 - val_loss: 1.0867 ## Epoch 31/50 ## 32/32 - 2s - 60ms/step - loss: 0.3131 - val_loss: 1.4197 ## Epoch 32/50 ## 32/32 - 2s - 60ms/step - loss: 0.3093 - val_loss: 1.0851 ## Epoch 33/50 ## 32/32 - 2s - 61ms/step - loss: 0.2939 - val_loss: 1.4807 ## Epoch 34/50 ## 32/32 - 2s - 60ms/step - loss: 0.2763 - val_loss: 1.1851 ## Epoch 35/50 ## 32/32 - 2s - 60ms/step - loss: 0.2702 - val_loss: 1.1337 ## Epoch 36/50 ## 32/32 - 2s - 61ms/step - loss: 0.2584 - val_loss: 1.0315 ## Epoch 37/50 ## 32/32 - 2s - 61ms/step - loss: 0.2440 - val_loss: 1.0631 ## Epoch 38/50 ## 32/32 - 2s - 60ms/step - loss: 0.2353 - val_loss: 1.1609 ## Epoch 39/50 ## 32/32 - 2s - 61ms/step - loss: 0.2285 - val_loss: 1.1839 ## Epoch 40/50 ## 32/32 - 2s - 60ms/step - loss: 0.2307 - val_loss: 1.1293 ## Epoch 41/50 ## 32/32 - 2s - 61ms/step - loss: 0.2357 - val_loss: 0.9948 ## Epoch 42/50 ## 32/32 - 2s - 60ms/step - loss: 0.2279 - val_loss: 1.1329 ## Epoch 43/50 ## 32/32 - 2s - 61ms/step - loss: 0.2174 - val_loss: 1.0418 ## Epoch 44/50 ## 32/32 - 2s - 61ms/step - loss: 0.2076 - val_loss: 1.1141 ## Epoch 45/50 ## 32/32 - 2s - 61ms/step - loss: 0.2004 - val_loss: 1.1162 ## Epoch 46/50 ## 32/32 - 2s - 60ms/step - loss: 0.1930 - val_loss: 1.0939 ## Epoch 47/50 ## 32/32 - 2s - 61ms/step - loss: 0.1852 - val_loss: 1.0499 ## Epoch 48/50 ## 32/32 - 2s - 60ms/step - loss: 0.1796 - val_loss: 1.0651 ## Epoch 49/50 ## 32/32 - 2s - 61ms/step - loss: 0.1762 - val_loss: 1.0679 ## Epoch 50/50 ## 32/32 - 2s - 60ms/step - loss: 0.1757 - val_loss: 1.1762"},{"path":"https://keras.posit.co/articles/examples/oxford_pets_image_segmentation.html","id":"visualize-predictions","dir":"Articles > Examples","previous_headings":"","what":"Visualize predictions","title":"Image segmentation with a U-Net-like architecture","text":"","code":"model <- load_model(\"models/oxford_segmentation.keras\") # Generate predictions for all images in the validation set val_dataset <- get_dataset(   batch_size, img_size, val_input_img_paths, val_target_img_paths ) val_preds <- predict(model, val_dataset) ## 32/32 - 4s - 111ms/step display_mask <- function(i) {   # Quick utility to display a model's prediction.   mask <- val_preds[i,,,] %>%     apply(c(1,2), which.max) %>%     array_reshape(dim = c(img_size, 1))   mask <- abind::abind(mask, mask, mask, along = 3)   plot(as.raster(mask, max = 3)) }  # Display results for validation image #10 i <- 10  par(mfrow = c(1, 3)) # Display input image input_img_paths[i] |>   jpeg::readJPEG() |>   as.raster() |>   plot()  # Display ground-truth target mask target_img_paths[i] |>   png::readPNG() |>   magrittr::multiply_by(255)|>   as.raster(max = 3) |>   plot()  # Display mask predicted by our model display_mask(i)  # Note that the model only sees inputs at 150x150."},{"path":"https://keras.posit.co/articles/examples/structured_data/imbalanced_classification.html","id":"introduction","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Introduction","title":"Imbalanced classification: credit card fraud detection","text":"example looks Kaggle Credit Card Fraud Detection dataset demonstrate train classification model data highly imbalanced classes. can download data clicking “Download” link, ’re setup kaggle API key \"~/.kaggle/kagle.json\", can run following:","code":"reticulate::py_install(\"kaggle\", pip = TRUE) system(\"kaggle datasets download -d mlg-ulb/creditcardfraud\") zip::unzip(\"creditcardfraud.zip\", files = \"creditcard.csv\")"},{"path":"https://keras.posit.co/articles/examples/structured_data/imbalanced_classification.html","id":"first-load-the-data","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"First, load the data","title":"Imbalanced classification: credit card fraud detection","text":"","code":"library(readr) df <- read_csv(\"creditcard.csv\", col_types = cols(   Class = col_integer(),   .default = col_double() )) tibble::glimpse(df) ## Rows: 284,807 ## Columns: 31 ## $ Time   <dbl> 0, 0, 1, 1, 2, 2, 4, 7, 7, 9, 10, 10, 10, 11, 12, 12, 12, 1… ## $ V1     <dbl> -1.3598071, 1.1918571, -1.3583541, -0.9662717, -1.1582331, … ## $ V2     <dbl> -0.07278117, 0.26615071, -1.34016307, -0.18522601, 0.877736… ## $ V3     <dbl> 2.53634674, 0.16648011, 1.77320934, 1.79299334, 1.54871785,… ## $ V4     <dbl> 1.37815522, 0.44815408, 0.37977959, -0.86329128, 0.40303393… ## $ V5     <dbl> -0.33832077, 0.06001765, -0.50319813, -0.01030888, -0.40719… ## $ V6     <dbl> 0.46238778, -0.08236081, 1.80049938, 1.24720317, 0.09592146… ## $ V7     <dbl> 0.239598554, -0.078802983, 0.791460956, 0.237608940, 0.5929… ## $ V8     <dbl> 0.098697901, 0.085101655, 0.247675787, 0.377435875, -0.2705… ## $ V9     <dbl> 0.3637870, -0.2554251, -1.5146543, -1.3870241, 0.8177393, -… ## $ V10    <dbl> 0.09079417, -0.16697441, 0.20764287, -0.05495192, 0.7530744… ## $ V11    <dbl> -0.55159953, 1.61272666, 0.62450146, -0.22648726, -0.822842… ## $ V12    <dbl> -0.61780086, 1.06523531, 0.06608369, 0.17822823, 0.53819555… ## $ V13    <dbl> -0.99138985, 0.48909502, 0.71729273, 0.50775687, 1.34585159… ## $ V14    <dbl> -0.31116935, -0.14377230, -0.16594592, -0.28792375, -1.1196… ## $ V15    <dbl> 1.468176972, 0.635558093, 2.345864949, -0.631418118, 0.1751… ## $ V16    <dbl> -0.47040053, 0.46391704, -2.89008319, -1.05964725, -0.45144… ## $ V17    <dbl> 0.207971242, -0.114804663, 1.109969379, -0.684092786, -0.23… ## $ V18    <dbl> 0.02579058, -0.18336127, -0.12135931, 1.96577500, -0.038194… ## $ V19    <dbl> 0.40399296, -0.14578304, -2.26185710, -1.23262197, 0.803486… ## $ V20    <dbl> 0.25141210, -0.06908314, 0.52497973, -0.20803778, 0.4085423… ## $ V21    <dbl> -0.018306778, -0.225775248, 0.247998153, -0.108300452, -0.0… ## $ V22    <dbl> 0.277837576, -0.638671953, 0.771679402, 0.005273597, 0.7982… ## $ V23    <dbl> -0.110473910, 0.101288021, 0.909412262, -0.190320519, -0.13… ## $ V24    <dbl> 0.06692807, -0.33984648, -0.68928096, -1.17557533, 0.141266… ## $ V25    <dbl> 0.12853936, 0.16717040, -0.32764183, 0.64737603, -0.2060095… ## $ V26    <dbl> -0.18911484, 0.12589453, -0.13909657, -0.22192884, 0.502292… ## $ V27    <dbl> 0.133558377, -0.008983099, -0.055352794, 0.062722849, 0.219… ## $ V28    <dbl> -0.021053053, 0.014724169, -0.059751841, 0.061457629, 0.215… ## $ Amount <dbl> 149.62, 2.69, 378.66, 123.50, 69.99, 3.67, 4.99, 40.80, 93.… ## $ Class  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…"},{"path":"https://keras.posit.co/articles/examples/structured_data/imbalanced_classification.html","id":"prepare-a-validation-set","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Prepare a validation set","title":"Imbalanced classification: credit card fraud detection","text":"","code":"val_idx <- nrow(df) %>% sample.int(., round( . * 0.2)) val_df <- df[val_idx, ] train_df <- df[-val_idx, ]  cat(\"Number of training samples:\", nrow(train_df), \"\\n\") ## Number of training samples: 227846 cat(\"Number of validation samples:\", nrow(val_df), \"\\n\") ## Number of validation samples: 56961"},{"path":"https://keras.posit.co/articles/examples/structured_data/imbalanced_classification.html","id":"analyze-class-imbalance-in-the-targets","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Analyze class imbalance in the targets","title":"Imbalanced classification: credit card fraud detection","text":"","code":"counts <- table(train_df$Class) counts ## ##      0      1 ## 227459    387 cat(sprintf(\"Number of positive samples in training data: %i (%.2f%% of total)\",             counts[\"1\"], 100 * counts[\"1\"] / sum(counts))) ## Number of positive samples in training data: 387 (0.17% of total) weight_for_0 = 1 / counts[\"0\"] weight_for_1 = 1 / counts[\"1\"]"},{"path":"https://keras.posit.co/articles/examples/structured_data/imbalanced_classification.html","id":"normalize-the-data-using-training-set-statistics","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Normalize the data using training set statistics","title":"Imbalanced classification: credit card fraud detection","text":"","code":"feature_names <- colnames(train_df) %>% setdiff(\"Class\")  train_features <- as.matrix(train_df[feature_names]) train_targets <- as.matrix(train_df$Class)  val_features <- as.matrix(val_df[feature_names]) val_targets <- as.matrix(val_df$Class)  train_features %<>% scale() val_features %<>% scale(center = attr(train_features, \"scaled:center\"),                         scale = attr(train_features, \"scaled:scale\"))"},{"path":"https://keras.posit.co/articles/examples/structured_data/imbalanced_classification.html","id":"build-a-binary-classification-model","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Build a binary classification model","title":"Imbalanced classification: credit card fraud detection","text":"","code":"model <-   keras_model_sequential(input_shape = ncol(train_features)) |>   layer_dense(256, activation = \"relu\") |>   layer_dense(256, activation = \"relu\") |>   layer_dropout(0.3) |>   layer_dense(256, activation = \"relu\") |>   layer_dropout(0.3) |>   layer_dense(1, activation = \"sigmoid\")  model ## Model: \"sequential\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ dense_3 (Dense)                 │ (None, 256)            │         7,936 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_2 (Dense)                 │ (None, 256)            │        65,792 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout_1 (Dropout)             │ (None, 256)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_1 (Dense)                 │ (None, 256)            │        65,792 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout (Dropout)               │ (None, 256)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense (Dense)                   │ (None, 1)              │           257 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 139,777 (546.00 KB) ##  Trainable params: 139,777 (546.00 KB) ##  Non-trainable params: 0 (0.00 B)"},{"path":"https://keras.posit.co/articles/examples/structured_data/imbalanced_classification.html","id":"train-the-model-with-class_weight-argument","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Train the model with class_weight argument","title":"Imbalanced classification: credit card fraud detection","text":"","code":"metrics <- list(   metric_false_negatives(name = \"fn\"),   metric_false_positives(name = \"fp\"),   metric_true_negatives(name = \"tn\"),   metric_true_positives(name = \"tp\"),   metric_precision(name = \"precision\"),   metric_recall(name = \"recall\") ) model |> compile(   optimizer = optimizer_adam(1e-2),   loss = \"binary_crossentropy\",   metrics = metrics ) callbacks <- list(   callback_model_checkpoint(\"fraud_model_at_epoch_{epoch}.keras\") )  class_weight <- list(\"0\" = weight_for_0,                      \"1\" = weight_for_1)  model |> fit(   train_features, train_targets,   validation_data = list(val_features, val_targets),   class_weight = class_weight,   batch_size = 2048,   epochs = 30,   callbacks = callbacks,   verbose = 2 ) ## Epoch 1/30 ## 112/112 - 2s - 21ms/step - fn: 44.0000 - fp: 23999.0000 - loss: 2.2310e-06 - precision: 0.0141 - recall: 0.8863 - tn: 203460.0000 - tp: 343.0000 - val_fn: 6.0000 - val_fp: 3122.0000 - val_loss: 0.1931 - val_precision: 0.0307 - val_recall: 0.9429 - val_tn: 53734.0000 - val_tp: 99.0000 ## Epoch 2/30 ## 112/112 - 0s - 2ms/step - fn: 32.0000 - fp: 9264.0000 - loss: 1.4367e-06 - precision: 0.0369 - recall: 0.9173 - tn: 218195.0000 - tp: 355.0000 - val_fn: 3.0000 - val_fp: 4081.0000 - val_loss: 0.2209 - val_precision: 0.0244 - val_recall: 0.9714 - val_tn: 52775.0000 - val_tp: 102.0000 ## Epoch 3/30 ## 112/112 - 0s - 2ms/step - fn: 31.0000 - fp: 8504.0000 - loss: 1.1797e-06 - precision: 0.0402 - recall: 0.9199 - tn: 218955.0000 - tp: 356.0000 - val_fn: 7.0000 - val_fp: 577.0000 - val_loss: 0.0613 - val_precision: 0.1452 - val_recall: 0.9333 - val_tn: 56279.0000 - val_tp: 98.0000 ## Epoch 4/30 ## 112/112 - 0s - 2ms/step - fn: 31.0000 - fp: 10927.0000 - loss: 1.5436e-06 - precision: 0.0316 - recall: 0.9199 - tn: 216532.0000 - tp: 356.0000 - val_fn: 8.0000 - val_fp: 1432.0000 - val_loss: 0.1177 - val_precision: 0.0634 - val_recall: 0.9238 - val_tn: 55424.0000 - val_tp: 97.0000 ## Epoch 5/30 ## 112/112 - 0s - 2ms/step - fn: 29.0000 - fp: 9174.0000 - loss: 1.1107e-06 - precision: 0.0376 - recall: 0.9251 - tn: 218285.0000 - tp: 358.0000 - val_fn: 6.0000 - val_fp: 2538.0000 - val_loss: 0.1354 - val_precision: 0.0375 - val_recall: 0.9429 - val_tn: 54318.0000 - val_tp: 99.0000 ## Epoch 6/30 ## 112/112 - 0s - 2ms/step - fn: 15.0000 - fp: 8220.0000 - loss: 8.1028e-07 - precision: 0.0433 - recall: 0.9612 - tn: 219239.0000 - tp: 372.0000 - val_fn: 7.0000 - val_fp: 1182.0000 - val_loss: 0.0774 - val_precision: 0.0766 - val_recall: 0.9333 - val_tn: 55674.0000 - val_tp: 98.0000 ## Epoch 7/30 ## 112/112 - 0s - 2ms/step - fn: 13.0000 - fp: 7803.0000 - loss: 8.1749e-07 - precision: 0.0457 - recall: 0.9664 - tn: 219656.0000 - tp: 374.0000 - val_fn: 8.0000 - val_fp: 944.0000 - val_loss: 0.0536 - val_precision: 0.0932 - val_recall: 0.9238 - val_tn: 55912.0000 - val_tp: 97.0000 ## Epoch 8/30 ## 112/112 - 0s - 2ms/step - fn: 13.0000 - fp: 8117.0000 - loss: 6.9381e-07 - precision: 0.0440 - recall: 0.9664 - tn: 219342.0000 - tp: 374.0000 - val_fn: 9.0000 - val_fp: 794.0000 - val_loss: 0.0396 - val_precision: 0.1079 - val_recall: 0.9143 - val_tn: 56062.0000 - val_tp: 96.0000 ## Epoch 9/30 ## 112/112 - 0s - 2ms/step - fn: 19.0000 - fp: 9817.0000 - loss: 9.3896e-07 - precision: 0.0361 - recall: 0.9509 - tn: 217642.0000 - tp: 368.0000 - val_fn: 9.0000 - val_fp: 1292.0000 - val_loss: 0.0652 - val_precision: 0.0692 - val_recall: 0.9143 - val_tn: 55564.0000 - val_tp: 96.0000 ## Epoch 10/30 ## 112/112 - 0s - 2ms/step - fn: 12.0000 - fp: 8198.0000 - loss: 7.3109e-07 - precision: 0.0437 - recall: 0.9690 - tn: 219261.0000 - tp: 375.0000 - val_fn: 4.0000 - val_fp: 3894.0000 - val_loss: 0.1868 - val_precision: 0.0253 - val_recall: 0.9619 - val_tn: 52962.0000 - val_tp: 101.0000 ## Epoch 11/30 ## 112/112 - 0s - 2ms/step - fn: 15.0000 - fp: 8182.0000 - loss: 8.4644e-07 - precision: 0.0435 - recall: 0.9612 - tn: 219277.0000 - tp: 372.0000 - val_fn: 7.0000 - val_fp: 1779.0000 - val_loss: 0.0909 - val_precision: 0.0522 - val_recall: 0.9333 - val_tn: 55077.0000 - val_tp: 98.0000 ## Epoch 12/30 ## 112/112 - 0s - 2ms/step - fn: 9.0000 - fp: 7708.0000 - loss: 6.8122e-07 - precision: 0.0467 - recall: 0.9767 - tn: 219751.0000 - tp: 378.0000 - val_fn: 8.0000 - val_fp: 1376.0000 - val_loss: 0.0585 - val_precision: 0.0659 - val_recall: 0.9238 - val_tn: 55480.0000 - val_tp: 97.0000 ## Epoch 13/30 ## 112/112 - 0s - 2ms/step - fn: 7.0000 - fp: 5156.0000 - loss: 4.5651e-07 - precision: 0.0686 - recall: 0.9819 - tn: 222303.0000 - tp: 380.0000 - val_fn: 7.0000 - val_fp: 1870.0000 - val_loss: 0.0813 - val_precision: 0.0498 - val_recall: 0.9333 - val_tn: 54986.0000 - val_tp: 98.0000 ## Epoch 14/30 ## 112/112 - 0s - 2ms/step - fn: 5.0000 - fp: 4924.0000 - loss: 3.7919e-07 - precision: 0.0720 - recall: 0.9871 - tn: 222535.0000 - tp: 382.0000 - val_fn: 8.0000 - val_fp: 1144.0000 - val_loss: 0.0494 - val_precision: 0.0782 - val_recall: 0.9238 - val_tn: 55712.0000 - val_tp: 97.0000 ## Epoch 15/30 ## 112/112 - 0s - 2ms/step - fn: 2.0000 - fp: 4101.0000 - loss: 3.1106e-07 - precision: 0.0858 - recall: 0.9948 - tn: 223358.0000 - tp: 385.0000 - val_fn: 7.0000 - val_fp: 849.0000 - val_loss: 0.0382 - val_precision: 0.1035 - val_recall: 0.9333 - val_tn: 56007.0000 - val_tp: 98.0000 ## Epoch 16/30 ## 112/112 - 0s - 2ms/step - fn: 5.0000 - fp: 4255.0000 - loss: 5.1135e-07 - precision: 0.0824 - recall: 0.9871 - tn: 223204.0000 - tp: 382.0000 - val_fn: 14.0000 - val_fp: 589.0000 - val_loss: 0.0395 - val_precision: 0.1338 - val_recall: 0.8667 - val_tn: 56267.0000 - val_tp: 91.0000 ## Epoch 17/30 ## 112/112 - 0s - 2ms/step - fn: 16.0000 - fp: 12359.0000 - loss: 2.4119e-06 - precision: 0.0291 - recall: 0.9587 - tn: 215100.0000 - tp: 371.0000 - val_fn: 8.0000 - val_fp: 4416.0000 - val_loss: 0.4735 - val_precision: 0.0215 - val_recall: 0.9238 - val_tn: 52440.0000 - val_tp: 97.0000 ## Epoch 18/30 ## 112/112 - 0s - 2ms/step - fn: 25.0000 - fp: 9988.0000 - loss: 1.6301e-06 - precision: 0.0350 - recall: 0.9354 - tn: 217471.0000 - tp: 362.0000 - val_fn: 5.0000 - val_fp: 4161.0000 - val_loss: 0.1967 - val_precision: 0.0235 - val_recall: 0.9524 - val_tn: 52695.0000 - val_tp: 100.0000 ## Epoch 19/30 ## 112/112 - 0s - 2ms/step - fn: 12.0000 - fp: 8257.0000 - loss: 9.2278e-07 - precision: 0.0434 - recall: 0.9690 - tn: 219202.0000 - tp: 375.0000 - val_fn: 5.0000 - val_fp: 1834.0000 - val_loss: 0.0939 - val_precision: 0.0517 - val_recall: 0.9524 - val_tn: 55022.0000 - val_tp: 100.0000 ## Epoch 20/30 ## 112/112 - 0s - 2ms/step - fn: 12.0000 - fp: 8497.0000 - loss: 9.5626e-07 - precision: 0.0423 - recall: 0.9690 - tn: 218962.0000 - tp: 375.0000 - val_fn: 8.0000 - val_fp: 1707.0000 - val_loss: 0.1129 - val_precision: 0.0538 - val_recall: 0.9238 - val_tn: 55149.0000 - val_tp: 97.0000 ## Epoch 21/30 ## 112/112 - 0s - 2ms/step - fn: 9.0000 - fp: 7602.0000 - loss: 9.2171e-07 - precision: 0.0474 - recall: 0.9767 - tn: 219857.0000 - tp: 378.0000 - val_fn: 8.0000 - val_fp: 1326.0000 - val_loss: 0.1349 - val_precision: 0.0682 - val_recall: 0.9238 - val_tn: 55530.0000 - val_tp: 97.0000 ## Epoch 22/30 ## 112/112 - 0s - 2ms/step - fn: 6.0000 - fp: 5799.0000 - loss: 5.3588e-07 - precision: 0.0617 - recall: 0.9845 - tn: 221660.0000 - tp: 381.0000 - val_fn: 9.0000 - val_fp: 701.0000 - val_loss: 0.0293 - val_precision: 0.1205 - val_recall: 0.9143 - val_tn: 56155.0000 - val_tp: 96.0000 ## Epoch 23/30 ## 112/112 - 0s - 2ms/step - fn: 3.0000 - fp: 4258.0000 - loss: 4.9946e-07 - precision: 0.0827 - recall: 0.9922 - tn: 223201.0000 - tp: 384.0000 - val_fn: 7.0000 - val_fp: 1142.0000 - val_loss: 0.0481 - val_precision: 0.0790 - val_recall: 0.9333 - val_tn: 55714.0000 - val_tp: 98.0000 ## Epoch 24/30 ## 112/112 - 0s - 2ms/step - fn: 4.0000 - fp: 4713.0000 - loss: 3.3949e-07 - precision: 0.0752 - recall: 0.9897 - tn: 222746.0000 - tp: 383.0000 - val_fn: 9.0000 - val_fp: 822.0000 - val_loss: 0.0394 - val_precision: 0.1046 - val_recall: 0.9143 - val_tn: 56034.0000 - val_tp: 96.0000 ## Epoch 25/30 ## 112/112 - 0s - 2ms/step - fn: 10.0000 - fp: 9210.0000 - loss: 1.7289e-06 - precision: 0.0393 - recall: 0.9742 - tn: 218249.0000 - tp: 377.0000 - val_fn: 5.0000 - val_fp: 2974.0000 - val_loss: 0.2395 - val_precision: 0.0325 - val_recall: 0.9524 - val_tn: 53882.0000 - val_tp: 100.0000 ## Epoch 26/30 ## 112/112 - 0s - 2ms/step - fn: 6.0000 - fp: 7946.0000 - loss: 1.1577e-06 - precision: 0.0458 - recall: 0.9845 - tn: 219513.0000 - tp: 381.0000 - val_fn: 7.0000 - val_fp: 1538.0000 - val_loss: 0.1599 - val_precision: 0.0599 - val_recall: 0.9333 - val_tn: 55318.0000 - val_tp: 98.0000 ## Epoch 27/30 ## 112/112 - 0s - 2ms/step - fn: 6.0000 - fp: 6427.0000 - loss: 8.6088e-07 - precision: 0.0560 - recall: 0.9845 - tn: 221032.0000 - tp: 381.0000 - val_fn: 9.0000 - val_fp: 1082.0000 - val_loss: 0.0663 - val_precision: 0.0815 - val_recall: 0.9143 - val_tn: 55774.0000 - val_tp: 96.0000 ## Epoch 28/30 ## 112/112 - 0s - 2ms/step - fn: 6.0000 - fp: 4652.0000 - loss: 4.1927e-07 - precision: 0.0757 - recall: 0.9845 - tn: 222807.0000 - tp: 381.0000 - val_fn: 9.0000 - val_fp: 764.0000 - val_loss: 0.0376 - val_precision: 0.1116 - val_recall: 0.9143 - val_tn: 56092.0000 - val_tp: 96.0000 ## Epoch 29/30 ## 112/112 - 0s - 2ms/step - fn: 1.0000 - fp: 2879.0000 - loss: 2.4674e-07 - precision: 0.1182 - recall: 0.9974 - tn: 224580.0000 - tp: 386.0000 - val_fn: 10.0000 - val_fp: 570.0000 - val_loss: 0.0317 - val_precision: 0.1429 - val_recall: 0.9048 - val_tn: 56286.0000 - val_tp: 95.0000 ## Epoch 30/30 ## 112/112 - 0s - 2ms/step - fn: 4.0000 - fp: 5770.0000 - loss: 9.0391e-07 - precision: 0.0622 - recall: 0.9897 - tn: 221689.0000 - tp: 383.0000 - val_fn: 8.0000 - val_fp: 908.0000 - val_loss: 0.1193 - val_precision: 0.0965 - val_recall: 0.9238 - val_tn: 55948.0000 - val_tp: 97.0000 val_pred <- model %>%   predict(val_features) %>%   { as.integer(. > 0.5) } ## 1781/1781 - 1s - 344us/step pred_correct <- val_df$Class == val_pred cat(sprintf(\"Validation accuracy: %.2f\", mean(pred_correct))) ## Validation accuracy: 0.98 fraudulent <- val_df$Class == 1  n_fraudulent_detected <- sum(fraudulent & pred_correct) n_fraudulent_missed <- sum(fraudulent & !pred_correct) n_legitimate_flagged <- sum(!fraudulent & !pred_correct)"},{"path":"https://keras.posit.co/articles/examples/structured_data/imbalanced_classification.html","id":"conclusions","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Conclusions","title":"Imbalanced classification: credit card fraud detection","text":"end training, 56,961 validation transactions, : Correctly identifying 97 fraudulent Missing 8 fraudulent transactions cost incorrectly flagging 908 legitimate transactions real world, one put even higher weight class 1, reflect False Negatives costly False Positives. Next time credit card gets declined online purchase – .","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"introduction","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Introduction","title":"Structured data classification with FeatureSpace","text":"example demonstrates structured data classification (also known tabular data classification), starting raw CSV file. data includes numerical features, integer categorical features, string categorical features. use utility layer_feature_space() index, preprocess, encode features. code adapted example Structured data classification scratch. previous example managed low-level feature preprocessing encoding Keras preprocessing layers, example delegate everything layer_feature_space(), making workflow extremely quick easy.","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"the-dataset","dir":"Articles > Examples > Structured_data","previous_headings":"Introduction","what":"The dataset","title":"Structured data classification with FeatureSpace","text":"dataset provided Cleveland Clinic Foundation Heart Disease. ’s CSV file 303 rows. row contains information patient (sample), column describes attribute patient (feature). use features predict whether patient heart disease (binary classification). ’s description feature:","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"setup","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Setup","title":"Structured data classification with FeatureSpace","text":"","code":"library(readr) library(dplyr, warn.conflicts = FALSE) library(keras3) library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(tfdatasets, exclude = \"shape\")  conflicted::conflicts_prefer(   keras3::shape(),   keras3::set_random_seed(),   dplyr::filter(),   .quiet = TRUE )  use_backend(\"tensorflow\")"},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"preparing-the-data","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Preparing the data","title":"Structured data classification with FeatureSpace","text":"Let’s download data load Pandas dataframe: dataset includes 303 samples 14 columns per sample (13 features, plus target label) ’s preview samples: last column, “target”, indicates whether patient heart disease (1) (0). Let’s split data training validation set: Let’s generate tf_dataset objects dataframe: tf_dataset yields tuple (input, target) input dictionary (named list) features target value 0 1: Let’s batch datasets:","code":"file_url <-   \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\" df <- read_csv(file_url, col_types = cols(   oldpeak = col_double(),   thal = col_character(),   .default = col_integer() ))  # the dataset has two malformed rows, filter them out df <- df |> filter(!thal %in% c(\"1\", \"2\")) glimpse(df) ## Rows: 301 ## Columns: 14 ## $ age      <int> 63, 67, 67, 37, 41, 56, 62, 57, 63, 53, 57, 56, 56, 44, 5… ## $ sex      <int> 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, … ## $ cp       <int> 1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3, 2, 3, 3, 2, 4, 3, … ## $ trestbps <int> 145, 160, 120, 130, 130, 120, 140, 120, 130, 140, 140, 14… ## $ chol     <int> 233, 286, 229, 250, 204, 236, 268, 354, 254, 203, 192, 29… ## $ fbs      <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, … ## $ restecg  <int> 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, … ## $ thalach  <int> 150, 108, 129, 187, 172, 178, 160, 163, 147, 155, 148, 15… ## $ exang    <int> 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, … ## $ oldpeak  <dbl> 2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6, 1.4, 3.1, 0.4, 1.… ## $ slope    <int> 3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2, 1, 1, 1, 3, 1, 1, … ## $ ca       <int> 0, 3, 2, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, … ## $ thal     <chr> \"fixed\", \"normal\", \"reversible\", \"normal\", \"normal\", \"nor… ## $ target   <int> 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, … df ## # A tibble: 301 × 14 ##      age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak ##    <int> <int> <int>    <int> <int> <int>   <int>   <int> <int>   <dbl> ##  1    63     1     1      145   233     1       2     150     0     2.3 ##  2    67     1     4      160   286     0       2     108     1     1.5 ##  3    67     1     4      120   229     0       2     129     1     2.6 ##  4    37     1     3      130   250     0       0     187     0     3.5 ##  5    41     0     2      130   204     0       2     172     0     1.4 ##  6    56     1     2      120   236     0       0     178     0     0.8 ##  7    62     0     4      140   268     0       2     160     0     3.6 ##  8    57     0     4      120   354     0       0     163     1     0.6 ##  9    63     1     4      130   254     0       2     147     0     1.4 ## 10    53     1     4      140   203     1       2     155     1     3.1 ## # ℹ 291 more rows ## # ℹ 4 more variables: slope <int>, ca <int>, thal <chr>, target <int> val_idx <- nrow(df) %>% sample.int(., . * 0.2) val_df <- df[val_idx, ] train_df <- df[-val_idx, ]  cat(sprintf(   \"Using %d samples for training and %d for validation\",   nrow(train_df), nrow(val_df) )) ## Using 241 samples for training and 60 for validation dataframe_to_dataset <- function(df) {   labels <- df |> pull(target) |> as.integer()   inputs <- df |> select(-target) |> as.list()    ds <- tensor_slices_dataset(list(inputs, labels)) |>     dataset_shuffle(nrow(df))    ds }  train_ds <- dataframe_to_dataset(train_df) val_ds <- dataframe_to_dataset(val_df) c(x, y) %<-% iter_next(as_iterator(train_ds)) cat(\"Input: \"); str(x) cat(\"Target: \"); str(y) ## Input: List of 13 ##  $ age     :<tf.Tensor: shape=(), dtype=int32, numpy=57> ##  $ sex     :<tf.Tensor: shape=(), dtype=int32, numpy=0> ##  $ cp      :<tf.Tensor: shape=(), dtype=int32, numpy=4> ##  $ trestbps:<tf.Tensor: shape=(), dtype=int32, numpy=140> ##  $ chol    :<tf.Tensor: shape=(), dtype=int32, numpy=241> ##  $ fbs     :<tf.Tensor: shape=(), dtype=int32, numpy=0> ##  $ restecg :<tf.Tensor: shape=(), dtype=int32, numpy=0> ##  $ thalach :<tf.Tensor: shape=(), dtype=int32, numpy=123> ##  $ exang   :<tf.Tensor: shape=(), dtype=int32, numpy=1> ##  $ oldpeak :<tf.Tensor: shape=(), dtype=float32, numpy=0.2> ##  $ slope   :<tf.Tensor: shape=(), dtype=int32, numpy=2> ##  $ ca      :<tf.Tensor: shape=(), dtype=int32, numpy=0> ##  $ thal    :<tf.Tensor: shape=(), dtype=string, numpy=b'reversible'> ## Target: <tf.Tensor: shape=(), dtype=int32, numpy=0> train_ds <- train_ds |> dataset_batch(32) val_ds <- val_ds |> dataset_batch(32)"},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"configuring-a-featurespace","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Configuring a FeatureSpace","title":"Structured data classification with FeatureSpace","text":"configure feature preprocessed, instantiate layer_feature_space, pass dictionary (named list unique names) maps name features string describes feature type. “integer categorical” features \"FBS\", one “string categorical” feature (\"thal\"), numerical features, ’d like normalize – except \"age\", ’d like discretize number bins. also use crosses argument capture feature interactions categorical features, say, create additional features represent value co-occurrences categorical features. can compute feature crosses like arbitrary sets categorical features – just tuples two features. resulting co-occurences hashed fixed-sized vector, don’t need worry whether co-occurence space large.","code":"feature_space <- layer_feature_space(   features = list(     # Categorical features encoded as integers     sex = \"integer_categorical\",     cp = \"integer_categorical\",     fbs = \"integer_categorical\",     restecg = \"integer_categorical\",     exang = \"integer_categorical\",     ca = \"integer_categorical\",     # Categorical feature encoded as string     thal = \"string_categorical\",     # Numerical features to discretize     age = \"float_discretized\",     # Numerical features to normalize     trestbps = \"float_normalized\",     chol = \"float_normalized\",     thalach = \"float_normalized\",     oldpeak = \"float_normalized\",     slope = \"float_normalized\"   ),   # We create additional features by hashing   # value co-occurrences for the   # following groups of categorical features.   crosses = list(c(\"sex\", \"age\"), c(\"thal\", \"ca\")),   # The hashing space for these co-occurrences   # wil be 32-dimensional.   crossing_dim = 32,   # Our utility will one-hot encode all categorical   # features and concat all features into a single   # vector (one vector per sample).   output_mode = \"concat\" )"},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"further-customizing-a-featurespace","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Further customizing a FeatureSpace","title":"Structured data classification with FeatureSpace","text":"Specifying feature type via string name quick easy, sometimes may want configure preprocessing feature. instance, case, categorical features don’t large set possible values – ’s handful values per feature (e.g. 1 0 feature \"FBS\"), possible values represented training set. result, don’t need reserve index represent “vocabulary” values features – default behavior. , just specify num_oov_indices=0 features tell feature preprocessor skip “vocabulary” indexing. customizations access include specifying number bins discretizing features type \"float_discretized\", dimensionality hashing space feature crossing.","code":"feature_space <- layer_feature_space(   features = list(     # Categorical features encoded as integers     sex       = feature_integer_categorical(num_oov_indices = 0),     cp        = feature_integer_categorical(num_oov_indices = 0),     fbs       = feature_integer_categorical(num_oov_indices = 0),     restecg   = feature_integer_categorical(num_oov_indices = 0),     exang     = feature_integer_categorical(num_oov_indices = 0),     ca        = feature_integer_categorical(num_oov_indices = 0),     # Categorical feature encoded as string     thal      = feature_string_categorical(num_oov_indices = 0),     # Numerical features to discretize     age       = feature_float_discretized(num_bins = 30),     # Numerical features to normalize     trestbps  = feature_float_normalized(),     chol      = feature_float_normalized(),     thalach   = feature_float_normalized(),     oldpeak   = feature_float_normalized(),     slope     = feature_float_normalized()   ),   # Specify feature cross with a custom crossing dim.   crosses = list(     feature_cross(       feature_names = c(\"sex\", \"age\"),       crossing_dim = 64     ),     feature_cross(       feature_names = c(\"thal\", \"ca\"),       crossing_dim = 16     )   ),   output_mode = \"concat\" )"},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"adapt-the-featurespace-to-the-training-data","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Adapt the FeatureSpace to the training data","title":"Structured data classification with FeatureSpace","text":"start using FeatureSpace build model, adapt training data. adapt(), FeatureSpace : Index set possible values categorical features. Compute mean variance numerical features normalize. Compute value boundaries different bins numerical features discretize. Note adapt() called tf_dataset yields dicts (named lists) feature values – labels. point, FeatureSpace can called dict raw feature values, return single concatenate vector sample, combining encoded features feature crosses.","code":"train_ds_with_no_labels <- train_ds |> dataset_map(\\(x, y) x) feature_space |> adapt(train_ds_with_no_labels) c(x, y) %<-% iter_next(as_iterator(train_ds)) preprocessed_x <- feature_space(x) preprocessed_x ## tf.Tensor( ## [[0. 0. 0. ... 1. 0. 0.] ##  [0. 0. 0. ... 0. 0. 0.] ##  [0. 0. 0. ... 0. 0. 0.] ##  ... ##  [0. 0. 0. ... 0. 0. 0.] ##  [0. 0. 0. ... 0. 0. 0.] ##  [0. 0. 0. ... 0. 0. 0.]], shape=(32, 136), dtype=float32)"},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"two-ways-to-manage-preprocessing-as-part-of-the-tf-data-pipeline-or-in-the-model-itself","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Two ways to manage preprocessing: as part of the tf.data pipeline, or in the model itself","title":"Structured data classification with FeatureSpace","text":"two ways can leverage FeatureSpace:","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"asynchronous-preprocessing-in-tf-data","dir":"Articles > Examples > Structured_data","previous_headings":"Two ways to manage preprocessing: as part of the tf.data pipeline, or in the model itself","what":"Asynchronous preprocessing in tf.data","title":"Structured data classification with FeatureSpace","text":"can make part data pipeline, model. enables asynchronous parallel preprocessing data CPU hits model. ’re training GPU TPU, want speed preprocessing. Usually, always right thing training.","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"synchronous-preprocessing-in-the-model","dir":"Articles > Examples > Structured_data","previous_headings":"Two ways to manage preprocessing: as part of the tf.data pipeline, or in the model itself","what":"Synchronous preprocessing in the model","title":"Structured data classification with FeatureSpace","text":"can make part model. means model expect dicts raw feature values, preprocessing batch done synchronously (blocking manner) rest forward pass. want end--end model can process raw feature values – keep mind model able run CPU, since types feature preprocessing (e.g. string preprocessing) GPU TPU compatible. GPU / TPU performance-sensitive settings. general, want -model preprocessing inference CPU. case, apply FeatureSpace tf.data pipeline training, inference end--end model includes FeatureSpace. Let’s create training validation dataset preprocessed batches:","code":"preprocessed_train_ds <- train_ds |>   dataset_map(\\(x, y) list(feature_space(x), y),               num_parallel_calls = tf$data$AUTOTUNE) |>   dataset_prefetch(tf$data$AUTOTUNE)  preprocessed_val_ds <- val_ds |>   dataset_map(\\(x, y) list(feature_space(x), y),               num_parallel_calls = tf$data$AUTOTUNE) |>   dataset_prefetch(tf$data$AUTOTUNE)"},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"build-a-model","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Build a model","title":"Structured data classification with FeatureSpace","text":"Time build model – rather two models: training model expects preprocessed features (one sample = one vector) inference model expects raw features (one sample = dict raw feature values)","code":"dict_inputs <- feature_space$get_inputs() encoded_features <- feature_space$get_encoded_features()  predictions <- encoded_features |>   layer_dense(32, activation=\"relu\") |>   layer_dropout(0.5) |>   layer_dense(1, activation=\"sigmoid\")  training_model <- keras_model(inputs = encoded_features,                               outputs = predictions) training_model |> compile(optimizer = \"adam\",                           loss = \"binary_crossentropy\",                           metrics = \"accuracy\")  inference_model <- keras_model(inputs = dict_inputs,                                outputs = predictions)"},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"train-the-model","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Train the model","title":"Structured data classification with FeatureSpace","text":"Let’s train model 20 epochs. Note feature preprocessing happening part tf.data pipeline, part model. quickly get 80% validation accuracy.","code":"training_model |> fit(   preprocessed_train_ds,   epochs = 20,   validation_data = preprocessed_val_ds,   verbose = 2 ) ## Epoch 1/20 ## 8/8 - 3s - 390ms/step - accuracy: 0.5685 - loss: 0.7120 - val_accuracy: 0.6500 - val_loss: 0.6607 ## Epoch 2/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.6722 - loss: 0.6131 - val_accuracy: 0.6500 - val_loss: 0.6212 ## Epoch 3/20 ## 8/8 - 0s - 16ms/step - accuracy: 0.7137 - loss: 0.5685 - val_accuracy: 0.6500 - val_loss: 0.5961 ## Epoch 4/20 ## 8/8 - 0s - 14ms/step - accuracy: 0.7718 - loss: 0.4981 - val_accuracy: 0.6667 - val_loss: 0.5758 ## Epoch 5/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.7635 - loss: 0.4804 - val_accuracy: 0.6500 - val_loss: 0.5575 ## Epoch 6/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.7676 - loss: 0.4739 - val_accuracy: 0.6667 - val_loss: 0.5309 ## Epoch 7/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.7842 - loss: 0.4141 - val_accuracy: 0.6667 - val_loss: 0.5161 ## Epoch 8/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.8133 - loss: 0.3841 - val_accuracy: 0.6667 - val_loss: 0.5080 ## Epoch 9/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8133 - loss: 0.3997 - val_accuracy: 0.6667 - val_loss: 0.4980 ## Epoch 10/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8340 - loss: 0.3618 - val_accuracy: 0.6833 - val_loss: 0.4882 ## Epoch 11/20 ## 8/8 - 0s - 14ms/step - accuracy: 0.8548 - loss: 0.3335 - val_accuracy: 0.6833 - val_loss: 0.4814 ## Epoch 12/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.8465 - loss: 0.3535 - val_accuracy: 0.6833 - val_loss: 0.4818 ## Epoch 13/20 ## 8/8 - 0s - 14ms/step - accuracy: 0.8340 - loss: 0.3363 - val_accuracy: 0.7000 - val_loss: 0.4755 ## Epoch 14/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.8548 - loss: 0.3224 - val_accuracy: 0.7333 - val_loss: 0.4745 ## Epoch 15/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.8714 - loss: 0.3083 - val_accuracy: 0.7500 - val_loss: 0.4813 ## Epoch 16/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8797 - loss: 0.3270 - val_accuracy: 0.7500 - val_loss: 0.4690 ## Epoch 17/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8631 - loss: 0.2955 - val_accuracy: 0.7500 - val_loss: 0.4782 ## Epoch 18/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8797 - loss: 0.2831 - val_accuracy: 0.7667 - val_loss: 0.4818 ## Epoch 19/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.8797 - loss: 0.2872 - val_accuracy: 0.7667 - val_loss: 0.4767 ## Epoch 20/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.8631 - loss: 0.2877 - val_accuracy: 0.7833 - val_loss: 0.4781"},{"path":"https://keras.posit.co/articles/examples/structured_data/structured_data_classification_with_feature_space.html","id":"inference-on-new-data-with-the-end-to-end-model","dir":"Articles > Examples > Structured_data","previous_headings":"","what":"Inference on new data with the end-to-end model","title":"Structured data classification with FeatureSpace","text":"Now, can use inference model (includes FeatureSpace) make predictions based dicts raw features values, follows:","code":"sample <- list(   age = 60,   sex = 1,   cp = 1,   trestbps = 145,   chol = 233,   fbs = 1,   restecg = 2,   thalach = 150,   exang = 0,   oldpeak = 2.3,   slope = 3,   ca = 0,   thal = \"fixed\" )  input_dict <- lapply(sample, \\(x) op_convert_to_tensor(array(x))) predictions <- inference_model |> predict(input_dict) ## 1/1 - 0s - 337ms/step glue::glue(r\"---(   This particular patient had a {(100 * predictions) |> signif(3)}% probability   of having a heart disease, as evaluated by our model. )---\") ## This particular patient had a 55% probability ## of having a heart disease, as evaluated by our model."},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"introduction","dir":"Articles > Examples","previous_headings":"","what":"Introduction","title":"Structured data classification with FeatureSpace","text":"example demonstrates structured data classification (also known tabular data classification), starting raw CSV file. data includes numerical features, integer categorical features, string categorical features. use utility layer_feature_space() index, preprocess, encode features. code adapted example Structured data classification scratch. previous example managed low-level feature preprocessing encoding Keras preprocessing layers, example delegate everything layer_feature_space(), making workflow extremely quick easy.","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"the-dataset","dir":"Articles > Examples","previous_headings":"Introduction","what":"The dataset","title":"Structured data classification with FeatureSpace","text":"dataset provided Cleveland Clinic Foundation Heart Disease. ’s CSV file 303 rows. row contains information patient (sample), column describes attribute patient (feature). use features predict whether patient heart disease (binary classification). ’s description feature:","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"setup","dir":"Articles > Examples","previous_headings":"","what":"Setup","title":"Structured data classification with FeatureSpace","text":"","code":"library(readr) library(dplyr, warn.conflicts = FALSE) library(keras3) library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(tfdatasets, exclude = \"shape\")  conflicted::conflicts_prefer(   keras3::shape(),   keras3::set_random_seed(),   dplyr::filter(),   .quiet = TRUE )  use_backend(\"tensorflow\")"},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"preparing-the-data","dir":"Articles > Examples","previous_headings":"","what":"Preparing the data","title":"Structured data classification with FeatureSpace","text":"Let’s download data load Pandas dataframe: dataset includes 303 samples 14 columns per sample (13 features, plus target label) ’s preview samples: last column, “target”, indicates whether patient heart disease (1) (0). Let’s split data training validation set: Let’s generate tf_dataset objects dataframe: tf_dataset yields tuple (input, target) input dictionary (named list) features target value 0 1: Let’s batch datasets:","code":"file_url <-   \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\" df <- read_csv(file_url, col_types = cols(   oldpeak = col_double(),   thal = col_character(),   .default = col_integer() ))  # the dataset has two malformed rows, filter them out df <- df |> filter(!thal %in% c(\"1\", \"2\")) glimpse(df) ## Rows: 301 ## Columns: 14 ## $ age      <int> 63, 67, 67, 37, 41, 56, 62, 57, 63, 53, 57, 56, 56, 44, 5… ## $ sex      <int> 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, … ## $ cp       <int> 1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3, 2, 3, 3, 2, 4, 3, … ## $ trestbps <int> 145, 160, 120, 130, 130, 120, 140, 120, 130, 140, 140, 14… ## $ chol     <int> 233, 286, 229, 250, 204, 236, 268, 354, 254, 203, 192, 29… ## $ fbs      <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, … ## $ restecg  <int> 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, … ## $ thalach  <int> 150, 108, 129, 187, 172, 178, 160, 163, 147, 155, 148, 15… ## $ exang    <int> 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, … ## $ oldpeak  <dbl> 2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6, 1.4, 3.1, 0.4, 1.… ## $ slope    <int> 3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2, 1, 1, 1, 3, 1, 1, … ## $ ca       <int> 0, 3, 2, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, … ## $ thal     <chr> \"fixed\", \"normal\", \"reversible\", \"normal\", \"normal\", \"nor… ## $ target   <int> 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, … df ## # A tibble: 301 × 14 ##      age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak ##    <int> <int> <int>    <int> <int> <int>   <int>   <int> <int>   <dbl> ##  1    63     1     1      145   233     1       2     150     0     2.3 ##  2    67     1     4      160   286     0       2     108     1     1.5 ##  3    67     1     4      120   229     0       2     129     1     2.6 ##  4    37     1     3      130   250     0       0     187     0     3.5 ##  5    41     0     2      130   204     0       2     172     0     1.4 ##  6    56     1     2      120   236     0       0     178     0     0.8 ##  7    62     0     4      140   268     0       2     160     0     3.6 ##  8    57     0     4      120   354     0       0     163     1     0.6 ##  9    63     1     4      130   254     0       2     147     0     1.4 ## 10    53     1     4      140   203     1       2     155     1     3.1 ## # ℹ 291 more rows ## # ℹ 4 more variables: slope <int>, ca <int>, thal <chr>, target <int> val_idx <- nrow(df) %>% sample.int(., . * 0.2) val_df <- df[val_idx, ] train_df <- df[-val_idx, ]  cat(sprintf(   \"Using %d samples for training and %d for validation\",   nrow(train_df), nrow(val_df) )) ## Using 241 samples for training and 60 for validation dataframe_to_dataset <- function(df) {   labels <- df |> pull(target) |> as.integer()   inputs <- df |> select(-target) |> as.list()    ds <- tensor_slices_dataset(list(inputs, labels)) |>     dataset_shuffle(nrow(df))    ds }  train_ds <- dataframe_to_dataset(train_df) val_ds <- dataframe_to_dataset(val_df) c(x, y) %<-% iter_next(as_iterator(train_ds)) cat(\"Input: \"); str(x) cat(\"Target: \"); str(y) ## Input: List of 13 ##  $ age     :<tf.Tensor: shape=(), dtype=int32, numpy=57> ##  $ sex     :<tf.Tensor: shape=(), dtype=int32, numpy=0> ##  $ cp      :<tf.Tensor: shape=(), dtype=int32, numpy=4> ##  $ trestbps:<tf.Tensor: shape=(), dtype=int32, numpy=140> ##  $ chol    :<tf.Tensor: shape=(), dtype=int32, numpy=241> ##  $ fbs     :<tf.Tensor: shape=(), dtype=int32, numpy=0> ##  $ restecg :<tf.Tensor: shape=(), dtype=int32, numpy=0> ##  $ thalach :<tf.Tensor: shape=(), dtype=int32, numpy=123> ##  $ exang   :<tf.Tensor: shape=(), dtype=int32, numpy=1> ##  $ oldpeak :<tf.Tensor: shape=(), dtype=float32, numpy=0.2> ##  $ slope   :<tf.Tensor: shape=(), dtype=int32, numpy=2> ##  $ ca      :<tf.Tensor: shape=(), dtype=int32, numpy=0> ##  $ thal    :<tf.Tensor: shape=(), dtype=string, numpy=b'reversible'> ## Target: <tf.Tensor: shape=(), dtype=int32, numpy=0> train_ds <- train_ds |> dataset_batch(32) val_ds <- val_ds |> dataset_batch(32)"},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"configuring-a-featurespace","dir":"Articles > Examples","previous_headings":"","what":"Configuring a FeatureSpace","title":"Structured data classification with FeatureSpace","text":"configure feature preprocessed, instantiate layer_feature_space, pass dictionary (named list unique names) maps name features string describes feature type. “integer categorical” features \"FBS\", one “string categorical” feature (\"thal\"), numerical features, ’d like normalize – except \"age\", ’d like discretize number bins. also use crosses argument capture feature interactions categorical features, say, create additional features represent value co-occurrences categorical features. can compute feature crosses like arbitrary sets categorical features – just tuples two features. resulting co-occurences hashed fixed-sized vector, don’t need worry whether co-occurence space large.","code":"feature_space <- layer_feature_space(   features = list(     # Categorical features encoded as integers     sex = \"integer_categorical\",     cp = \"integer_categorical\",     fbs = \"integer_categorical\",     restecg = \"integer_categorical\",     exang = \"integer_categorical\",     ca = \"integer_categorical\",     # Categorical feature encoded as string     thal = \"string_categorical\",     # Numerical features to discretize     age = \"float_discretized\",     # Numerical features to normalize     trestbps = \"float_normalized\",     chol = \"float_normalized\",     thalach = \"float_normalized\",     oldpeak = \"float_normalized\",     slope = \"float_normalized\"   ),   # We create additional features by hashing   # value co-occurrences for the   # following groups of categorical features.   crosses = list(c(\"sex\", \"age\"), c(\"thal\", \"ca\")),   # The hashing space for these co-occurrences   # wil be 32-dimensional.   crossing_dim = 32,   # Our utility will one-hot encode all categorical   # features and concat all features into a single   # vector (one vector per sample).   output_mode = \"concat\" )"},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"further-customizing-a-featurespace","dir":"Articles > Examples","previous_headings":"","what":"Further customizing a FeatureSpace","title":"Structured data classification with FeatureSpace","text":"Specifying feature type via string name quick easy, sometimes may want configure preprocessing feature. instance, case, categorical features don’t large set possible values – ’s handful values per feature (e.g. 1 0 feature \"FBS\"), possible values represented training set. result, don’t need reserve index represent “vocabulary” values features – default behavior. , just specify num_oov_indices=0 features tell feature preprocessor skip “vocabulary” indexing. customizations access include specifying number bins discretizing features type \"float_discretized\", dimensionality hashing space feature crossing.","code":"feature_space <- layer_feature_space(   features = list(     # Categorical features encoded as integers     sex       = feature_integer_categorical(num_oov_indices = 0),     cp        = feature_integer_categorical(num_oov_indices = 0),     fbs       = feature_integer_categorical(num_oov_indices = 0),     restecg   = feature_integer_categorical(num_oov_indices = 0),     exang     = feature_integer_categorical(num_oov_indices = 0),     ca        = feature_integer_categorical(num_oov_indices = 0),     # Categorical feature encoded as string     thal      = feature_string_categorical(num_oov_indices = 0),     # Numerical features to discretize     age       = feature_float_discretized(num_bins = 30),     # Numerical features to normalize     trestbps  = feature_float_normalized(),     chol      = feature_float_normalized(),     thalach   = feature_float_normalized(),     oldpeak   = feature_float_normalized(),     slope     = feature_float_normalized()   ),   # Specify feature cross with a custom crossing dim.   crosses = list(     feature_cross(       feature_names = c(\"sex\", \"age\"),       crossing_dim = 64     ),     feature_cross(       feature_names = c(\"thal\", \"ca\"),       crossing_dim = 16     )   ),   output_mode = \"concat\" )"},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"adapt-the-featurespace-to-the-training-data","dir":"Articles > Examples","previous_headings":"","what":"Adapt the FeatureSpace to the training data","title":"Structured data classification with FeatureSpace","text":"start using FeatureSpace build model, adapt training data. adapt(), FeatureSpace : Index set possible values categorical features. Compute mean variance numerical features normalize. Compute value boundaries different bins numerical features discretize. Note adapt() called tf_dataset yields dicts (named lists) feature values – labels. point, FeatureSpace can called dict raw feature values, return single concatenate vector sample, combining encoded features feature crosses.","code":"train_ds_with_no_labels <- train_ds |> dataset_map(\\(x, y) x) feature_space |> adapt(train_ds_with_no_labels) c(x, y) %<-% iter_next(as_iterator(train_ds)) preprocessed_x <- feature_space(x) preprocessed_x ## tf.Tensor( ## [[0. 0. 0. ... 1. 0. 0.] ##  [0. 0. 0. ... 0. 0. 0.] ##  [0. 0. 0. ... 0. 0. 0.] ##  ... ##  [0. 0. 0. ... 0. 0. 0.] ##  [0. 0. 0. ... 0. 0. 0.] ##  [0. 0. 0. ... 0. 0. 0.]], shape=(32, 136), dtype=float32)"},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"two-ways-to-manage-preprocessing-as-part-of-the-tf-data-pipeline-or-in-the-model-itself","dir":"Articles > Examples","previous_headings":"","what":"Two ways to manage preprocessing: as part of the tf.data pipeline, or in the model itself","title":"Structured data classification with FeatureSpace","text":"two ways can leverage FeatureSpace:","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"asynchronous-preprocessing-in-tf-data","dir":"Articles > Examples","previous_headings":"Two ways to manage preprocessing: as part of the tf.data pipeline, or in the model itself","what":"Asynchronous preprocessing in tf.data","title":"Structured data classification with FeatureSpace","text":"can make part data pipeline, model. enables asynchronous parallel preprocessing data CPU hits model. ’re training GPU TPU, want speed preprocessing. Usually, always right thing training.","code":""},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"synchronous-preprocessing-in-the-model","dir":"Articles > Examples","previous_headings":"Two ways to manage preprocessing: as part of the tf.data pipeline, or in the model itself","what":"Synchronous preprocessing in the model","title":"Structured data classification with FeatureSpace","text":"can make part model. means model expect dicts raw feature values, preprocessing batch done synchronously (blocking manner) rest forward pass. want end--end model can process raw feature values – keep mind model able run CPU, since types feature preprocessing (e.g. string preprocessing) GPU TPU compatible. GPU / TPU performance-sensitive settings. general, want -model preprocessing inference CPU. case, apply FeatureSpace tf.data pipeline training, inference end--end model includes FeatureSpace. Let’s create training validation dataset preprocessed batches:","code":"preprocessed_train_ds <- train_ds |>   dataset_map(\\(x, y) list(feature_space(x), y),               num_parallel_calls = tf$data$AUTOTUNE) |>   dataset_prefetch(tf$data$AUTOTUNE)  preprocessed_val_ds <- val_ds |>   dataset_map(\\(x, y) list(feature_space(x), y),               num_parallel_calls = tf$data$AUTOTUNE) |>   dataset_prefetch(tf$data$AUTOTUNE)"},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"build-a-model","dir":"Articles > Examples","previous_headings":"","what":"Build a model","title":"Structured data classification with FeatureSpace","text":"Time build model – rather two models: training model expects preprocessed features (one sample = one vector) inference model expects raw features (one sample = dict raw feature values)","code":"dict_inputs <- feature_space$get_inputs() encoded_features <- feature_space$get_encoded_features()  predictions <- encoded_features |>   layer_dense(32, activation=\"relu\") |>   layer_dropout(0.5) |>   layer_dense(1, activation=\"sigmoid\")  training_model <- keras_model(inputs = encoded_features,                               outputs = predictions) training_model |> compile(optimizer = \"adam\",                           loss = \"binary_crossentropy\",                           metrics = \"accuracy\")  inference_model <- keras_model(inputs = dict_inputs,                                outputs = predictions)"},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"train-the-model","dir":"Articles > Examples","previous_headings":"","what":"Train the model","title":"Structured data classification with FeatureSpace","text":"Let’s train model 20 epochs. Note feature preprocessing happening part tf.data pipeline, part model. quickly get 80% validation accuracy.","code":"training_model |> fit(   preprocessed_train_ds,   epochs = 20,   validation_data = preprocessed_val_ds,   verbose = 2 ) ## Epoch 1/20 ## 8/8 - 3s - 343ms/step - accuracy: 0.5685 - loss: 0.7120 - val_accuracy: 0.6500 - val_loss: 0.6607 ## Epoch 2/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.6722 - loss: 0.6131 - val_accuracy: 0.6500 - val_loss: 0.6212 ## Epoch 3/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.7137 - loss: 0.5685 - val_accuracy: 0.6500 - val_loss: 0.5961 ## Epoch 4/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.7718 - loss: 0.4981 - val_accuracy: 0.6667 - val_loss: 0.5758 ## Epoch 5/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.7635 - loss: 0.4804 - val_accuracy: 0.6500 - val_loss: 0.5575 ## Epoch 6/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.7676 - loss: 0.4739 - val_accuracy: 0.6667 - val_loss: 0.5309 ## Epoch 7/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.7842 - loss: 0.4141 - val_accuracy: 0.6667 - val_loss: 0.5161 ## Epoch 8/20 ## 8/8 - 0s - 13ms/step - accuracy: 0.8133 - loss: 0.3841 - val_accuracy: 0.6667 - val_loss: 0.5080 ## Epoch 9/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8133 - loss: 0.3997 - val_accuracy: 0.6667 - val_loss: 0.4980 ## Epoch 10/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8340 - loss: 0.3618 - val_accuracy: 0.6833 - val_loss: 0.4882 ## Epoch 11/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8548 - loss: 0.3335 - val_accuracy: 0.6833 - val_loss: 0.4814 ## Epoch 12/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8465 - loss: 0.3535 - val_accuracy: 0.6833 - val_loss: 0.4818 ## Epoch 13/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8340 - loss: 0.3363 - val_accuracy: 0.7000 - val_loss: 0.4755 ## Epoch 14/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8548 - loss: 0.3224 - val_accuracy: 0.7333 - val_loss: 0.4745 ## Epoch 15/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8714 - loss: 0.3083 - val_accuracy: 0.7500 - val_loss: 0.4813 ## Epoch 16/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8797 - loss: 0.3270 - val_accuracy: 0.7500 - val_loss: 0.4690 ## Epoch 17/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8631 - loss: 0.2955 - val_accuracy: 0.7500 - val_loss: 0.4782 ## Epoch 18/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8797 - loss: 0.2831 - val_accuracy: 0.7667 - val_loss: 0.4818 ## Epoch 19/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8797 - loss: 0.2872 - val_accuracy: 0.7667 - val_loss: 0.4767 ## Epoch 20/20 ## 8/8 - 0s - 12ms/step - accuracy: 0.8631 - loss: 0.2877 - val_accuracy: 0.7833 - val_loss: 0.4781"},{"path":"https://keras.posit.co/articles/examples/structured_data_classification_with_feature_space.html","id":"inference-on-new-data-with-the-end-to-end-model","dir":"Articles > Examples","previous_headings":"","what":"Inference on new data with the end-to-end model","title":"Structured data classification with FeatureSpace","text":"Now, can use inference model (includes FeatureSpace) make predictions based dicts raw features values, follows:","code":"sample <- list(   age = 60,   sex = 1,   cp = 1,   trestbps = 145,   chol = 233,   fbs = 1,   restecg = 2,   thalach = 150,   exang = 0,   oldpeak = 2.3,   slope = 3,   ca = 0,   thal = \"fixed\" )  input_dict <- lapply(sample, \\(x) op_convert_to_tensor(array(x))) predictions <- inference_model |> predict(input_dict) ## 1/1 - 1s - 548ms/step glue::glue(r\"---(   This particular patient had a {(100 * predictions) |> signif(3)}% probability   of having a heart disease, as evaluated by our model. )---\") ## This particular patient had a 55% probability ## of having a heart disease, as evaluated by our model."},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"introduction","dir":"Articles > Examples","previous_headings":"","what":"Introduction","title":"Text classification from scratch","text":"example shows text classification starting raw text (set text files disk). demonstrate workflow IMDB sentiment classification dataset (unprocessed version). use [layer_text_vectorization()] word splitting & indexing.","code":""},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"setup","dir":"Articles > Examples","previous_headings":"","what":"Setup","title":"Text classification from scratch","text":"","code":"options(conflicts.policy = \"strict\") library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(tfdatasets, exclude = \"shape\") library(keras3) use_virtualenv(\"r-keras\")"},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"load-the-data-imdb-movie-review-sentiment-classification","dir":"Articles > Examples","previous_headings":"","what":"Load the data: IMDB movie review sentiment classification","title":"Text classification from scratch","text":"Let’s download data inspect structure. aclImdb folder contains train test subfolder: aclImdb/train/pos aclImdb/train/neg folders contain text files, represents one review (either positive negative): interested pos neg subfolders, let’s delete subfolder text files : can use utility text_dataset_from_directory() generate labeled tf_dataset object set text files disk filed class-specific folders. Let’s use generate training, validation, test datasets. validation training datasets generated two subsets train directory, 20% samples going validation dataset 80% going training dataset. validation dataset addition test dataset useful tuning hyperparameters, model architecture, test dataset used. putting model real world however, retrained using available training data (without creating validation dataset), performance maximized. using validation_split subset arguments, make sure either specify random seed, pass shuffle=FALSE, validation & training splits get overlap. Let’s preview samples:","code":"if (!dir.exists(\"datasets/aclImdb\")) {   dir.create(\"datasets\")   download.file(     \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",     \"datasets/aclImdb_v1.tar.gz\"   )   untar(\"datasets/aclImdb_v1.tar.gz\", exdir = \"datasets\")   unlink(\"datasets/aclImdb/train/unsup\", recursive = TRUE) } head(list.files(\"datasets/aclImdb/test\")) ## [1] \"labeledBow.feat\" \"neg\"             \"pos\"             \"urls_neg.txt\" ## [5] \"urls_pos.txt\" head(list.files(\"datasets/aclImdb/train\")) ## [1] \"labeledBow.feat\" \"neg\"             \"pos\"             \"unsupBow.feat\" ## [5] \"urls_neg.txt\"    \"urls_pos.txt\" cat(readLines(\"datasets/aclImdb/train/pos/6248_7.txt\")) ## Being an Austrian myself this has been a straight knock in my face. Fortunately I don't live nowhere near the place where this movie takes place but unfortunately it portrays everything that the rest of Austria hates about Viennese people (or people close to that region). And it is very easy to read that this is exactly the directors intention: to let your head sink into your hands and say \"Oh my god, how can THAT be possible!\". No, not with me, the (in my opinion) totally exaggerated uncensored swinger club scene is not necessary, I watch porn, sure, but in this context I was rather disgusted than put in the right context.<br /><br />This movie tells a story about how misled people who suffer from lack of education or bad company try to survive and live in a world of redundancy and boring horizons. A girl who is treated like a whore by her super-jealous boyfriend (and still keeps coming back), a female teacher who discovers her masochism by putting the life of her super-cruel \"lover\" on the line, an old couple who has an almost mathematical daily cycle (she is the \"official replacement\" of his ex wife), a couple that has just divorced and has the ex husband suffer under the acts of his former wife obviously having a relationship with her masseuse and finally a crazy hitchhiker who asks her drivers the most unusual questions and stretches their nerves by just being super-annoying.<br /><br />After having seen it you feel almost nothing. You're not even shocked, sad, depressed or feel like doing anything... Maybe that's why I gave it 7 points, it made me react in a way I never reacted before. If that's good or bad is up to you! unlink(\"datasets/aclImdb/train/unsup\", recursive = TRUE) batch_size <- 32  raw_train_ds <- text_dataset_from_directory(   \"datasets/aclImdb/train\",   batch_size = batch_size,   validation_split = 0.2,   subset = \"training\",   seed = 1337 ) ## Found 25000 files belonging to 2 classes. ## Using 20000 files for training. raw_val_ds <- text_dataset_from_directory(   \"datasets/aclImdb/train\",   batch_size = batch_size,   validation_split = 0.2,   subset = \"validation\",   seed = 1337 ) ## Found 25000 files belonging to 2 classes. ## Using 5000 files for validation. raw_test_ds <- text_dataset_from_directory(   \"datasets/aclImdb/test\",   batch_size = batch_size ) ## Found 25000 files belonging to 2 classes. cat(\"Number of batches in raw_train_ds:\", length(raw_train_ds), \"\\n\") ## Number of batches in raw_train_ds: 625 cat(\"Number of batches in raw_val_ds:\", length(raw_val_ds), \"\\n\") ## Number of batches in raw_val_ds: 157 cat(\"Number of batches in raw_test_ds:\", length(raw_test_ds), \"\\n\") ## Number of batches in raw_test_ds: 782 # It's important to take a look at your raw data to ensure your normalization # and tokenization will work as expected. We can do that by taking a few # examples from the training set and looking at them. # This is one of the places where eager execution shines: # we can just evaluate these tensors using .numpy() # instead of needing to evaluate them in a Session/Graph context. batch <- iter_next(as_iterator(raw_train_ds)) str(batch) ## List of 2 ##  $ :<tf.Tensor: shape=(32), dtype=string, numpy=…> ##  $ :<tf.Tensor: shape=(32), dtype=int32, numpy=…> c(text_batch, label_batch) %<-% batch for (i in 1:3) {   print(text_batch[i])   print(label_batch[i]) } ## tf.Tensor(b\"I have read the novel Reaper of Ben Mezrich a fews years ago and last night I accidentally came to see this adaption.<br /><br />Although it's been years since I read the story the first time, the differences between the novel and the movie are humongous. Very important elements, which made the whole thing plausible are just written out or changed to bad.<br /><br />If the plot sounds interesting to you: go and get the novel. Its much, much, much better.<br /><br />Still 4 out of 10 since it was hard to stop watching because of the great basic plot by Ben Mezrich.\", shape=(), dtype=string) ## tf.Tensor(0, shape=(), dtype=int32) ## tf.Tensor(b'After seeing all the Jesse James, Quantrill, jayhawkers,etc films in the fifties, it is quite a thrill to see this film with a new perspective by director Ang Lee. The scene of the attack of Lawrence, Kansas is awesome. The romantic relationship between Jewel and Toby Mcguire turns out to be one of the best parts and Jonathan Rhys-Meyers is outstanding as the bad guy. All the time this film makes you feel the horror of war, and the desperate situation of the main characters who do not know if they are going to survive the next hours. Definitely worth seeing.', shape=(), dtype=string) ## tf.Tensor(1, shape=(), dtype=int32) ## tf.Tensor(b'AG was an excellent presentation of drama, suspense and thriller that is so rare to American TV. Sheriff Lucas gave many a viewer the willies. We rooted for Caleb as he strove to resist the overtures of Sheriff Lucas. We became engrossed and fearful upon learning of the unthinkable connection between these two characters. The manipulations which weekly gave cause to fear what Lucas would do next were truly surprising. This show lived up to the \"Gothic\" moniker in ways American entertainment has so seldom attempted, much less mastered. The suits definitely made a big mistake in not supporting this show. This show puts shame to the current glut of \"reality\" shows- which are so less than satisfying viewing.The call for a DVD box set is well based. This show is quality viewing for a discerning market hungry for quality viewing. A public that is tiring of over-saturation of mind-numbing reality fare will welcome this gem of real storytelling. Bring on the DVD box set!!', shape=(), dtype=string) ## tf.Tensor(1, shape=(), dtype=int32)"},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"prepare-the-data","dir":"Articles > Examples","previous_headings":"","what":"Prepare the data","title":"Text classification from scratch","text":"particular, remove <br /> tags.","code":"# Having looked at our data above, we see that the raw text contains HTML break # tags of the form '<br />'. These tags will not be removed by the default # standardizer (which doesn't strip HTML). Because of this, we will need to # create a custom standardization function. custom_standardization_fn <- function(string_tensor) {   string_tensor |>     tf$strings$lower() |> # convert to all lowercase     tf$strings$regex_replace(\"<br />\", \" \") |> # remove '<br />' HTML tag     tf$strings$regex_replace(\"[[:punct:]]\", \"\") # remove punctuation }   # Model constants. max_features <- 20000 embedding_dim <- 128 sequence_length <- 500  # Now that we have our custom standardization, we can instantiate our text # vectorization layer. We are using this layer to normalize, split, and map # strings to integers, so we set our 'output_mode' to 'int'. # Note that we're using the default split function, # and the custom standardization defined above. # We also set an explicit maximum sequence length, since the CNNs later in our # model won't support ragged sequences. vectorize_layer <- layer_text_vectorization(   standardize = custom_standardization_fn,   max_tokens = max_features,   output_mode = \"int\",   output_sequence_length = sequence_length, )  # Now that the vectorize_layer has been created, call `adapt` on a text-only # dataset to create the vocabulary. You don't have to batch, but for very large # datasets this means you're not keeping spare copies of the dataset in memory.  # Let's make a text-only dataset (no labels): text_ds <- raw_train_ds |>   dataset_map(\\(x, y) x) # Let's call `adapt`: vectorize_layer |> adapt(text_ds)"},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"two-options-to-vectorize-the-data","dir":"Articles > Examples","previous_headings":"","what":"Two options to vectorize the data","title":"Text classification from scratch","text":"2 ways can use text vectorization layer: Option 1: Make part model, obtain model processes raw strings, like : Option 2: Apply text dataset obtain dataset word indices, feed model expects integer sequences inputs. important difference two option 2 enables asynchronous CPU processing buffering data training GPU. ’re training model GPU, probably want go option get best performance. . export model production, ’d ship model accepts raw strings input, like code snippet option 1 . can done training. last section.","code":"text_input <- keras_input(shape = c(1L), dtype = \"string\", name = 'text') x <- text_input |>   vectorize_layer() |>   layer_embedding(max_features + 1, embedding_dim) vectorize_text <- function(text, label) {   text <- text |>     op_expand_dims(-1) |>     vectorize_layer()   list(text, label) }  # Vectorize the data. train_ds <- raw_train_ds |> dataset_map(vectorize_text) val_ds   <- raw_val_ds   |> dataset_map(vectorize_text) test_ds  <- raw_test_ds  |> dataset_map(vectorize_text)  # Do async prefetching / buffering of the data for best performance on GPU. train_ds <- train_ds |>   dataset_cache() |>   dataset_prefetch(buffer_size = 10) val_ds <- val_ds |>   dataset_cache() |>   dataset_prefetch(buffer_size = 10) test_ds <- test_ds |>   dataset_cache() |>   dataset_prefetch(buffer_size = 10)"},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"build-a-model","dir":"Articles > Examples","previous_headings":"","what":"Build a model","title":"Text classification from scratch","text":"choose simple 1D convnet starting Embedding layer.","code":"# A integer input for vocab indices. inputs <- keras_input(shape = c(NA), dtype = \"int64\")  predictions <- inputs |>   # Next, we add a layer to map those vocab indices into a space of dimensionality   # 'embedding_dim'.   layer_embedding(max_features, embedding_dim) |>   layer_dropout(0.5) |>   # Conv1D + global max pooling   layer_conv_1d(128, 7, padding = \"valid\", activation = \"relu\", strides = 3) |>   layer_conv_1d(128, 7, padding = \"valid\", activation = \"relu\", strides = 3) |>   layer_global_max_pooling_1d() |>   # We add a vanilla hidden layer:   layer_dense(128, activation = \"relu\") |>   layer_dropout(0.5) |>   # We project onto a single unit output layer, and squash it with a sigmoid:   layer_dense(1, activation = \"sigmoid\", name = \"predictions\")  model <- keras_model(inputs, predictions)  summary(model) ## Model: \"functional_1\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ input_layer (InputLayer)        │ (None, None)           │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ embedding_1 (Embedding)         │ (None, None, 128)      │     2,560,000 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout_1 (Dropout)             │ (None, None, 128)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv1d_1 (Conv1D)               │ (None, None, 128)      │       114,816 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv1d (Conv1D)                 │ (None, None, 128)      │       114,816 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ global_max_pooling1d            │ (None, 128)            │             0 │ ## │ (GlobalMaxPooling1D)            │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense (Dense)                   │ (None, 128)            │        16,512 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout (Dropout)               │ (None, 128)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ predictions (Dense)             │ (None, 1)              │           129 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 2,806,273 (10.71 MB) ##  Trainable params: 2,806,273 (10.71 MB) ##  Non-trainable params: 0 (0.00 B) # Compile the model with binary crossentropy loss and an adam optimizer. model |> compile(loss = \"binary_crossentropy\",                  optimizer = \"adam\",                  metrics = \"accuracy\")"},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"train-the-model","dir":"Articles > Examples","previous_headings":"","what":"Train the model","title":"Text classification from scratch","text":"","code":"epochs <- 3  # Fit the model using the train and test datasets. model |> fit(train_ds, validation_data = val_ds, epochs = epochs) ## Epoch 1/3 ## 625/625 - 6s - 9ms/step - accuracy: 0.7327 - loss: 0.4894 - val_accuracy: 0.8638 - val_loss: 0.3162 ## Epoch 2/3 ## 625/625 - 2s - 2ms/step - accuracy: 0.9116 - loss: 0.2230 - val_accuracy: 0.8780 - val_loss: 0.3131 ## Epoch 3/3 ## 625/625 - 2s - 2ms/step - accuracy: 0.9603 - loss: 0.1118 - val_accuracy: 0.8646 - val_loss: 0.3735"},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"evaluate-the-model-on-the-test-set","dir":"Articles > Examples","previous_headings":"","what":"Evaluate the model on the test set","title":"Text classification from scratch","text":"","code":"model |> evaluate(test_ds) ## 782/782 - 1s - 2ms/step - accuracy: 0.8532 - loss: 0.4071 ## $accuracy ## [1] 0.8532 ## ## $loss ## [1] 0.407085"},{"path":"https://keras.posit.co/articles/examples/text_classification_from_scratch.html","id":"make-an-end-to-end-model","dir":"Articles > Examples","previous_headings":"","what":"Make an end-to-end model","title":"Text classification from scratch","text":"want obtain model capable processing raw strings, can simply create new model (using weights just trained):","code":"# A string input inputs <- keras_input(shape = c(1), dtype = \"string\") # Turn strings into vocab indices indices <- vectorize_layer(inputs) # Turn vocab indices into predictions outputs <- model(indices)  # Our end to end model end_to_end_model <- keras_model(inputs, outputs) end_to_end_model |> compile(   loss = \"binary_crossentropy\",   optimizer = \"adam\",   metrics = c(\"accuracy\") )  # Test it with `raw_test_ds`, which yields raw strings end_to_end_model |> evaluate(raw_test_ds) ## 782/782 - 3s - 4ms/step - accuracy: 0.8532 - loss: 0.4063 ## $accuracy ## [1] 0.8532 ## ## $loss ## [1] 0.4062699"},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"introduction","dir":"Articles > Examples > Timeseries","previous_headings":"","what":"Introduction","title":"Timeseries classification from scratch","text":"example shows timeseries classification scratch, starting raw CSV timeseries files disk. demonstrate workflow FordA dataset UCR/UEA archive.","code":""},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"setup","dir":"Articles > Examples > Timeseries","previous_headings":"","what":"Setup","title":"Timeseries classification from scratch","text":"","code":"library(keras3) use_backend(\"jax\")"},{"path":[]},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"dataset-description","dir":"Articles > Examples > Timeseries","previous_headings":"Load the data: the FordA dataset","what":"Dataset description","title":"Timeseries classification from scratch","text":"dataset using called FordA. data comes UCR archive. dataset contains 3601 training instances another 1320 testing instances. timeseries corresponds measurement engine noise captured motor sensor. task, goal automatically detect presence specific issue engine. problem balanced binary classification task. full description dataset can found .","code":""},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"read-the-tsv-data","dir":"Articles > Examples > Timeseries","previous_headings":"Load the data: the FordA dataset","what":"Read the TSV data","title":"Timeseries classification from scratch","text":"use FordA_TRAIN file training FordA_TEST file testing. simplicity dataset allows us demonstrate effectively use ConvNets timeseries classification. file, first column corresponds label.","code":"get_data <- function(path) {   if(path |> startsWith(\"https://\"))     path <- get_file(origin = path)  # cache file locally    data <- readr::read_tsv(     path, col_names = FALSE,     # Each row is: one integer (the label),     # followed by 500 doubles (the timeseries)     col_types = paste0(\"i\", strrep(\"d\", 500))   )    y <- as.matrix(data[[1]])   x <- as.matrix(data[,-1])   dimnames(x) <- dimnames(y) <- NULL    list(x, y) }  root_url <- \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\" c(x_train, y_train) %<-% get_data(paste0(root_url, \"FordA_TRAIN.tsv\")) c(x_test, y_test) %<-% get_data(paste0(root_url, \"FordA_TEST.tsv\"))  str(keras3:::named_list(   x_train, y_train,   x_test, y_test )) ## List of 4 ##  $ x_train: num [1:3601, 1:500] -0.797 0.805 0.728 -0.234 -0.171 ... ##  $ y_train: int [1:3601, 1] -1 1 -1 -1 -1 1 1 1 1 1 ... ##  $ x_test : num [1:1320, 1:500] -0.14 0.334 0.717 1.24 -1.159 ... ##  $ y_test : int [1:1320, 1] -1 -1 -1 1 -1 1 -1 -1 1 1 ..."},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"visualize-the-data","dir":"Articles > Examples > Timeseries","previous_headings":"","what":"Visualize the data","title":"Timeseries classification from scratch","text":"visualize one timeseries example class dataset.","code":"plot(NULL, main = \"Timeseries Data\",      xlab = \"Timepoints\",  ylab = \"Values\",      xlim = c(1, ncol(x_test)),      ylim = range(x_test)) grid() lines(x_test[match(-1, y_test), ], col = \"blue\") lines(x_test[match( 1, y_test), ], col = \"red\") legend(\"topright\", legend=c(\"label -1\", \"label 1\"), col=c(\"blue\", \"red\"), lty=1)"},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"standardize-the-data","dir":"Articles > Examples > Timeseries","previous_headings":"","what":"Standardize the data","title":"Timeseries classification from scratch","text":"timeseries already single length (500). However, values usually various ranges. ideal neural network; general seek make input values normalized. specific dataset, data already z-normalized: timeseries sample mean equal zero standard deviation equal one. type normalization common timeseries classification problems, see Bagnall et al. (2016). Note timeseries data used univariate, meaning one channel per timeseries example. therefore transform timeseries multivariate one one channel using simple reshaping via numpy. allow us construct model easily applicable multivariate time series. Finally, order use sparse_categorical_crossentropy, count number classes beforehand. Now shuffle training set using validation_split option later training. Standardize labels positive integers. expected labels 0 1.","code":"dim(x_train) <- c(dim(x_train), 1) dim(x_test) <- c(dim(x_test), 1) num_classes <- length(unique(y_train)) c(x_train, y_train) %<-% listarrays::shuffle_rows(x_train, y_train) # idx <- sample.int(nrow(x_train)) # x_train %<>% .[idx,, ,drop = FALSE] # y_train %<>% .[idx,  ,drop = FALSE] y_train[y_train == -1L] <- 0L y_test[y_test == -1L] <- 0L"},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"build-a-model","dir":"Articles > Examples > Timeseries","previous_headings":"","what":"Build a model","title":"Timeseries classification from scratch","text":"build Fully Convolutional Neural Network originally proposed paper. implementation based TF 2 version provided . following hyperparameters (kernel_size, filters, usage BatchNorm) found via random search using KerasTuner. plot chunk unnamed-chunk-9","code":"make_model <- function(input_shape) {   inputs <- keras_input(input_shape)    outputs <- inputs |>     # conv1     layer_conv_1d(filters = 64, kernel_size = 3, padding = \"same\") |>     layer_batch_normalization() |>     layer_activation_relu() |>     # conv2     layer_conv_1d(filters = 64, kernel_size = 3, padding = \"same\") |>     layer_batch_normalization() |>     layer_activation_relu() |>     # conv3     layer_conv_1d(filters = 64, kernel_size = 3, padding = \"same\") |>     layer_batch_normalization() |>     layer_activation_relu() |>     # pooling     layer_global_average_pooling_1d() |>     # final output     layer_dense(num_classes, activation = \"softmax\")    keras_model(inputs, outputs) }  model <- make_model(input_shape = dim(x_train)[-1]) model ## Model: \"functional_1\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓ ## ┃ Layer (type)                ┃ Output Shape          ┃    Param # ┃ Trai… ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩ ## │ input_layer (InputLayer)    │ (None, 500, 1)        │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ conv1d_2 (Conv1D)           │ (None, 500, 64)       │        256 │   Y   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ batch_normalization_2       │ (None, 500, 64)       │        256 │   Y   │ ## │ (BatchNormalization)        │                       │            │       │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ re_lu_2 (ReLU)              │ (None, 500, 64)       │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ conv1d_1 (Conv1D)           │ (None, 500, 64)       │     12,352 │   Y   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ batch_normalization_1       │ (None, 500, 64)       │        256 │   Y   │ ## │ (BatchNormalization)        │                       │            │       │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ re_lu_1 (ReLU)              │ (None, 500, 64)       │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ conv1d (Conv1D)             │ (None, 500, 64)       │     12,352 │   Y   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ batch_normalization         │ (None, 500, 64)       │        256 │   Y   │ ## │ (BatchNormalization)        │                       │            │       │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ re_lu (ReLU)                │ (None, 500, 64)       │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ global_average_pooling1d    │ (None, 64)            │          0 │   -   │ ## │ (GlobalAveragePooling1D)    │                       │            │       │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ dense (Dense)               │ (None, 2)             │        130 │   Y   │ ## └─────────────────────────────┴───────────────────────┴────────────┴───────┘ ##  Total params: 25,858 (101.01 KB) ##  Trainable params: 25,474 (99.51 KB) ##  Non-trainable params: 384 (1.50 KB) plot(model, show_shapes = TRUE)"},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"train-the-model","dir":"Articles > Examples > Timeseries","previous_headings":"","what":"Train the model","title":"Timeseries classification from scratch","text":"","code":"epochs <- 500 batch_size <- 32  callbacks <- c(   callback_model_checkpoint(     \"best_model.keras\", save_best_only = TRUE,     monitor = \"val_loss\"   ),   callback_reduce_lr_on_plateau(     monitor = \"val_loss\", factor = 0.5,     patience = 20, min_lr = 0.0001   ),   callback_early_stopping(     monitor = \"val_loss\", patience = 50,     verbose = 1   ) )   model |> compile(   optimizer = \"adam\",   loss = \"sparse_categorical_crossentropy\",   metrics = \"sparse_categorical_accuracy\" )  history <- model |> fit(   x_train, y_train,   batch_size = batch_size,   epochs = epochs,   callbacks = callbacks,   validation_split = 0.2 ) ## Epoch 1/500 ## 90/90 - 2s - 20ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.6958 - val_loss: 0.7534 - val_sparse_categorical_accuracy: 0.4896 - learning_rate: 0.0010 ## Epoch 2/500 ## 90/90 - 0s - 2ms/step - loss: 0.4916 - sparse_categorical_accuracy: 0.7552 - val_loss: 0.7851 - val_sparse_categorical_accuracy: 0.4896 - learning_rate: 0.0010 ## Epoch 3/500 ## 90/90 - 0s - 2ms/step - loss: 0.4628 - sparse_categorical_accuracy: 0.7670 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.5645 - learning_rate: 0.0010 ## Epoch 4/500 ## 90/90 - 0s - 2ms/step - loss: 0.4168 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.6447 - val_sparse_categorical_accuracy: 0.6713 - learning_rate: 0.0010 ## Epoch 5/500 ## 90/90 - 0s - 2ms/step - loss: 0.4194 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5328 - val_sparse_categorical_accuracy: 0.7323 - learning_rate: 0.0010 ## Epoch 6/500 ## 90/90 - 0s - 2ms/step - loss: 0.4026 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.4502 - val_sparse_categorical_accuracy: 0.8239 - learning_rate: 0.0010 ## Epoch 7/500 ## 90/90 - 0s - 2ms/step - loss: 0.3974 - sparse_categorical_accuracy: 0.8059 - val_loss: 1.1050 - val_sparse_categorical_accuracy: 0.6227 - learning_rate: 0.0010 ## Epoch 8/500 ## 90/90 - 0s - 2ms/step - loss: 0.3852 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.3881 - val_sparse_categorical_accuracy: 0.8183 - learning_rate: 0.0010 ## Epoch 9/500 ## 90/90 - 0s - 1ms/step - loss: 0.3827 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.7892 - learning_rate: 0.0010 ## Epoch 10/500 ## 90/90 - 0s - 1ms/step - loss: 0.3802 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.3901 - val_sparse_categorical_accuracy: 0.8225 - learning_rate: 0.0010 ## Epoch 11/500 ## 90/90 - 0s - 2ms/step - loss: 0.3727 - sparse_categorical_accuracy: 0.8174 - val_loss: 0.6322 - val_sparse_categorical_accuracy: 0.6741 - learning_rate: 0.0010 ## Epoch 12/500 ## 90/90 - 0s - 2ms/step - loss: 0.3656 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.3699 - val_sparse_categorical_accuracy: 0.8308 - learning_rate: 0.0010 ## Epoch 13/500 ## 90/90 - 0s - 1ms/step - loss: 0.3524 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.4632 - val_sparse_categorical_accuracy: 0.7642 - learning_rate: 0.0010 ## Epoch 14/500 ## 90/90 - 0s - 2ms/step - loss: 0.3553 - sparse_categorical_accuracy: 0.8306 - val_loss: 0.4022 - val_sparse_categorical_accuracy: 0.7795 - learning_rate: 0.0010 ## Epoch 15/500 ## 90/90 - 0s - 2ms/step - loss: 0.3404 - sparse_categorical_accuracy: 0.8444 - val_loss: 0.5106 - val_sparse_categorical_accuracy: 0.7240 - learning_rate: 0.0010 ## Epoch 16/500 ## 90/90 - 0s - 2ms/step - loss: 0.3394 - sparse_categorical_accuracy: 0.8497 - val_loss: 0.3802 - val_sparse_categorical_accuracy: 0.8169 - learning_rate: 0.0010 ## Epoch 17/500 ## 90/90 - 0s - 1ms/step - loss: 0.3282 - sparse_categorical_accuracy: 0.8559 - val_loss: 0.3894 - val_sparse_categorical_accuracy: 0.8086 - learning_rate: 0.0010 ## Epoch 18/500 ## 90/90 - 0s - 2ms/step - loss: 0.3183 - sparse_categorical_accuracy: 0.8566 - val_loss: 0.3239 - val_sparse_categorical_accuracy: 0.8558 - learning_rate: 0.0010 ## Epoch 19/500 ## 90/90 - 0s - 2ms/step - loss: 0.3146 - sparse_categorical_accuracy: 0.8642 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.7725 - learning_rate: 0.0010 ## Epoch 20/500 ## 90/90 - 0s - 2ms/step - loss: 0.3107 - sparse_categorical_accuracy: 0.8656 - val_loss: 0.7768 - val_sparse_categorical_accuracy: 0.6214 - learning_rate: 0.0010 ## Epoch 21/500 ## 90/90 - 0s - 2ms/step - loss: 0.2951 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.3365 - val_sparse_categorical_accuracy: 0.8516 - learning_rate: 0.0010 ## Epoch 22/500 ## 90/90 - 0s - 2ms/step - loss: 0.2946 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.3139 - val_sparse_categorical_accuracy: 0.8544 - learning_rate: 0.0010 ## Epoch 23/500 ## 90/90 - 0s - 1ms/step - loss: 0.2847 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.8195 - val_sparse_categorical_accuracy: 0.5714 - learning_rate: 0.0010 ## Epoch 24/500 ## 90/90 - 0s - 2ms/step - loss: 0.2788 - sparse_categorical_accuracy: 0.8861 - val_loss: 0.6453 - val_sparse_categorical_accuracy: 0.6616 - learning_rate: 0.0010 ## Epoch 25/500 ## 90/90 - 0s - 2ms/step - loss: 0.2819 - sparse_categorical_accuracy: 0.8809 - val_loss: 1.8959 - val_sparse_categorical_accuracy: 0.5104 - learning_rate: 0.0010 ## Epoch 26/500 ## 90/90 - 0s - 2ms/step - loss: 0.3038 - sparse_categorical_accuracy: 0.8625 - val_loss: 1.0902 - val_sparse_categorical_accuracy: 0.5811 - learning_rate: 0.0010 ## Epoch 27/500 ## 90/90 - 0s - 2ms/step - loss: 0.2678 - sparse_categorical_accuracy: 0.8917 - val_loss: 0.9476 - val_sparse_categorical_accuracy: 0.6297 - learning_rate: 0.0010 ## Epoch 28/500 ## 90/90 - 0s - 2ms/step - loss: 0.2883 - sparse_categorical_accuracy: 0.8760 - val_loss: 2.6088 - val_sparse_categorical_accuracy: 0.5368 - learning_rate: 0.0010 ## Epoch 29/500 ## 90/90 - 0s - 1ms/step - loss: 0.2730 - sparse_categorical_accuracy: 0.8795 - val_loss: 0.8953 - val_sparse_categorical_accuracy: 0.6227 - learning_rate: 0.0010 ## Epoch 30/500 ## 90/90 - 0s - 1ms/step - loss: 0.2686 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.4891 - val_sparse_categorical_accuracy: 0.7739 - learning_rate: 0.0010 ## Epoch 31/500 ## 90/90 - 0s - 2ms/step - loss: 0.2662 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.3040 - val_sparse_categorical_accuracy: 0.8710 - learning_rate: 0.0010 ## Epoch 32/500 ## 90/90 - 0s - 1ms/step - loss: 0.2629 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.3474 - val_sparse_categorical_accuracy: 0.8363 - learning_rate: 0.0010 ## Epoch 33/500 ## 90/90 - 0s - 2ms/step - loss: 0.2515 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.4071 - val_sparse_categorical_accuracy: 0.7961 - learning_rate: 0.0010 ## Epoch 34/500 ## 90/90 - 0s - 1ms/step - loss: 0.2420 - sparse_categorical_accuracy: 0.8997 - val_loss: 1.1083 - val_sparse_categorical_accuracy: 0.5229 - learning_rate: 0.0010 ## Epoch 35/500 ## 90/90 - 0s - 2ms/step - loss: 0.2657 - sparse_categorical_accuracy: 0.8872 - val_loss: 1.1045 - val_sparse_categorical_accuracy: 0.5465 - learning_rate: 0.0010 ## Epoch 36/500 ## 90/90 - 0s - 2ms/step - loss: 0.2502 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.5667 - val_sparse_categorical_accuracy: 0.7143 - learning_rate: 0.0010 ## Epoch 37/500 ## 90/90 - 0s - 2ms/step - loss: 0.2487 - sparse_categorical_accuracy: 0.8931 - val_loss: 0.5075 - val_sparse_categorical_accuracy: 0.7448 - learning_rate: 0.0010 ## Epoch 38/500 ## 90/90 - 0s - 2ms/step - loss: 0.2533 - sparse_categorical_accuracy: 0.8962 - val_loss: 2.2239 - val_sparse_categorical_accuracy: 0.6019 - learning_rate: 0.0010 ## Epoch 39/500 ## 90/90 - 0s - 2ms/step - loss: 0.2472 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.7943 - val_sparse_categorical_accuracy: 0.6630 - learning_rate: 0.0010 ## Epoch 40/500 ## 90/90 - 0s - 2ms/step - loss: 0.2465 - sparse_categorical_accuracy: 0.8983 - val_loss: 0.3195 - val_sparse_categorical_accuracy: 0.8516 - learning_rate: 0.0010 ## Epoch 41/500 ## 90/90 - 0s - 2ms/step - loss: 0.2316 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.3884 - val_sparse_categorical_accuracy: 0.8031 - learning_rate: 0.0010 ## Epoch 42/500 ## 90/90 - 0s - 1ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.7739 - learning_rate: 0.0010 ## Epoch 43/500 ## 90/90 - 0s - 2ms/step - loss: 0.2431 - sparse_categorical_accuracy: 0.8993 - val_loss: 0.2912 - val_sparse_categorical_accuracy: 0.8752 - learning_rate: 0.0010 ## Epoch 44/500 ## 90/90 - 0s - 2ms/step - loss: 0.2297 - sparse_categorical_accuracy: 0.9087 - val_loss: 1.2659 - val_sparse_categorical_accuracy: 0.6338 - learning_rate: 0.0010 ## Epoch 45/500 ## 90/90 - 0s - 2ms/step - loss: 0.2300 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.2956 - val_sparse_categorical_accuracy: 0.8724 - learning_rate: 0.0010 ## Epoch 46/500 ## 90/90 - 0s - 2ms/step - loss: 0.2330 - sparse_categorical_accuracy: 0.9062 - val_loss: 0.7793 - val_sparse_categorical_accuracy: 0.6796 - learning_rate: 0.0010 ## Epoch 47/500 ## 90/90 - 0s - 2ms/step - loss: 0.2155 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.9919 - val_sparse_categorical_accuracy: 0.6436 - learning_rate: 0.0010 ## Epoch 48/500 ## 90/90 - 0s - 2ms/step - loss: 0.2166 - sparse_categorical_accuracy: 0.9135 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.8627 - learning_rate: 0.0010 ## Epoch 49/500 ## 90/90 - 0s - 2ms/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9125 - val_loss: 1.2487 - val_sparse_categorical_accuracy: 0.7101 - learning_rate: 0.0010 ## Epoch 50/500 ## 90/90 - 0s - 2ms/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9184 - val_loss: 0.2427 - val_sparse_categorical_accuracy: 0.8974 - learning_rate: 0.0010 ## Epoch 51/500 ## 90/90 - 0s - 2ms/step - loss: 0.2137 - sparse_categorical_accuracy: 0.9135 - val_loss: 1.0448 - val_sparse_categorical_accuracy: 0.6644 - learning_rate: 0.0010 ## Epoch 52/500 ## 90/90 - 0s - 2ms/step - loss: 0.2035 - sparse_categorical_accuracy: 0.9208 - val_loss: 3.2190 - val_sparse_categorical_accuracy: 0.5090 - learning_rate: 0.0010 ## Epoch 53/500 ## 90/90 - 0s - 2ms/step - loss: 0.1939 - sparse_categorical_accuracy: 0.9257 - val_loss: 3.7529 - val_sparse_categorical_accuracy: 0.5562 - learning_rate: 0.0010 ## Epoch 54/500 ## 90/90 - 0s - 1ms/step - loss: 0.1866 - sparse_categorical_accuracy: 0.9253 - val_loss: 2.3514 - val_sparse_categorical_accuracy: 0.6089 - learning_rate: 0.0010 ## Epoch 55/500 ## 90/90 - 0s - 2ms/step - loss: 0.1748 - sparse_categorical_accuracy: 0.9347 - val_loss: 1.5064 - val_sparse_categorical_accuracy: 0.6533 - learning_rate: 0.0010 ## Epoch 56/500 ## 90/90 - 0s - 1ms/step - loss: 0.1562 - sparse_categorical_accuracy: 0.9472 - val_loss: 1.7046 - val_sparse_categorical_accuracy: 0.6158 - learning_rate: 0.0010 ## Epoch 57/500 ## 90/90 - 0s - 2ms/step - loss: 0.1536 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.2666 - val_sparse_categorical_accuracy: 0.8752 - learning_rate: 0.0010 ## Epoch 58/500 ## 90/90 - 0s - 2ms/step - loss: 0.1457 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1585 - val_sparse_categorical_accuracy: 0.9348 - learning_rate: 0.0010 ## Epoch 59/500 ## 90/90 - 0s - 2ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.9663 - val_sparse_categorical_accuracy: 0.6546 - learning_rate: 0.0010 ## Epoch 60/500 ## 90/90 - 0s - 2ms/step - loss: 0.1355 - sparse_categorical_accuracy: 0.9597 - val_loss: 4.1886 - val_sparse_categorical_accuracy: 0.5950 - learning_rate: 0.0010 ## Epoch 61/500 ## 90/90 - 0s - 1ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9542 - val_loss: 1.8469 - val_sparse_categorical_accuracy: 0.6893 - learning_rate: 0.0010 ## Epoch 62/500 ## 90/90 - 0s - 1ms/step - loss: 0.1378 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.4279 - val_sparse_categorical_accuracy: 0.7933 - learning_rate: 0.0010 ## Epoch 63/500 ## 90/90 - 0s - 1ms/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9465 - val_loss: 0.2616 - val_sparse_categorical_accuracy: 0.8696 - learning_rate: 0.0010 ## Epoch 64/500 ## 90/90 - 0s - 1ms/step - loss: 0.1395 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8363 - learning_rate: 0.0010 ## Epoch 65/500 ## 90/90 - 0s - 1ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.1658 - val_sparse_categorical_accuracy: 0.9376 - learning_rate: 0.0010 ## Epoch 66/500 ## 90/90 - 0s - 2ms/step - loss: 0.1188 - sparse_categorical_accuracy: 0.9639 - val_loss: 0.1924 - val_sparse_categorical_accuracy: 0.9168 - learning_rate: 0.0010 ## Epoch 67/500 ## 90/90 - 0s - 1ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.2742 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 0.0010 ## Epoch 68/500 ## 90/90 - 0s - 1ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.2514 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 0.0010 ## Epoch 69/500 ## 90/90 - 0s - 1ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.4682 - val_sparse_categorical_accuracy: 0.7684 - learning_rate: 0.0010 ## Epoch 70/500 ## 90/90 - 0s - 1ms/step - loss: 0.1244 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.2919 - val_sparse_categorical_accuracy: 0.8627 - learning_rate: 0.0010 ## Epoch 71/500 ## 90/90 - 0s - 1ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9608 - val_loss: 1.0799 - val_sparse_categorical_accuracy: 0.7240 - learning_rate: 0.0010 ## Epoch 72/500 ## 90/90 - 0s - 1ms/step - loss: 0.1249 - sparse_categorical_accuracy: 0.9587 - val_loss: 1.2666 - val_sparse_categorical_accuracy: 0.7143 - learning_rate: 0.0010 ## Epoch 73/500 ## 90/90 - 0s - 1ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9670 - val_loss: 1.9443 - val_sparse_categorical_accuracy: 0.6963 - learning_rate: 0.0010 ## Epoch 74/500 ## 90/90 - 0s - 2ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1345 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 0.0010 ## Epoch 75/500 ## 90/90 - 0s - 2ms/step - loss: 0.1250 - sparse_categorical_accuracy: 0.9594 - val_loss: 0.2415 - val_sparse_categorical_accuracy: 0.9140 - learning_rate: 0.0010 ## Epoch 76/500 ## 90/90 - 0s - 1ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9071 - learning_rate: 0.0010 ## Epoch 77/500 ## 90/90 - 0s - 2ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1445 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 0.0010 ## Epoch 78/500 ## 90/90 - 0s - 2ms/step - loss: 0.1151 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.1520 - val_sparse_categorical_accuracy: 0.9376 - learning_rate: 0.0010 ## Epoch 79/500 ## 90/90 - 0s - 1ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.2077 - val_sparse_categorical_accuracy: 0.9029 - learning_rate: 0.0010 ## Epoch 80/500 ## 90/90 - 0s - 1ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9653 - val_loss: 2.8488 - val_sparse_categorical_accuracy: 0.6935 - learning_rate: 0.0010 ## Epoch 81/500 ## 90/90 - 0s - 1ms/step - loss: 0.1139 - sparse_categorical_accuracy: 0.9639 - val_loss: 2.7853 - val_sparse_categorical_accuracy: 0.6602 - learning_rate: 0.0010 ## Epoch 82/500 ## 90/90 - 0s - 2ms/step - loss: 0.1031 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.3471 - val_sparse_categorical_accuracy: 0.8155 - learning_rate: 0.0010 ## Epoch 83/500 ## 90/90 - 0s - 2ms/step - loss: 0.1164 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.1823 - val_sparse_categorical_accuracy: 0.9279 - learning_rate: 0.0010 ## Epoch 84/500 ## 90/90 - 0s - 2ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.1702 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 0.0010 ## Epoch 85/500 ## 90/90 - 0s - 2ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.8909 - val_sparse_categorical_accuracy: 0.7559 - learning_rate: 0.0010 ## Epoch 86/500 ## 90/90 - 0s - 1ms/step - loss: 0.1007 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.1385 - val_sparse_categorical_accuracy: 0.9445 - learning_rate: 0.0010 ## Epoch 87/500 ## 90/90 - 0s - 1ms/step - loss: 0.1053 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1473 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 0.0010 ## Epoch 88/500 ## 90/90 - 0s - 1ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.2733 - val_sparse_categorical_accuracy: 0.8890 - learning_rate: 0.0010 ## Epoch 89/500 ## 90/90 - 0s - 1ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9625 - val_loss: 1.0660 - val_sparse_categorical_accuracy: 0.7379 - learning_rate: 0.0010 ## Epoch 90/500 ## 90/90 - 0s - 1ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9688 - val_loss: 1.0865 - val_sparse_categorical_accuracy: 0.7393 - learning_rate: 0.0010 ## Epoch 91/500 ## 90/90 - 0s - 2ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.1782 - val_sparse_categorical_accuracy: 0.9237 - learning_rate: 0.0010 ## Epoch 92/500 ## 90/90 - 0s - 1ms/step - loss: 0.1020 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.5247 - val_sparse_categorical_accuracy: 0.8003 - learning_rate: 0.0010 ## Epoch 93/500 ## 90/90 - 0s - 1ms/step - loss: 0.1002 - sparse_categorical_accuracy: 0.9663 - val_loss: 1.4023 - val_sparse_categorical_accuracy: 0.7323 - learning_rate: 0.0010 ## Epoch 94/500 ## 90/90 - 0s - 2ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.4220 - val_sparse_categorical_accuracy: 0.8280 - learning_rate: 0.0010 ## Epoch 95/500 ## 90/90 - 0s - 2ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1210 - val_sparse_categorical_accuracy: 0.9445 - learning_rate: 5.0000e-04 ## Epoch 96/500 ## 90/90 - 0s - 1ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.1591 - val_sparse_categorical_accuracy: 0.9320 - learning_rate: 5.0000e-04 ## Epoch 97/500 ## 90/90 - 0s - 2ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 5.0000e-04 ## Epoch 98/500 ## 90/90 - 0s - 2ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1150 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 5.0000e-04 ## Epoch 99/500 ## 90/90 - 0s - 1ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.1212 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 5.0000e-04 ## Epoch 100/500 ## 90/90 - 0s - 1ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1309 - val_sparse_categorical_accuracy: 0.9473 - learning_rate: 5.0000e-04 ## Epoch 101/500 ## 90/90 - 0s - 1ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.2148 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 5.0000e-04 ## Epoch 102/500 ## 90/90 - 0s - 1ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 5.0000e-04 ## Epoch 103/500 ## 90/90 - 0s - 2ms/step - loss: 0.0862 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 5.0000e-04 ## Epoch 104/500 ## 90/90 - 0s - 2ms/step - loss: 0.0857 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1257 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 5.0000e-04 ## Epoch 105/500 ## 90/90 - 0s - 2ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9126 - learning_rate: 5.0000e-04 ## Epoch 106/500 ## 90/90 - 0s - 1ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.2501 - val_sparse_categorical_accuracy: 0.9168 - learning_rate: 5.0000e-04 ## Epoch 107/500 ## 90/90 - 0s - 2ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.1464 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 5.0000e-04 ## Epoch 108/500 ## 90/90 - 0s - 1ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1954 - val_sparse_categorical_accuracy: 0.9223 - learning_rate: 5.0000e-04 ## Epoch 109/500 ## 90/90 - 0s - 2ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.3662 - val_sparse_categorical_accuracy: 0.8696 - learning_rate: 5.0000e-04 ## Epoch 110/500 ## 90/90 - 0s - 2ms/step - loss: 0.0871 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1478 - val_sparse_categorical_accuracy: 0.9334 - learning_rate: 5.0000e-04 ## Epoch 111/500 ## 90/90 - 0s - 2ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1419 - val_sparse_categorical_accuracy: 0.9473 - learning_rate: 5.0000e-04 ## Epoch 112/500 ## 90/90 - 0s - 2ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.2088 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 5.0000e-04 ## Epoch 113/500 ## 90/90 - 0s - 1ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.2227 - val_sparse_categorical_accuracy: 0.9029 - learning_rate: 5.0000e-04 ## Epoch 114/500 ## 90/90 - 0s - 1ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.2138 - val_sparse_categorical_accuracy: 0.8932 - learning_rate: 5.0000e-04 ## Epoch 115/500 ## 90/90 - 0s - 1ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.2368 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 5.0000e-04 ## Epoch 116/500 ## 90/90 - 0s - 1ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.1174 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 5.0000e-04 ## Epoch 117/500 ## 90/90 - 0s - 2ms/step - loss: 0.0795 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1728 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 5.0000e-04 ## Epoch 118/500 ## 90/90 - 0s - 2ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1200 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 5.0000e-04 ## Epoch 119/500 ## 90/90 - 0s - 1ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.1758 - val_sparse_categorical_accuracy: 0.9279 - learning_rate: 5.0000e-04 ## Epoch 120/500 ## 90/90 - 0s - 2ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1413 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 5.0000e-04 ## Epoch 121/500 ## 90/90 - 0s - 2ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9348 - learning_rate: 5.0000e-04 ## Epoch 122/500 ## 90/90 - 0s - 1ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1244 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 5.0000e-04 ## Epoch 123/500 ## 90/90 - 0s - 1ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1682 - val_sparse_categorical_accuracy: 0.9376 - learning_rate: 5.0000e-04 ## Epoch 124/500 ## 90/90 - 0s - 1ms/step - loss: 0.0799 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.1143 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 2.5000e-04 ## Epoch 125/500 ## 90/90 - 0s - 2ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1146 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04 ## Epoch 126/500 ## 90/90 - 0s - 1ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1217 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04 ## Epoch 127/500 ## 90/90 - 0s - 1ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1158 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04 ## Epoch 128/500 ## 90/90 - 0s - 1ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9334 - learning_rate: 2.5000e-04 ## Epoch 129/500 ## 90/90 - 0s - 2ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1121 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 2.5000e-04 ## Epoch 130/500 ## 90/90 - 0s - 1ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1289 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 2.5000e-04 ## Epoch 131/500 ## 90/90 - 0s - 2ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.1122 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 2.5000e-04 ## Epoch 132/500 ## 90/90 - 0s - 2ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.1418 - val_sparse_categorical_accuracy: 0.9348 - learning_rate: 2.5000e-04 ## Epoch 133/500 ## 90/90 - 0s - 2ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1114 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04 ## Epoch 134/500 ## 90/90 - 0s - 2ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1259 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 2.5000e-04 ## Epoch 135/500 ## 90/90 - 0s - 2ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04 ## Epoch 136/500 ## 90/90 - 0s - 2ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1163 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04 ## Epoch 137/500 ## 90/90 - 0s - 2ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1444 - val_sparse_categorical_accuracy: 0.9404 - learning_rate: 2.5000e-04 ## Epoch 138/500 ## 90/90 - 0s - 1ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1133 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 2.5000e-04 ## Epoch 139/500 ## 90/90 - 0s - 2ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1315 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04 ## Epoch 140/500 ## 90/90 - 0s - 2ms/step - loss: 0.0703 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.2403 - val_sparse_categorical_accuracy: 0.9085 - learning_rate: 2.5000e-04 ## Epoch 141/500 ## 90/90 - 0s - 1ms/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1141 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04 ## Epoch 142/500 ## 90/90 - 0s - 1ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 2.5000e-04 ## Epoch 143/500 ## 90/90 - 0s - 1ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1443 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04 ## Epoch 144/500 ## 90/90 - 0s - 1ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1368 - val_sparse_categorical_accuracy: 0.9431 - learning_rate: 2.5000e-04 ## Epoch 145/500 ## 90/90 - 0s - 2ms/step - loss: 0.0661 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1226 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04 ## Epoch 146/500 ## 90/90 - 0s - 2ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1898 - val_sparse_categorical_accuracy: 0.9223 - learning_rate: 2.5000e-04 ## Epoch 147/500 ## 90/90 - 0s - 1ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1139 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04 ## Epoch 148/500 ## 90/90 - 0s - 1ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1119 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04 ## Epoch 149/500 ## 90/90 - 0s - 2ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04 ## Epoch 150/500 ## 90/90 - 0s - 2ms/step - loss: 0.0723 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1411 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 2.5000e-04 ## Epoch 151/500 ## 90/90 - 0s - 2ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 2.5000e-04 ## Epoch 152/500 ## 90/90 - 0s - 2ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.2827 - val_sparse_categorical_accuracy: 0.8946 - learning_rate: 2.5000e-04 ## Epoch 153/500 ## 90/90 - 0s - 2ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1050 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04 ## Epoch 154/500 ## 90/90 - 0s - 2ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1110 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04 ## Epoch 155/500 ## 90/90 - 0s - 1ms/step - loss: 0.0688 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1171 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04 ## Epoch 156/500 ## 90/90 - 0s - 2ms/step - loss: 0.0710 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1373 - val_sparse_categorical_accuracy: 0.9431 - learning_rate: 2.5000e-04 ## Epoch 157/500 ## 90/90 - 0s - 1ms/step - loss: 0.0706 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1091 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04 ## Epoch 158/500 ## 90/90 - 0s - 2ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.5644 - val_sparse_categorical_accuracy: 0.8280 - learning_rate: 2.5000e-04 ## Epoch 159/500 ## 90/90 - 0s - 2ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04 ## Epoch 160/500 ## 90/90 - 0s - 2ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1114 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04 ## Epoch 161/500 ## 90/90 - 0s - 1ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1200 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04 ## Epoch 162/500 ## 90/90 - 0s - 2ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1382 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04 ## Epoch 163/500 ## 90/90 - 0s - 1ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1175 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 2.5000e-04 ## Epoch 164/500 ## 90/90 - 0s - 2ms/step - loss: 0.0655 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1251 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 2.5000e-04 ## Epoch 165/500 ## 90/90 - 0s - 2ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1051 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 2.5000e-04 ## Epoch 166/500 ## 90/90 - 0s - 2ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1921 - val_sparse_categorical_accuracy: 0.9223 - learning_rate: 2.5000e-04 ## Epoch 167/500 ## 90/90 - 0s - 1ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1396 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 2.5000e-04 ## Epoch 168/500 ## 90/90 - 0s - 2ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8807 - learning_rate: 2.5000e-04 ## Epoch 169/500 ## 90/90 - 0s - 1ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1077 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 2.5000e-04 ## Epoch 170/500 ## 90/90 - 0s - 1ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.2135 - val_sparse_categorical_accuracy: 0.9154 - learning_rate: 2.5000e-04 ## Epoch 171/500 ## 90/90 - 0s - 1ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1792 - val_sparse_categorical_accuracy: 0.9390 - learning_rate: 2.5000e-04 ## Epoch 172/500 ## 90/90 - 0s - 2ms/step - loss: 0.0648 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.2222 - val_sparse_categorical_accuracy: 0.9126 - learning_rate: 2.5000e-04 ## Epoch 173/500 ## 90/90 - 0s - 2ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1139 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 2.5000e-04 ## Epoch 174/500 ## 90/90 - 0s - 3ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04 ## Epoch 175/500 ## 90/90 - 0s - 2ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.2025 - val_sparse_categorical_accuracy: 0.9209 - learning_rate: 2.5000e-04 ## Epoch 176/500 ## 90/90 - 0s - 2ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.5486 - val_sparse_categorical_accuracy: 0.8405 - learning_rate: 2.5000e-04 ## Epoch 177/500 ## 90/90 - 0s - 2ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1643 - val_sparse_categorical_accuracy: 0.9404 - learning_rate: 2.5000e-04 ## Epoch 178/500 ## 90/90 - 0s - 1ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1540 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 2.5000e-04 ## Epoch 179/500 ## 90/90 - 0s - 1ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1096 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 2.5000e-04 ## Epoch 180/500 ## 90/90 - 0s - 2ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1349 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.2500e-04 ## Epoch 181/500 ## 90/90 - 0s - 2ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1554 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 1.2500e-04 ## Epoch 182/500 ## 90/90 - 0s - 1ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1344 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.2500e-04 ## Epoch 183/500 ## 90/90 - 0s - 2ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.2500e-04 ## Epoch 184/500 ## 90/90 - 0s - 2ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1557 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 1.2500e-04 ## Epoch 185/500 ## 90/90 - 0s - 2ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04 ## Epoch 186/500 ## 90/90 - 0s - 2ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1537 - val_sparse_categorical_accuracy: 0.9445 - learning_rate: 1.2500e-04 ## Epoch 187/500 ## 90/90 - 0s - 2ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1106 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.2500e-04 ## Epoch 188/500 ## 90/90 - 0s - 2ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1444 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 1.2500e-04 ## Epoch 189/500 ## 90/90 - 0s - 2ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1516 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 1.2500e-04 ## Epoch 190/500 ## 90/90 - 0s - 2ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1198 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04 ## Epoch 191/500 ## 90/90 - 0s - 2ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1348 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 1.2500e-04 ## Epoch 192/500 ## 90/90 - 0s - 2ms/step - loss: 0.0647 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.1879 - val_sparse_categorical_accuracy: 0.9293 - learning_rate: 1.2500e-04 ## Epoch 193/500 ## 90/90 - 0s - 2ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1514 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.2500e-04 ## Epoch 194/500 ## 90/90 - 0s - 3ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1164 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 1.2500e-04 ## Epoch 195/500 ## 90/90 - 0s - 2ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1167 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 1.2500e-04 ## Epoch 196/500 ## 90/90 - 0s - 2ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1196 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.2500e-04 ## Epoch 197/500 ## 90/90 - 0s - 2ms/step - loss: 0.0589 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1153 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04 ## Epoch 198/500 ## 90/90 - 0s - 2ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1679 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 1.2500e-04 ## Epoch 199/500 ## 90/90 - 0s - 2ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 1.2500e-04 ## Epoch 200/500 ## 90/90 - 0s - 2ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04 ## Epoch 201/500 ## 90/90 - 0s - 1ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.1133 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04 ## Epoch 202/500 ## 90/90 - 0s - 2ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1110 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 1.0000e-04 ## Epoch 203/500 ## 90/90 - 0s - 2ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.0000e-04 ## Epoch 204/500 ## 90/90 - 0s - 2ms/step - loss: 0.0539 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1057 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.0000e-04 ## Epoch 205/500 ## 90/90 - 0s - 2ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1037 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04 ## Epoch 206/500 ## 90/90 - 0s - 2ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1385 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 1.0000e-04 ## Epoch 207/500 ## 90/90 - 0s - 2ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.0000e-04 ## Epoch 208/500 ## 90/90 - 0s - 1ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1185 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04 ## Epoch 209/500 ## 90/90 - 0s - 2ms/step - loss: 0.0563 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04 ## Epoch 209: early stopping"},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"evaluate-model-on-test-data","dir":"Articles > Examples > Timeseries","previous_headings":"","what":"Evaluate model on test data","title":"Timeseries classification from scratch","text":"","code":"model = keras.models.load_model(\"best_model.keras\")  test_loss, test_acc = model.evaluate(x_test, y_test)  print(\"Test accuracy\", test_acc) print(\"Test loss\", test_loss) model <- load_model(\"best_model.keras\")  results <- model |> evaluate(x_test, y_test) ## 42/42 - 0s - 10ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9697 str(results) ## List of 2 ##  $ loss                       : num 0.0893 ##  $ sparse_categorical_accuracy: num 0.97 cat(   \"Test accuracy: \", results$sparse_categorical_accuracy, \"\\n\",   \"Test loss: \", results$loss, \"\\n\",   sep = \"\" ) ## Test accuracy: 0.969697 ## Test loss: 0.08933648"},{"path":"https://keras.posit.co/articles/examples/timeseries/timeseries_classification_from_scratch.html","id":"plot-the-models-training-history","dir":"Articles > Examples > Timeseries","previous_headings":"","what":"Plot the model’s training history","title":"Timeseries classification from scratch","text":"Plot just training validation accuracy: can see training accuracy reaches almost 0.95 100 epochs. However, observing validation accuracy can see network still needs training reaches almost 0.97 validation training accuracy 200 epochs. Beyond 200th epoch, continue training, validation accuracy start decreasing training accuracy continue increasing: model starts overfitting.","code":"plot(history) plot(history, metric = \"sparse_categorical_accuracy\") +   # scale x axis to actual number of epochs run before early stopping   ggplot2::xlim(0, length(history$metrics$loss))"},{"path":"https://keras.posit.co/articles/examples/vision/autoencoder.html","id":"introduction","dir":"Articles > Examples > Vision","previous_headings":"","what":"Introduction","title":"Convolutional autoencoder for image denoising","text":"example demonstrates implement deep convolutional autoencoder image denoising, mapping noisy digits images MNIST dataset clean digits images. implementation based original blog post titled Building Autoencoders Keras François Chollet.","code":""},{"path":"https://keras.posit.co/articles/examples/vision/autoencoder.html","id":"setup","dir":"Articles > Examples > Vision","previous_headings":"","what":"Setup","title":"Convolutional autoencoder for image denoising","text":"","code":"library(keras3)  # Normalizes the supplied array and reshapes it. preprocess <- function(array) {   array_reshape(array/255, c(dim(array)[1], 28, 28, 1)) }  # Adds random noise to each image in the supplied array. noise <- function(array) {   noise_factor <- 0.4   noisy_array <- array + noise_factor * random_normal(dim(array))   op_clip(noisy_array, 0.0, 1.0) }  display <- function(array1, array2) {   n <- 2   indices <- sample.int(dim(array1)[1], n)   images1 <- as.array(array1)[indices, , , ]   images2 <- as.array(array2)[indices, , , ]    par(mfrow = c(2, n), mar = c(0, 0, 0, 0))   for (i in seq_len(n)) {     plot(as.raster(images1[i, , ]))     plot(as.raster(images2[i, , ]))   } }"},{"path":"https://keras.posit.co/articles/examples/vision/autoencoder.html","id":"prepare-the-data","dir":"Articles > Examples > Vision","previous_headings":"","what":"Prepare the data","title":"Convolutional autoencoder for image denoising","text":"","code":"# Since we only need images from the dataset to encode and decode, we # won't use the labels. c(c(train_data, .), c(test_data, .)) %<-% dataset_mnist()  # Normalize and reshape the data train_data <- preprocess(train_data) test_data <- preprocess(test_data)  # Create a copy of the data with added noise noisy_train_data <- noise(train_data) noisy_test_data <- noise(test_data)  # Display the train data and a version of it with added noise display(train_data, noisy_train_data)"},{"path":"https://keras.posit.co/articles/examples/vision/autoencoder.html","id":"build-the-autoencoder","dir":"Articles > Examples > Vision","previous_headings":"","what":"Build the autoencoder","title":"Convolutional autoencoder for image denoising","text":"going use Functional API build convolutional autoencoder. Now can train autoencoder using train_data input data target. Notice setting validation data using format. Let’s predict test dataset display original image together prediction autoencoder. Notice predictions pretty close original images, although quite . Now know autoencoder works, let’s retrain using noisy data input clean data target. want autoencoder learn denoise images. Let’s now predict noisy data display results autoencoder. Notice autoencoder amazing job removing noise input images.","code":"input <- keras_input(shape = c(28, 28, 1))  # Encoder enc <- input |>   layer_conv_2d(filters = 32, kernel_size = c(3, 3),                 activation = \"relu\", padding = \"same\") |>   layer_max_pooling_2d(pool_size = c(2, 2), padding = \"same\") |>   layer_conv_2d(filters = 32, kernel_size = c(3, 3),                 activation = \"relu\", padding = \"same\") |>   layer_max_pooling_2d(pool_size = c(2, 2), padding = \"same\")  # Decoder dec <- enc |>   layer_conv_2d_transpose(filters = 32, kernel_size = c(3, 3), strides = 2,                           activation = \"relu\", padding = \"same\") |>   layer_conv_2d_transpose(filters = 32, kernel_size = c(3, 3), strides = 2,                           activation = \"relu\", padding = \"same\") |>   layer_conv_2d(filters = 1, kernel_size = c(3, 3),                 activation = \"sigmoid\", padding = \"same\")  # Autoencoder autoencoder <- keras_model(input, dec) autoencoder |> compile(optimizer = \"adam\", loss = \"binary_crossentropy\") autoencoder |> summary() ## Model: \"functional_1\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ input_layer (InputLayer)        │ (None, 28, 28, 1)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_1 (Conv2D)               │ (None, 28, 28, 32)     │           320 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d_1 (MaxPooling2D)  │ (None, 14, 14, 32)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 14, 14, 32)     │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 7, 7, 32)       │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_1              │ (None, 14, 14, 32)     │         9,248 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose                │ (None, 28, 28, 32)     │         9,248 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_2 (Conv2D)               │ (None, 28, 28, 1)      │           289 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 28,353 (110.75 KB) ##  Trainable params: 28,353 (110.75 KB) ##  Non-trainable params: 0 (0.00 B) autoencoder |> fit(   x = train_data,   y = train_data,   epochs = 50,   batch_size = 128,   shuffle = TRUE,   validation_data = list(test_data, test_data), ) ## Epoch 1/50 ## 469/469 - 5s - 11ms/step - loss: 0.1322 - val_loss: 0.0736 ## Epoch 2/50 ## 469/469 - 1s - 3ms/step - loss: 0.0721 - val_loss: 0.0698 ## Epoch 3/50 ## 469/469 - 1s - 3ms/step - loss: 0.0695 - val_loss: 0.0681 ## Epoch 4/50 ## 469/469 - 1s - 3ms/step - loss: 0.0682 - val_loss: 0.0672 ## Epoch 5/50 ## 469/469 - 1s - 3ms/step - loss: 0.0673 - val_loss: 0.0665 ## Epoch 6/50 ## 469/469 - 1s - 3ms/step - loss: 0.0667 - val_loss: 0.0660 ## Epoch 7/50 ## 469/469 - 1s - 3ms/step - loss: 0.0662 - val_loss: 0.0656 ## Epoch 8/50 ## 469/469 - 1s - 3ms/step - loss: 0.0659 - val_loss: 0.0652 ## Epoch 9/50 ## 469/469 - 1s - 3ms/step - loss: 0.0655 - val_loss: 0.0649 ## Epoch 10/50 ## 469/469 - 1s - 3ms/step - loss: 0.0652 - val_loss: 0.0646 ## Epoch 11/50 ## 469/469 - 1s - 3ms/step - loss: 0.0650 - val_loss: 0.0644 ## Epoch 12/50 ## 469/469 - 1s - 3ms/step - loss: 0.0647 - val_loss: 0.0642 ## Epoch 13/50 ## 469/469 - 1s - 3ms/step - loss: 0.0645 - val_loss: 0.0640 ## Epoch 14/50 ## 469/469 - 1s - 3ms/step - loss: 0.0643 - val_loss: 0.0638 ## Epoch 15/50 ## 469/469 - 1s - 3ms/step - loss: 0.0642 - val_loss: 0.0636 ## Epoch 16/50 ## 469/469 - 1s - 3ms/step - loss: 0.0640 - val_loss: 0.0635 ## Epoch 17/50 ## 469/469 - 1s - 3ms/step - loss: 0.0639 - val_loss: 0.0634 ## Epoch 18/50 ## 469/469 - 1s - 3ms/step - loss: 0.0638 - val_loss: 0.0632 ## Epoch 19/50 ## 469/469 - 1s - 3ms/step - loss: 0.0636 - val_loss: 0.0631 ## Epoch 20/50 ## 469/469 - 1s - 3ms/step - loss: 0.0635 - val_loss: 0.0630 ## Epoch 21/50 ## 469/469 - 1s - 3ms/step - loss: 0.0634 - val_loss: 0.0630 ## Epoch 22/50 ## 469/469 - 1s - 3ms/step - loss: 0.0634 - val_loss: 0.0629 ## Epoch 23/50 ## 469/469 - 1s - 3ms/step - loss: 0.0633 - val_loss: 0.0628 ## Epoch 24/50 ## 469/469 - 1s - 3ms/step - loss: 0.0632 - val_loss: 0.0627 ## Epoch 25/50 ## 469/469 - 1s - 3ms/step - loss: 0.0631 - val_loss: 0.0627 ## Epoch 26/50 ## 469/469 - 1s - 3ms/step - loss: 0.0630 - val_loss: 0.0626 ## Epoch 27/50 ## 469/469 - 1s - 3ms/step - loss: 0.0630 - val_loss: 0.0625 ## Epoch 28/50 ## 469/469 - 1s - 3ms/step - loss: 0.0629 - val_loss: 0.0625 ## Epoch 29/50 ## 469/469 - 1s - 3ms/step - loss: 0.0629 - val_loss: 0.0624 ## Epoch 30/50 ## 469/469 - 1s - 3ms/step - loss: 0.0628 - val_loss: 0.0624 ## Epoch 31/50 ## 469/469 - 1s - 3ms/step - loss: 0.0628 - val_loss: 0.0623 ## Epoch 32/50 ## 469/469 - 1s - 3ms/step - loss: 0.0627 - val_loss: 0.0623 ## Epoch 33/50 ## 469/469 - 1s - 3ms/step - loss: 0.0627 - val_loss: 0.0623 ## Epoch 34/50 ## 469/469 - 1s - 3ms/step - loss: 0.0626 - val_loss: 0.0622 ## Epoch 35/50 ## 469/469 - 1s - 3ms/step - loss: 0.0626 - val_loss: 0.0622 ## Epoch 36/50 ## 469/469 - 1s - 3ms/step - loss: 0.0626 - val_loss: 0.0622 ## Epoch 37/50 ## 469/469 - 1s - 3ms/step - loss: 0.0625 - val_loss: 0.0621 ## Epoch 38/50 ## 469/469 - 1s - 3ms/step - loss: 0.0625 - val_loss: 0.0621 ## Epoch 39/50 ## 469/469 - 1s - 3ms/step - loss: 0.0625 - val_loss: 0.0621 ## Epoch 40/50 ## 469/469 - 1s - 3ms/step - loss: 0.0624 - val_loss: 0.0620 ## Epoch 41/50 ## 469/469 - 1s - 3ms/step - loss: 0.0624 - val_loss: 0.0620 ## Epoch 42/50 ## 469/469 - 2s - 3ms/step - loss: 0.0624 - val_loss: 0.0620 ## Epoch 43/50 ## 469/469 - 2s - 3ms/step - loss: 0.0624 - val_loss: 0.0620 ## Epoch 44/50 ## 469/469 - 2s - 3ms/step - loss: 0.0623 - val_loss: 0.0620 ## Epoch 45/50 ## 469/469 - 1s - 3ms/step - loss: 0.0623 - val_loss: 0.0619 ## Epoch 46/50 ## 469/469 - 2s - 3ms/step - loss: 0.0623 - val_loss: 0.0619 ## Epoch 47/50 ## 469/469 - 2s - 4ms/step - loss: 0.0623 - val_loss: 0.0619 ## Epoch 48/50 ## 469/469 - 2s - 4ms/step - loss: 0.0622 - val_loss: 0.0619 ## Epoch 49/50 ## 469/469 - 2s - 3ms/step - loss: 0.0622 - val_loss: 0.0619 ## Epoch 50/50 ## 469/469 - 2s - 3ms/step - loss: 0.0622 - val_loss: 0.0618 predictions <- autoencoder |> predict(test_data) ## 313/313 - 1s - 2ms/step display(test_data, predictions) autoencoder |> fit(   x = noisy_train_data,   y = train_data,   epochs = 100,   batch_size = 128,   shuffle = TRUE,   validation_data = list(noisy_test_data, test_data), ) ## Epoch 1/100 ## 469/469 - 2s - 3ms/step - loss: 0.1001 - val_loss: 0.0931 ## Epoch 2/100 ## 469/469 - 2s - 3ms/step - loss: 0.0927 - val_loss: 0.0909 ## Epoch 3/100 ## 469/469 - 2s - 3ms/step - loss: 0.0911 - val_loss: 0.0898 ## Epoch 4/100 ## 469/469 - 2s - 3ms/step - loss: 0.0901 - val_loss: 0.0890 ## Epoch 5/100 ## 469/469 - 2s - 3ms/step - loss: 0.0894 - val_loss: 0.0883 ## Epoch 6/100 ## 469/469 - 2s - 4ms/step - loss: 0.0889 - val_loss: 0.0878 ## Epoch 7/100 ## 469/469 - 2s - 3ms/step - loss: 0.0884 - val_loss: 0.0874 ## Epoch 8/100 ## 469/469 - 2s - 3ms/step - loss: 0.0881 - val_loss: 0.0872 ## Epoch 9/100 ## 469/469 - 2s - 3ms/step - loss: 0.0878 - val_loss: 0.0869 ## Epoch 10/100 ## 469/469 - 2s - 3ms/step - loss: 0.0875 - val_loss: 0.0867 ## Epoch 11/100 ## 469/469 - 1s - 3ms/step - loss: 0.0873 - val_loss: 0.0865 ## Epoch 12/100 ## 469/469 - 1s - 3ms/step - loss: 0.0871 - val_loss: 0.0863 ## Epoch 13/100 ## 469/469 - 1s - 3ms/step - loss: 0.0869 - val_loss: 0.0861 ## Epoch 14/100 ## 469/469 - 2s - 3ms/step - loss: 0.0867 - val_loss: 0.0860 ## Epoch 15/100 ## 469/469 - 2s - 3ms/step - loss: 0.0866 - val_loss: 0.0859 ## Epoch 16/100 ## 469/469 - 2s - 3ms/step - loss: 0.0865 - val_loss: 0.0858 ## Epoch 17/100 ## 469/469 - 1s - 3ms/step - loss: 0.0863 - val_loss: 0.0856 ## Epoch 18/100 ## 469/469 - 1s - 3ms/step - loss: 0.0862 - val_loss: 0.0855 ## Epoch 19/100 ## 469/469 - 1s - 3ms/step - loss: 0.0861 - val_loss: 0.0854 ## Epoch 20/100 ## 469/469 - 2s - 3ms/step - loss: 0.0860 - val_loss: 0.0854 ## Epoch 21/100 ## 469/469 - 1s - 3ms/step - loss: 0.0859 - val_loss: 0.0853 ## Epoch 22/100 ## 469/469 - 2s - 3ms/step - loss: 0.0859 - val_loss: 0.0852 ## Epoch 23/100 ## 469/469 - 2s - 3ms/step - loss: 0.0858 - val_loss: 0.0851 ## Epoch 24/100 ## 469/469 - 2s - 3ms/step - loss: 0.0857 - val_loss: 0.0851 ## Epoch 25/100 ## 469/469 - 2s - 3ms/step - loss: 0.0856 - val_loss: 0.0850 ## Epoch 26/100 ## 469/469 - 1s - 3ms/step - loss: 0.0855 - val_loss: 0.0849 ## Epoch 27/100 ## 469/469 - 1s - 3ms/step - loss: 0.0855 - val_loss: 0.0849 ## Epoch 28/100 ## 469/469 - 2s - 3ms/step - loss: 0.0854 - val_loss: 0.0848 ## Epoch 29/100 ## 469/469 - 1s - 3ms/step - loss: 0.0853 - val_loss: 0.0848 ## Epoch 30/100 ## 469/469 - 2s - 3ms/step - loss: 0.0853 - val_loss: 0.0847 ## Epoch 31/100 ## 469/469 - 2s - 3ms/step - loss: 0.0852 - val_loss: 0.0847 ## Epoch 32/100 ## 469/469 - 2s - 3ms/step - loss: 0.0852 - val_loss: 0.0846 ## Epoch 33/100 ## 469/469 - 2s - 3ms/step - loss: 0.0851 - val_loss: 0.0846 ## Epoch 34/100 ## 469/469 - 1s - 3ms/step - loss: 0.0851 - val_loss: 0.0846 ## Epoch 35/100 ## 469/469 - 2s - 3ms/step - loss: 0.0851 - val_loss: 0.0845 ## Epoch 36/100 ## 469/469 - 1s - 3ms/step - loss: 0.0850 - val_loss: 0.0845 ## Epoch 37/100 ## 469/469 - 1s - 3ms/step - loss: 0.0850 - val_loss: 0.0845 ## Epoch 38/100 ## 469/469 - 1s - 3ms/step - loss: 0.0849 - val_loss: 0.0844 ## Epoch 39/100 ## 469/469 - 1s - 3ms/step - loss: 0.0849 - val_loss: 0.0844 ## Epoch 40/100 ## 469/469 - 1s - 3ms/step - loss: 0.0849 - val_loss: 0.0844 ## Epoch 41/100 ## 469/469 - 1s - 3ms/step - loss: 0.0849 - val_loss: 0.0844 ## Epoch 42/100 ## 469/469 - 1s - 3ms/step - loss: 0.0848 - val_loss: 0.0843 ## Epoch 43/100 ## 469/469 - 1s - 3ms/step - loss: 0.0848 - val_loss: 0.0843 ## Epoch 44/100 ## 469/469 - 2s - 3ms/step - loss: 0.0848 - val_loss: 0.0843 ## Epoch 45/100 ## 469/469 - 1s - 3ms/step - loss: 0.0847 - val_loss: 0.0843 ## Epoch 46/100 ## 469/469 - 2s - 3ms/step - loss: 0.0847 - val_loss: 0.0842 ## Epoch 47/100 ## 469/469 - 1s - 3ms/step - loss: 0.0847 - val_loss: 0.0842 ## Epoch 48/100 ## 469/469 - 2s - 3ms/step - loss: 0.0847 - val_loss: 0.0842 ## Epoch 49/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0842 ## Epoch 50/100 ## 469/469 - 2s - 3ms/step - loss: 0.0846 - val_loss: 0.0842 ## Epoch 51/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0842 ## Epoch 52/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0841 ## Epoch 53/100 ## 469/469 - 1s - 3ms/step - loss: 0.0846 - val_loss: 0.0841 ## Epoch 54/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 55/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 56/100 ## 469/469 - 2s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 57/100 ## 469/469 - 1s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 58/100 ## 469/469 - 2s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 59/100 ## 469/469 - 2s - 3ms/step - loss: 0.0845 - val_loss: 0.0841 ## Epoch 60/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 61/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 62/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 63/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 64/100 ## 469/469 - 2s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 65/100 ## 469/469 - 2s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 66/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 67/100 ## 469/469 - 1s - 3ms/step - loss: 0.0844 - val_loss: 0.0840 ## Epoch 68/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0840 ## Epoch 69/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0839 ## Epoch 70/100 ## 469/469 - 2s - 3ms/step - loss: 0.0843 - val_loss: 0.0839 ## Epoch 71/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0839 ## Epoch 72/100 ## 469/469 - 2s - 3ms/step - loss: 0.0843 - val_loss: 0.0839 ## Epoch 73/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0839 ## Epoch 74/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0839 ## Epoch 75/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0839 ## Epoch 76/100 ## 469/469 - 1s - 3ms/step - loss: 0.0843 - val_loss: 0.0839 ## Epoch 77/100 ## 469/469 - 2s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 78/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 79/100 ## 469/469 - 2s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 80/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 81/100 ## 469/469 - 2s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 82/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 83/100 ## 469/469 - 2s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 84/100 ## 469/469 - 2s - 3ms/step - loss: 0.0842 - val_loss: 0.0839 ## Epoch 85/100 ## 469/469 - 2s - 3ms/step - loss: 0.0842 - val_loss: 0.0838 ## Epoch 86/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0838 ## Epoch 87/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0838 ## Epoch 88/100 ## 469/469 - 1s - 3ms/step - loss: 0.0842 - val_loss: 0.0838 ## Epoch 89/100 ## 469/469 - 2s - 3ms/step - loss: 0.0842 - val_loss: 0.0838 ## Epoch 90/100 ## 469/469 - 2s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 91/100 ## 469/469 - 2s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 92/100 ## 469/469 - 2s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 93/100 ## 469/469 - 1s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 94/100 ## 469/469 - 2s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 95/100 ## 469/469 - 1s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 96/100 ## 469/469 - 2s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 97/100 ## 469/469 - 1s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 98/100 ## 469/469 - 2s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 99/100 ## 469/469 - 1s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 ## Epoch 100/100 ## 469/469 - 2s - 3ms/step - loss: 0.0841 - val_loss: 0.0838 predictions <- autoencoder |> predict(noisy_test_data) ## 313/313 - 0s - 866us/step display(noisy_test_data, predictions)"},{"path":"https://keras.posit.co/articles/examples/vision/mnist_convnet.html","id":"setup","dir":"Articles > Examples > Vision","previous_headings":"","what":"Setup","title":"Simple MNIST convnet","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/examples/vision/mnist_convnet.html","id":"prepare-the-data","dir":"Articles > Examples > Vision","previous_headings":"","what":"Prepare the data","title":"Simple MNIST convnet","text":"","code":"# Model / data parameters num_classes <- 10 input_shape <- c(28, 28, 1)  # Load the data and split it between train and test sets c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()  # Scale images to the [0, 1] range x_train <- x_train / 255 x_test <- x_test / 255 # Make sure images have shape (28, 28, 1) x_train <- op_expand_dims(x_train, -1) x_test <- op_expand_dims(x_test, -1)   dim(x_train) ## [1] 60000    28    28     1 dim(x_test) ## [1] 10000    28    28     1 # convert class vectors to binary class matrices y_train <- to_categorical(y_train, num_classes) y_test <- to_categorical(y_test, num_classes)"},{"path":"https://keras.posit.co/articles/examples/vision/mnist_convnet.html","id":"build-the-model","dir":"Articles > Examples > Vision","previous_headings":"","what":"Build the model","title":"Simple MNIST convnet","text":"","code":"model <- keras_model_sequential(input_shape = input_shape) model |>   layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = \"relu\") |>   layer_max_pooling_2d(pool_size = c(2, 2)) |>   layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = \"relu\") |>   layer_max_pooling_2d(pool_size = c(2, 2)) |>   layer_flatten() |>   layer_dropout(rate = 0.5) |>   layer_dense(units = num_classes, activation = \"softmax\")  summary(model) ## Model: \"sequential\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ conv2d_1 (Conv2D)               │ (None, 26, 26, 32)     │           320 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d_1 (MaxPooling2D)  │ (None, 13, 13, 32)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 11, 11, 64)     │        18,496 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 5, 5, 64)       │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ flatten (Flatten)               │ (None, 1600)           │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout (Dropout)               │ (None, 1600)           │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense (Dense)                   │ (None, 10)             │        16,010 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 34,826 (136.04 KB) ##  Trainable params: 34,826 (136.04 KB) ##  Non-trainable params: 0 (0.00 B)"},{"path":"https://keras.posit.co/articles/examples/vision/mnist_convnet.html","id":"train-the-model","dir":"Articles > Examples > Vision","previous_headings":"","what":"Train the model","title":"Simple MNIST convnet","text":"","code":"batch_size <- 128 epochs <- 15  model |> compile(   loss = \"categorical_crossentropy\",   optimizer = \"adam\",   metrics = \"accuracy\" )  model |> fit(   x_train, y_train,   batch_size = batch_size,   epochs = epochs,   validation_split = 0.1 ) ## Epoch 1/15 ## 422/422 - 6s - 13ms/step - accuracy: 0.8845 - loss: 0.3815 - val_accuracy: 0.9783 - val_loss: 0.0808 ## Epoch 2/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9645 - loss: 0.1151 - val_accuracy: 0.9865 - val_loss: 0.0548 ## Epoch 3/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9737 - loss: 0.0839 - val_accuracy: 0.9877 - val_loss: 0.0455 ## Epoch 4/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9782 - loss: 0.0690 - val_accuracy: 0.9897 - val_loss: 0.0418 ## Epoch 5/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9812 - loss: 0.0608 - val_accuracy: 0.9905 - val_loss: 0.0375 ## Epoch 6/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9822 - loss: 0.0562 - val_accuracy: 0.9910 - val_loss: 0.0360 ## Epoch 7/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9848 - loss: 0.0488 - val_accuracy: 0.9918 - val_loss: 0.0328 ## Epoch 8/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9842 - loss: 0.0487 - val_accuracy: 0.9915 - val_loss: 0.0337 ## Epoch 9/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9859 - loss: 0.0440 - val_accuracy: 0.9920 - val_loss: 0.0321 ## Epoch 10/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9868 - loss: 0.0405 - val_accuracy: 0.9927 - val_loss: 0.0322 ## Epoch 11/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9875 - loss: 0.0390 - val_accuracy: 0.9918 - val_loss: 0.0318 ## Epoch 12/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9881 - loss: 0.0371 - val_accuracy: 0.9927 - val_loss: 0.0307 ## Epoch 13/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9878 - loss: 0.0362 - val_accuracy: 0.9930 - val_loss: 0.0280 ## Epoch 14/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9890 - loss: 0.0333 - val_accuracy: 0.9932 - val_loss: 0.0293 ## Epoch 15/15 ## 422/422 - 1s - 2ms/step - accuracy: 0.9897 - loss: 0.0310 - val_accuracy: 0.9923 - val_loss: 0.0295"},{"path":"https://keras.posit.co/articles/examples/vision/mnist_convnet.html","id":"evaluate-the-trained-model","dir":"Articles > Examples > Vision","previous_headings":"","what":"Evaluate the trained model","title":"Simple MNIST convnet","text":"","code":"score <- model |> evaluate(x_test, y_test, verbose = 0) score ## $accuracy ## [1] 0.9906 ## ## $loss ## [1] 0.02566285"},{"path":"https://keras.posit.co/articles/examples/vision/oxford_pets_image_segmentation.html","id":"download-the-data","dir":"Articles > Examples > Vision","previous_headings":"","what":"Download the data","title":"Image segmentation with a U-Net-like architecture","text":"","code":"options(timeout = 5000) download.file(   \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\",   \"datasets/images.tar.gz\" ) download.file(   \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\",   \"datasets/annotations.tar.gz\" )  untar(\"datasets/images.tar.gz\", exdir = \"datasets\") untar(\"datasets/annotations.tar.gz\", exdir = \"datasets\")"},{"path":"https://keras.posit.co/articles/examples/vision/oxford_pets_image_segmentation.html","id":"prepare-paths-of-input-images-and-target-segmentation-masks","dir":"Articles > Examples > Vision","previous_headings":"","what":"Prepare paths of input images and target segmentation masks","title":"Image segmentation with a U-Net-like architecture","text":"","code":"library(keras3) input_dir <- \"datasets/images/\" target_dir <- \"datasets/annotations/trimaps/\" img_size <- c(160, 160) num_classes <- 3 batch_size <- 32  input_img_paths <- fs::dir_ls(input_dir, glob = \"*.jpg\") |> sort() target_img_paths <- fs::dir_ls(target_dir, glob = \"*.png\") |> sort()  cat(\"Number of samples:\", length(input_img_paths), \"\\n\") ## Number of samples: 7390 for (i in 1:10) {   cat(input_img_paths[i], \"|\", target_img_paths[i], \"\\n\") } ## datasets/images/Abyssinian_1.jpg | datasets/annotations/trimaps/Abyssinian_1.png ## datasets/images/Abyssinian_10.jpg | datasets/annotations/trimaps/Abyssinian_10.png ## datasets/images/Abyssinian_100.jpg | datasets/annotations/trimaps/Abyssinian_100.png ## datasets/images/Abyssinian_101.jpg | datasets/annotations/trimaps/Abyssinian_101.png ## datasets/images/Abyssinian_102.jpg | datasets/annotations/trimaps/Abyssinian_102.png ## datasets/images/Abyssinian_103.jpg | datasets/annotations/trimaps/Abyssinian_103.png ## datasets/images/Abyssinian_104.jpg | datasets/annotations/trimaps/Abyssinian_104.png ## datasets/images/Abyssinian_105.jpg | datasets/annotations/trimaps/Abyssinian_105.png ## datasets/images/Abyssinian_106.jpg | datasets/annotations/trimaps/Abyssinian_106.png ## datasets/images/Abyssinian_107.jpg | datasets/annotations/trimaps/Abyssinian_107.png"},{"path":"https://keras.posit.co/articles/examples/vision/oxford_pets_image_segmentation.html","id":"what-does-one-input-image-and-corresponding-segmentation-mask-look-like","dir":"Articles > Examples > Vision","previous_headings":"","what":"What does one input image and corresponding segmentation mask look like?","title":"Image segmentation with a U-Net-like architecture","text":"","code":"# Display input image #10 input_img_paths[10] |>   jpeg::readJPEG() |>   as.raster() |>   plot() target_img_paths[10] |>   png::readPNG() |>   magrittr::multiply_by(255)|>   as.raster(max = 3) |>   plot()"},{"path":"https://keras.posit.co/articles/examples/vision/oxford_pets_image_segmentation.html","id":"prepare-dataset-to-load-vectorize-batches-of-data","dir":"Articles > Examples > Vision","previous_headings":"","what":"Prepare dataset to load & vectorize batches of data","title":"Image segmentation with a U-Net-like architecture","text":"","code":"library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(tfdatasets, exclude = \"shape\")   # Returns a tf_dataset get_dataset <- function(batch_size, img_size, input_img_paths, target_img_paths,                         max_dataset_len = NULL) {    img_size <- as.integer(img_size)    load_img_masks <- function(input_img_path, target_img_path) {     input_img <- input_img_path |>       tf$io$read_file() |>       tf$io$decode_jpeg(channels = 3) |>       tf$image$resize(img_size) |>       tf$image$convert_image_dtype(\"float32\")      target_img <- target_img_path |>       tf$io$read_file() |>       tf$io$decode_png(channels = 1) |>       tf$image$resize(img_size, method = \"nearest\") |>       tf$image$convert_image_dtype(\"uint8\")      # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:     target_img <- target_img - 1L      list(input_img, target_img)   }    if (!is.null(max_dataset_len)) {     input_img_paths <- input_img_paths[1:max_dataset_len]     target_img_paths <- target_img_paths[1:max_dataset_len]   }    list(input_img_paths, target_img_paths) |>     tensor_slices_dataset() |>     dataset_map(load_img_masks, num_parallel_calls = tf$data$AUTOTUNE)|>     dataset_batch(batch_size) }"},{"path":"https://keras.posit.co/articles/examples/vision/oxford_pets_image_segmentation.html","id":"prepare-u-net-xception-style-model","dir":"Articles > Examples > Vision","previous_headings":"","what":"Prepare U-Net Xception-style model","title":"Image segmentation with a U-Net-like architecture","text":"","code":"get_model <- function(img_size, num_classes) {    inputs <- keras_input(shape = c(img_size, 3))    ### [First half of the network: downsampling inputs] ###    # Entry block   x <- inputs |>     layer_conv_2d(filters = 32, kernel_size = 3, strides = 2, padding = \"same\") |>     layer_batch_normalization() |>     layer_activation(\"relu\")    previous_block_activation <- x  # Set aside residual    for (filters in c(64, 128, 256)) {     x <- x |>       layer_activation(\"relu\") |>       layer_separable_conv_2d(filters = filters, kernel_size = 3, padding = \"same\") |>       layer_batch_normalization() |>        layer_activation(\"relu\") |>       layer_separable_conv_2d(filters = filters, kernel_size = 3, padding = \"same\") |>       layer_batch_normalization() |>        layer_max_pooling_2d(pool_size = 3, strides = 2, padding = \"same\")      residual <- previous_block_activation |>       layer_conv_2d(filters = filters, kernel_size = 1, strides = 2, padding = \"same\")      x <- layer_add(x, residual)  # Add back residual     previous_block_activation <- x  # Set aside next residual   }    ### [Second half of the network: upsampling inputs] ###    for (filters in c(256, 128, 64, 32)) {     x <- x |>       layer_activation(\"relu\") |>       layer_conv_2d_transpose(filters = filters, kernel_size = 3, padding = \"same\") |>       layer_batch_normalization() |>        layer_activation(\"relu\") |>       layer_conv_2d_transpose(filters = filters, kernel_size = 3, padding = \"same\") |>       layer_batch_normalization() |>        layer_upsampling_2d(size = 2)      # Project residual     residual <- previous_block_activation |>       layer_upsampling_2d(size = 2) |>       layer_conv_2d(filters = filters, kernel_size = 1, padding = \"same\")      x <- layer_add(x, residual)     # Add back residual     previous_block_activation <- x  # Set aside next residual   }    # Add a per-pixel classification layer   outputs <- x |>     layer_conv_2d(num_classes, 3, activation = \"softmax\", padding = \"same\")    # Define the model   keras_model(inputs, outputs) }  # Build model model <- get_model(img_size, num_classes) summary(model) ## Model: \"functional_1\" ## ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━┓ ## ┃ Layer (type)      ┃ Output Shape    ┃   Param # ┃ Connected to   ┃ Trai… ┃ ## ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━┩ ## │ input_layer       │ (None, 160,     │         0 │ -              │   -   │ ## │ (InputLayer)      │ 160, 3)         │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d (Conv2D)   │ (None, 80, 80,  │       896 │ input_layer[0… │   Y   │ ## │                   │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       128 │ conv2d[0][0]   │   Y   │ ## │ (BatchNormalizat… │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation        │ (None, 80, 80,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_2      │ (None, 80, 80,  │         0 │ activation[0]… │   -   │ ## │ (Activation)      │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 80, 80,  │     2,400 │ activation_2[… │   Y   │ ## │ (SeparableConv2D) │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       256 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_1      │ (None, 80, 80,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d  │ (None, 80, 80,  │     4,736 │ activation_1[… │   Y   │ ## │ (SeparableConv2D) │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       256 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ max_pooling2d     │ (None, 40, 40,  │         0 │ batch_normali… │   -   │ ## │ (MaxPooling2D)    │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_1 (Conv2D) │ (None, 40, 40,  │     2,112 │ activation[0]… │   Y   │ ## │                   │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add (Add)         │ (None, 40, 40,  │         0 │ max_pooling2d… │   -   │ ## │                   │ 64)             │           │ conv2d_1[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_4      │ (None, 40, 40,  │         0 │ add[0][0]      │   -   │ ## │ (Activation)      │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 40, 40,  │     8,896 │ activation_4[… │   Y   │ ## │ (SeparableConv2D) │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 40, 40,  │       512 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_3      │ (None, 40, 40,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 40, 40,  │    17,664 │ activation_3[… │   Y   │ ## │ (SeparableConv2D) │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 40, 40,  │       512 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ max_pooling2d_1   │ (None, 20, 20,  │         0 │ batch_normali… │   -   │ ## │ (MaxPooling2D)    │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_2 (Conv2D) │ (None, 20, 20,  │     8,320 │ add[0][0]      │   Y   │ ## │                   │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_1 (Add)       │ (None, 20, 20,  │         0 │ max_pooling2d… │   -   │ ## │                   │ 128)            │           │ conv2d_2[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_6      │ (None, 20, 20,  │         0 │ add_1[0][0]    │   -   │ ## │ (Activation)      │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 20, 20,  │    34,176 │ activation_6[… │   Y   │ ## │ (SeparableConv2D) │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 20, 20,  │     1,024 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_5      │ (None, 20, 20,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ separable_conv2d… │ (None, 20, 20,  │    68,096 │ activation_5[… │   Y   │ ## │ (SeparableConv2D) │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 20, 20,  │     1,024 │ separable_con… │   Y   │ ## │ (BatchNormalizat… │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ max_pooling2d_2   │ (None, 10, 10,  │         0 │ batch_normali… │   -   │ ## │ (MaxPooling2D)    │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_3 (Conv2D) │ (None, 10, 10,  │    33,024 │ add_1[0][0]    │   Y   │ ## │                   │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_2 (Add)       │ (None, 10, 10,  │         0 │ max_pooling2d… │   -   │ ## │                   │ 256)            │           │ conv2d_3[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_8      │ (None, 10, 10,  │         0 │ add_2[0][0]    │   -   │ ## │ (Activation)      │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 10, 10,  │   590,080 │ activation_8[… │   Y   │ ## │ (Conv2DTranspose) │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 10, 10,  │     1,024 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_7      │ (None, 10, 10,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose  │ (None, 10, 10,  │   590,080 │ activation_7[… │   Y   │ ## │ (Conv2DTranspose) │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 10, 10,  │     1,024 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_1   │ (None, 20, 20,  │         0 │ add_2[0][0]    │   -   │ ## │ (UpSampling2D)    │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d     │ (None, 20, 20,  │         0 │ batch_normali… │   -   │ ## │ (UpSampling2D)    │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_4 (Conv2D) │ (None, 20, 20,  │    65,792 │ up_sampling2d… │   Y   │ ## │                   │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_3 (Add)       │ (None, 20, 20,  │         0 │ up_sampling2d… │   -   │ ## │                   │ 256)            │           │ conv2d_4[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_10     │ (None, 20, 20,  │         0 │ add_3[0][0]    │   -   │ ## │ (Activation)      │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 20, 20,  │   295,040 │ activation_10… │   Y   │ ## │ (Conv2DTranspose) │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 20, 20,  │       512 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_9      │ (None, 20, 20,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 20, 20,  │   147,584 │ activation_9[… │   Y   │ ## │ (Conv2DTranspose) │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 20, 20,  │       512 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_3   │ (None, 40, 40,  │         0 │ add_3[0][0]    │   -   │ ## │ (UpSampling2D)    │ 256)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_2   │ (None, 40, 40,  │         0 │ batch_normali… │   -   │ ## │ (UpSampling2D)    │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_5 (Conv2D) │ (None, 40, 40,  │    32,896 │ up_sampling2d… │   Y   │ ## │                   │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_4 (Add)       │ (None, 40, 40,  │         0 │ up_sampling2d… │   -   │ ## │                   │ 128)            │           │ conv2d_5[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_12     │ (None, 40, 40,  │         0 │ add_4[0][0]    │   -   │ ## │ (Activation)      │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 40, 40,  │    73,792 │ activation_12… │   Y   │ ## │ (Conv2DTranspose) │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 40, 40,  │       256 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_11     │ (None, 40, 40,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 40, 40,  │    36,928 │ activation_11… │   Y   │ ## │ (Conv2DTranspose) │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 40, 40,  │       256 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_5   │ (None, 80, 80,  │         0 │ add_4[0][0]    │   -   │ ## │ (UpSampling2D)    │ 128)            │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_4   │ (None, 80, 80,  │         0 │ batch_normali… │   -   │ ## │ (UpSampling2D)    │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_6 (Conv2D) │ (None, 80, 80,  │     8,256 │ up_sampling2d… │   Y   │ ## │                   │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_5 (Add)       │ (None, 80, 80,  │         0 │ up_sampling2d… │   -   │ ## │                   │ 64)             │           │ conv2d_6[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_14     │ (None, 80, 80,  │         0 │ add_5[0][0]    │   -   │ ## │ (Activation)      │ 64)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 80, 80,  │    18,464 │ activation_14… │   Y   │ ## │ (Conv2DTranspose) │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       128 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ activation_13     │ (None, 80, 80,  │         0 │ batch_normali… │   -   │ ## │ (Activation)      │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_transpose… │ (None, 80, 80,  │     9,248 │ activation_13… │   Y   │ ## │ (Conv2DTranspose) │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ batch_normalizat… │ (None, 80, 80,  │       128 │ conv2d_transp… │   Y   │ ## │ (BatchNormalizat… │ 32)             │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_7   │ (None, 160,     │         0 │ add_5[0][0]    │   -   │ ## │ (UpSampling2D)    │ 160, 64)        │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ up_sampling2d_6   │ (None, 160,     │         0 │ batch_normali… │   -   │ ## │ (UpSampling2D)    │ 160, 32)        │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_7 (Conv2D) │ (None, 160,     │     2,080 │ up_sampling2d… │   Y   │ ## │                   │ 160, 32)        │           │                │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ add_6 (Add)       │ (None, 160,     │         0 │ up_sampling2d… │   -   │ ## │                   │ 160, 32)        │           │ conv2d_7[0][0] │       │ ## ├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤ ## │ conv2d_8 (Conv2D) │ (None, 160,     │       867 │ add_6[0][0]    │   Y   │ ## │                   │ 160, 3)         │           │                │       │ ## └───────────────────┴─────────────────┴───────────┴────────────────┴───────┘ ##  Total params: 2,058,979 (7.85 MB) ##  Trainable params: 2,055,203 (7.84 MB) ##  Non-trainable params: 3,776 (14.75 KB)"},{"path":"https://keras.posit.co/articles/examples/vision/oxford_pets_image_segmentation.html","id":"set-aside-a-validation-split","dir":"Articles > Examples > Vision","previous_headings":"","what":"Set aside a validation split","title":"Image segmentation with a U-Net-like architecture","text":"","code":"# Split our img paths into a training and a validation set val_samples <- 1000 val_samples <- sample.int(length(input_img_paths), val_samples)  train_input_img_paths <- input_img_paths[-val_samples] train_target_img_paths <- target_img_paths[-val_samples]  val_input_img_paths <- input_img_paths[val_samples] val_target_img_paths <- target_img_paths[val_samples]  # Instantiate dataset for each split # Limit input files in `max_dataset_len` for faster epoch training time. # Remove the `max_dataset_len` arg when running with full dataset. train_dataset <- get_dataset(   batch_size,   img_size,   train_input_img_paths,   train_target_img_paths,   max_dataset_len = 1000 ) valid_dataset <- get_dataset(   batch_size, img_size, val_input_img_paths, val_target_img_paths )"},{"path":"https://keras.posit.co/articles/examples/vision/oxford_pets_image_segmentation.html","id":"train-the-model","dir":"Articles > Examples > Vision","previous_headings":"","what":"Train the model","title":"Image segmentation with a U-Net-like architecture","text":"","code":"# Configure the model for training. # We use the \"sparse\" version of categorical_crossentropy # because our target data is integers. model |> compile(   optimizer = optimizer_adam(1e-4),   loss = \"sparse_categorical_crossentropy\" )  callbacks <- list(   callback_model_checkpoint(     \"models/oxford_segmentation.keras\", save_best_only = TRUE   ) )  # Train the model, doing validation at the end of each epoch. epochs <- 50 model |> fit(     train_dataset,     epochs=epochs,     validation_data=valid_dataset,     callbacks=callbacks,     verbose=2 ) ## Epoch 1/50 ## 32/32 - 40s - 1s/step - loss: 1.3044 - val_loss: 1.5495 ## Epoch 2/50 ## 32/32 - 2s - 64ms/step - loss: 0.8717 - val_loss: 1.9555 ## Epoch 3/50 ## 32/32 - 2s - 65ms/step - loss: 0.7695 - val_loss: 2.1943 ## Epoch 4/50 ## 32/32 - 2s - 64ms/step - loss: 0.7079 - val_loss: 2.4876 ## Epoch 5/50 ## 32/32 - 2s - 64ms/step - loss: 0.6690 - val_loss: 2.7756 ## Epoch 6/50 ## 32/32 - 2s - 63ms/step - loss: 0.6378 - val_loss: 3.1124 ## Epoch 7/50 ## 32/32 - 2s - 63ms/step - loss: 0.6129 - val_loss: 3.3610 ## Epoch 8/50 ## 32/32 - 2s - 63ms/step - loss: 0.5919 - val_loss: 3.5156 ## Epoch 9/50 ## 32/32 - 2s - 64ms/step - loss: 0.5725 - val_loss: 3.6194 ## Epoch 10/50 ## 32/32 - 2s - 63ms/step - loss: 0.5538 - val_loss: 3.7202 ## Epoch 11/50 ## 32/32 - 2s - 63ms/step - loss: 0.5353 - val_loss: 3.8030 ## Epoch 12/50 ## 32/32 - 2s - 64ms/step - loss: 0.5160 - val_loss: 3.9021 ## Epoch 13/50 ## 32/32 - 2s - 64ms/step - loss: 0.4957 - val_loss: 4.0130 ## Epoch 14/50 ## 32/32 - 2s - 65ms/step - loss: 0.4737 - val_loss: 4.0613 ## Epoch 15/50 ## 32/32 - 2s - 64ms/step - loss: 0.4499 - val_loss: 4.0181 ## Epoch 16/50 ## 32/32 - 2s - 64ms/step - loss: 0.4241 - val_loss: 3.8091 ## Epoch 17/50 ## 32/32 - 2s - 65ms/step - loss: 0.3969 - val_loss: 3.3580 ## Epoch 18/50 ## 32/32 - 2s - 64ms/step - loss: 0.3695 - val_loss: 2.7060 ## Epoch 19/50 ## 32/32 - 2s - 66ms/step - loss: 0.3428 - val_loss: 1.9607 ## Epoch 20/50 ## 32/32 - 2s - 72ms/step - loss: 0.3180 - val_loss: 1.4338 ## Epoch 21/50 ## 32/32 - 2s - 69ms/step - loss: 0.2958 - val_loss: 1.1353 ## Epoch 22/50 ## 32/32 - 2s - 72ms/step - loss: 0.2769 - val_loss: 1.0399 ## Epoch 23/50 ## 32/32 - 2s - 65ms/step - loss: 0.2617 - val_loss: 1.0413 ## Epoch 24/50 ## 32/32 - 2s - 66ms/step - loss: 0.2522 - val_loss: 1.0951 ## Epoch 25/50 ## 32/32 - 2s - 66ms/step - loss: 0.2567 - val_loss: 1.2183 ## Epoch 26/50 ## 32/32 - 2s - 64ms/step - loss: 0.3220 - val_loss: 1.2226 ## Epoch 27/50 ## 32/32 - 2s - 67ms/step - loss: 0.3700 - val_loss: 1.1705 ## Epoch 28/50 ## 32/32 - 2s - 69ms/step - loss: 0.3202 - val_loss: 0.8911 ## Epoch 29/50 ## 32/32 - 2s - 63ms/step - loss: 0.3166 - val_loss: 1.0647 ## Epoch 30/50 ## 32/32 - 2s - 65ms/step - loss: 0.3126 - val_loss: 1.2200 ## Epoch 31/50 ## 32/32 - 2s - 64ms/step - loss: 0.3167 - val_loss: 1.2343 ## Epoch 32/50 ## 32/32 - 2s - 65ms/step - loss: 0.3117 - val_loss: 1.1527 ## Epoch 33/50 ## 32/32 - 2s - 64ms/step - loss: 0.2927 - val_loss: 1.4531 ## Epoch 34/50 ## 32/32 - 2s - 65ms/step - loss: 0.2791 - val_loss: 1.2449 ## Epoch 35/50 ## 32/32 - 2s - 70ms/step - loss: 0.2683 - val_loss: 1.1767 ## Epoch 36/50 ## 32/32 - 2s - 71ms/step - loss: 0.2567 - val_loss: 1.0950 ## Epoch 37/50 ## 32/32 - 2s - 66ms/step - loss: 0.2498 - val_loss: 1.0185 ## Epoch 38/50 ## 32/32 - 2s - 68ms/step - loss: 0.2454 - val_loss: 1.0815 ## Epoch 39/50 ## 32/32 - 2s - 68ms/step - loss: 0.2367 - val_loss: 1.0641 ## Epoch 40/50 ## 32/32 - 2s - 70ms/step - loss: 0.2371 - val_loss: 1.0128 ## Epoch 41/50 ## 32/32 - 2s - 68ms/step - loss: 0.2306 - val_loss: 0.9964 ## Epoch 42/50 ## 32/32 - 2s - 64ms/step - loss: 0.2205 - val_loss: 1.0386 ## Epoch 43/50 ## 32/32 - 2s - 66ms/step - loss: 0.2141 - val_loss: 0.9902 ## Epoch 44/50 ## 32/32 - 2s - 66ms/step - loss: 0.2112 - val_loss: 1.0470 ## Epoch 45/50 ## 32/32 - 2s - 64ms/step - loss: 0.2063 - val_loss: 1.1052 ## Epoch 46/50 ## 32/32 - 2s - 64ms/step - loss: 0.1966 - val_loss: 1.1831 ## Epoch 47/50 ## 32/32 - 2s - 64ms/step - loss: 0.1877 - val_loss: 1.0777 ## Epoch 48/50 ## 32/32 - 2s - 65ms/step - loss: 0.1820 - val_loss: 1.1287 ## Epoch 49/50 ## 32/32 - 2s - 65ms/step - loss: 0.1780 - val_loss: 1.1378 ## Epoch 50/50 ## 32/32 - 2s - 66ms/step - loss: 0.1730 - val_loss: 1.2166"},{"path":"https://keras.posit.co/articles/examples/vision/oxford_pets_image_segmentation.html","id":"visualize-predictions","dir":"Articles > Examples > Vision","previous_headings":"","what":"Visualize predictions","title":"Image segmentation with a U-Net-like architecture","text":"","code":"model <- load_model(\"models/oxford_segmentation.keras\") # Generate predictions for all images in the validation set val_dataset <- get_dataset(   batch_size, img_size, val_input_img_paths, val_target_img_paths ) val_preds <- predict(model, val_dataset) ## 32/32 - 5s - 144ms/step display_mask <- function(i) {   # Quick utility to display a model's prediction.   mask <- val_preds[i,,,] %>%     apply(c(1,2), which.max) %>%     array_reshape(dim = c(img_size, 1))   mask <- abind::abind(mask, mask, mask, along = 3)   plot(as.raster(mask, max = 3)) }  # Display results for validation image #10 i <- 10  par(mfrow = c(1, 3)) # Display input image input_img_paths[i] |>   jpeg::readJPEG() |>   as.raster() |>   plot()  # Display ground-truth target mask target_img_paths[i] |>   png::readPNG() |>   magrittr::multiply_by(255)|>   as.raster(max = 3) |>   plot()  # Display mask predicted by our model display_mask(i)  # Note that the model only sees inputs at 150x150."},{"path":"https://keras.posit.co/articles/functional_api.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"The Functional API","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"The Functional API","text":"Keras functional API way create models flexible sequential API. functional API can handle models non-linear topology, shared layers, even multiple inputs outputs. main idea deep learning model usually directed acyclic graph (DAG) layers. functional API way build graphs layers. Consider following model: basic graph three layers. build model using functional API, start creating input node: shape data set 784-dimensional vector. batch size always omitted since shape sample specified. , example, image input shape (32, 32, 3), use: inputs returned contains information shape dtype input data feed model. ’s shape: ’s dtype: create new node graph layers calling layer inputs object: “layer call” action like drawing arrow “inputs” layer created. ’re “passing” inputs dense layer, get x output. Let’s add layers graph layers: point, can create Model specifying inputs outputs graph layers: Let’s check model summary looks like: can also plot model graph:  , optionally, display input output shapes layer plotted graph:  figure code almost identical. code version, connection arrows replaced call operation. “graph layers” intuitive mental image deep learning model, functional API way create models closely mirrors .","code":"(input: 784-dimensional vectors)        ↧ [Dense (64 units, relu activation)]        ↧ [Dense (64 units, relu activation)]        ↧ [Dense (10 units, softmax activation)]        ↧ (output: logits of a probability distribution over 10 classes) inputs <- keras_input(shape = c(784)) # Just for demonstration purposes. img_inputs <- keras_input(shape = c(32, 32, 3)) shape(inputs) ## shape(NA, 784) inputs$dtype ## [1] \"float32\" dense <- layer_dense(units = 64, activation=\"relu\") x <- dense(inputs) outputs <- x |>   layer_dense(units = 64, activation = \"relu\") |>   layer_dense(units = 10) model <- keras_model(inputs = inputs, outputs = outputs, name = \"mnist_model\") summary(model) ## Model: \"mnist_model\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ input_layer (InputLayer)        │ (None, 784)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense (Dense)                   │ (None, 64)             │        50,240 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_2 (Dense)                 │ (None, 64)             │         4,160 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_1 (Dense)                 │ (None, 10)             │           650 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 55,050 (215.04 KB) ##  Trainable params: 55,050 (215.04 KB) ##  Non-trainable params: 0 (0.00 B) plot(model) plot(model, show_shapes = TRUE)"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"training-evaluation-and-inference","dir":"Articles","previous_headings":"","what":"Training, evaluation, and inference","title":"The Functional API","text":"Training, evaluation, inference work exactly way models built using functional API Sequential models. Model class offers built-training loop (fit() method) built-evaluation loop (evaluate() method). Note can easily customize loops implement training routines beyond supervised learning (e.g. GANs). , load MNIST image data, reshape vectors, fit model data (monitoring performance validation split), evaluate model test data: reading, see training evaluation guide.","code":"c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()  x_train <- array_reshape(x_train, c(60000, 784)) / 255 x_test <- array_reshape(x_test, c(10000, 784)) / 255  model |> compile(   loss = loss_sparse_categorical_crossentropy(from_logits = TRUE),   optimizer = optimizer_rmsprop(),   metrics = \"accuracy\" )  history <- model |> fit(     x_train, y_train, batch_size = 64, epochs = 2, validation_split = 0.2 ) ## Epoch 1/2 ## 750/750 - 2s - 2ms/step - accuracy: 0.9015 - loss: 0.3513 - val_accuracy: 0.9442 - val_loss: 0.1921 ## Epoch 2/2 ## 750/750 - 1s - 818us/step - accuracy: 0.9508 - loss: 0.1643 - val_accuracy: 0.9581 - val_loss: 0.1423 test_scores <- model |> evaluate(x_test, y_test, verbose=2) ## 313/313 - 0s - 1ms/step - accuracy: 0.9578 - loss: 0.1338 cat(\"Test loss:\", test_scores$loss, \"\\n\") cat(\"Test accuracy:\", test_scores$accuracy, \"\\n\") ## Test loss: 0.1337984 ## Test accuracy: 0.9578"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"save-and-serialize","dir":"Articles","previous_headings":"","what":"Save and serialize","title":"The Functional API","text":"Saving model serialization work way models built using functional API Sequential models. standard way save functional model call model.save() save entire model single file. can later recreate model file, even code built model longer available. saved file includes : - model architecture - model weight values (learned training) - model training config, (passed compile()) - optimizer state, (restart training left ) details, read model serialization & saving guide.","code":"model |> save_model(\"my_model.keras\") rm(model) # Recreate the exact same model purely from the file: model <- load_model(\"my_model.keras\")"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"use-the-same-graph-of-layers-to-define-multiple-models","dir":"Articles","previous_headings":"","what":"Use the same graph of layers to define multiple models","title":"The Functional API","text":"functional API, models created specifying inputs outputs graph layers. means single graph layers can used generate multiple models. example , use stack layers instantiate two models: encoder model turns image inputs 16-dimensional vectors, end--end autoencoder model training. , decoding architecture strictly symmetrical encoding architecture, output shape input shape (28, 28, 1). reverse conv_2d layer conv_2d_transpose layer, reverse max_pooling_2d layer upsampling_2d layer.","code":"encoder_input <- keras_input(shape = c(28, 28, 1), name=\"img\") encoder_output <- encoder_input |>   layer_conv_2d(16, 3, activation = \"relu\") |>   layer_conv_2d(32, 3, activation = \"relu\") |>   layer_max_pooling_2d(3) |>   layer_conv_2d(32, 3, activation = \"relu\") |>   layer_conv_2d(16, 3, activation = \"relu\") |>   layer_global_max_pooling_2d()  encoder <- keras_model(encoder_input, encoder_output, name=\"encoder\") summary(encoder) ## Model: \"encoder\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ img (InputLayer)                │ (None, 28, 28, 1)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_3 (Conv2D)               │ (None, 26, 26, 16)     │           160 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_2 (Conv2D)               │ (None, 24, 24, 32)     │         4,640 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 8, 8, 32)       │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_1 (Conv2D)               │ (None, 6, 6, 32)       │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 4, 4, 16)       │         4,624 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ global_max_pooling2d            │ (None, 16)             │             0 │ ## │ (GlobalMaxPooling2D)            │                        │               │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 18,672 (72.94 KB) ##  Trainable params: 18,672 (72.94 KB) ##  Non-trainable params: 0 (0.00 B) decoder_output <- encoder_output |>   layer_reshape(c(4, 4, 1)) |>   layer_conv_2d_transpose(16, 3, activation = \"relu\") |>   layer_conv_2d_transpose(32, 3, activation = \"relu\") |>   layer_upsampling_2d(3) |>   layer_conv_2d_transpose(16, 3, activation = \"relu\") |>   layer_conv_2d_transpose(1, 3, activation = \"relu\")  autoencoder <- keras_model(encoder_input, decoder_output, name=\"autoencoder\") summary(autoencoder) ## Model: \"autoencoder\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ img (InputLayer)                │ (None, 28, 28, 1)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_3 (Conv2D)               │ (None, 26, 26, 16)     │           160 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_2 (Conv2D)               │ (None, 24, 24, 32)     │         4,640 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 8, 8, 32)       │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_1 (Conv2D)               │ (None, 6, 6, 32)       │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 4, 4, 16)       │         4,624 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ global_max_pooling2d            │ (None, 16)             │             0 │ ## │ (GlobalMaxPooling2D)            │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ reshape (Reshape)               │ (None, 4, 4, 1)        │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_3              │ (None, 6, 6, 16)       │           160 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_2              │ (None, 8, 8, 32)       │         4,640 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ up_sampling2d (UpSampling2D)    │ (None, 24, 24, 32)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_1              │ (None, 26, 26, 16)     │         4,624 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose                │ (None, 28, 28, 1)      │           145 │ ## │ (Conv2DTranspose)               │                        │               │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 28,241 (110.32 KB) ##  Trainable params: 28,241 (110.32 KB) ##  Non-trainable params: 0 (0.00 B)"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"all-models-are-callable-just-like-layers","dir":"Articles","previous_headings":"","what":"All models are callable, just like layers","title":"The Functional API","text":"can treat model layer invoking Input output another layer. calling model aren’t just reusing architecture model, ’re also reusing weights. see action, ’s different take autoencoder example creates encoder model, decoder model, chains two calls obtain autoencoder model: can see, model can nested: model can contain sub-models (since model just like layer). common use case model nesting ensembling. example, ’s ensemble set models single model averages predictions:","code":"encoder_input <- keras_input(shape = c(28, 28, 1), name=\"img\") encoder_output <- encoder_input |>   layer_conv_2d(16, 3, activation = \"relu\") |>   layer_conv_2d(32, 3, activation = \"relu\") |>   layer_max_pooling_2d(3) |>   layer_conv_2d(32, 3, activation = \"relu\") |>   layer_conv_2d(16, 3, activation = \"relu\") |>   layer_global_max_pooling_2d()  encoder <- keras_model(encoder_input, encoder_output, name=\"encoder\") summary(encoder) ## Model: \"encoder\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ img (InputLayer)                │ (None, 28, 28, 1)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_7 (Conv2D)               │ (None, 26, 26, 16)     │           160 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_6 (Conv2D)               │ (None, 24, 24, 32)     │         4,640 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d_1 (MaxPooling2D)  │ (None, 8, 8, 32)       │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_5 (Conv2D)               │ (None, 6, 6, 32)       │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_4 (Conv2D)               │ (None, 4, 4, 16)       │         4,624 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ global_max_pooling2d_1          │ (None, 16)             │             0 │ ## │ (GlobalMaxPooling2D)            │                        │               │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 18,672 (72.94 KB) ##  Trainable params: 18,672 (72.94 KB) ##  Non-trainable params: 0 (0.00 B) decoder_input <- keras_input(shape = c(16), name = \"encoded_img\") decoder_output <- decoder_input |>   layer_reshape(c(4, 4, 1)) |>   layer_conv_2d_transpose(16, 3, activation = \"relu\") |>   layer_conv_2d_transpose(32, 3, activation = \"relu\") |>   layer_upsampling_2d(3) |>   layer_conv_2d_transpose(16, 3, activation = \"relu\") |>   layer_conv_2d_transpose(1, 3, activation = \"relu\")  decoder <- keras_model(decoder_input, decoder_output, name = \"decoder\") summary(decoder) ## Model: \"decoder\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ encoded_img (InputLayer)        │ (None, 16)             │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ reshape_1 (Reshape)             │ (None, 4, 4, 1)        │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_7              │ (None, 6, 6, 16)       │           160 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_6              │ (None, 8, 8, 32)       │         4,640 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ up_sampling2d_1 (UpSampling2D)  │ (None, 24, 24, 32)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_5              │ (None, 26, 26, 16)     │         4,624 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_4              │ (None, 28, 28, 1)      │           145 │ ## │ (Conv2DTranspose)               │                        │               │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 9,569 (37.38 KB) ##  Trainable params: 9,569 (37.38 KB) ##  Non-trainable params: 0 (0.00 B) autoencoder_input <- keras_input(shape = c(28, 28, 1), name = \"img\") encoded_img <- encoder(autoencoder_input) decoded_img <- decoder(encoded_img) autoencoder <- keras_model(autoencoder_input, decoded_img,                            name = \"autoencoder\") summary(autoencoder) ## Model: \"autoencoder\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ img (InputLayer)                │ (None, 28, 28, 1)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ encoder (Functional)            │ (None, 16)             │        18,672 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ decoder (Functional)            │ (None, 28, 28, 1)      │         9,569 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 28,241 (110.32 KB) ##  Trainable params: 28,241 (110.32 KB) ##  Non-trainable params: 0 (0.00 B) get_model <- function() {   inputs <- keras_input(shape = 128)   outputs <- inputs |> layer_dense(1)   keras_model(inputs, outputs) }  model1 <- get_model() model2 <- get_model() model3 <- get_model()  inputs <- keras_input(shape = 128) y1 <- model1(inputs) y2 <- model2(inputs) y3 <- model3(inputs) outputs <- layer_average(list(y1, y2, y3)) ensemble_model <- keras_model(inputs = inputs, outputs = outputs)"},{"path":[]},{"path":"https://keras.posit.co/articles/functional_api.html","id":"models-with-multiple-inputs-and-outputs","dir":"Articles","previous_headings":"Manipulate complex graph topologies","what":"Models with multiple inputs and outputs","title":"The Functional API","text":"functional API makes easy manipulate multiple inputs outputs. handled Sequential API. example, ’re building system ranking customer issue tickets priority routing correct department, model three inputs: title ticket (text input), text body ticket (text input), tags added user (categorical input) model two outputs: priority score 0 1 (scalar sigmoid output), department handle ticket (softmax output set departments). can build model lines functional API: Now plot model:  compiling model, can assign different losses output. can even assign different weights loss – modulate contribution total training loss. Since output layers different names, also specify losses loss weights corresponding layer names: Train model passing lists NumPy arrays inputs targets: calling fit Dataset object, yield either list lists like list(list(title_data, body_data, tags_data), list(priority_targets, dept_targets)) list named lists like list(list(title = title_data, body = body_data, tags = tags_data), list(priority = priority_targets, department = dept_targets)). detailed explanation, refer training evaluation guide.","code":"num_tags <- 12  # Number of unique issue tags num_words <- 10000  # Size of vocabulary obtained when preprocessing text data num_departments <- 4  # Number of departments for predictions  title_input <- # Variable-length sequence of ints   keras_input(shape(NA), name = \"title\") body_input <-  # Variable-length sequence of ints   keras_input(shape(NA), name = \"body\") tags_input <-  # Binary vectors of size `num_tags`   keras_input(shape = num_tags, name = \"tags\")  # Embed each word in the title into a 64-dimensional vector title_features <- layer_embedding(title_input, num_words, 64) # Embed each word in the text into a 64-dimensional vector body_features <- layer_embedding(body_input, num_words, 64)  # Reduce sequence of embedded words in the title # into a single 128-dimensional vector title_features <- layer_lstm(title_features, 128) # Reduce sequence of embedded words in the body # into a single 32-dimensional vector body_features <- layer_lstm(body_features, 32)  # Merge all available features into a single large vector via concatenation x <- layer_concatenate(title_features, body_features, tags_input)  # Stick a logistic regression for priority prediction on top of the features priority_pred <- layer_dense(x, 1, name = \"priority\")  # Stick a department classifier on top of the features department_pred <- layer_dense(x, num_departments, name = \"department\")  # Instantiate an end-to-end model predicting both priority and department model <- keras_model(   inputs = list(title_input, body_input, tags_input),   outputs = list(priority = priority_pred, department = department_pred) ) plot(model, show_shapes = TRUE) model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(     loss_binary_crossentropy(from_logits = TRUE),     loss_categorical_crossentropy(from_logits = TRUE)   ),   loss_weights = c(1.0, 0.2) ) model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(     priority = loss_binary_crossentropy(from_logits = TRUE),     department = loss_categorical_crossentropy(from_logits = TRUE)   ),   loss_weights = list(priority = 1.0, department = 0.2) ) # Dummy input data title_data <- random_integer(c(1280, 10), 0, num_words) body_data <- random_integer(c(1280, 100), 0, num_words) tags_data <- random_integer(c(1280, num_tags), 0, 2)  # Dummy target data priority_targets <- random_normal(c(1280, 1)) dept_targets <- random_integer(c(1280, num_departments), 0, 2)  model |> fit(   list(title = title_data, body = body_data, tags = tags_data),   list(priority = priority_targets, department = dept_targets),   epochs = 2,   batch_size = 32 ) ## Epoch 1/2 ## 40/40 - 2s - 61ms/step - loss: 0.3948 ## Epoch 2/2 ## 40/40 - 0s - 5ms/step - loss: 0.1971"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"a-toy-resnet-model","dir":"Articles","previous_headings":"Manipulate complex graph topologies","what":"A toy ResNet model","title":"The Functional API","text":"addition models multiple inputs outputs, functional API makes easy manipulate non-linear connectivity topologies – models layers connected sequentially, Sequential API handle. common use case residual connections. Let’s build toy ResNet model CIFAR10 demonstrate : Plot model:  Now train model:","code":"inputs <- keras_input(shape = c(32, 32, 3), name = \"img\") block_1_output <- inputs |>   layer_conv_2d(32, kernel_size = 3, activation = \"relu\") |>   layer_conv_2d(64, kernel_size = 3, activation = \"relu\") |>   layer_max_pooling_2d(pool_size = 3)  block_2_output <- block_1_output |>   layer_conv_2d(32, kernel_size = 3, activation = \"relu\", padding = \"same\") |>   layer_conv_2d(64, kernel_size = 3, activation = \"relu\", padding = \"same\") |>   layer_add(block_1_output)  block_3_output <- block_2_output |>   layer_conv_2d(64, kernel_size = 3, activation = \"relu\", padding = \"same\") |>   layer_conv_2d(64, kernel_size = 3, activation = \"relu\", padding = \"same\") |>   layer_add(block_2_output)  outputs <- block_3_output |>   layer_conv_2d(64, 3, activation = \"relu\") |>   layer_global_average_pooling_2d() |>   layer_dense(256, activation = \"relu\") |>   layer_dropout(0.5) |>   layer_dense(10)  model <- keras_model(inputs, outputs, name = \"toy_resnet\") summary(model) ## Model: \"toy_resnet\" ## ┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩ ## │ img (InputLayer)    │ (None, 32, 32, 3) │          0 │ -                 │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ conv2d_9 (Conv2D)   │ (None, 30, 30,    │        896 │ img[0][0]         │ ## │                     │ 32)               │            │                   │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ conv2d_8 (Conv2D)   │ (None, 28, 28,    │     18,496 │ conv2d_9[0][0]    │ ## │                     │ 64)               │            │                   │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ max_pooling2d_2     │ (None, 9, 9, 64)  │          0 │ conv2d_8[0][0]    │ ## │ (MaxPooling2D)      │                   │            │                   │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ conv2d_11 (Conv2D)  │ (None, 9, 9, 32)  │     18,464 │ max_pooling2d_2[… │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ conv2d_10 (Conv2D)  │ (None, 9, 9, 64)  │     18,496 │ conv2d_11[0][0]   │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ add (Add)           │ (None, 9, 9, 64)  │          0 │ conv2d_10[0][0],  │ ## │                     │                   │            │ max_pooling2d_2[… │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ conv2d_13 (Conv2D)  │ (None, 9, 9, 64)  │     36,928 │ add[0][0]         │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ conv2d_12 (Conv2D)  │ (None, 9, 9, 64)  │     36,928 │ conv2d_13[0][0]   │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ add_1 (Add)         │ (None, 9, 9, 64)  │          0 │ conv2d_12[0][0],  │ ## │                     │                   │            │ add[0][0]         │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ conv2d_14 (Conv2D)  │ (None, 7, 7, 64)  │     36,928 │ add_1[0][0]       │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ global_average_poo… │ (None, 64)        │          0 │ conv2d_14[0][0]   │ ## │ (GlobalAveragePool… │                   │            │                   │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ dense_7 (Dense)     │ (None, 256)       │     16,640 │ global_average_p… │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ dropout (Dropout)   │ (None, 256)       │          0 │ dense_7[0][0]     │ ## ├─────────────────────┼───────────────────┼────────────┼───────────────────┤ ## │ dense_6 (Dense)     │ (None, 10)        │      2,570 │ dropout[0][0]     │ ## └─────────────────────┴───────────────────┴────────────┴───────────────────┘ ##  Total params: 186,346 (727.91 KB) ##  Trainable params: 186,346 (727.91 KB) ##  Non-trainable params: 0 (0.00 B) plot(model, show_shapes = TRUE) c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_cifar10()  x_train <- x_train / 255.0 x_test <- x_test / 255.0  model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = loss_sparse_categorical_crossentropy(from_logits = TRUE),   metrics = \"acc\" ) # We restrict the data to the first 1000 samples so as to limit the # guide render time. # Try to train on the entire dataset until convergence! model |> fit(   x_train[1:1000, , , ],   y_train[1:1000, ],   batch_size = 64,   epochs = 1,   validation_split = 0.2 ) ## 13/13 - 5s - 419ms/step - acc: 0.1262 - loss: 2.3036 - val_acc: 0.1150 - val_loss: 2.3078"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"shared-layers","dir":"Articles","previous_headings":"","what":"Shared layers","title":"The Functional API","text":"Another good use functional API models use shared layers. Shared layers layer instances reused multiple times model – learn features correspond multiple paths graph--layers. Shared layers often used encode inputs similar spaces (say, two different pieces text feature similar vocabulary). enable sharing information across different inputs, make possible train model less data. given word seen one inputs, benefit processing inputs pass shared layer. share layer functional API, call layer instance multiple times. instance, ’s Embedding layer shared across two different text inputs:","code":"# Embedding for 1000 unique words mapped to 128-dimensional vectors shared_embedding <- layer_embedding(input_dim = 1000, output_dim = 128)  # Variable-length sequence of integers text_input_a <- keras_input(shape = shape(NA), dtype=\"int32\")  # Variable-length sequence of integers text_input_b <- keras_input(shape = shape(NA), dtype=\"int32\")  # Reuse the same layer to encode both inputs encoded_input_a <- shared_embedding(text_input_a) encoded_input_b <- shared_embedding(text_input_b)"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"extract-and-reuse-nodes-in-the-graph-of-layers","dir":"Articles","previous_headings":"","what":"Extract and reuse nodes in the graph of layers","title":"The Functional API","text":"graph layers manipulating static data structure, can accessed inspected. able plot functional models images. also means can access activations intermediate layers (“nodes” graph) reuse elsewhere – useful something like feature extraction. Let’s look example. VGG19 model weights pretrained ImageNet: intermediate activations model, obtained querying graph data structure: Use features create new feature-extraction model returns values intermediate layer activations: comes handy tasks like neural style transfer, among things.","code":"vgg19 <- application_vgg19() features_list <- lapply(vgg19$layers, function(x) x$output) feat_extraction_model <- keras_model(inputs = vgg19$input,                                      outputs = features_list)  img <- random_normal(c(1, 224, 224, 3)) extracted_features <- feat_extraction_model(img)"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"extend-the-api-using-custom-layers","dir":"Articles","previous_headings":"","what":"Extend the API using custom layers","title":"The Functional API","text":"keras includes wide range built-layers, example: Convolutional layers: conv_1d, conv_2d, conv_3d, conv_2d_transpose Pooling layers: max_pooling_1d, max_pooling_2d, max_pooling_3d, average_pooling_3d RNN layers: gru, lstm, conv_lstm_2d batch_normalization, dropout, embedding, etc. don’t find need, ’s easy extend API creating layers. layers subclass Layer class implement: call method, specifies computation done layer. build method, creates weights layer (just style convention since can create weights initialize, well). learn creating layers scratch, read custom layers models guide. following basic implementation layer_dense(): serialization support custom layer, define get_config() method returns constructor arguments layer instance: Optionally, implement class method from_config(cls, config) used recreating layer instance given config dictionary. default implementation from_config :","code":"custom_dense <- Layer(   classname = \"CustomDense\",   initialize = function(units = 32) {     super$initialize()     self$units <- as.integer(units)   },   build = function(input_shape) {     self$w <- self$add_weight(       shape = shape(input_shape[[2]], self$units),       initializer = \"random_normal\",       trainable = TRUE,     )     self$b <- self$add_weight(       shape = shape(self$units),       initializer=\"random_normal\",       trainable = TRUE     )   },   call = function(inputs) {     op_matmul(inputs, self$w) + self$b   } )  inputs <- keras_input(c(4)) outputs <- custom_dense(inputs, 10)  model <- keras_model(inputs, outputs) custom_dense <- Layer(   classname = \"CustomDense\",    initialize = function(units = 32, ...) {     super$initialize()     self$units <- as.integer(units)   },    build = function(input_shape) {     self$w <- self$add_weight(       shape = shape(input_shape[[2]], self$units),       initializer = \"random_normal\",       trainable = TRUE,     )     self$b <- self$add_weight(       shape = shape(self$units),       initializer=\"random_normal\",       trainable = TRUE     )   },    call = function(inputs) {     op_matmul(inputs, self$w) + self$b   },    get_config = function() {     list(units = self$units)   } )  inputs <- keras_input(c(4)) outputs <- custom_dense(inputs, 10)  model <- keras_model(inputs, outputs) config <- get_config(model)  new_model <-   from_config(config, custom_objects = list(CustomDense = custom_dense)) from_config <- function(cls, config) {   do.call(cls, config) }"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"when-to-use-the-functional-api","dir":"Articles","previous_headings":"","what":"When to use the functional API","title":"The Functional API","text":"use Keras functional API create new model, just subclass Model class directly? general, functional API higher-level, easier safer, number features subclassed models support. However, model subclassing provides greater flexibility building models easily expressible directed acyclic graphs layers. example, implement Tree-RNN functional API subclass Model directly. -depth look differences functional API model subclassing, read Symbolic Imperative APIs TensorFlow 2.0?.","code":""},{"path":"https://keras.posit.co/articles/functional_api.html","id":"functional-api-strengths","dir":"Articles","previous_headings":"When to use the functional API","what":"Functional API strengths:","title":"The Functional API","text":"following properties also true Sequential models (also data structures), true subclassed models (R Python (byte)code, data structures).","code":""},{"path":"https://keras.posit.co/articles/functional_api.html","id":"less-verbose","dir":"Articles","previous_headings":"When to use the functional API > Functional API strengths:","what":"Less verbose","title":"The Functional API","text":"super$initialize(...), call = function(...), self$..., etc. Compare: subclassed version:","code":"inputs <- keras_input(shape = shape(32)) outputs <- inputs |>   layer_dense(64, activation = \"relu\") |>   layer_dense(10) mlp <- keras_model(inputs, outputs) MLP <- Model(   classname = \"MLP\",   initialize = function(...) {     super$initialize(...)     self$dense_1 <- layer_dense(units = 64, activation = \"relu\")     self$dense_2 <- layer_dense(units = 10)   },   call = function(inputs) {     inputs |>       self$dense_1() |>       self$dense_2()   } )  # Instantiate the model. mlp <- MLP() # Necessary to create the model's state. # The model doesn't have a state until it's called at least once. out <- mlp(op_zeros(c(1, 32)))"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"model-validation-while-defining-its-connectivity-graph","dir":"Articles","previous_headings":"When to use the functional API > Functional API strengths:","what":"Model validation while defining its connectivity graph","title":"The Functional API","text":"functional API, input specification (shape dtype) created advance (using Input). Every time call layer, layer checks specification passed matches assumptions, raise helpful error message . guarantees model can build functional API run. debugging – convergence-related debugging – happens statically model construction execution time. similar type checking compiler.","code":""},{"path":"https://keras.posit.co/articles/functional_api.html","id":"a-functional-model-is-plottable-and-inspectable","dir":"Articles","previous_headings":"When to use the functional API > Functional API strengths:","what":"A functional model is plottable and inspectable","title":"The Functional API","text":"can plot model graph, can easily access intermediate nodes graph. example, extract reuse activations intermediate layers (seen previous example):","code":"features_list <- lapply(vgg19$layers, function(x) x$output) feat_extraction_model <- keras_model(inputs = vgg19$input,                                      outputs = features_list)"},{"path":"https://keras.posit.co/articles/functional_api.html","id":"a-functional-model-can-be-serialized-or-cloned","dir":"Articles","previous_headings":"When to use the functional API > Functional API strengths:","what":"A functional model can be serialized or cloned","title":"The Functional API","text":"functional model data structure rather piece code, safely serializable can saved single file allows recreate exact model without access original code. See serialization & saving guide. serialize subclassed model, necessary implementer specify get_config() from_config() method model level.","code":""},{"path":[]},{"path":"https://keras.posit.co/articles/functional_api.html","id":"it-does-not-support-dynamic-architectures","dir":"Articles","previous_headings":"When to use the functional API > Functional API weakness:","what":"It does not support dynamic architectures","title":"The Functional API","text":"functional API treats models DAGs layers. true deep learning architectures, – example, recursive networks Tree RNNs follow assumption implemented functional API.","code":""},{"path":"https://keras.posit.co/articles/functional_api.html","id":"mix-and-match-api-styles","dir":"Articles","previous_headings":"","what":"Mix-and-match API styles","title":"The Functional API","text":"Choosing functional API Model subclassing isn’t binary decision restricts one category models. models keras API can interact , whether ’re Sequential models, functional models, subclassed models written scratch. can always use functional model Sequential model part subclassed model layer: can use subclassed layer model functional API long implements call method follows one following patterns: call(inputs, ...) – inputs tensor nested structure tensors (e.g. list tensors), ... non-tensor arguments (non-inputs). call(inputs, training = NULL, ...) – training boolean indicating whether layer behave training mode inference mode. call(inputs, mask = NULL, ...) – mask boolean mask tensor (useful RNNs, instance). call(inputs, training = NULL, mask = NULL, ...) – course, can masking training-specific behavior time. Additionally, implement get_config() method custom Layer model, functional models create still serializable cloneable. ’s quick example custom RNN, written scratch, used functional model:","code":"units <- 32 timesteps <- 10 input_dim <- 5  # Define a Functional model inputs <- keras_input(shape(NA, units)) outputs <- inputs |>   layer_global_average_pooling_1d() |>   layer_dense(units = 1)  model <- keras_model(inputs, outputs)  layer_custom_rnn <- Layer(   classname = \"CustomRNN\",   initialize = function(...) {     super$initialize(...)     self$units <- units     self$projection_1 <- layer_dense(units = units, activation = \"tanh\")     self$projection_2 <- layer_dense(units = units, activation = \"tanh\")     self$classifier <- model   },   call = function(inputs, ...) {     outputs <- list()     state <- op_zeros(c(shape(inputs)[[1]], self$units))     for (t in 1:(shape(inputs)[[2]])) {       x <- inputs[, t, ]       h <- self$projection_1(x)       y <- h + self$projection_2(state)       state <- y       outputs[[t]] <- y     }     features <- op_stack(outputs, axis = 2)     self$classifier(features)   } )  rnn <- layer_custom_rnn() out <- rnn(op_zeros(c(1, timesteps, input_dim))) units <- 32 timesteps <- 10 input_dim <- 5 batch_size <- 16  layer_custom_rnn <- Layer(   \"custom_rnn\",   initialize = function(...) {     super$initialize(...)     self$units <- units     self$projection_1 <- layer_dense(units = units, activation = \"tanh\")     self$projection_2 <- layer_dense(units = units, activation = \"tanh\")     self$classifier <- layer_dense(units = 1)   },   call = function(inputs, ...) {     outputs <- list()     state <- op_zeros(c(shape(inputs)[[1]], self$units))     for (t in 1:(shape(inputs)[[2]])) {       x <- inputs[, t, ]       h <- self$projection_1(x)       y <- h + self$projection_2(state)       state <- y       outputs[[t]] <- y     }     features <- op_stack(outputs, axis = 2)     self$classifier(features)   } )  # Note that you specify a static batch size for the inputs with the `batch_shape` # arg, because the inner computation of `layer_custom_rnn()` requires a static batch size # (when you create the `state` zeros tensor). inputs <- keras_input(batch_shape = shape(batch_size, timesteps, input_dim)) outputs <- inputs |>   layer_conv_1d(filters = 32, kernel_size = 3) |>   layer_custom_rnn()  model <- keras_model(inputs, outputs) out <- model(op_zeros(c(1, 10, 5)))"},{"path":"https://keras.posit.co/articles/getting_started.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Getting Started with Keras","text":"Keras high-level neural networks API developed focus enabling fast experimentation. able go idea result least possible delay key good research. Keras following key features: Allows code run CPU GPU, seamlessly. User-friendly API makes easy quickly prototype deep learning models. Built-support convolutional networks (computer vision), recurrent networks (sequence processing), combination . Supports arbitrary network architectures: multi-input multi-output models, layer sharing, model sharing, etc. means Keras appropriate building essentially deep learning model, memory network neural Turing machine. website provides documentation R interface Keras. See main Keras website https://keras.io additional information project.","code":""},{"path":"https://keras.posit.co/articles/getting_started.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started with Keras","text":"First, install keras R package: install development version : Keras R interface requires backend engine installed. TensorFlow default. provide default installation Keras TensorFlow GPU capable, GPU available. want customized installation, e.g. see documentation install_keras() installation section.","code":"install.packages(\"keras3\") remotes::install_github(\"rstudio/keras\") keras3::install_keras(backend = \"tensorflow\")"},{"path":"https://keras.posit.co/articles/getting_started.html","id":"mnist-example","dir":"Articles","previous_headings":"","what":"MNIST Example","title":"Getting Started with Keras","text":"can learn basics Keras walking simple example: recognizing handwritten digits MNIST dataset. MNIST consists 28 x 28 grayscale images handwritten digits like :  dataset also includes labels image, telling us digit . example, labels images 5, 0, 4, 1.","code":""},{"path":"https://keras.posit.co/articles/getting_started.html","id":"preparing-the-data","dir":"Articles","previous_headings":"MNIST Example","what":"Preparing the Data","title":"Getting Started with Keras","text":"MNIST dataset included Keras can accessed using dataset_mnist() function. load dataset create variables test training data: x data 3-d array (images, width, height) grayscale values. prepare data training convert 3-d arrays matrices reshaping width height single dimension (28x28 images flattened length 784 vectors). , convert grayscale values integers ranging 0 255 floating point values ranging 0 1: Note use array_reshape() function rather dim<-() function reshape array. data re-interpreted using row-major semantics (opposed R’s default column-major semantics), turn compatible way numerical libraries called Keras interpret array dimensions. y data integer vector values ranging 0 9. prepare data training one-hot encode vectors binary class matrices using Keras to_categorical() function:","code":"library(keras3) mnist <- dataset_mnist() x_train <- mnist$train$x y_train <- mnist$train$y x_test <- mnist$test$x y_test <- mnist$test$y # reshape x_train <- array_reshape(x_train, c(nrow(x_train), 784)) x_test <- array_reshape(x_test, c(nrow(x_test), 784)) # rescale x_train <- x_train / 255 x_test <- x_test / 255 y_train <- to_categorical(y_train, 10) y_test <- to_categorical(y_test, 10)"},{"path":"https://keras.posit.co/articles/getting_started.html","id":"defining-the-model","dir":"Articles","previous_headings":"MNIST Example","what":"Defining the Model","title":"Getting Started with Keras","text":"core data structure Keras model, way organize layers. simplest type model Sequential model, linear stack layers. begin creating sequential model adding layers using pipe (|>) operator: input_shape argument first layer specifies shape input data (length 784 numeric vector representing grayscale image). final layer outputs length 10 numeric vector (probabilities digit) using softmax activation function. Use summary() function print details model: Next, compile model appropriate loss function, optimizer, metrics:","code":"model <- keras_model_sequential(input_shape = c(784)) model |>   layer_dense(units = 256, activation = 'relu') |>   layer_dropout(rate = 0.4) |>   layer_dense(units = 128, activation = 'relu') |>   layer_dropout(rate = 0.3) |>   layer_dense(units = 10, activation = 'softmax') summary(model) ## Model: \"sequential\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ dense_2 (Dense)                 │ (None, 256)            │       200,960 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout_1 (Dropout)             │ (None, 256)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_1 (Dense)                 │ (None, 128)            │        32,896 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout (Dropout)               │ (None, 128)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense (Dense)                   │ (None, 10)             │         1,290 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 235,146 (918.54 KB) ##  Trainable params: 235,146 (918.54 KB) ##  Non-trainable params: 0 (0.00 B) plot(model) model |> compile(   loss = 'categorical_crossentropy',   optimizer = optimizer_rmsprop(),   metrics = c('accuracy') )"},{"path":"https://keras.posit.co/articles/getting_started.html","id":"training-and-evaluation","dir":"Articles","previous_headings":"MNIST Example","what":"Training and Evaluation","title":"Getting Started with Keras","text":"Use fit() function train model 30 epochs using batches 128 images: history object returned fit() includes loss accuracy metrics can plot: Evaluate model’s performance test data: Generate predictions new data: Keras provides vocabulary building deep learning models simple, elegant, intuitive. Building question answering system, image classification model, neural Turing machine, model just straightforward.","code":"history <- model |> fit(   x_train, y_train,   epochs = 30, batch_size = 128,   validation_split = 0.2 ) plot(history) model |> evaluate(x_test, y_test) ## 313/313 - 1s - 2ms/step - accuracy: 0.9821 - loss: 0.0926 ## $accuracy ## [1] 0.9821 ## ## $loss ## [1] 0.09263836 probs <- model |> predict(x_test) ## 313/313 - 0s - 1ms/step max.col(probs) - 1L ##   [1] 7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 ##  [36] 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 ##  [71] 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 ##  [ reached getOption(\"max.print\") -- omitted 9900 entries ]"},{"path":"https://keras.posit.co/articles/getting_started.html","id":"deep-learning-with-r-book","dir":"Articles","previous_headings":"MNIST Example","what":"Deep Learning with R Book","title":"Getting Started with Keras","text":"want comprehensive introduction Keras concepts practice deep learning, recommend Deep Learning R, 2nd Edition book Manning. book collaboration François Chollet, creator (Python) Keras, J.J. Allaire, wrote original R interface Keras, Tomasz Kalinowski, maintainer R interface Keras. book presumes significant knowledge machine learning deep learning, goes way basic theory advanced practical applications, using R interface Keras.","code":""},{"path":"https://keras.posit.co/articles/getting_started.html","id":"why-this-name-keras","dir":"Articles","previous_headings":"","what":"Why this name, Keras?","title":"Getting Started with Keras","text":"Keras (κέρας) means horn Greek. reference literary image ancient Greek Latin literature, first found Odyssey, dream spirits (Oneiroi, singular Oneiros) divided deceive men false visions, arrive Earth gate ivory, announce future come pass, arrive gate horn. ’s play words κέρας (horn) / κραίνω (fulfill), ἐλέφας (ivory) / ἐλεφαίρομαι (deceive). Keras initially developed part research effort project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System). “Oneiroi beyond unravelling –can sure tale tell? men look comes pass. Two gates give passage fleeting Oneiroi; one made horn, one ivory. Oneiroi pass sawn ivory deceitful, bearing message fulfilled; come polished horn truth behind , accomplished men see .” Homer, Odyssey 19. 562 ff (Shewring translation).","code":""},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Introduction to Keras for engineers","text":"Keras 3 deep learning framework works TensorFlow, JAX, PyTorch interchangeably. notebook walk key Keras 3 workflows. Let’s start installing Keras 3: pip install keras –upgrade –quiet","code":""},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Introduction to Keras for engineers","text":"’re going using tensorflow backend – can edit string \"jax\" \"torch\" hit “Restart runtime”, whole notebook run just ! entire guide backend-agnostic.","code":"library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(keras3)  # Note that you must configure the backend # before calling any other keras functions. # The backend cannot be changed once the # package is imported. use_backend(\"tensorflow\")"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"a-first-example-a-mnist-convnet","dir":"Articles","previous_headings":"","what":"A first example: A MNIST convnet","title":"Introduction to Keras for engineers","text":"Let’s start Hello World ML: training convnet classify MNIST digits. ’s data: ’s model. Different model-building options Keras offers include: Sequential API (use ) Functional API (typical) Writing models via subclassing (advanced use cases) ’s model summary: use compile() method specify optimizer, loss function, metrics monitor. Note JAX TensorFlow backends, XLA compilation turned default. Let’s train evaluate model. ’ll set aside validation split 15% data training monitor generalization unseen data. training, saving model end epoch. can also save model latest state like : reload like : Next, can query predictions class probabilities predict(): ’s basics!","code":"# Load the data and split it between train and test sets c(c(x_train, y_train), c(x_test, y_test)) %<-% keras3::dataset_mnist()  # Scale images to the [0, 1] range x_train <- x_train / 255 x_test <- x_test / 255 # Make sure images have shape (28, 28, 1) x_train <- op_expand_dims(x_train, -1) x_test <- op_expand_dims(x_test, -1)  dim(x_train) ## [1] 60000    28    28     1 dim(x_test) ## [1] 10000    28    28     1 # Model parameters num_classes <- 10 input_shape <- c(28, 28, 1)  model <- keras_model_sequential(input_shape = input_shape) model |>   layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = \"relu\") |>   layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = \"relu\") |>   layer_max_pooling_2d(pool_size = c(2, 2)) |>   layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = \"relu\") |>   layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = \"relu\") |>   layer_global_average_pooling_2d() |>   layer_dropout(rate = 0.5) |>   layer_dense(units = num_classes, activation = \"softmax\") summary(model) ## Model: \"sequential\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ conv2d_3 (Conv2D)               │ (None, 26, 26, 64)     │           640 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_2 (Conv2D)               │ (None, 24, 24, 64)     │        36,928 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 12, 12, 64)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_1 (Conv2D)               │ (None, 10, 10, 128)    │        73,856 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 8, 8, 128)      │       147,584 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ global_average_pooling2d        │ (None, 128)            │             0 │ ## │ (GlobalAveragePooling2D)        │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dropout (Dropout)               │ (None, 128)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense (Dense)                   │ (None, 10)             │         1,290 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 260,298 (1016.79 KB) ##  Trainable params: 260,298 (1016.79 KB) ##  Non-trainable params: 0 (0.00 B) model |> compile(   optimizer = \"adam\",   loss = \"sparse_categorical_crossentropy\",   metrics = list(     metric_sparse_categorical_accuracy(name = \"acc\")   ) ) batch_size <- 128 epochs <- 10  callbacks <- list(   callback_model_checkpoint(filepath=\"model_at_epoch_{epoch}.keras\"),   callback_early_stopping(monitor=\"val_loss\", patience=2) )  model |> fit(   x_train, y_train,   batch_size = batch_size,   epochs = epochs,   validation_split = 0.15,   callbacks = callbacks ) ## Epoch 1/10 ## 399/399 - 7s - 17ms/step - acc: 0.7342 - loss: 0.7829 - val_acc: 0.9593 - val_loss: 0.1409 ## Epoch 2/10 ## 399/399 - 2s - 5ms/step - acc: 0.9285 - loss: 0.2394 - val_acc: 0.9703 - val_loss: 0.0940 ## Epoch 3/10 ## 399/399 - 2s - 5ms/step - acc: 0.9468 - loss: 0.1791 - val_acc: 0.9788 - val_loss: 0.0688 ## Epoch 4/10 ## 399/399 - 2s - 5ms/step - acc: 0.9575 - loss: 0.1450 - val_acc: 0.9834 - val_loss: 0.0571 ## Epoch 5/10 ## 399/399 - 2s - 5ms/step - acc: 0.9640 - loss: 0.1230 - val_acc: 0.9858 - val_loss: 0.0482 ## Epoch 6/10 ## 399/399 - 2s - 5ms/step - acc: 0.9681 - loss: 0.1074 - val_acc: 0.9867 - val_loss: 0.0471 ## Epoch 7/10 ## 399/399 - 2s - 5ms/step - acc: 0.9719 - loss: 0.0960 - val_acc: 0.9873 - val_loss: 0.0432 ## Epoch 8/10 ## 399/399 - 2s - 5ms/step - acc: 0.9732 - loss: 0.0894 - val_acc: 0.9897 - val_loss: 0.0404 ## Epoch 9/10 ## 399/399 - 2s - 5ms/step - acc: 0.9760 - loss: 0.0806 - val_acc: 0.9904 - val_loss: 0.0333 ## Epoch 10/10 ## 399/399 - 2s - 5ms/step - acc: 0.9784 - loss: 0.0731 - val_acc: 0.9898 - val_loss: 0.0380 score <- model |> evaluate(x_test, y_test, verbose = 0) save_model(model, \"final_model.keras\", overwrite=TRUE) model <- load_model(\"final_model.keras\") predictions <- model |> predict(x_test) ## 313/313 - 0s - 2ms/step dim(predictions) ## [1] 10000    10"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"writing-cross-framework-custom-components","dir":"Articles","previous_headings":"","what":"Writing cross-framework custom components","title":"Introduction to Keras for engineers","text":"Keras enables write custom Layers, Models, Metrics, Losses, Optimizers work across TensorFlow, JAX, PyTorch codebase. Let’s take look custom layers first. op_ namespace contains: implementation NumPy API, e.g. op_stack op_matmul. set neural network specific ops absent NumPy, op_conv op_binary_crossentropy. Let’s make custom Dense layer works backends: Next, let’s make custom Dropout layer relies random_* namespace: Next, let’s write custom subclassed model uses two custom layers: Let’s compile fit :","code":"layer_my_dense <- Layer(   classname = \"MyDense\",   initialize = function(units, activation = NULL, name = NULL, ...) {     super$initialize(name = name, ...)     self$units <- units     self$activation <- activation   },   build = function(input_shape) {     input_dim <- tail(input_shape, 1)     self$w <- self$add_weight(       shape = shape(input_dim, self$units),       initializer = initializer_glorot_normal(),       name = \"kernel\",       trainable = TRUE     )     self$b <- self$add_weight(       shape = shape(self$units),       initializer = initializer_zeros(),       name = \"bias\",       trainable = TRUE     )   },   call = function(inputs) {     # Use Keras ops to create backend-agnostic layers/metrics/etc.     x <- op_matmul(inputs, self$w) + self$b     if (!is.null(self$activation))       x <- self$activation(x)     x   } ) layer_my_dropout <- Layer(   \"MyDropout\",   initialize = function(rate, name = NULL, seed = NULL, ...) {     super$initialize(name = name)     self$rate <- rate     # Use seed_generator for managing RNG state.     # It is a state element and its seed variable is     # tracked as part of `layer$variables`.     self$seed_generator <- random_seed_generator(seed)   },   call = function(inputs) {     # Use `keras3::random_*` for random ops.     random_dropout(inputs, self$rate, seed = self$seed_generator)   } ) MyModel <- Model(   \"MyModel\",   initialize = function(num_classes, ...) {     super$initialize(...)     self$conv_base <-       keras_model_sequential() |>       layer_conv_2d(64, kernel_size = c(3, 3), activation = \"relu\") |>       layer_conv_2d(64, kernel_size = c(3, 3), activation = \"relu\") |>       layer_max_pooling_2d(pool_size = c(2, 2)) |>       layer_conv_2d(128, kernel_size = c(3, 3), activation = \"relu\") |>       layer_conv_2d(128, kernel_size = c(3, 3), activation = \"relu\") |>       layer_global_average_pooling_2d()      self$dp <- layer_my_dropout(rate = 0.5)     self$dense <- layer_my_dense(units = num_classes,                                  activation = activation_softmax)   },   call = function(inputs) {     inputs |>       self$conv_base() |>       self$dp() |>       self$dense()   } ) model <- MyModel(num_classes = 10) model |> compile(   loss = loss_sparse_categorical_crossentropy(),   optimizer = optimizer_adam(learning_rate = 1e-3),   metrics = list(     metric_sparse_categorical_accuracy(name = \"acc\")   ) )  model |> fit(   x_train, y_train,   batch_size = batch_size,   epochs = 1, # For speed   validation_split = 0.15 ) ## 399/399 - 7s - 18ms/step - acc: 0.7397 - loss: 0.7578 - val_acc: 0.9236 - val_loss: 0.2547"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"training-models-on-arbitrary-data-sources","dir":"Articles","previous_headings":"","what":"Training models on arbitrary data sources","title":"Introduction to Keras for engineers","text":"Keras models can trained evaluated wide variety data sources, independently backend ’re using. includes: Arrays Dataframes TensorFlow tf_dataset objects PyTorch DataLoader objects Keras PyDataset objects work whether ’re using TensorFlow, JAX, PyTorch Keras backend. Let’s try tf_dataset:","code":"library(tfdatasets, exclude = \"shape\")  train_dataset <- list(x_train, y_train) |>   tensor_slices_dataset() |>   dataset_batch(batch_size) |>   dataset_prefetch(buffer_size = tf$data$AUTOTUNE)  test_dataset <- list(x_test, y_test) |>   tensor_slices_dataset() |>   dataset_batch(batch_size) |>   dataset_prefetch(buffer_size = tf$data$AUTOTUNE)  model <- MyModel(num_classes = 10) model |> compile(   loss = loss_sparse_categorical_crossentropy(),   optimizer = optimizer_adam(learning_rate = 1e-3),   metrics = list(     metric_sparse_categorical_accuracy(name = \"acc\")   ) )  model |> fit(train_dataset, epochs = 1, validation_data = test_dataset) ## 469/469 - 8s - 17ms/step - acc: 0.7582 - loss: 0.7179 - val_acc: 0.9028 - val_loss: 0.3014"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further reading","title":"Introduction to Keras for engineers","text":"concludes short overview new multi-backend capabilities Keras 3. Next, can learn :","code":""},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"how-to-customize-what-happens-in-fit","dir":"Articles","previous_headings":"Further reading","what":"How to customize what happens in fit()","title":"Introduction to Keras for engineers","text":"Want implement non-standard training algorithm still want benefit power usability fit()? ’s easy customize fit() support arbitrary use cases: Customizing happens fit() TensorFlow","code":""},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"how-to-write-custom-training-loops","dir":"Articles","previous_headings":"","what":"How to write custom training loops","title":"Introduction to Keras for engineers","text":"Writing training loop scratch TensorFlow","code":""},{"path":"https://keras.posit.co/articles/intro_to_keras_for_engineers.html","id":"how-to-distribute-training","dir":"Articles","previous_headings":"","what":"How to distribute training","title":"Introduction to Keras for engineers","text":"Guide distributed training TensorFlow Enjoy library! 🚀","code":""},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Introduction to Keras for Researchers","text":"","code":"library(keras3) library(tensorflow)"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Introduction to Keras for Researchers","text":"machine learning researcher? publish NeurIPS push state---art CV NLP? guide serve first introduction core Keras & TensorFlow API concepts. guide, learn : Tensors, variables, gradients TensorFlow Creating layers subclassing [Layer] class Writing low-level training loops Tracking losses created layers via add_loss() method Tracking metrics low-level training loop Speeding execution compiled [tensorflow::tf_function()] Executing layers training inference mode Keras Functional API also see Keras API action two end--end research examples: Variational Autoencoder, Hypernetwork.","code":""},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"tensors","dir":"Articles","previous_headings":"","what":"Tensors","title":"Introduction to Keras for Researchers","text":"TensorFlow infrastructure layer differentiable programming. heart, ’s framework manipulating N-dimensional arrays (tensors), much like NumPy. However, three key differences NumPy TensorFlow: TensorFlow can leverage hardware accelerators GPUs TPUs. TensorFlow can automatically compute gradient arbitrary differentiable tensor expressions. TensorFlow computation can distributed large numbers devices single machine, large number machines (potentially multiple devices ). Let’s take look object core TensorFlow: Tensor. ’s constant tensor: can get value R array calling .array(): features attributes dtype shape: common way create constant tensors via tf$ones tf$zeros: can also create random constant tensors:","code":"x <- tf$constant(rbind(c(5, 2), c(1, 3))) print(x) ## tf.Tensor( ## [[5. 2.] ##  [1. 3.]], shape=(2, 2), dtype=float64) as.array(x) ##      [,1] [,2] ## [1,]    5    2 ## [2,]    1    3 x$dtype ## tf.float64 x$shape ## TensorShape([2, 2]) tf$ones(shape = shape(2, 1)) ## tf.Tensor( ## [[1.] ##  [1.]], shape=(2, 1), dtype=float32) tf$zeros(shape = shape(2, 1)) ## tf.Tensor( ## [[0.] ##  [0.]], shape=(2, 1), dtype=float32) x <- random_normal(shape = c(2, 2), mean = 0.0, stddev = 1.0) x <- random_uniform(shape = c(2, 2), minval = 0, maxval = 10)"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Introduction to Keras for Researchers","text":"Variables special tensors used store mutable state (weights neural network). create Variable using initial value: update value Variable using methods $assign(value), $assign_add(increment), $assign_sub(decrement):","code":"initial_value <- random_normal(shape=c(2, 2)) a <- tf$Variable(initial_value) print(a) ## <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy= ## array([[ 0.9057419 ,  0.7916686 ], ##        [ 0.28754202, -0.5408822 ]], dtype=float32)> new_value <- random_normal(shape=c(2, 2)) a$assign(new_value) ## <tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy= ## array([[-0.3405368 , -2.1463926 ], ##        [ 1.2602988 ,  0.12241419]], dtype=float32)> added_value <- random_normal(shape=c(2, 2)) a$assign_add(added_value) ## <tf.Variable 'UnreadVariable' shape=(2, 2) dtype=float32, numpy= ## array([[ 0.04820395, -2.6854615 ], ##        [ 0.23246336,  1.4535258 ]], dtype=float32)>"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"doing-math-in-tensorflow","dir":"Articles","previous_headings":"","what":"Doing math in TensorFlow","title":"Introduction to Keras for Researchers","text":"’ve used NumPy, math TensorFlow look familiar. main difference TensorFlow code can run GPU TPU.","code":"a <- random_normal(shape=c(2, 2)) b <- random_normal(shape=c(2, 2))  c <- a + b d <- tf$square(c) e <- tf$exp(d)"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"gradients","dir":"Articles","previous_headings":"","what":"Gradients","title":"Introduction to Keras for Researchers","text":"’s another big difference R: can automatically retrieve gradient differentiable expression. Just open GradientTape, start “watching” tensor via tape$watch(), compose differentiable expression using tensor input: default, variables watched automatically, don’t need manually watch : Note can compute higher-order derivatives nesting tapes:","code":"a <- random_normal(shape=c(2, 2)) b <- random_normal(shape=c(2, 2))  with(tf$GradientTape() %as% tape, {   tape$watch(a)  # Start recording the history of operations applied to `a`   c <- tf$sqrt(tf$square(a) + tf$square(b))  # Do some math using `a`   # What's the gradient of `c` with respect to `a`?   dc_da <- tape$gradient(c, a)   print(dc_da) }) ## tf.Tensor( ## [[ 0.9969011  -0.7707146 ] ##  [ 0.23378514  0.96255165]], shape=(2, 2), dtype=float32) a <- tf$Variable(a)  with(tf$GradientTape() %as% tape, {   c <- tf$sqrt(tf$square(a) + tf$square(b))   dc_da <- tape$gradient(c, a)   print(dc_da) }) ## tf.Tensor( ## [[ 0.9969011  -0.7707146 ] ##  [ 0.23378514  0.96255165]], shape=(2, 2), dtype=float32) with(tf$GradientTape() %as% outer_tape, {   with(tf$GradientTape() %as% tape, {     c <- tf$sqrt(tf$square(a) + tf$square(b))     dc_da <- tape$gradient(c, a)   })   d2c_da2 <- outer_tape$gradient(dc_da, a)   print(d2c_da2) }) ## tf.Tensor( ## [[3.3447742e-03 7.1282005e-01] ##  [5.7464113e+00 5.5013180e-02]], shape=(2, 2), dtype=float32)"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"keras-layers","dir":"Articles","previous_headings":"","what":"Keras layers","title":"Introduction to Keras for Researchers","text":"TensorFlow infrastructure layer differentiable programming, dealing tensors, variables, gradients, Keras user interface deep learning, dealing layers, models, optimizers, loss functions, metrics, . Keras serves high-level API TensorFlow: Keras makes TensorFlow simple productive. Layer class fundamental abstraction Keras. Layer encapsulates state (weights) computation (defined call method). simple layer looks like . self$add_weight() method gives shortcut creating weights: use Layer instance much like R function: weight variables (created initialize) automatically tracked weights property: many built-layers available, Dense Conv2D LSTM fancier ones like Conv3DTranspose ConvLSTM2D. smart reusing built-functionality.","code":"Linear <- new_layer_class(   \"Linear\",   initialize = function(units = 32, input_dim = 32) {     super$initialize()     self$w <- self$add_weight(       shape = shape(input_dim, units),       initializer = \"random_normal\",       trainable = TRUE     )     self$b <- self$add_weight(       shape = shape(units),       initializer = \"zeros\",       trainable = TRUE     )   },   call = function(inputs) {     tf$matmul(inputs, self$w) + self$b   } ) # Instantiate our layer. linear_layer <- Linear(units=4, input_dim=2)  # The layer can be treated as a function. # Here we call it on some data. y <- linear_layer(tf$ones(shape(2, 2))) linear_layer$weights ## [[1]] ## <KerasVariable shape=(2, 4), dtype=float32, path=linear/variable> ## ## [[2]] ## <KerasVariable shape=(4), dtype=float32, path=linear/variable_1>"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"layer-weight-creation-in-buildinput_shape","dir":"Articles","previous_headings":"","what":"Layer weight creation in build(input_shape)","title":"Introduction to Keras for Researchers","text":"’s often good idea defer weight creation build() method, don’t need specify input dim/shape layer construction time:","code":"Linear <- new_layer_class(   \"Linear\",   initialize = function(units = 32) {     super$initialize()     self$units <- units   },   build = function(input_shape) {     self$w <- self$add_weight(       shape = shape(input_shape[-1], self$units),       initializer = \"random_normal\",       trainable = TRUE     )     self$b <- self$add_weight(       shape = shape(self$units),       initializer = \"zeros\",       trainable = TRUE     )   },   call = function(inputs) {     tf$matmul(inputs, self$w) + self$b   } )  # Instantiate our layer. linear_layer <- Linear(units = 4)  # This will also call `build(input_shape)` and create the weights. y <- linear_layer(tf$ones(shape(2, 2)))"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"layer-gradients","dir":"Articles","previous_headings":"","what":"Layer gradients","title":"Introduction to Keras for Researchers","text":"can automatically retrieve gradients weights layer calling inside GradientTape. Using gradients, can update weights layer, either manually, using optimizer object. course, can modify gradients using , need .","code":"# Prepare a dataset. c(c(x_train, y_train), .) %<-% dataset_mnist()  x_train <- array_reshape(x_train, c(60000, 784)) / 255  dataset <- tfdatasets::tensor_slices_dataset(list(x_train, y_train)) %>%   tfdatasets::dataset_shuffle(buffer_size=1024) %>%   tfdatasets::dataset_batch(64)  # Instantiate our linear layer (defined above) with 10 units. linear_layer <- Linear(units = 10)  # Instantiate a logistic loss function that expects integer targets. loss_fn <- loss_sparse_categorical_crossentropy(from_logits=TRUE)  # Instantiate an optimizer. optimizer <- optimizer_sgd(learning_rate=1e-3)  # Iterate over the batches of the dataset. coro::loop(for(data in dataset) {   # Open a GradientTape.   with(tf$GradientTape() %as% tape, {     # Forward pass.     logits <- linear_layer(data[[1]])      # Loss value for this batch.     loss_value <- loss_fn(data[[2]], logits)   })    # Get gradients of the loss wrt the weights.   gradients <- tape$gradient(loss_value, linear_layer$trainable_weights)    # Update the weights of our linear layer.   optimizer$apply_gradients(zip_lists(gradients, linear_layer$trainable_weights)) }) loss_value ## tf.Tensor(1.2819729, shape=(), dtype=float32)"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"trainable-and-non-trainable-weights","dir":"Articles","previous_headings":"","what":"Trainable and non-trainable weights","title":"Introduction to Keras for Researchers","text":"Weights created layers can either trainable non-trainable. ’re exposed trainable_weights non_trainable_weights respectively. ’s layer non-trainable weight:","code":"ComputeSum <- new_layer_class(   \"ComputeSum\",   initialize = function(input_dim) {     super$initialize()     # Create a non-trainable weight.     self$total <- self$add_weight(       initializer = \"zeros\",       shape = shape(input_dim),       trainable = FALSE     )   },   call = function(inputs) {     self$total$assign_add(tf$reduce_sum(inputs, axis=0L))     self$total   } )  my_sum <- ComputeSum(input_dim = 2) x <- tf$ones(shape(2, 2))  as.array(my_sum(x)) ## [1] 2 2 as.array(my_sum(x)) ## [1] 4 4 my_sum$trainable_weights ## list()"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"layers-that-own-layers","dir":"Articles","previous_headings":"","what":"Layers that own layers","title":"Introduction to Keras for Researchers","text":"Layers can recursively nested create bigger computation blocks. layer track weights sublayers (trainable non-trainable). Note manually-created MLP equivalent following built-option:","code":"# Let's reuse the Linear class # with a `build` method that we defined above.  MLP <- new_layer_class(   \"MLP\",   initialize = function() {     super$initialize()     self$linear_1 <- Linear(units = 32)     self$linear_2 <- Linear(units = 32)     self$linear_3 <- Linear(units = 10)   },   call = function(inputs) {     x <- self$linear_1(inputs)     x <- tf$nn$relu(x)     x <- self$linear_2(x)     x <- tf$nn$relu(x)     return(self$linear_3(x))   } )  mlp <- MLP()  # The first call to the `mlp` object will create the weights. y <- mlp(tf$ones(shape=shape(3, 64)))  # Weights are recursively tracked. length(mlp$weights) ## [1] 6 mlp <- keras_model_sequential() %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 10)"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"tracking-losses-created-by-layers","dir":"Articles","previous_headings":"","what":"Tracking losses created by layers","title":"Introduction to Keras for Researchers","text":"Layers can create losses forward pass via add_loss() method. especially useful regularization losses. losses created sublayers recursively tracked parent layers. ’s layer creates activity regularization loss: model incorporating layer track regularization loss: losses cleared top-level layer start forward pass – don’t accumulate. layer.losses always contains losses created last forward pass. typically use losses summing computing gradients writing training loop.","code":"# A layer that creates an activity sparsity regularization loss ActivityRegularization <- new_layer_class(   \"ActivityRegularization\",   initialize = function(rate=1e-2) {     super$initialize()     self$rate <- rate   },   call = function(inputs) {     self$add_loss(self$rate * tf$reduce_sum(tf$abs(inputs)))     inputs   } ) # Let's use the loss layer in a MLP block. SparseMLP <- new_layer_class(   \"SparseMLP\",   initialize = function() {     super$initialize()     self$linear_1 <- Linear(units = 32)     self$reg <- ActivityRegularization(rate = 1e-2)     self$linear_3 <- Linear(units = 10)   },   call = function(inputs) {     x <- self$linear_1(inputs)     x <- tf$nn$relu(x)     x <- self$reg(x)     return(self$linear_3(x))   } )  mlp <- SparseMLP() y <- mlp(tf$ones(shape(10, 10)))  mlp$losses  # List containing one float32 scalar ## [[1]] ## tf.Tensor(0.18065463, shape=(), dtype=float32) # Losses correspond to the *last* forward pass. mlp <- SparseMLP() mlp(tf$ones(shape(10, 10))) ## tf.Tensor( ## [[ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621]], shape=(10, 10), dtype=float32) length(mlp$losses) ## [1] 1 mlp(tf$ones(shape(10, 10))) ## tf.Tensor( ## [[ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621] ##  [ 0.0388482  -0.03920118  0.01624808 -0.01361975 -0.01354899  0.07107338 ##   -0.01077365  0.05688906 -0.02838149 -0.04084621]], shape=(10, 10), dtype=float32) length(mlp$losses)  # No accumulation. ## [1] 1 # Let's demonstrate how to use these losses in a training loop.  # Prepare a dataset. c(c(x_train, y_train), .) %<-% dataset_mnist() x_train <- array_reshape(x_train, c(60000, 784)) / 255  dataset <- tfdatasets::tensor_slices_dataset(list(x_train, y_train)) %>%   tfdatasets::dataset_shuffle(buffer_size=1024) %>%   tfdatasets::dataset_batch(64)  # A new MLP. mlp <- SparseMLP()  # Loss and optimizer. loss_fn <- loss_sparse_categorical_crossentropy(from_logits=TRUE) optimizer <- optimizer_sgd(learning_rate=1e-3)  coro::loop(for(data in dataset) {   x <- data[[1]]   y <- data[[2]]   with(tf$GradientTape() %as% tape, {     # Forward pass.     logits <- mlp(x)      # External loss value for this batch.     loss <- loss_fn(y, logits)      # Add the losses created during the forward pass.     loss <- loss + Reduce(`+`, mlp$losses)      # Get gradients of the loss wrt the weights.     gradients <- tape$gradient(loss, mlp$trainable_weights)      # Update the weights of our linear layer.     optimizer$apply_gradients(zip_lists(gradients, mlp$trainable_weights))   }) })"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"keeping-track-of-training-metrics","dir":"Articles","previous_headings":"","what":"Keeping track of training metrics","title":"Introduction to Keras for Researchers","text":"Keras offers broad range built-metrics, like metric_auc metric_precision_at_recall. ’s also easy create metrics lines code. use metric custom training loop, : Instantiate metric object, e.g. metric = metric_auc() Call metric$udpate_state(targets, predictions) method batch data Query result via metric$result() Reset metric’s state end epoch start evaluation via metric$reset_state() ’s simple example: can also define metrics subclassing keras.metrics.Metric. need override three functions called : Override update_state() update statistic values. Override result() return metric value. Override reset_state() reset metric initial state. example implement F1-score metric (support sample weighting). Let’s test-drive :","code":"# Instantiate a metric object accuracy <- metric_sparse_categorical_accuracy()  # Prepare our layer, loss, and optimizer. model <- keras_model_sequential() %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 10) loss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE) optimizer <- optimizer_adam(learning_rate=1e-3)  for (epoch in seq_len(2)) {   coro::loop(for (data in dataset) {     x <- data[[1]]     y <- data[[2]]     with(tf$GradientTape() %as% tape, {       # Forward pass.       logits <- model(x)        # External loss value for this batch.       loss_value <- loss_fn(y, logits)     })      # Update the state of the `accuracy` metric.     accuracy$update_state(y, logits)      # Update the weights of the model to minimize the loss value.     gradients <- tape$gradient(loss_value, model$trainable_weights)     optimizer$apply_gradients(zip_lists(gradients, model$trainable_weights))    })   cat(\"Epoch:\", epoch, \"Accuracy:\", as.numeric(accuracy$result()), \"\\n\")   accuracy$reset_state() } ## Epoch: 1 Accuracy: 0.8757833 ## Epoch: 2 Accuracy: 0.93915 F1Score <- new_metric_class(   \"F1Score\",   initialize = function(self, name=\"f1_score\", dtype=\"float32\", threshold=0.5, ...) {     super$initialize(name=name, dtype=dtype, ...)     self$threshold <- threshold     self$true_positives <- self$add_weight(       name=\"tp\", dtype=dtype, initializer=\"zeros\"     )     self$false_positives <- self$add_weight(       name=\"fp\", dtype=dtype, initializer=\"zeros\"     )     self$false_negatives <- self$add_weight(       name=\"fn\", dtype=dtype, initializer=\"zeros\"     )   },   update_state = function(y_true, y_pred, sample_weight=NULL) {     y_pred <- tf$math$greater_equal(y_pred, self$threshold)     y_true <- tf$cast(y_true, tf$bool)     y_pred <- tf$cast(y_pred, tf$bool)      true_positives <- tf$cast(y_true & y_pred, self$dtype)     false_positives <- tf$cast((!y_true) & y_pred, self$dtype)     false_negatives <- tf$cast(y_true & (!y_pred), self$dtype)      if (!is.null(sample_weight)) {       sample_weight <- tf$cast(sample_weight, self$dtype)       true_positives <- true_positives * sample_weight       false_positives <- false_positives * sample_weight       false_negatives <- false_negatives * sample_weight     }      self$true_positives$assign_add(tf$reduce_sum(true_positives))     self$false_positives$assign_add(tf$reduce_sum(false_positives))     self$false_negatives$assign_add(tf$reduce_sum(false_negatives))   },    result = function() {     precision <- self$true_positives / (self$true_positives + self$false_positives)     recall <- self$true_positives / (self$true_positives + self$false_negatives)     f1_score <- 2 * precision * recall / (precision + recall)     f1_score   },    reset_state = function() {     self$true_positives$assign(0)     self$false_positives$assign(0)     self$false_negatives$assign(0)   } ) m <- F1Score() m$update_state(c(0, 1, 0, 0), c(0.3, 0.5, 0.8, 0.9)) cat(\"Intermediate result:\", as.numeric(m$result()), \"\\n\") ## Intermediate result: 0.5 m$update_state(c(1, 1, 1, 1), c(0.1, 0.7, 0.6, 0.0)) cat(\"Final result:\", as.numeric(m$result()), \"\\n\") ## Final result: 0.6"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"compiled-functions","dir":"Articles","previous_headings":"","what":"Compiled functions","title":"Introduction to Keras for Researchers","text":"Running eagerly great debugging, get better performance compiling computation static graphs. Static graphs researcher’s best friends. can compile function wrapping tf.function decorator.","code":"# Prepare our layer, loss, and optimizer. model <- keras_model_sequential() %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 10) loss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE) optimizer <- optimizer_adam(learning_rate=1e-3)  # Create a training step function. train_on_batch <- tf_function(function(x, y) {   with(tf$GradientTape() %as% tape, {     # Forward pass.     logits <- model(x)     # External loss value for this batch.     loss_value <- loss_fn(y, logits)   })   # Update the weights of the model to minimize the loss value.   gradients <- tape$gradient(loss_value, model$trainable_weights)   optimizer$apply_gradients(zip_lists(gradients, model$trainable_weights))   loss_value })   # Prepare a dataset. c(c(x_train, y_train), .) %<-% dataset_mnist() x_train <- array_reshape(x_train, c(60000, 784)) / 255  dataset <- tfdatasets::tensor_slices_dataset(list(x_train, y_train)) %>%   tfdatasets::dataset_shuffle(buffer_size=1024) %>%   tfdatasets::dataset_batch(64)  i <- 0 coro::loop(for (data in dataset) {   i <- i + 1   x <- data[[1]]   y <- data[[2]]   loss <- train_on_batch(x, y)   if (i %% 100 == 0)     cat(\"Loss:\", as.numeric(loss), \"\\n\") }) ## Loss: 0.551749 ## Loss: 0.2131135 ## Loss: 0.2765952 ## Loss: 0.1296219 ## Loss: 0.2657076 ## Loss: 0.2683381 ## Loss: 0.1570166 ## Loss: 0.3139241 ## Loss: 0.08981849"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"training-mode-inference-mode","dir":"Articles","previous_headings":"","what":"Training mode & inference mode","title":"Introduction to Keras for Researchers","text":"layers, particular BatchNormalization layer Dropout layer, different behaviors training inference. layers, standard practice expose training (boolean) argument call method. exposing argument call, enable built-training evaluation loops (e.g. fit) correctly use layer training inference modes.","code":"Dropout <- new_layer_class(   \"Dropout\",   initialize = function(rate) {     super$initialize()     self$rate <- rate   },   call = function(inputs, training = NULL) {     if (!is.null(training) && training) {       return(tf$nn$dropout(inputs, rate = self$rate))     }     inputs   } )  MLPWithDropout <- new_layer_class(   \"MLPWithDropout\",   initialize = function() {     super$initialize()     self$linear_1 <- Linear(units = 32)     self$dropout <- Dropout(rate = 0.5)     self$linear_3 <- Linear(units = 10)   },   call = function(inputs, training = NULL) {     x <- self$linear_1(inputs)     x <- tf$nn$relu(x)     x <- self$dropout(x, training = training)     self$linear_3(x)   } )  mlp <- MLPWithDropout() y_train <- mlp(tf$ones(shape(2, 2)), training=TRUE) y_test <- mlp(tf$ones(shape(2, 2)), training=FALSE)"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"the-functional-api-for-model-building","dir":"Articles","previous_headings":"","what":"The Functional API for model-building","title":"Introduction to Keras for Researchers","text":"build deep learning models, don’t use object-oriented programming time. layers ’ve seen far can also composed functionally, like (call “Functional API”): Functional API tends concise subclassing, provides advantages (generally advantages functional, typed languages provide untyped OO development). However, can used define DAGs layers – recursive networks defined Layer subclasses instead. Learn Functional API . research workflows, may often find mix--matching OO models Functional models. Note Model class also features built-training & evaluation loops: fit(), predict() evaluate() (configured via compile() method). built-functions give access following built-training infrastructure features: Callbacks. can leverage built-callbacks early-stopping, model checkpointing, monitoring training TensorBoard. can also implement custom callbacks needed. Distributed training. can easily scale training multiple GPUs, TPU, even multiple machines tf.distribute API – changes code. Step fusing. steps_per_execution argument Model.compile(), can process multiple batches single tf.function call, greatly improves device utilization TPUs. won’t go details, provide simple code example . leverages built-training infrastructure implement MNIST example . can always subclass Model class (works exactly like subclassing Layer) want leverage built-training loops OO models. Just override Model$train_step() customize happens fit() retaining support built-infrastructure features outlined – callbacks, zero-code distribution support, step fusing support. may also override test_step() customize happens evaluate(), override predict_step() customize happens predict(). information, please refer guide.","code":"# We use an `Input` object to describe the shape and dtype of the inputs. # This is the deep learning equivalent of *declaring a type*. # The shape argument is per-sample; it does not include the batch size. # The functional API focused on defining per-sample transformations. # The model we create will automatically batch the per-sample transformations, # so that it can be called on batches of data. inputs <- layer_input(shape = 16, dtype = \"float32\")  # We call layers on these \"type\" objects # and they return updated types (new shapes/dtypes). outputs <- inputs %>%   Linear(units = 32) %>% # We are reusing the Linear layer we defined earlier.   Dropout(rate = 0.5) %>% # We are reusing the Dropout layer we defined earlier.   Linear(units = 10)  # A functional `Model` can be defined by specifying inputs and outputs. # A model is itself a layer like any other. model <- keras_model(inputs, outputs)  # A functional model already has weights, before being called on any data. # That's because we defined its input shape in advance (in `Input`). length(model$weights) ## [1] 4 # Let's call our model on some data, for fun. y <- model(tf$ones(shape(2, 16))) y$shape ## TensorShape([2, 10]) # You can pass a `training` argument in `__call__` # (it will get passed down to the Dropout layer). y <- model(tf$ones(shape(2, 16)), training=TRUE) inputs <- layer_input(shape = 784, dtype=\"float32\") outputs <- inputs %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 10) model <- keras_model(inputs, outputs)  # Specify the loss, optimizer, and metrics with `compile()`. model %>% compile(     loss = loss_sparse_categorical_crossentropy(from_logits=TRUE),     optimizer=optimizer_adam(learning_rate=1e-3),     metrics=list(metric_sparse_categorical_accuracy()), )  # Train the model with the dataset for 2 epochs. model %>% fit(dataset, epochs=2) ## Epoch 1/2 ## 938/938 - 4s - 4ms/step - loss: 0.3958 - sparse_categorical_accuracy: 0.8866 ## Epoch 2/2 ## 938/938 - 1s - 960us/step - loss: 0.1888 - sparse_categorical_accuracy: 0.9443 predictions <- model %>% predict(dataset) ## 938/938 - 1s - 1ms/step model %>% evaluate(dataset) ## 938/938 - 1s - 1ms/step - loss: 0.1763 - sparse_categorical_accuracy: 0.9454 ## $loss ## [1] 0.1763445 ## ## $sparse_categorical_accuracy ## [1] 0.9454167 CustomModel <- new_model_class(   \"CustomModel\",   initialize = function(...) {     super$initialize(...)     self$loss_tracker <- metric_mean(name=\"loss\")     self$accuracy <- metric_sparse_categorical_accuracy()     self$loss_fn <- loss_sparse_categorical_crossentropy(from_logits=TRUE)     self$optimizer <- optimizer_adam(learning_rate=1e-3)   },   train_step = function(data) {     c(x, y, sample_weight) %<-% unpack_x_y_sample_weight(data)     with(tf$GradientTape() %as% tape, {       y_pred <- self(x, training=TRUE)       loss <- self$loss_fn(y = y, y_pred = y_pred, sample_weight=sample_weight)     })     gradients <- tape$gradient(loss, self$trainable_variables)     self$optimizer$apply_gradients(       zip_lists(gradients, self$trainable_variables)     )      # Update metrics (includes the metric that tracks the loss)     self$loss_tracker$update_state(loss)     self$accuracy$update_state(y, y_pred, sample_weight=sample_weight)     # Return a list mapping metric names to current value     list(       loss = self$loss_tracker$result(),       accuracy = self$accuracy$result()     )   },   metrics = mark_active(function() {     list(self$loss_tracker, self$accuracy)   }) )  inputs <- layer_input(shape = 784, dtype=\"float32\") outputs <- inputs %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 32, activation = \"relu\") %>%   layer_dense(units = 10) model <- CustomModel(inputs, outputs) model %>% compile() model %>% fit(dataset, epochs=2) ## Epoch 1/2 ## 938/938 - 2s - 2ms/step - loss: 0.3869 - sparse_categorical_accuracy: 0.8924 ## Epoch 2/2 ## 938/938 - 1s - 1ms/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9370"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"end-to-end-experiment-example-1-variational-autoencoders-","dir":"Articles","previous_headings":"","what":"End-to-end experiment example 1: variational autoencoders.","title":"Introduction to Keras for Researchers","text":"things ’ve learned far: Layer encapsulates state (created __init__ build) computation (defined call). Layers can recursively nested create new, bigger computation blocks. can easily write highly hackable training loops opening GradientTape, calling model inside tape’s scope, retrieving gradients applying via optimizer. can speed training loops using @tf.function decorator. Layers can create track losses (typically regularization losses) via self.add_loss(). Let’s put things together end--end example: ’re going implement Variational AutoEncoder (VAE). ’ll train MNIST digits. VAE subclass Layer, built nested composition layers subclass Layer. feature regularization loss (KL divergence). model definition. First, Encoder class, uses Sampling layer map MNIST digit latent-space triplet (z_mean, z_log_var, z). Next, Decoder class, maps probabilistic latent space coordinates back MNIST digit. Finally, VariationalAutoEncoder composes together encoder decoder, creates KL divergence regularization loss via add_loss(). Now, let’s write training loop. training step decorated @tf.function compile super fast graph function. can see, building training type model Keras quick painless.","code":"Sampling <- new_layer_class(   \"Sampling\",   call = function(inputs) {     c(z_mean, z_log_var) %<-% inputs     batch <- op_shape(z_mean)[[1]]     dim <- op_shape(z_mean)[[2]]     epsilon <- random_normal(shape = c(batch, dim))     z_mean + op_exp(0.5 * z_log_var) * epsilon   } )  Encoder <- new_layer_class(   \"Encoder\",   initialize = function(latent_dim = 32, intermediate_dim = 64, ...) {     super$initialize(...)     self$dense_proj <- layer_dense(units = intermediate_dim, activation = \"relu\")     self$dense_mean <- layer_dense(units = latent_dim)     self$dense_log_var <- layer_dense(units = latent_dim)     self$sampling <- Sampling()   },   call = function(inputs) {     x <- self$dense_proj(inputs)     z_mean <- self$dense_mean(x)     z_log_var <- self$dense_log_var(x)     z <- self$sampling(list(z_mean, z_log_var))     list(z_mean, z_log_var, z)   } ) Decoder <- new_layer_class(   \"Decoder\",   initialize = function(original_dim, intermediate_dim = 64, ...) {     super$initialize(...)     self$dense_proj <- layer_dense(units = intermediate_dim, activation = \"relu\")     self$dense_output <- layer_dense(units = original_dim, activation = \"sigmoid\")   },   call = function(inputs) {     x <- self$dense_proj(inputs)     self$dense_output(x)   } ) VariationalAutoEncoder <- new_model_class(   \"VariationalAutoEncoder\",   initialize = function(original_dim,         intermediate_dim=64,         latent_dim=32,         name=\"autoencoder\", ...) {     super$initialize(name = name, ...)     self$original_dim <- original_dim     self$encoder <- Encoder(       latent_dim = latent_dim,       intermediate_dim = intermediate_dim     )     self$decoder <- Decoder(       original_dim = original_dim,       intermediate_dim = intermediate_dim     )   },   call = function(inputs) {     c(z_mean, z_log_var, z) %<-% self$encoder(inputs)     reconstructed <- self$decoder(z)     # Add KL divergence regularization loss.     kl_loss <- -0.5 * op_mean(       z_log_var - op_square(z_mean) - op_exp(z_log_var) + 1     )     self$add_loss(kl_loss)     reconstructed   } ) # Our model. vae <- VariationalAutoEncoder(   original_dim = 784,   intermediate_dim = 64,   latent_dim = 32 )  # Loss and optimizer. loss_fn <- loss_mean_squared_error() optimizer = optimizer_adam(learning_rate=1e-3)  # Prepare a dataset. c(c(x_train, .), .) %<-% dataset_mnist() x_train <- array_reshape(x_train, c(60000, 784)) / 255  dataset <- tfdatasets::tensor_slices_dataset(x_train) %>%   tfdatasets::dataset_shuffle(buffer_size=1024) %>%   tfdatasets::dataset_batch(32)   training_step <- tf_function(function(x) {   with(tf$GradientTape() %as% tape, {     reconstructed <- vae(x)  # Compute input reconstruction.     # Compute loss.     loss <- loss_fn(x, reconstructed)     loss <- loss + op_sum(vae$losses)  # Add KLD term.   })   # Update the weights of the VAE.   grads <- tape$gradient(loss, vae$trainable_weights)   optimizer$apply_gradients(zip_lists(grads, vae$trainable_weights))   loss })  losses <- c()  # Keep track of the losses over time. coro::loop(for(data in dataset) {   loss <- training_step(data)    # Logging.   losses[length(losses) + 1] <- as.numeric(loss)   if (length(losses) %% 100 == 0) {     cat(\"Step:\", length(losses), \"Loss:\", mean(losses), \"\\n\")   }   # Stop after 1000 steps.   # Training the model to convergence is left   # as an exercise to the reader.   if (length(losses) >= 1000) {     break   } }) ## Step: 100 Loss: 0.1270978 ## Step: 200 Loss: 0.1003238 ## Step: 300 Loss: 0.09001128 ## Step: 400 Loss: 0.08493649 ## Step: 500 Loss: 0.08171404 ## Step: 600 Loss: 0.07926706 ## Step: 700 Loss: 0.07790599 ## Step: 800 Loss: 0.07670419 ## Step: 900 Loss: 0.07570736 ## Step: 1000 Loss: 0.07476593"},{"path":"https://keras.posit.co/articles/intro_to_keras_for_researchers.html","id":"end-to-end-experiment-example-2-hypernetworks-","dir":"Articles","previous_headings":"","what":"End-to-end experiment example 2: hypernetworks.","title":"Introduction to Keras for Researchers","text":"Let’s take look another kind research experiment: hypernetworks. idea use small deep neural network (hypernetwork) generate weights larger network (main network). Let’s implement really trivial hypernetwork: ’ll use small 2-layer network generate weights larger 3-layer network. training loop. batch data: use hypernetwork generate array weight coefficients, weights_pred reshape coefficients kernel & bias tensors main_network run forward pass main_network compute actual MNIST predictions run backprop weights hypernetwork minimize final classification loss Implementing arbitrary research ideas Keras straightforward highly productive. Imagine trying 25 ideas per day (20 minutes per experiment average)! Keras designed go idea results fast possible, believe key great research. hope enjoyed quick introduction. Let us know build Keras!","code":"input_dim <- 784 classes <- 10  # This is the main network we'll actually use to predict labels. inputs <- layer_input(shape = input_dim) dense1 <- layer_dense(units = 64, activation = \"relu\") dense1$built <- TRUE  dense2 <- layer_dense(units = classes) dense2$built <- TRUE  outputs <- inputs %>% dense1() %>% dense2() main_network <- keras_model(inputs, outputs)  # This is the number of weight coefficients to generate. Each layer in the # main network requires output_dim * input_dim + output_dim coefficients. num_weights_to_generate <- (classes * 64 + classes) + (64 * input_dim + 64)  # This is the hypernetwork that generates the weights of the `main_network` above. hypernetwork <- keras_model_sequential() %>%   layer_dense(units=16, activation=\"relu\") %>%   layer_dense(units=num_weights_to_generate, activation=\"sigmoid\") # Loss and optimizer. loss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE) optimizer <- optimizer_adam(learning_rate=1e-4)  # Prepare a dataset. c(c(x_train, y_train), .) %<-% dataset_mnist() x_train <- array_reshape(x_train, c(60000, 784)) / 255  dataset <- tfdatasets::tensor_slices_dataset(list(x_train, y_train)) %>%   tfdatasets::dataset_shuffle(buffer_size=1024) %>%   # We'll use a batch size of 1 for this experiment.   tfdatasets::dataset_batch(1)  train_step <- function(x, y) {   with(tf$GradientTape() %as% tape, {     weights_pred <- hypernetwork(x)      # Reshape them to the expected shapes for w and b for the outer model.     # Layer 1 kernel.     start_index <- 1     w1_shape <- c(input_dim, 64)     w1_coeffs <- weights_pred[, start_index:(start_index + prod(w1_shape) - 1)]     w1 <- tf$reshape(w1_coeffs, as.integer(w1_shape))     start_index <- start_index + prod(w1_shape)      # Layer 1 bias.     b1_shape <- c(64)     b1_coeffs <- weights_pred[, start_index:(start_index + prod(b1_shape) - 1)]     b1 <- tf$reshape(b1_coeffs, as.integer(b1_shape))     start_index <- start_index + prod(b1_shape)      # Layer 2 kernel.     w2_shape <- c(64, classes)     w2_coeffs <- weights_pred[, start_index:(start_index + prod(w2_shape) - 1)]     w2 <- tf$reshape(w2_coeffs, as.integer(w2_shape))     start_index <- start_index + prod(w2_shape)      # Layer 2 bias.     b2_shape <- c(classes)     b2_coeffs <- weights_pred[, start_index:(start_index + prod(b2_shape) - 1)]     b2 <- tf$reshape(b2_coeffs, as.integer(b2_shape))     start_index <- start_index + prod(b2_shape)      # Set the weight predictions as the weight variables on the outer model.     dense1$kernel <- w1     dense1$bias <- b1     dense2$kernel <- w2     dense2$bias <- b2      # Inference on the outer model.     preds <- main_network(x)     loss <- loss_fn(y, preds)   })    grads <- tape$gradient(loss, hypernetwork$trainable_weights)   optimizer$apply_gradients(zip_lists(grads, hypernetwork$trainable_weights))   loss }  losses <- c()  # Keep track of the losses over time. coro::loop(for (data in dataset) {   x <- data[[1]]   y <- data[[2]]   loss <- train_step(x, y)    # Logging.   losses[length(losses) + 1] <- as.numeric(loss)   if (length(losses) %% 100 == 0) {     cat(\"Step:\", length(losses), \"Loss:\", mean(losses), \"\\n\")   }   # Stop after 1000 steps.   # Training the model to convergence is left   # as an exercise to the reader.   if (length(losses) >= 1000) {     break   } }) ## Step: 100 Loss: 2.536778 ## Step: 200 Loss: 2.236472 ## Step: 300 Loss: 2.119417 ## Step: 400 Loss: 2.040341 ## Step: 500 Loss: 1.949125 ## Step: 600 Loss: 1.859384 ## Step: 700 Loss: 1.845726 ## Step: 800 Loss: 1.820594 ## Step: 900 Loss: 1.771334 ## Step: 1000 Loss: 1.730648"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Making new layers and models via subclassing","text":"guide cover everything need know build subclassed layers models. particular, ’ll learn following features: Layer class add_weight() method Trainable non-trainable weights build() method Making sure layers can used backend add_loss() method training argument call() mask argument call() Making sure layers can serialized Let’s dive .","code":""},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Making new layers and models via subclassing","text":"","code":"library(keras3) library(tensorflow, exclude = c(\"set_random_seed\", \"shape\")) library(tfdatasets, exclude = \"shape\")"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"the-layer-class-the-combination-of-state-weights-and-some-computation","dir":"Articles","previous_headings":"","what":"The Layer class: the combination of state (weights) and some computation","title":"Making new layers and models via subclassing","text":"One central abstractions Keras Layer class. layer encapsulates state (layer’s “weights”) transformation inputs outputs (“call”, layer’s forward pass). ’s densely-connected layer. two state variables: variables w b. use layer calling tensor input(s), much like R function. Note weights w b automatically tracked layer upon set layer attributes:","code":"layer_linear <- Layer(\"Linear\",    initialize = function(units = 32, input_dim = 32, ...) {     super$initialize(...)     self$w <- self$add_weight(       shape = shape(input_dim, units),       initializer = \"random_normal\",       trainable = TRUE     )     self$b <- self$add_weight(       shape = shape(units),       initializer = \"zeros\",       trainable = TRUE     )   },    call = function(inputs) {     op_matmul(inputs, self$w) + self$b   } ) x <- op_ones(c(2, 2)) linear_layer <- layer_linear(units = 4, input_dim = 2) y <- linear_layer(x) print(y) ## tf.Tensor( ## [[0.02153057 0.15450525 0.0205495  0.04493225] ##  [0.02153057 0.15450525 0.0205495  0.04493225]], shape=(2, 4), dtype=float32) linear_layer$weights ## [[1]] ## <KerasVariable shape=(2, 4), dtype=float32, path=linear/variable> ## ## [[2]] ## <KerasVariable shape=(4), dtype=float32, path=linear/variable_1>"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"layers-can-have-non-trainable-weights","dir":"Articles","previous_headings":"","what":"Layers can have non-trainable weights","title":"Making new layers and models via subclassing","text":"Besides trainable weights, can add non-trainable weights layer well. weights meant taken account backpropagation, training layer. ’s add use non-trainable weight: ’s part layer$weights, gets categorized non-trainable weight:","code":"layer_compute_sum <- Layer(   \"ComputeSum\",   initialize = function(input_dim) {     super$initialize()     self$total <- self$add_weight(       initializer = \"zeros\",       shape = shape(input_dim),       trainable = FALSE     )   },   call = function(inputs) {     self$total$assign_add(op_sum(inputs, axis = 1))     self$total   } )  x <- op_ones(c(2, 2)) my_sum <- layer_compute_sum(input_dim = 2) y <- my_sum(x) print(as.array(y)) ## [1] 2 2 y <- my_sum(x) print(as.array(y)) ## [1] 4 4 cat(\"weights:\", length(my_sum$weights)) ## weights: 1 cat(\"non-trainable weights:\", length(my_sum$non_trainable_weights)) ## non-trainable weights: 1 # It's not included in the trainable weights: cat(\"trainable_weights:\", length(my_sum$trainable_weights)) ## trainable_weights: 0"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known","dir":"Articles","previous_headings":"","what":"Best practice: deferring weight creation until the shape of the inputs is known","title":"Making new layers and models via subclassing","text":"Linear layer took input_dim argument used compute shape weights w b initialize(): many cases, may know advance size inputs, like lazily create weights value becomes known, time instantiating layer. Keras API, recommend creating layer weights build(self, inputs_shape) method layer. Like : call() method layer automatically run build first time called. now layer ’s lazy thus easier use: Implementing build() separately shown nicely separates creating weights using weights every call.","code":"layer_linear <- Layer(\"Linear\",    initialize = function(units = 32, input_dim = 32, ...) {     super$initialize(...)     self$w <- self$add_weight(       shape = shape(input_dim, units),       initializer = \"random_normal\",       trainable = TRUE     )     self$b <- self$add_weight(       shape = shape(units),       initializer = \"zeros\",       trainable = TRUE     )   },    call = function(inputs) {     op_matmul(inputs, self$w) + self$b   } ) layer_linear <- Layer(   \"Linear\",   initialize = function(units = 32, ...) {     self$units <- as.integer(units)     super$initialize(...)   },   build = function(input_shape) {     self$w <- self$add_weight(       shape = shape(tail(input_shape, 1), self$units),       initializer = \"random_normal\",       trainable = TRUE     )     self$b <- self$add_weight(       shape = shape(self$units),       initializer = \"zeros\",       trainable = TRUE     )   },   call = function(inputs) {     op_matmul(inputs, self$w) + self$b   } ) # At instantiation, we don't know on what inputs this is going to get called linear_layer <- layer_linear(units = 32)  # The layer's weights are created dynamically the first time the layer is called y <- linear_layer(x)"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"layers-are-recursively-composable","dir":"Articles","previous_headings":"","what":"Layers are recursively composable","title":"Making new layers and models via subclassing","text":"assign Layer instance attribute another Layer, outer layer start tracking weights created inner layer. recommend creating sublayers initialize() method leave first call() trigger building weights.","code":"MLPBlock <- Layer(   \"MLPBlock\",   initialize = function() {     super$initialize()     self$linear_1 <- layer_linear(units = 32)     self$linear_2 <- layer_linear(units = 32)     self$linear_3 <- layer_linear(units = 1)   },   call = function(inputs) {     inputs |>       self$linear_1() |>       activation_relu() |>       self$linear_2() |>       activation_relu() |>       self$linear_3()   } )  mlp <- MLPBlock() # The first call to the `mlp` will create the weights y <- mlp(op_ones(shape = c(3, 64)))  cat(\"weights:\", length(mlp$weights), \"\\n\") ## weights: 6 cat(\"trainable weights:\", length(mlp$trainable_weights), \"\\n\") ## trainable weights: 6"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"backend-agnostic-layers-and-backend-specific-layers","dir":"Articles","previous_headings":"","what":"Backend-agnostic layers and backend-specific layers","title":"Making new layers and models via subclassing","text":"long layer uses APIs ops namespace (ie. using functions starting op_), (Keras namespaces activations_*, random_*, layer_*), can used backend – TensorFlow, JAX, PyTorch. layers ’ve seen far guide work Keras backends. ops namespace gives access : NumPy API, e.g. op_matmul, op_sum, op_reshape, op_stack, etc. Neural networks-specific APIs op_softmax, op_conv, op_binary_crossentropy, op_relu, etc. can also use backend-native APIs layers (tf$nn functions), , layer usable backend question. instance, write following JAX-specific layer using jax$numpy: equivalent TensorFlow-specific layer: equivalent PyTorch-specific layer: cross-backend compatibility tremendously useful property, strongly recommend seek always make layers backend-agnostic leveraging Keras APIs.","code":"# keras3::install_keras(backend = c(\"jax\")) jax <- reticulate::import(\"jax\")  Linear <- new_layer_class(   ...   call = function(inputs) {     jax$numpy$matmul(inputs, self$w) + self$b   } ) library(tensorflow)  Linear <- new_layer_class(   ...   call = function(inputs) {     tf$matmul(inputs, self$w) + self$b   } ) torch <- reticulate::import(\"torch\")  Linear <- new_layer_class(   ...   call = function(inputs) {     torch$matmul(inputs, self$w) + self$b   } )"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"the-add_loss-method","dir":"Articles","previous_headings":"","what":"The add_loss() method","title":"Making new layers and models via subclassing","text":"writing call() method layer, can create loss tensors want use later, writing training loop. doable calling self$add_loss(value): losses (including created inner layer) can retrieved via layer$losses. property reset start every call top-level layer, layer$losses always contains loss values created last forward pass. addition, loss property also contains regularization losses created weights inner layer: losses meant taken account writing custom training loops. also work seamlessly fit() (get automatically summed added main loss, ):","code":"# A layer that creates an activity regularization loss layer_activity_regularization <- Layer(   \"ActivityRegularizationLayer\",   initialize = function(rate = 1e-2) {     self$rate <- as.numeric(rate)     super$initialize()   },   call = function(inputs) {     self$add_loss(self$rate * op_mean(inputs))     inputs   } ) layer_outer <- Layer(   \"OuterLayer\",   initialize = function() {     super$initialize()     self$activity_reg <- layer_activity_regularization(rate = 1e-2)   },   call = function(inputs) {     self$activity_reg(inputs)     inputs   } )  layer <- layer_outer() # No losses yet since the layer has never been called cat(\"losses:\", length(layer$losses), \"\\n\") ## losses: 0 x <- layer(op_zeros(c(1, 1))) # We created one loss value cat(\"losses:\", length(layer$losses), \"\\n\") ## losses: 1 # `layer$losses` gets reset at the start of each call x <- layer(op_zeros(c(1, 1))) # This is the loss created during the call above cat(\"losses:\", length(layer$losses), \"\\n\") ## losses: 1 layer_outer_with_kernel_regularizer <- Layer(   \"OuterLayerWithKernelRegularizer\",   initialize = function() {     super$initialize()     self$dense <- layer_dense(units = 32,                               kernel_regularizer = regularizer_l2(1e-3))   },   call = function(inputs) {     self$dense(inputs)   } )  layer <- layer_outer_with_kernel_regularizer() x <- layer(op_zeros(c(1, 1)))  # This is `1e-3 * sum(layer$dense$kernel ** 2)`, # created by the `kernel_regularizer` above. print(layer$losses) ## [[1]] ## tf.Tensor(0.002025157, shape=(), dtype=float32) inputs <- keras_input(shape = 3) outputs <- inputs |> layer_activity_regularization() model <- keras_model(inputs, outputs)  # If there is a loss passed in `compile`, the regularization # losses get added to it model |> compile(optimizer = \"adam\", loss = \"mse\") model |> fit(random_normal(c(2, 3)), random_normal(c(2, 3)), epochs = 1) ## 1/1 - 0s - 128ms/step - loss: 1.8971 # It's also possible not to pass any loss in `compile`, # since the model already has a loss to minimize, via the `add_loss` # call during the forward pass! model |> compile(optimizer = \"adam\") model |> fit(random_normal(c(2, 3)), random_normal(c(2, 3)), epochs = 1) ## 1/1 - 0s - 77ms/step - loss: -3.3344e-03"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"you-can-optionally-enable-serialization-on-your-layers","dir":"Articles","previous_headings":"","what":"You can optionally enable serialization on your layers","title":"Making new layers and models via subclassing","text":"need custom layers serializable part Functional model, can optionally implement get_config() method: Note initialize() method base Layer class takes keyword arguments, particular name dtype. ’s good practice pass arguments parent class initialize() include layer config: need flexibility deserializing layer config, can also override from_config() class method. base implementation from_config(): learn serialization saving, see complete guide saving serializing models.","code":"layer_linear <- Layer(   \"Linear\",   initialize = function(units = 32) {     self$units <- as.integer(units)     super$initialize()   },   build = function(input_shape) {     self$w <- self$add_weight(       shape = shape(tail(input_shape, 1), self$units),       initializer = \"random_normal\",       trainable = TRUE     )     self$b <- self$add_weight(       shape = shape(self$units),       initializer = \"zeros\",       trainable = TRUE     )   },   call = function(inputs) {     op_matmul(inputs, self$w) + self$b   },   get_config = function() {     list(units = self$units)   } )  # Now you can recreate the layer from its config: layer <- layer_linear(units = 64) config <- get_config(layer) str(config) ## List of 1 ##  $ units: int 64 ##  - attr(*, \"__class__\")=<class '<r-globalenv>.Linear'> new_layer <- from_config(config) Linear <- new_layer_class(   \"Linear\",   initialize = function(units = 32, ...) {     self$units <- as.integer(units)     super$initialize(...)   },   build = function(input_shape) {     self$w <- self$add_weight(       shape = shape(tail(input_shape, 1), self$units),       initializer = \"random_normal\",       trainable = TRUE     )     self$b <- self$add_weight(       shape = shape(self$units),       initializer = \"zeros\",       trainable = TRUE     )   },   call = function(inputs) {     op_matmul(inputs, self$w) + self$b   },   get_config = function() {     list(units = self$units)   } )  layer <- Linear(units = 64) config <- get_config(layer) str(config) ## List of 1 ##  $ units: int 64 ##  - attr(*, \"__class__\")=<class '<r-globalenv>.Linear'> new_layer <- from_config(config) Layer(   ...,   from_config = function(config) {     # calling `__class__`() creates a new instance and calls initialize()     do.call(`__class__`, config)   } )"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"privileged-training-argument-in-the-call-method","dir":"Articles","previous_headings":"","what":"Privileged training argument in the call() method","title":"Making new layers and models via subclassing","text":"layers, particular BatchNormalization layer Dropout layer, different behaviors training inference. layers, standard practice expose training (boolean) argument call() method. exposing argument call(), enable built-training evaluation loops (e.g. fit()) correctly use layer training inference.","code":"layer_custom_dropout <- Layer(   \"CustomDropout\",   initialize = function(rate, ...) {     super$initialize(...)     self$rate <- rate     self$seed_generator <- random_seed_generator(1337)   },   call = function(inputs, training = NULL) {     if (isTRUE(training))       return(random_dropout(inputs, rate = self$rate,                             seed = self.seed_generator))     inputs   } )"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"privileged-mask-argument-in-the-call-method","dir":"Articles","previous_headings":"","what":"Privileged mask argument in the call() method","title":"Making new layers and models via subclassing","text":"privileged argument supported call() mask argument. find Keras RNN layers. mask boolean tensor (one boolean value per timestep input) used skip certain input timesteps processing timeseries data. Keras automatically pass correct mask argument call() layers support , mask generated prior layer. Mask-generating layers Embedding layer configured mask_zero = TRUE, Masking layer.","code":""},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"the-model-class","dir":"Articles","previous_headings":"","what":"The Model class","title":"Making new layers and models via subclassing","text":"general, use Layer class define inner computation blocks, use Model class define outer model – object train. instance, ResNet50 model, several ResNet blocks subclassing Layer, single Model encompassing entire ResNet50 network. Model class API Layer, following differences: exposes built-training, evaluation, prediction loops (fit(), evaluate(), predict()). exposes list inner layers, via model$layers property. exposes saving serialization APIs (save(), save_weights()…) Effectively, Layer class corresponds refer literature “layer” (“convolution layer” “recurrent layer”) “block” (“ResNet block” “Inception block”). Meanwhile, Model class corresponds referred literature “model” (“deep learning model”) “network” (“deep neural network”). ’re wondering, “use Layer class Model class?”, ask : need call fit() ? need call save() ? , go Model. (either class just block bigger system, writing training & saving code ), use Layer. instance, take mini-resnet example , use build Model train fit(), save save_weights():","code":"ResNet <- Model(   \"ResNet\",   initialize = function(num_classes = 1000, ...) {     super$initialize(...)     self$block_1 <- layer_resnet_block()     self$block_2 <- layer_resnet_block()     self$global_pool <- layer_global_average_pooling_2d()     self$classifier <- layer_dense(num_classes)   },   call = function(inputs) {     inputs |>       self$block_1() |>       self$block_2() |>       self$global_pool() |>       self$classifier()   } )  resnet <- ResNet() dataset <- ... resnet |> fit(dataset, epochs=10) resnet |> save_model(\"filepath.keras\")"},{"path":"https://keras.posit.co/articles/making_new_layers_and_models_via_subclassing.html","id":"putting-it-all-together-an-end-to-end-example","dir":"Articles","previous_headings":"","what":"Putting it all together: an end-to-end example","title":"Making new layers and models via subclassing","text":"’s ’ve learned far: Layer encapsulate state (created initialize() build()) computation (defined call()). Layers can recursively nested create new, bigger computation blocks. Layers backend-agnostic long use Keras APIs. can use backend-native APIs (jax$numpy, torch$nn tf$nn), layer usable specific backend. Layers can create track losses (typically regularization losses) via add_loss(). outer container, thing want train, Model. Model just like Layer, added training serialization utilities. Let’s put things together end--end example: ’re going implement Variational AutoEncoder (VAE) backend-agnostic fashion – runs TensorFlow, JAX, PyTorch. ’ll train MNIST digits. VAE subclass Model, built nested composition layers subclass Layer. feature regularization loss (KL divergence). Let’s train MNIST using fit() API:","code":"layer_sampling <- Layer(   \"Sampling\",   initialize = function(...) {     super$initialize(...)     self$seed_generator <- random_seed_generator(1337)   },   call = function(inputs) {     c(z_mean, z_log_var) %<-% inputs     batch <- op_shape(z_mean)[[1]]     dim <- op_shape(z_mean)[[2]]     epsilon <- random_normal(shape = c(batch, dim),                              seed=self$seed_generator)     z_mean + op_exp(0.5 * z_log_var) * epsilon   } )  # Maps MNIST digits to a triplet (z_mean, z_log_var, z). layer_encoder <- Layer(   \"Encoder\",   initialize = function(latent_dim = 32, intermediate_dim = 64, ...) {     super$initialize(...)     self$dense_proj <-       layer_dense(units = intermediate_dim,  activation = \"relu\")     self$dense_mean <- layer_dense(units = latent_dim)     self$dense_log_var <- layer_dense(units = latent_dim)     self$sampling <- layer_sampling()   },   call = function(inputs) {     x <- self$dense_proj(inputs)     z_mean <- self$dense_mean(x)     z_log_var <- self$dense_log_var(x)     z <- self$sampling(list(z_mean, z_log_var))     list(z_mean, z_log_var, z)   } )  # Converts z, the encoded digit vector, back into a readable digit. layer_decoder <- Layer(   \"Decoder\",   initialize = function(original_dim, intermediate_dim = 64, ...) {     super$initialize(...)     self$dense_proj <-       layer_dense(units = intermediate_dim, activation = \"relu\")     self$dense_output <-       layer_dense(units = original_dim, activation = \"sigmoid\")   },   call = function(inputs) {     x <- self$dense_proj(inputs)     self$dense_output(x)   } )  # Combines the encoder and decoder into an end-to-end model for training. VariationalAutoEncoder <- Model(   \"VariationalAutoEncoder\",    initialize = function(original_dim, intermediate_dim = 64, latent_dim = 32,                         name = \"autoencoder\", ...) {     super$initialize(name = name, ...)     self$original_dim <- original_dim     self$encoder <- layer_encoder(latent_dim = latent_dim,                             intermediate_dim = intermediate_dim)     self$decoder <- layer_decoder(original_dim = original_dim,                             intermediate_dim = intermediate_dim)   },    call = function(inputs) {     c(z_mean, z_log_var, z) %<-% self$encoder(inputs)     reconstructed <- self$decoder(z)     # Add KL divergence regularization loss.     kl_loss <- -0.5 * op_mean(z_log_var - op_square(z_mean) - op_exp(z_log_var) + 1)     self$add_loss(kl_loss)     reconstructed   } ) c(c(x_train, .), .) %<-% dataset_mnist() x_train <- x_train |>   op_reshape(c(60000, 784)) |>   op_cast(\"float32\") |>   op_divide(255)  original_dim <- 784 vae <- VariationalAutoEncoder(   original_dim = 784,   intermediate_dim = 64,   latent_dim = 32 )  optimizer <- optimizer_adam(learning_rate = 1e-3) vae |> compile(optimizer, loss = loss_mean_squared_error())  vae |> fit(x_train, x_train, epochs = 2, batch_size = 64) ## Epoch 1/2 ## 938/938 - 5s - 5ms/step - loss: 0.0748 ## Epoch 2/2 ## 938/938 - 1s - 752us/step - loss: 0.0676"},{"path":"https://keras.posit.co/articles/sequential_model.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"The Sequential model","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/sequential_model.html","id":"when-to-use-a-sequential-model","dir":"Articles","previous_headings":"","what":"When to use a Sequential model","title":"The Sequential model","text":"Sequential model appropriate plain stack layers layer exactly one input tensor one output tensor. Schematically, following Sequential model: equivalent function: Sequential model appropriate : model multiple inputs multiple outputs layers multiple inputs multiple outputs need layer sharing want non-linear topology (e.g. residual connection, multi-branch model)","code":"model <- keras_model_sequential() |>   layer_dense(units = 2, activation = \"relu\", name = \"layer1\") |>   layer_dense(units = 3, activation = \"relu\", name = \"layer2\") |>   layer_dense(units = 4, name = \"layer3\")  # Call model on a test input x <- op_ones(c(3, 3)) y <- model(x) # Create 3 layers layer1 <- layer_dense(units = 2, activation=\"relu\", name=\"layer1\") layer2 <- layer_dense(units = 3, activation=\"relu\", name=\"layer2\") layer3 <- layer_dense(units = 4, name=\"layer3\")  # Call layers on a test input x <- op_ones(c(3, 3)) y <- x |> layer1() |> layer2() |> layer3()"},{"path":"https://keras.posit.co/articles/sequential_model.html","id":"creating-a-sequential-model","dir":"Articles","previous_headings":"","what":"Creating a Sequential model","title":"The Sequential model","text":"can create Sequential model piping layers keras_model_sequential() object: passing list layers keras_model_sequential(): layers accessible via layers attribute: can also create Sequential model incrementally: Note ’s also corresponding pop_layer() method remove layers: Sequential model behaves much like stack layers. Also note Sequential constructor accepts name argument, just like layer model Keras. useful annotate TensorBoard graphs semantically meaningful names.","code":"model <- keras_model_sequential() |>   layer_dense(units = 2, activation = \"relu\") |>   layer_dense(units = 3, activation = \"relu\") |>   layer_dense(units = 4) model <- keras_model_sequential(layers = list(   layer_dense(units = 2, activation = \"relu\"),   layer_dense(units = 3, activation = \"relu\"),   layer_dense(units = 4) )) model$layers ## [[1]] ## <Dense name=dense_3, built=False> ## ## [[2]] ## <Dense name=dense_4, built=False> ## ## [[3]] ## <Dense name=dense_5, built=False> model <- keras_model_sequential() model |> layer_dense(units = 2, activation=\"relu\") model |> layer_dense(units = 3, activation=\"relu\") model |> layer_dense(units = 4) model |> pop_layer() length(model$layers)  # 2 ## [1] 2 model <- keras_model_sequential(name = \"my_sequential\") model |> layer_dense(units = 2, activation=\"relu\", name = \"layer1\") model |> layer_dense(units = 3, activation=\"relu\", name = \"layer2\") model |> layer_dense(units = 4, name = \"layer3\")"},{"path":"https://keras.posit.co/articles/sequential_model.html","id":"specifying-the-input-shape-in-advance","dir":"Articles","previous_headings":"","what":"Specifying the input shape in advance","title":"The Sequential model","text":"Generally, layers Keras need know shape inputs order able create weights. create layer like , initially, weights: creates weights first time called input, since shape weights depends shape inputs: Naturally, also applies Sequential models. instantiate Sequential model without input shape, isn’t “built”: weights (calling model$weights results error stating just ). weights created model first sees input data: model “built”, can call summary() method display contents: However, can useful building Sequential model incrementally able display summary model far, including current output shape. case, start model passing input_shape argument model, knows input shape start: Models built predefined input shape like always weights (even seeing data) always defined output shape. general, ’s recommended best practice always specify input shape Sequential model advance know .","code":"layer <- layer_dense(units = 3) layer$weights  # Empty ## list() # Call layer on a test input x <- op_ones(c(1, 4)) y <- layer(x) layer$weights  # Now it has weights, of shape (4, 3) and (3,) ## [[1]] ## <KerasVariable shape=(4, 3), dtype=float32, path=dense_9/kernel> ## ## [[2]] ## <KerasVariable shape=(3), dtype=float32, path=dense_9/bias> model <- keras_model_sequential() |>   layer_dense(units = 2, activation = \"relu\") |>   layer_dense(units = 3, activation = \"relu\") |>   layer_dense(units = 4) # No weights at this stage!  # At this point, you can't do this: # model$weights   # Call the model on a test input x <- op_ones(c(1, 4)) y <- model(x) length(model$weights) ## [1] 6 summary(model) ## Model: \"sequential_4\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ dense_12 (Dense)                │ (1, 2)                 │            10 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_11 (Dense)                │ (1, 3)                 │             9 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_10 (Dense)                │ (1, 4)                 │            16 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 35 (140.00 B) ##  Trainable params: 35 (140.00 B) ##  Non-trainable params: 0 (0.00 B) model <- keras_model_sequential(input_shape = 4) |>   layer_dense(units = 2, activation = \"relu\") summary(model) ## Model: \"sequential_5\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ dense_13 (Dense)                │ (None, 2)              │            10 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 10 (40.00 B) ##  Trainable params: 10 (40.00 B) ##  Non-trainable params: 0 (0.00 B) model$layers ## [[1]] ## <Dense name=dense_13, built=True>"},{"path":"https://keras.posit.co/articles/sequential_model.html","id":"a-common-debugging-workflow-add-layers-summary","dir":"Articles","previous_headings":"","what":"A common debugging workflow: add layers + summary()","title":"The Sequential model","text":"building new Sequential architecture, ’s useful incrementally stack layers |> frequently print model summaries. instance, enables monitor stack Conv2D MaxPooling2D layers downsampling image feature maps: practical, right? Note |> equivalent calling model$add(), modifies model -place, don’t need reassign model symbol step.","code":"model <- keras_model_sequential(input_shape = c(250, 250, 3)) |>   layer_conv_2d(filters = 32, kernel_size = 5, strides = 2, activation = \"relu\") |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\") |>   layer_max_pooling_2d(pool_size = c(3, 3))  # Can you guess what the current output shape is at this point? Probably not. # Let's just print it: summary(model) ## Model: \"sequential_6\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ conv2d_1 (Conv2D)               │ (None, 123, 123, 32)   │         2,432 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 121, 121, 32)   │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 40, 40, 32)     │             0 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 11,680 (45.62 KB) ##  Trainable params: 11,680 (45.62 KB) ##  Non-trainable params: 0 (0.00 B) # The answer was: (40, 40, 32), so we can keep downsampling...  model |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\") |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\") |>   layer_max_pooling_2d(pool_size = 3) |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\") |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\") |>   layer_max_pooling_2d(pool_size = 2)  # And now? summary(model) ## Model: \"sequential_6\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ conv2d_1 (Conv2D)               │ (None, 123, 123, 32)   │         2,432 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 121, 121, 32)   │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d (MaxPooling2D)    │ (None, 40, 40, 32)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_5 (Conv2D)               │ (None, 38, 38, 32)     │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_4 (Conv2D)               │ (None, 36, 36, 32)     │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d_2 (MaxPooling2D)  │ (None, 12, 12, 32)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_3 (Conv2D)               │ (None, 10, 10, 32)     │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_2 (Conv2D)               │ (None, 8, 8, 32)       │         9,248 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ max_pooling2d_1 (MaxPooling2D)  │ (None, 4, 4, 32)       │             0 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 48,672 (190.12 KB) ##  Trainable params: 48,672 (190.12 KB) ##  Non-trainable params: 0 (0.00 B) # Now that we have 4x4 feature maps, time to apply global max pooling. model |>   layer_global_max_pooling_2d()  # Finally, we add a classification layer. model |>   layer_dense(units = 10, activation = \"softmax\")"},{"path":"https://keras.posit.co/articles/sequential_model.html","id":"what-to-do-once-you-have-a-model","dir":"Articles","previous_headings":"","what":"What to do once you have a model","title":"The Sequential model","text":"model architecture ready, want : Train model, evaluate , run inference. See guide training & evaluation built-loops Save model disk restore . See guide serialization & saving.","code":""},{"path":"https://keras.posit.co/articles/sequential_model.html","id":"feature-extraction-with-a-sequential-model","dir":"Articles","previous_headings":"","what":"Feature extraction with a Sequential model","title":"The Sequential model","text":"Sequential model built, behaves like Functional API model. means every layer input output attribute. attributes can used neat things, like quickly creating model extracts outputs intermediate layers Sequential model: ’s similar example extract features one layer:","code":"initial_model <- keras_model_sequential(input_shape = c(250, 250, 3)) |>   layer_conv_2d(filters = 32, kernel_size = 5, strides = 2, activation = \"relu\") |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\") |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\")   feature_extractor <- keras_model(     inputs = initial_model$inputs,     outputs = lapply(initial_model$layers, function(x) x$output), )  # Call feature extractor on test input. x <- op_ones(c(1, 250, 250, 3)) features <- feature_extractor(x) initial_model <-   keras_model_sequential(input_shape = c(250, 250, 3)) |>   layer_conv_2d(filters = 32, kernel_size = 5, strides = 2,                 activation = \"relu\") |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\",                 name = \"my_intermediate_layer\") |>   layer_conv_2d(filters = 32, kernel_size = 3, activation = \"relu\")  feature_extractor <- keras_model(   inputs = initial_model$inputs,   outputs = get_layer(initial_model, \"my_intermediate_layer\")$output, )  # Call feature extractor on test input. x <- op_ones(c(1, 250, 250, 3)) features <- feature_extractor(x)"},{"path":"https://keras.posit.co/articles/sequential_model.html","id":"transfer-learning-with-a-sequential-model","dir":"Articles","previous_headings":"","what":"Transfer learning with a Sequential model","title":"The Sequential model","text":"Transfer learning consists freezing bottom layers model training top layers. aren’t familiar , make sure read guide transfer learning. two common transfer learning blueprint involving Sequential models. First, let’s say Sequential model, want freeze layers except last one. case, can call freeze_weights(). Alternatively, can iterate model$layers set layer$trainable <- FALSE layer, except last one. Like : Another common blueprint use Sequential model stack pre-trained model freshly initialized classification layers. Like : transfer learning, probably find frequently using two patterns. ’s need know Sequential models! find building models Keras, see: Guide Functional API Guide making new Layers & Models via subclassing","code":"model <- keras_model_sequential(input_shape = 784) |>   layer_dense(units = 32, activation = \"relu\") |>   layer_dense(units = 32, activation = \"relu\") |>   layer_dense(units = 32, activation = \"relu\") |>   layer_dense(units = 10) # Presumably you would want to first load pre-trained weights. model |> load_model_weights(...) # Freeze all layers except the last one. model |> freeze_weights(from = 1, to = -2) model # note the \"Trainable\" column now visible in the summary table ## Model: \"sequential_9\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓ ## ┃ Layer (type)                ┃ Output Shape          ┃    Param # ┃ Trai… ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩ ## │ dense_18 (Dense)            │ (None, 32)            │     25,120 │   N   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ dense_17 (Dense)            │ (None, 32)            │      1,056 │   N   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ dense_16 (Dense)            │ (None, 32)            │      1,056 │   N   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ dense_15 (Dense)            │ (None, 10)            │        330 │   Y   │ ## └─────────────────────────────┴───────────────────────┴────────────┴───────┘ ##  Total params: 27,562 (107.66 KB) ##  Trainable params: 330 (1.29 KB) ##  Non-trainable params: 27,232 (106.38 KB) # Another way to freeze all layers except the last one. for (layer in model$layers[-length(model$layers)]) {   layer$trainable <- FALSE }  # Recompile and train (this will only update the weights of the last layer). model |> compile(...) model |> fit(...) # Load a convolutional base with pre-trained weights base_model <- application_xception(weights = 'imagenet',                                    include_top = FALSE,                                    pooling = 'avg')  # Freeze the base model freeze_weights(base_model)  # Use a Sequential model to add a trainable classifier on top model <- keras_model_sequential() |>   base_model() |>   layer_dense(1000) # Compile & train model |> compile(...) model |> fit(...)"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Save, serialize, and export models","text":"Keras model consists multiple components: architecture, configuration, specifies layers model contain, ’re connected. set weights values (“state model”). optimizer (defined compiling model). set losses metrics (defined compiling model). Keras API saves pieces together unified format, marked .keras extension. zip archive consisting following: JSON-based configuration file (config.json): Records model, layer, trackables’ configuration. H5-based state file, model.weights.h5 (whole model), directory keys layers weights. metadata file JSON, storing things current Keras version. Let’s take look works.","code":""},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"how-to-save-and-load-a-model","dir":"Articles","previous_headings":"","what":"How to save and load a model","title":"Save, serialize, and export models","text":"10 seconds read guide, ’s need know. Saving Keras model: Loading model back: Now, let’s look details.","code":"# Get model (Sequential, Functional Model, or Model subclass) model <- ...  # The filename needs to end with the .keras extension model |> save_model('path/to/location.keras') model <- load_model('path/to/location.keras')"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Save, serialize, and export models","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"saving","dir":"Articles","previous_headings":"","what":"Saving","title":"Save, serialize, and export models","text":"section saving entire model single file. file include: model’s architecture/config model’s weight values (learned training) model’s compilation information (compile() called) optimizer state, (enables restart training left)","code":""},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"apis","dir":"Articles","previous_headings":"Saving","what":"APIs","title":"Save, serialize, and export models","text":"can save model save_model(). can load back load_model(). supported format Keras 3 “Keras v3” format, uses .keras extension. Example:","code":"get_model <- function() {   # Create a simple model.   inputs <- keras_input(shape(32))   outputs <- inputs |> layer_dense(1)   model <-  keras_model(inputs, outputs)   model |> compile(optimizer = optimizer_adam(), loss = \"mean_squared_error\")   model }  model <- get_model()  # Train the model. test_input <- random_uniform(c(128, 32)) test_target <- random_uniform(c(128, 1)) model |> fit(test_input, test_target)  # Calling `save('my_model.keras')` creates a zip archive `my_model.keras`. model |> save_model(\"my_model.keras\")  # It can be used to reconstruct the model identically. reconstructed_model <- load_model(\"my_model.keras\")  # Let's check: stopifnot(all.equal(   model |> predict(test_input),   reconstructed_model |> predict(test_input) ))"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"custom-objects","dir":"Articles","previous_headings":"Saving","what":"Custom objects","title":"Save, serialize, and export models","text":"section covers basic workflows handling custom layers, functions, models Keras saving reloading. saving model includes custom objects, subclassed Layer, must define get_config() method object class. arguments passed constructor (initialize() method) custom object aren’t simple objects (anything types like ints, strings, etc.), must also explicitly deserialize arguments from_config() class method. Like : Please see Defining config methods section details examples. saved .keras file lightweight store Python code custom objects. Therefore, reload model, load_model requires access definition custom objects used one following methods: Registering custom objects (preferred), Passing custom objects directly loading, Using custom object scope examples workflow:","code":"layer_custom <- Layer(   \"CustomLayer\",   initialize = function(sublayer, ...) {     super$initialize(...)     self$sublayer <- layer   },   call = function(x) {     self$sublayer(x)   },   get_config = function() {     base_config <- super$get_config()     config <- list(       sublayer = serialize_keras_object(self$sublayer)     )     c(base_config, config)   },   from_config = function(cls, config) {     sublayer_config <- config$sublayer     sublayer <- deserialize_keras_object(sublayer_config)     cls(sublayer, !!!config)   } )"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"registering-custom-objects-preferred","dir":"Articles","previous_headings":"Saving > Custom objects","what":"Registering custom objects (preferred)","title":"Save, serialize, and export models","text":"preferred method, custom object registration greatly simplifies saving loading code. Calling register_keras_serializable() custom object registers object globally master list, allowing Keras recognize object loading model. Let’s create custom model involving custom layer custom activation function demonstrate . Example:","code":"# Clear all previously registered custom objects set_custom_objects(clear = TRUE) ## named list() layer_custom <- Layer(   \"CustomLayer\",   initialize = function(self, factor) {     super$initialize()     self$factor = factor   },    call = function(self, x) {     x * self$factor   },    get_config = function(self) {     list(factor = self$factor)   } )  # Upon registration, you can optionally specify a package or a name. # If left blank, the package defaults to \"Custom\" and the name defaults to # the class name. register_keras_serializable(layer_custom, package = \"MyLayers\")  custom_fn <- keras3:::py_func2(function(x) x^2, name = \"custom_fn\", convert = TRUE)  register_keras_serializable(custom_fn, name=\"custom_fn\", package=\"my_package\")   # Create the model. get_model <- function() {   inputs <- keras_input(shape(4))   mid <- inputs |> layer_custom(0.5)   outputs <- mid |> layer_dense(1, activation = custom_fn)   model <- keras_model(inputs, outputs)   model |> compile(optimizer = \"rmsprop\", loss = \"mean_squared_error\")   model }   # Train the model. train_model <- function(model) {   input <- random_uniform(c(4, 4))   target <- random_uniform(c(4, 1))   model |> fit(input, target, verbose = FALSE, epochs = 1)   model }  test_input <- random_uniform(c(4, 4)) test_target <- random_uniform(c(4, 1))  model <- get_model() |> train_model() model |> save_model(\"custom_model.keras\", overwrite = TRUE)  # Now, we can simply load without worrying about our custom objects. reconstructed_model <- load_model(\"custom_model.keras\")  # Let's check: stopifnot(all.equal(   model |> predict(test_input, verbose = FALSE),   reconstructed_model |> predict(test_input, verbose = FALSE) ))"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"passing-custom-objects-to-load_model","dir":"Articles","previous_headings":"Saving > Custom objects","what":"Passing custom objects to load_model()","title":"Save, serialize, and export models","text":"","code":"model <- get_model() |> train_model()  # Calling `save_model('my_model.keras')` creates a zip archive `my_model.keras`. model |> save_model(\"custom_model.keras\", overwrite = TRUE)  # Upon loading, pass a named list containing the custom objects used in the # `custom_objects` argument of `load_model()`. reconstructed_model <-  load_model(   \"custom_model.keras\",   custom_objects = list(CustomLayer = layer_custom,                         custom_fn = custom_fn), )  # Let's check: stopifnot(all.equal(   model |> predict(test_input, verbose = FALSE),   reconstructed_model |> predict(test_input, verbose = FALSE) ))"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"using-a-custom-object-scope","dir":"Articles","previous_headings":"Saving > Custom objects","what":"Using a custom object scope","title":"Save, serialize, and export models","text":"code within custom object scope able recognize custom objects passed scope argument. Therefore, loading model within scope allow loading custom objects. Example:","code":"model <- get_model() |> train_model() model |> save_model(\"custom_model.keras\", overwrite = TRUE)  # Pass the custom objects dictionary to a custom object scope and place # the `keras.models.load_model()` call within the scope. custom_objects <- list(CustomLayer = layer_custom, custom_fn = custom_fn)  with_custom_object_scope(custom_objects, {   reconstructed_model <- load_model(\"custom_model.keras\") })  # Let's check: stopifnot(all.equal(   model |> predict(test_input, verbose = FALSE),   reconstructed_model |> predict(test_input, verbose = FALSE) ))"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"model-serialization","dir":"Articles","previous_headings":"Saving","what":"Model serialization","title":"Save, serialize, and export models","text":"section saving model’s configuration, without state. model’s configuration (architecture) specifies layers model contains, layers connected. configuration model, model can created freshly initialized state (weights compilation information).","code":""},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"apis-1","dir":"Articles","previous_headings":"Saving > Model serialization","what":"APIs","title":"Save, serialize, and export models","text":"following serialization APIs available: clone_model(model): make (randomly initialized) copy model. get_config() cls.from_config(): retrieve configuration layer model, recreate model instance config, respectively. keras.models.model_to_json() keras.models.model_from_json(): similar, JSON strings. keras.saving.serialize_keras_object(): retrieve configuration arbitrary Keras object. keras.saving.deserialize_keras_object(): recreate object instance configuration.","code":""},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"in-memory-model-cloning","dir":"Articles","previous_headings":"Saving > Model serialization","what":"In-memory model cloning","title":"Save, serialize, and export models","text":"can -memory cloning model via clone_model(). equivalent getting config recreating model config (preserve compilation information layer weights values). Example:","code":"new_model <- clone_model(model)"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"get_config-and-from_config","dir":"Articles","previous_headings":"Saving > Model serialization","what":"get_config() and from_config()","title":"Save, serialize, and export models","text":"Calling get_config(model) get_config(layer) return named list containing configuration model layer, respectively. define get_config() contain arguments needed initialize() method model layer. loading time, from_config(config) method call initialize() arguments reconstruct model layer. Layer example: Now let’s reconstruct layer using from_config() method: Sequential model example: Functional model example:","code":"layer <- layer_dense(, 3, activation=\"relu\") layer_config <- get_config(layer) str(layer_config) ## List of 12 ##  $ name              : chr \"dense_4\" ##  $ trainable         : logi TRUE ##  $ dtype             : chr \"float32\" ##  $ units             : int 3 ##  $ activation        : chr \"relu\" ##  $ use_bias          : logi TRUE ##  $ kernel_initializer:List of 4 ##   ..$ module         : chr \"keras.initializers\" ##   ..$ class_name     : chr \"GlorotUniform\" ##   ..$ config         :List of 1 ##   .. ..$ seed: NULL ##   ..$ registered_name: NULL ##  $ bias_initializer  :List of 4 ##   ..$ module         : chr \"keras.initializers\" ##   ..$ class_name     : chr \"Zeros\" ##   ..$ config         : Named list() ##   ..$ registered_name: NULL ##  $ kernel_regularizer: NULL ##  $ bias_regularizer  : NULL ##  $ kernel_constraint : NULL ##  $ bias_constraint   : NULL ##  - attr(*, \"__class__\")=<class 'keras.src.layers.core.dense.Dense'> new_layer <- from_config(layer_config) model <- keras_model_sequential(input_shape = c(32)) |>   layer_dense(1) config <- get_config(model) new_model <- from_config(config) inputs <- keras_input(c(32)) outputs <- inputs |> layer_dense(1) model <- keras_model(inputs, outputs) config <- get_config(model) new_model <- from_config(config)"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"save_model_config-and-load_model_config","dir":"Articles","previous_headings":"Saving > Model serialization","what":"save_model_config() and load_model_config()","title":"Save, serialize, and export models","text":"similar get_config / from_config, except turns model JSON file, can loaded without original model class. also specific models, isn’t meant layers. Example:","code":"model <- keras_model_sequential(input_shape = c(32)) |>   layer_dense(1) save_model_config(model, \"model_config.json\") new_model <- load_model_config(\"model_config.json\") unlink(\"model_config.json\")"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"arbitrary-object-serialization-and-deserialization","dir":"Articles","previous_headings":"Saving > Model serialization","what":"Arbitrary object serialization and deserialization","title":"Save, serialize, and export models","text":"serialize_keras_object() deserialize_keras_object() APIs general-purpose APIs can used serialize deserialize Keras object custom object. foundation saving model architecture behind serialize()/deserialize() calls keras. Example: Note serialization format containing necessary information proper reconstruction: module containing name Keras module identifying module object comes class_name containing name object’s class. config information needed reconstruct object registered_name custom objects. See . Now can reconstruct regularizer.","code":"my_reg <- regularizer_l1(0.005) config <- serialize_keras_object(my_reg) str(config) ## List of 4 ##  $ module         : chr \"keras.regularizers\" ##  $ class_name     : chr \"L1\" ##  $ config         :List of 1 ##   ..$ l1: num 0.005 ##  $ registered_name: NULL new_reg <- deserialize_keras_object(config) new_reg ## <keras.src.regularizers.regularizers.L1 object>"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"model-weights-saving","dir":"Articles","previous_headings":"Saving","what":"Model weights saving","title":"Save, serialize, and export models","text":"can choose save & load model’s weights. can useful : need model inference: case won’t need restart training, don’t need compilation information optimizer state. transfer learning: case training new model reusing state prior model, don’t need compilation information prior model.","code":""},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"apis-for-in-memory-weight-transfer","dir":"Articles","previous_headings":"Saving > Model weights saving","what":"APIs for in-memory weight transfer","title":"Save, serialize, and export models","text":"Weights can copied different objects using get_weights() set_weights(): get_weights(<layer>): Returns list arrays weight values. set_weights(<layer>weights): Sets model/layer weights values provided (arrays). Examples: Transferring weights one layer another, memory Transferring weights one model another model compatible architecture, memory case stateless layers stateless layers change order number weights, models can compatible architectures even extra/missing stateless layers.","code":"create_layer <- function() {   layer <- layer_dense(, 64, activation = \"relu\", name = \"dense_2\")   layer$build(shape(NA, 784))   layer }  layer_1 <- create_layer() layer_2 <- create_layer()  # Copy weights from layer 1 to layer 2 layer_2 |> set_weights(get_weights(layer_1)) # Create a simple functional model inputs <- keras_input(shape=c(784), name=\"digits\") outputs <- inputs |>   layer_dense(64, activation = \"relu\", name = \"dense_1\") |>   layer_dense(64, activation = \"relu\", name = \"dense_2\") |>   layer_dense(10, name = \"predictions\") functional_model <- keras_model(inputs = inputs, outputs = outputs,                                name = \"3_layer_mlp\")  # Define a subclassed model with the same architecture SubclassedModel <- new_model_class(   \"SubclassedModel\",   initialize = function(output_dim, name = NULL) {     super$initialize(name = name)     self$output_dim <- output_dim |> as.integer()     self$dense_1 <- layer_dense(, 64, activation = \"relu\",                                 name = \"dense_1\")     self$dense_2 <- layer_dense(, 64, activation = \"relu\",                                 name = \"dense_2\")     self$dense_3 <- layer_dense(, self$output_dim,                                 name = \"predictions\")   },    call = function(inputs) {     inputs |>       self$dense_1() |>       self$dense_2() |>       self$dense_3()   },    get_config = function(self) {     list(output_dim = self$output_dim,          name = self$name)   } )   subclassed_model <- SubclassedModel(10) # Call the subclassed model once to create the weights. subclassed_model(op_ones(c(1, 784))) |> invisible()  # Copy weights from functional_model to subclassed_model. set_weights(subclassed_model, get_weights(functional_model))  stopifnot(all.equal(   get_weights(functional_model),   get_weights(subclassed_model) )) input <- keras_input(shape = c(784), name = \"digits\") output <- input |>   layer_dense(64, activation = \"relu\", name = \"dense_1\") |>   layer_dense(64, activation = \"relu\", name = \"dense_2\") |>   layer_dense(10, name = \"predictions\") functional_model <- keras_model(inputs, outputs,                                 name = \"3_layer_mlp\")  input <- keras_input(shape = c(784), name = \"digits\") output <- input |>   layer_dense(64, activation = \"relu\", name = \"dense_1\") |>   layer_dense(64, activation = \"relu\", name = \"dense_2\") |>   # Add a dropout layer, which does not contain any weights.   layer_dropout(0.5) |>   layer_dense(10, name = \"predictions\")  functional_model_with_dropout <-   keras_model(input, output, name = \"3_layer_mlp\")  set_weights(functional_model_with_dropout,             get_weights(functional_model))"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"apis-for-saving-weights-to-disk-loading-them-back","dir":"Articles","previous_headings":"Saving > Model weights saving","what":"APIs for saving weights to disk & loading them back","title":"Save, serialize, and export models","text":"Weights can saved disk calling save_model_weights(filepath). filename end .weights.h5. Example: Note using freeze_weights() may result different output get_weights(layer) ordering model contains nested layers.","code":"sequential_model = keras_model_sequential(input_shape = c(784),                                           input_name = \"digits\") |>   layer_dense(64, activation = \"relu\", name = \"dense_1\") |>   layer_dense(64, activation = \"relu\", name = \"dense_2\") |>   layer_dense(10, name = \"predictions\") sequential_model |> save_model_weights(\"my_model.weights.h5\") sequential_model |> load_model_weights(\"my_model.weights.h5\")"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"transfer-learning-example","dir":"Articles","previous_headings":"Saving > Model weights saving > APIs for saving weights to disk & loading them back","what":"Transfer learning example","title":"Save, serialize, and export models","text":"loading pretrained weights weights file, recommended load weights original checkpointed model, extract desired weights/layers new model. Example:","code":"create_functional_model <- function() {   inputs <- keras_input(shape = c(784), name = \"digits\")   outputs <- inputs |>     layer_dense(64, activation = \"relu\", name = \"dense_1\") |>     layer_dense(64, activation = \"relu\", name = \"dense_2\") |>     layer_dense(10, name = \"predictions\")   keras_model(inputs, outputs, name = \"3_layer_mlp\") }  functional_model <- create_functional_model() functional_model |> save_model_weights(\"pretrained.weights.h5\")  # In a separate program: pretrained_model <- create_functional_model() pretrained_model |> load_model_weights(\"pretrained.weights.h5\")  # Create a new model by extracting layers from the original model: extracted_layers <- pretrained_model$layers |> head(-1) model <- keras_model_sequential(layers = extracted_layers) |>   layer_dense(5, name = \"dense_3\") summary(model) ## Model: \"sequential_4\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ dense_1 (Dense)                 │ (None, 64)             │        50,240 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_2 (Dense)                 │ (None, 64)             │         4,160 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_3 (Dense)                 │ (None, 5)              │           325 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 54,725 (213.77 KB) ##  Trainable params: 54,725 (213.77 KB) ##  Non-trainable params: 0 (0.00 B)"},{"path":[]},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"defining-the-config-methods","dir":"Articles","previous_headings":"Saving > Appendix: Handling custom objects","what":"Defining the config methods","title":"Save, serialize, and export models","text":"Specifications: get_config() return JSON-serializable named list order compatible Keras architecture model-saving APIs. from_config(config) (class method) return new layer model object created config. default implementation returns .call(cls, config). NOTE: constructor arguments already serializable, e.g. strings ints, non-custom Keras objects, overriding from_config() necessary. However, complex objects layers models passed initialize(), deserialization must handled explicitly either initialize overriding from_config() method. Example: Note overriding from_config unnecessary MyDense hidden_units, kernel_initializer, kernel_regularizer ints, strings, built-Keras object, respectively. means default from_config implementation cls(!!!config) work intended. complex objects, layers models passed initialize(), example, must explicitly deserialize objects. Let’s take look example model from_config override necessary. Example:","code":"layer_my_dense <- register_keras_serializable(   package = \"MyLayers\", name = \"KernelMult\",   object = Layer(     \"MyDense\",     initialize = function(units,                           ...,                           kernel_regularizer = NULL,                           kernel_initializer = NULL,                           nested_model = NULL) {       super$initialize(...)       self$hidden_units <- units       self$kernel_regularizer <- kernel_regularizer       self$kernel_initializer <- kernel_initializer       self$nested_model <- nested_model     },     get_config = function() {       config <- super$get_config()       # Update the config with the custom layer's parameters       config <- modifyList(         config,         list(           units = self$hidden_units,           kernel_regularizer = self$kernel_regularizer,           kernel_initializer = self$kernel_initializer,           nested_model = self$nested_model         )       )       config     },     build = function(input_shape) {       input_units <- tail(input_shape, 1)       self$kernel <- self$add_weight(         name = \"kernel\",         shape = shape(input_units, self$hidden_units),         regularizer = self$kernel_regularizer,         initializer = self$kernel_initializer,       )     },     call = function(inputs) {       op_matmul(inputs, self$kernel)     }   ) )   layer <- layer_my_dense(units = 16,                         kernel_regularizer = \"l1\",                         kernel_initializer = \"ones\") layer3 <- layer_my_dense(units = 64, nested_model = layer)  config <- serialize_keras_object(layer3) str(config) ## List of 4 ##  $ module         : chr \"<r-globalenv>\" ##  $ class_name     : chr \"MyDense\" ##  $ config         :List of 5 ##   ..$ name        : chr \"my_dense_1\" ##   ..$ trainable   : logi TRUE ##   ..$ dtype       : chr \"float32\" ##   ..$ units       : num 64 ##   ..$ nested_model:List of 4 ##   .. ..$ module         : chr \"<r-globalenv>\" ##   .. ..$ class_name     : chr \"MyDense\" ##   .. ..$ config         :List of 6 ##   .. .. ..$ name              : chr \"my_dense\" ##   .. .. ..$ trainable         : logi TRUE ##   .. .. ..$ dtype             : chr \"float32\" ##   .. .. ..$ units             : num 16 ##   .. .. ..$ kernel_regularizer: chr \"l1\" ##   .. .. ..$ kernel_initializer: chr \"ones\" ##   .. ..$ registered_name: chr \"MyLayers>KernelMult\" ##  $ registered_name: chr \"MyLayers>KernelMult\" new_layer <- deserialize_keras_object(config) new_layer ## <MyDense name=my_dense_1, built=False> `%||%` <- \\(x, y) if(is.null(x)) y else x layer_custom_model <- register_keras_serializable(   package = \"ComplexModels\",   object = Layer(     \"CustomModel\",     initialize = function(first_layer, second_layer = NULL, ...) {       super$initialize(...)       self$first_layer <- first_layer       self$second_layer <- second_layer %||% layer_dense(, 8)     },      get_config = function() {       config <- super$get_config()       config <- modifyList(config, list(         first_layer = self$first_layer,         second_layer = self$second_layer       ))       config     },      from_config = function(config) {       config$first_layer %<>% deserialize_keras_object()       config$second_layer %<>% deserialize_keras_object()       # note that the class is available in methods under the classname symbol,       # (`CustomModel` for this class), and also under the symbol `__class__`       cls(!!!config)       # CustomModel(!!!config)     },     call = function(self, inputs) {       inputs |>         self$first_layer() |>         self$second_layer()     }   ) )  # Let's make our first layer the custom layer from the previous example (MyDense) inputs <- keras_input(c(32)) outputs <-  inputs |> layer_custom_model(first_layer=layer) model <- keras_model(inputs, outputs)  config <- get_config(model) new_model <- from_config(config)"},{"path":"https://keras.posit.co/articles/serialization_and_saving.html","id":"how-custom-objects-are-serialized","dir":"Articles","previous_headings":"Saving > Appendix: Handling custom objects","what":"How custom objects are serialized","title":"Save, serialize, and export models","text":"serialization format special key custom objects registered via register_keras_serializable(). registered_name key allows easy retrieval loading/deserialization time also allowing users add custom naming. Let’s take look config serializing custom layer MyDense defined . Example: shown, registered_name key contains lookup information Keras master list, including package MyLayers custom name KernelMult gave calling register_keras_serializables(). Take look custom class definition/registration . Note class_name key contains original name class, allowing proper re-initialization from_config. Additionally, note module key NULL since custom object.","code":"layer <- layer_my_dense(   units = 16,   kernel_regularizer = regularizer_l1_l2(l1 = 1e-5, l2 = 1e-4),   kernel_initializer = \"ones\", ) config <- serialize_keras_object(layer) str(config) ## List of 4 ##  $ module         : chr \"<r-globalenv>\" ##  $ class_name     : chr \"MyDense\" ##  $ config         :List of 6 ##   ..$ name              : chr \"my_dense_2\" ##   ..$ trainable         : logi TRUE ##   ..$ dtype             : chr \"float32\" ##   ..$ units             : num 16 ##   ..$ kernel_regularizer:List of 4 ##   .. ..$ module         : chr \"keras.regularizers\" ##   .. ..$ class_name     : chr \"L1L2\" ##   .. ..$ config         :List of 2 ##   .. .. ..$ l1: num 1e-05 ##   .. .. ..$ l2: num 1e-04 ##   .. ..$ registered_name: NULL ##   ..$ kernel_initializer: chr \"ones\" ##  $ registered_name: chr \"MyLayers>KernelMult\""},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Training & evaluation with the built-in methods","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Training & evaluation with the built-in methods","text":"guide covers training, evaluation, prediction (inference) models using built-APIs training & validation (fit(), evaluate() predict()). interested leveraging fit() specifying training step function, see Customizing happens fit() guide. interested writing training & evaluation loops scratch, see guide Writing training loop scratch. general, whether using built-loops writing , model training & evaluation works strictly way across every kind Keras model – Sequential models, models built Functional API, models written scratch via model subclassing.","code":""},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"api-overview-a-first-end-to-end-example","dir":"Articles","previous_headings":"","what":"API overview: a first end-to-end example","title":"Training & evaluation with the built-in methods","text":"passing data built-training loops model, either use: Arrays (data small fits memory) tf_dataset objects PyTorch DataLoader instances next paragraphs, ’ll use MNIST dataset NumPy arrays, order demonstrate use optimizers, losses, metrics. Afterwards, ’ll take close look options. Let’s consider following model (, build Functional API, Sequential model subclassed model well): ’s typical end--end workflow looks like, consisting : Training Validation holdout set generated original training data Evaluation test data ’ll use MNIST data example. specify training configuration (optimizer, loss, metrics): call fit(), train model slicing data “batches” size batch_size, repeatedly iterating entire dataset given number epochs. returned history object holds record loss values metric values training: evaluate model test data via evaluate(): Now, let’s review piece workflow detail.","code":"inputs <- keras_input(shape = 784, name=\"digits\") outputs <- inputs |>   layer_dense(units = 64, activation = \"relu\", name = \"dense_1\") |>   layer_dense(units = 64, activation = \"relu\", name = \"dense_2\") |>   layer_dense(units = 10, activation = \"softmax\", name = \"predictions\") model <- keras_model(inputs = inputs, outputs = outputs) summary(model) ## Model: \"functional_1\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ digits (InputLayer)             │ (None, 784)            │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_1 (Dense)                 │ (None, 64)             │        50,240 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_2 (Dense)                 │ (None, 64)             │         4,160 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ predictions (Dense)             │ (None, 10)             │           650 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 55,050 (215.04 KB) ##  Trainable params: 55,050 (215.04 KB) ##  Non-trainable params: 0 (0.00 B) c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()  # Preprocess the data (these are NumPy arrays) x_train <- array_reshape(x_train, c(60000, 784)) / 255 x_test <- array_reshape(x_test, c(10000, 784)) / 255  # Reserve 10,000 samples for validation x_val <- x_train[1:10000,] y_val <- y_train[1:10000] x_train <- x_train[-c(1:10000),] y_train <- y_train[-c(1:10000)] model |> compile(   # Optimizer   optimizer = optimizer_rmsprop(),   # Loss function to minimize   loss = loss_sparse_categorical_crossentropy(),   # List of metrics to monitor   metrics = list(metric_sparse_categorical_accuracy()) ) history <- model |> fit(   x_train, y_train,   batch_size = 64,   epochs = 2,   # We pass some validation for   # monitoring validation loss and metrics   # at the end of each epoch   validation_data = list(x_val, y_val) ) ## Epoch 1/2 ## 782/782 - 2s - 3ms/step - loss: 0.3481 - sparse_categorical_accuracy: 0.9004 - val_loss: 0.1968 - val_sparse_categorical_accuracy: 0.9444 ## Epoch 2/2 ## 782/782 - 1s - 757us/step - loss: 0.1651 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.1389 - val_sparse_categorical_accuracy: 0.9598 history ## ## Final epoch (plot to see history): ##                            loss: 0.1651 ##     sparse_categorical_accuracy: 0.952 ##                        val_loss: 0.1389 ## val_sparse_categorical_accuracy: 0.9598 # Evaluate the model on the test data using `evaluate` results <- model |> evaluate(x_test, y_test, batch_size=128) ## 79/79 - 0s - 3ms/step - loss: 0.1344 - sparse_categorical_accuracy: 0.9591 results ## $loss ## [1] 0.1343914 ## ## $sparse_categorical_accuracy ## [1] 0.9591 # Generate predictions (probabilities -- the output of the last layer) # on new data using `predict` predictions <- model |> predict(x_test[1:2,]) ## 1/1 - 0s - 127ms/step dim(predictions) ## [1]  2 10"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"the-compile-method-specifying-a-loss-metrics-and-an-optimizer","dir":"Articles","previous_headings":"","what":"The compile() method: specifying a loss, metrics, and an optimizer","title":"Training & evaluation with the built-in methods","text":"train model fit(), need specify loss function, optimizer, optionally, metrics monitor. pass model arguments compile() method: metrics argument list – model can number metrics. model multiple outputs, can specify different losses metrics output, can modulate contribution output total loss model. find details Passing data multi-input, multi-output models section. Note ’re satisfied default settings, many cases optimizer, loss, metrics can specified via string identifiers shortcut: later reuse, let’s put model definition compile step functions; call several times across different examples guide.","code":"model |> compile(   optimizer = optimizer_rmsprop(learning_rate = 1e-3),   loss = loss_sparse_categorical_crossentropy(),   metrics = list(metric_sparse_categorical_accuracy()) ) model |> compile(   optimizer = \"rmsprop\",   loss = \"sparse_categorical_crossentropy\",   metrics = c(\"sparse_categorical_accuracy\") ) get_uncompiled_model <- function() {   inputs <- keras_input(shape = 784, name = \"digits\")   outputs <- inputs |>     layer_dense(units = 64, activation = \"relu\", name = \"dense_1\") |>     layer_dense(units = 64, activation = \"relu\", name = \"dense_2\") |>     layer_dense(units = 10, activation = \"softmax\", name = \"predictions\")   keras_model(inputs = inputs, outputs = outputs) }  get_compiled_model <- function() {   model <- get_uncompiled_model()   model |> compile(     optimizer = \"rmsprop\",     loss = \"sparse_categorical_crossentropy\",     metrics = c(\"sparse_categorical_accuracy\")   )   model }"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"many-built-in-optimizers-losses-and-metrics-are-available","dir":"Articles","previous_headings":"The compile() method: specifying a loss, metrics, and an optimizer","what":"Many built-in optimizers, losses, and metrics are available","title":"Training & evaluation with the built-in methods","text":"general, won’t create losses, metrics, optimizers scratch, need likely already part Keras API: Optimizers: [optimizer_sgd()] (without momentum) [optimizer_rmsprop()] [optimizer_adam()] etc. Losses: [loss_mean_squared_error()] [loss_kl_divergence()] [loss_cosine_similarity()] etc. Metrics: [metric_auc()] [metric_precision()] [metric_recall()] etc.","code":""},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"custom-losses","dir":"Articles","previous_headings":"The compile() method: specifying a loss, metrics, and an optimizer","what":"Custom losses","title":"Training & evaluation with the built-in methods","text":"need create custom loss, Keras provides three ways . first method involves creating function accepts inputs y_true y_pred. following example shows loss function computes mean squared error real data predictions: need loss function takes parameters beside y_true y_pred, can subclass Keras base Loss class using [Loss()] implement following two methods: initialize(): accept parameters pass call loss function call(y_true, y_pred): use targets (y_true) model predictions (y_pred) compute model’s loss Let’s say want use mean squared error, added term de-incentivize prediction values far 0.5 (assume categorical targets one-hot encoded take values 0 1). creates incentive model confident, may help reduce overfitting (won’t know works try!). ’s :","code":"custom_mean_squared_error <- function(y_true, y_pred) {   op_mean(op_square(y_true - y_pred), axis = -1) }  model <- get_uncompiled_model() model |> compile(optimizer = \"adam\",                  loss = custom_mean_squared_error)  # We need to one-hot encode the labels to use MSE y_train_one_hot <- op_one_hot(y_train, num_classes = 10) model |> fit(x_train, y_train_one_hot, batch_size = 64, epochs = 2) ## Epoch 1/2 ## 782/782 - 2s - 2ms/step - loss: 0.0157 ## Epoch 2/2 ## 782/782 - 0s - 626us/step - loss: 0.0081 loss_custom_mse <- Loss(   classname = \"CustomMSE\",   initialize = function(regularization_factor = 0.1, name = \"custom_mse\") {     super$initialize(name = name)     self$regularization_factor <- regularization_factor   },   call = function(y_true, y_pred) {     mse <- op_mean(op_square(y_true - y_pred), axis = -1)     reg <- op_mean(op_square(0.5 - y_pred), axis = -1)     mse + reg * self$regularization_factor   } )  model <- get_uncompiled_model() model |> compile(optimizer=\"adam\", loss = loss_custom_mse())  y_train_one_hot <- op_one_hot(y_train, num_classes=10) model |> fit(x_train, y_train_one_hot, batch_size=64, epochs=1) ## 782/782 - 2s - 2ms/step - loss: 0.0383"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"custom-metrics","dir":"Articles","previous_headings":"The compile() method: specifying a loss, metrics, and an optimizer","what":"Custom metrics","title":"Training & evaluation with the built-in methods","text":"need metric isn’t part API, can easily create custom metrics subclassing Keras base Metric class using [Metric()]. need implement 4 methods: initialize(), create state variables metric. update_state(y_true, y_pred, sample_weight = NULL), uses targets y_true model predictions y_pred update state variables. result(), uses state variables compute final results. reset_state(), reinitializes state metric. State update results computation kept separate (update_state() result(), respectively) cases, results computation might expensive done periodically. ’s simple example showing implement CategoricalTruePositives metric counts many samples correctly classified belonging given class:","code":"metric_categorical_true_positives <- Metric(   \"CategoricalTruePositives\",    initialize = function(name = \"categorical_true_positives\", ...) {     super$initialize(name = name, ...)     self$true_positives <- self$add_variable(shape = shape(),                                              name = \"ctp\",                                              initializer = \"zeros\")   },    update_state = function(y_true, y_pred, sample_weight = NULL) {     y_pred <- op_argmax(y_pred, axis = 2) |> op_reshape(c(-1, 1))     values <- op_cast(y_true, \"int32\") == op_cast(y_pred, \"int32\")     values <- op_cast(values, \"float32\")     if (!is.null(sample_weight)) {       sample_weight <- op_cast(sample_weight, \"float32\")       values <- op_multiply(values, sample_weight)     }     self$true_positives$assign_add(op_sum(values))   },    result = function() {     self$true_positives$value   },    reset_state = function() {     self$true_positives$assign(0.0)   } )  model <- get_uncompiled_model() model |> compile(   optimizer = optimizer_rmsprop(learning_rate = 1e-3),   loss = loss_sparse_categorical_crossentropy(),   metrics = c(metric_categorical_true_positives()) ) history <- model |> fit(x_train, y_train, batch_size = 64, epochs = 3) ## Epoch 1/3 ## 782/782 - 1s - 2ms/step - categorical_true_positives: 360544.0000 - loss: 0.3421 ## Epoch 2/3 ## 782/782 - 0s - 635us/step - categorical_true_positives: 362643.0000 - loss: 0.1622 ## Epoch 3/3 ## 782/782 - 0s - 623us/step - categorical_true_positives: 363325.0000 - loss: 0.1179"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"handling-losses-and-metrics-that-dont-fit-the-standard-signature","dir":"Articles","previous_headings":"The compile() method: specifying a loss, metrics, and an optimizer","what":"Handling losses and metrics that don’t fit the standard signature","title":"Training & evaluation with the built-in methods","text":"overwhelming majority losses metrics can computed y_true y_pred, y_pred output model – . instance, regularization loss may require activation layer (targets case), activation may model output. cases, can call self$add_loss(loss_value) inside call method custom layer. Losses added way get added “main” loss training (one passed compile()). ’s simple example adds activity regularization (note activity regularization built-Keras layers – layer just sake providing concrete example): Note pass losses via add_loss(), becomes possible call compile() without loss function, since model already loss minimize. Consider following LogisticEndpoint layer: takes inputs targets & logits, tracks crossentropy loss via add_loss(). can use model two inputs (input data & targets), compiled without loss argument, like : information training multi-input models, see section Passing data multi-input, multi-output models.","code":"layer_custom_activity_regularizer <- Layer(   \"ActivityRegularization\",   call = function(inputs) {     self$add_loss(op_sum(inputs) * 0.1)     inputs  # Pass-through layer.   } )  inputs <- keras_input(shape = 784, name = \"digits\") outputs <- inputs |>   layer_dense(units = 32, activation = \"relu\", name = \"dense_1\") |>   layer_custom_activity_regularizer() |>   layer_dense(units = 64, activation = \"relu\", name = \"dense_2\") |>   layer_dense(units = 10, name = \"predictions\")  model <- keras_model(inputs = inputs, outputs = outputs) model |> compile(optimizer = optimizer_rmsprop(learning_rate = 1e-3),                  loss = loss_sparse_categorical_crossentropy(from_logits = TRUE))  # The displayed loss will be much higher than before # due to the regularization component. model |> fit(x_train, y_train, batch_size = 64, epochs = 1) ## 782/782 - 1s - 2ms/step - loss: 2.3949 layer_logistic_endpoint <- Layer(   \"LogisticEndpoint\",   initialize = function(name = NULL) {     super$initialize(name = name)     self$loss_fn <- loss_binary_crossentropy(from_logits = TRUE)   },   call = function(targets, logits, sample_weights = NULL) {     # Compute the training-time loss value and add it     # to the layer using `self.add_loss()`.     loss <- self$loss_fn(targets, logits, sample_weights)     self$add_loss(loss)      # Return the inference-time prediction tensor (for `predict()`).     op_softmax(logits)   } ) inputs <- keras_input(shape = 3, name = \"inputs\") targets <- keras_input(shape = 10, name = \"targets\")  logits <- inputs |> layer_dense(10) predictions <- layer_logistic_endpoint(name = \"predictions\")(targets, logits)  model <- keras_model(inputs = list(inputs, targets),                      outputs = predictions) model |> compile(optimizer = \"adam\")  # No loss argument!  data <- list(   inputs = random_normal(c(3, 3)),   targets = random_normal(c(3, 10)) ) model |> fit(data, epochs = 1) ## 1/1 - 1s - 521ms/step - loss: 1.0566"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"automatically-setting-apart-a-validation-holdout-set","dir":"Articles","previous_headings":"The compile() method: specifying a loss, metrics, and an optimizer","what":"Automatically setting apart a validation holdout set","title":"Training & evaluation with the built-in methods","text":"first end--end example saw, used validation_data argument pass list arrays list(x_val, y_val) model evaluating validation loss validation metrics end epoch. ’s another option: argument validation_split allows automatically reserve part training data validation. argument value represents fraction data reserved validation, set number higher 0 lower 1. instance, validation_split = 0.2 means “use 20% data validation”, validation_split = 0.6 means “use 60% data validation”. way validation computed taking last x% samples arrays received fit() call, shuffling. Note can use validation_split training NumPy data.","code":"model <- get_compiled_model() model |> fit(x_train, y_train,              batch_size = 64,              validation_split = 0.2, epochs = 1) ## 625/625 - 1s - 2ms/step - loss: 0.3694 - sparse_categorical_accuracy: 0.8948 - val_loss: 0.1911 - val_sparse_categorical_accuracy: 0.9453"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"training-evaluation-using-tf-dataset-objects","dir":"Articles","previous_headings":"","what":"Training & evaluation using TF Dataset objects","title":"Training & evaluation with the built-in methods","text":"past paragraphs, ’ve seen handle losses, metrics, optimizers, ’ve seen use validation_data validation_split arguments fit(), data passed arrays. Another option use iterator-like, tf.data.Dataset, PyTorch DataLoader, R generator function. Let’s take look former. tfdatasets R package containes set utilities loading preprocessing data way ’s fast scalable. complete guide creating Datasets, see tf.data documentation. can use tf.data train Keras models regardless backend ’re using – whether ’s JAX, PyTorch, TensorFlow. can pass Dataset instance directly methods fit(), evaluate(), predict(): Note Dataset reset end epoch, can reused next epoch. want run training specific number batches Dataset, can pass steps_per_epoch argument, specifies many training steps model run using Dataset moving next epoch. can also pass Dataset instance validation_data argument fit(): end epoch, model iterate validation dataset compute validation loss validation metrics. want run validation specific number batches dataset, can pass validation_steps argument, specifies many validation steps model run validation dataset interrupting validation moving next epoch: Note validation dataset reset use (always evaluating samples epoch epoch). argument validation_split (generating holdout set training data) supported training Dataset objects, since feature requires ability index samples datasets, possible general Dataset API.","code":"library(tfdatasets, exclude = \"shape\") model <- get_compiled_model()  # First, let's create a training Dataset instance. # For the sake of our example, we'll use the same MNIST data as before. train_dataset <- tensor_slices_dataset(list(x_train, y_train))  # Shuffle and slice the dataset. train_dataset <- train_dataset |>   dataset_shuffle(buffer_size=1024) |>   dataset_batch(64)  # Now we get a test dataset. test_dataset <-   tensor_slices_dataset(list(x_test, y_test)) |>   dataset_batch(64)  # Since the dataset already takes care of batching, # we don't pass a `batch_size` argument. model |> fit(train_dataset, epochs = 3) ## Epoch 1/3 ## 782/782 - 1s - 2ms/step - loss: 0.3417 - sparse_categorical_accuracy: 0.9033 ## Epoch 2/3 ## 782/782 - 0s - 639us/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9525 ## Epoch 3/3 ## 782/782 - 0s - 629us/step - loss: 0.1165 - sparse_categorical_accuracy: 0.9655 # You can also evaluate or predict on a dataset. result <- model |> evaluate(test_dataset) ## 157/157 - 0s - 3ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9636 result ## $loss ## [1] 0.1136581 ## ## $sparse_categorical_accuracy ## [1] 0.9636 model <- get_compiled_model()  # Prepare the training dataset train_dataset <- tensor_slices_dataset(list(x_train, y_train)) train_dataset <- train_dataset |>   dataset_shuffle(buffer_size = 1024) |>   dataset_batch(64)  # Only use the 100 batches per epoch (that's 64 * 100 samples) model |> fit(train_dataset, epochs = 3, steps_per_epoch = 100) ## Epoch 1/3 ## 100/100 - 1s - 7ms/step - loss: 0.8506 - sparse_categorical_accuracy: 0.7683 ## Epoch 2/3 ## 100/100 - 0s - 643us/step - loss: 0.3705 - sparse_categorical_accuracy: 0.8947 ## Epoch 3/3 ## 100/100 - 0s - 637us/step - loss: 0.3060 - sparse_categorical_accuracy: 0.9130 model <- get_compiled_model()  # Prepare the training dataset train_dataset <- tensor_slices_dataset(list(x_train, y_train)) train_dataset <- train_dataset |>   dataset_shuffle(buffer_size=1024) |>   dataset_batch(64)  # Prepare the validation dataset val_dataset <- tensor_slices_dataset(list(x_val, y_val)) val_dataset <- val_dataset |> dataset_batch(64)  model |> fit(train_dataset, epochs = 1, validation_data = val_dataset) ## 782/782 - 2s - 2ms/step - loss: 0.3355 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.2198 - val_sparse_categorical_accuracy: 0.9313 model  <- get_compiled_model()  # Prepare the training dataset train_dataset <- tensor_slices_dataset(list(x_train, y_train)) train_dataset <- train_dataset |>   dataset_shuffle(buffer_size = 1024) |>   dataset_batch(64)  # Prepare the validation dataset val_dataset <- tensor_slices_dataset(list(x_val, y_val)) val_dataset <- val_dataset |> dataset_batch(64)  model %>% fit(   train_dataset,   epochs = 1,   # Only run validation using the first 10 batches of the dataset   # using the `validation_steps` argument   validation_data = val_dataset,   validation_steps = 10, ) ## 782/782 - 2s - 2ms/step - loss: 0.3354 - sparse_categorical_accuracy: 0.9049 - val_loss: 0.2111 - val_sparse_categorical_accuracy: 0.9375"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"using-sample-weighting-and-class-weighting","dir":"Articles","previous_headings":"","what":"Using sample weighting and class weighting","title":"Training & evaluation with the built-in methods","text":"default settings weight sample decided frequency dataset. two methods weight data, independent sample frequency: Class weights Sample weights","code":""},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"class-weights","dir":"Articles","previous_headings":"Using sample weighting and class weighting","what":"Class weights","title":"Training & evaluation with the built-in methods","text":"set passing named list class_weight argument fit(). list maps class indices weight used samples belonging class. can used balance classes without resampling, train model gives importance particular class. instance, class “0” half represented class “1” data, use model |> fit(..., class_weight = c(\"0\" = 1, \"1\" = 0.5)). ’s R example use class weights sample weights give importance correct classification class #5 (digit “5” MNIST dataset).","code":"class_weight <- c(     \"0\" = 1.0,     \"1\" = 1.0,     \"2\" = 1.0,     \"3\" = 1.0,     \"4\" = 1.0,     # Set weight \"2\" for class \"5\",     # making this class 2x more important     \"5\" = 2.0,     \"6\" = 1.0,     \"7\" = 1.0,     \"8\" = 1.0,     \"9\" = 1.0 )  model <- get_compiled_model() model |> fit(x_train, y_train,              class_weight = class_weight,              batch_size = 64, epochs = 1) ## 782/782 - 1s - 2ms/step - loss: 0.3687 - sparse_categorical_accuracy: 0.9026"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"sample-weights","dir":"Articles","previous_headings":"Using sample weighting and class weighting","what":"Sample weights","title":"Training & evaluation with the built-in methods","text":"fine grained control, building classifier, can use sample_weights. training R arrays: Pass sample_weight argument fit(). training tf_dataset sort iterator: yield (input_batch, label_batch, sample_weight_batch) tuples. “sample weights” array array numbers specify much weight sample batch computing total loss. commonly used imbalanced classification problems (idea give weight rarely-seen classes). weights used ones zeros, array can used mask loss function (entirely discarding contribution certain samples total loss). ’s matching Dataset example:","code":"sample_weight <- rep(1.0, length(y_train)) sample_weight[y_train == 5] <- 2.0  model <- get_compiled_model() model |> fit(   x_train, y_train,   sample_weight = sample_weight,   batch_size = 64, epochs = 1 ) ## 782/782 - 1s - 2ms/step - loss: 0.3685 - sparse_categorical_accuracy: 0.9024 sample_weight <- rep(1.0, length(y_train)) sample_weight[y_train == 5] <- 2.0  # Create a Dataset that includes sample weights # (3rd element in the return tuple). train_dataset <- tensor_slices_dataset(list(     x_train, y_train, sample_weight ))  # Shuffle and slice the dataset. train_dataset <- train_dataset |>   dataset_shuffle(buffer_size = 1024) |>   dataset_batch(64)  model <- get_compiled_model() model |> fit(train_dataset, epochs = 1) ## 782/782 - 1s - 2ms/step - loss: 0.3843 - sparse_categorical_accuracy: 0.8999"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"passing-data-to-multi-input-multi-output-models","dir":"Articles","previous_headings":"","what":"Passing data to multi-input, multi-output models","title":"Training & evaluation with the built-in methods","text":"previous examples, considering model single input (tensor shape (764)) single output (prediction tensor shape (10)). models multiple inputs outputs? Consider following model, image input shape (32, 32, 3) (’s (height, width, channels)) time series input shape (NA, 10) (’s (timesteps, features)). model two outputs computed combination inputs: “score” (shape (1)) probability distribution five classes (shape (5)). Let’s plot model, can clearly see ’re (note shapes shown plot batch shapes, rather per-sample shapes). plot chunk unnamed-chunk-26 compilation time, can specify different losses different outputs, passing loss functions list: passed single loss function model, loss function applied every output (appropriate ). Likewise metrics: Since gave names output layers, also specify per-output losses metrics via named list: recommend use names 2 outputs. ’s possible give different weights different output-specific losses (instance, one might wish privilege “score” loss example, giving 2x importance class loss), using loss_weights argument: also choose compute loss certain outputs, outputs meant prediction training: Passing data multi-input multi-output model fit() works similar way specifying loss function compile: can pass lists arrays (1:1 mapping outputs received loss function) dicts mapping output names arrays. ’s Dataset use case: similarly R arrays, Dataset return tuple named lists (dicts).","code":"image_input <- keras_input(c(32, 32, 3), name = \"img_input\") timeseries_input <- keras_input(c(NA, 10), name = \"ts_input\")  x1 <- image_input |>   layer_conv_2d(filters = 3, kernel_size = c(3, 3)) |>   layer_global_max_pooling_2d()  x2 <- timeseries_input |>   layer_conv_1d(filters = 3, kernel_size = 3) |>   layer_global_max_pooling_1d()  x <- layer_concatenate(x1, x2)  score_output <- layer_dense(x, 1, name = \"score_output\") class_output <- layer_dense(x, 5, name = \"class_output\")  model <- keras_model(   inputs = list(image_input, timeseries_input),   outputs = list(score_output, class_output) ) plot(model, show_shapes = TRUE) model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(     loss_mean_squared_error(),     loss_categorical_crossentropy()   ) ) model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(     loss_mean_squared_error(),     loss_categorical_crossentropy()   ),   metrics = list(     list(       metric_mean_absolute_error(),       metric_mean_absolute_percentage_error()     ),     list(metric_categorical_accuracy())   ) ) model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(     score_output = loss_mean_squared_error(),     class_output = loss_categorical_crossentropy()   ),   metrics = list(     score_output = list(       metric_mean_absolute_error(),       metric_mean_absolute_percentage_error()     ),     class_output = list(metric_categorical_accuracy())   ) ) model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(     score_output = loss_mean_squared_error(),     class_output = loss_categorical_crossentropy()   ),   metrics = list(     score_output = list(       metric_mean_absolute_error(),       metric_mean_absolute_percentage_error()     ),     class_output = list(metric_categorical_accuracy())   ),   loss_weights = list(score_output = 2.0, class_output = 1.0) ) # loss list, positional version model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(NULL, loss_categorical_crossentropy()) )  # Or loss list, named version model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(class_output = loss_categorical_crossentropy()) ) model |> compile(   optimizer = optimizer_rmsprop(1e-3),   loss = list(     loss_mean_squared_error(),     loss_categorical_crossentropy()   ) )  # Generate dummy data img_data <- random_normal(c(100, 32, 32, 3)) ts_data <- random_normal(c(100, 20, 10)) score_targets <- random_normal(c(100, 1)) class_targets <- random_normal(c(100, 5))  # Fit on unnamed lists (positional matching) model |> fit(     list(img_data, ts_data),     list(score_targets, class_targets),     batch_size=32,     epochs=1 ) ## 4/4 - 2s - 480ms/step - loss: 0.5888 # Alternatively, fit on named lists (names matching) model |> fit(   list(img_input = img_data, ts_input = ts_data),   list(score_output = score_targets, class_output = class_targets),   batch_size = 32,   epochs = 1 ) ## 4/4 - 1s - 227ms/step - loss: -1.3254e+00 train_dataset <- tensor_slices_dataset(list(   list(img_input = img_data, ts_input = ts_data),   list(score_output = score_targets, class_output = class_targets) )) train_dataset <- train_dataset |>   dataset_shuffle(buffer_size = 1024) |>   dataset_batch(64)  model |> fit(train_dataset, epochs = 1) ## 2/2 - 1s - 569ms/step - loss: 1.7663"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"using-callbacks","dir":"Articles","previous_headings":"","what":"Using callbacks","title":"Training & evaluation with the built-in methods","text":"Callbacks Keras objects called different points training (start epoch, end batch, end epoch, etc.). can used implement certain behaviors, : validation different points training (beyond built-per-epoch validation) Checkpointing model regular intervals exceeds certain accuracy threshold Changing learning rate model training seems plateauing fine-tuning top layers training seems plateauing Sending email instant message notifications training ends certain performance threshold exceeded Etc. Callbacks can passed list call fit():","code":"model <- get_compiled_model()  callbacks <- list(   callback_early_stopping(     # Stop training when `val_loss` is no longer improving     monitor = \"val_loss\",     # \"no longer improving\" being defined as \"no better than 1e-2 less\"     min_delta = 1e-2,     # \"no longer improving\" being further defined as \"for at least 2 epochs\"     patience = 2,     verbose = 1   ) ) model |> fit(   x_train,   y_train,   epochs = 20,   batch_size = 64,   callbacks = callbacks,   validation_split = 0.2, ) ## Epoch 1/20 ## 625/625 - 1s - 2ms/step - loss: 0.3727 - sparse_categorical_accuracy: 0.8946 - val_loss: 0.1909 - val_sparse_categorical_accuracy: 0.9440 ## Epoch 2/20 ## 625/625 - 1s - 820us/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9485 - val_loss: 0.1441 - val_sparse_categorical_accuracy: 0.9572 ## Epoch 3/20 ## 625/625 - 1s - 845us/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9626 - val_loss: 0.1294 - val_sparse_categorical_accuracy: 0.9619 ## Epoch 4/20 ## 625/625 - 1s - 823us/step - loss: 0.0984 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.1213 - val_sparse_categorical_accuracy: 0.9647 ## Epoch 5/20 ## 625/625 - 1s - 824us/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.1153 - val_sparse_categorical_accuracy: 0.9667 ## Epoch 6/20 ## 625/625 - 1s - 844us/step - loss: 0.0683 - sparse_categorical_accuracy: 0.9803 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9680 ## Epoch 7/20 ## 625/625 - 1s - 829us/step - loss: 0.0578 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9694 ## Epoch 8/20 ## 625/625 - 1s - 811us/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.1156 - val_sparse_categorical_accuracy: 0.9708 ## Epoch 9/20 ## 625/625 - 1s - 814us/step - loss: 0.0423 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.1175 - val_sparse_categorical_accuracy: 0.9716 ## Epoch 9: early stopping"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"many-built-in-callbacks-are-available","dir":"Articles","previous_headings":"Using callbacks","what":"Many built-in callbacks are available","title":"Training & evaluation with the built-in methods","text":"many built-callbacks already available Keras, : callback_model_checkpoint(): Periodically save model. callback_early_stopping(): Stop training training longer improving validation metrics. callback_tensorboard(): periodically write model logs can visualized TensorBoard (details section “Visualization”). callback_csv_logger(): streams loss metrics data CSV file. etc. See callbacks documentation complete list.","code":""},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"writing-your-own-callback","dir":"Articles","previous_headings":"Using callbacks","what":"Writing your own callback","title":"Training & evaluation with the built-in methods","text":"can create custom callback subclassing base [Callback()] class. callback access associated model class property self$model. Make sure read complete guide writing custom callbacks. ’s simple example saving list per-batch loss values training:","code":"callback_loss_history <- Callback(   classname = \"LossHistory\",   initialize = function(file = \"per_training_batch_losses.txt\", ...) {     super$initialize(...)     private$file <- file   },   on_train_begin = function(logs = NULL) {     private$per_batch_losses <- fastmap::faststack()   },   on_train_batch_begin = function(batch, logs = NULL) {     private$per_batch_losses$push(logs$loss)   },   on_train_end = function(logs = NULL) {     per_batch_losses <- private$per_batch_losses$as_list() |> as.numeric()     write(per_batch_losses, private$file)   } )"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"checkpointing-models","dir":"Articles","previous_headings":"","what":"Checkpointing models","title":"Training & evaluation with the built-in methods","text":"’re training model relatively large datasets, ’s crucial save checkpoints model frequent intervals. easiest way achieve [callback_model_checkpoint()]: ModelCheckpoint callback can used implement fault-tolerance: ability restart training last saved state model case training gets randomly interrupted. ’s basic example: call also write callback saving restoring models. complete guide serialization saving, see guide saving serializing Models.","code":"model <- get_compiled_model()  callbacks <- list(   callback_model_checkpoint(     # Path where to save the model     # The two parameters below mean that we will overwrite     # the current checkpoint if and only if     # the `val_loss` score has improved.     # The saved model name will include the current epoch.     filepath = \"mymodel_{epoch}.keras\",     save_best_only = TRUE,     # Only save a model if `val_loss` has improved.     monitor = \"val_loss\",     verbose = 1   ) ) model |> fit(   x_train, y_train,   epochs = 2, batch_size = 64,   callbacks = callbacks,   validation_split = 0.2 ) ## Epoch 1/2 ## ## Epoch 1: val_loss improved from inf to 0.19317, saving model to mymodel_1.keras ## 625/625 - 1s - 2ms/step - loss: 0.3759 - sparse_categorical_accuracy: 0.8940 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9447 ## Epoch 2/2 ## ## Epoch 2: val_loss improved from 0.19317 to 0.14933, saving model to mymodel_2.keras ## 625/625 - 1s - 837us/step - loss: 0.1797 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.1493 - val_sparse_categorical_accuracy: 0.9576 # Prepare a directory to store all the checkpoints. checkpoint_dir <- \"./ckpt\" fs::dir_create(checkpoint_dir)  make_or_restore_model <- function() {   # Either restore the latest (best) model, or create a fresh one   # if there is no checkpoint available.   checkpoints <- Sys.glob(file.path(checkpoint_dir, \"model-loss=*.keras\"))    if (length(checkpoints) > 0) {     checkpoint_losses <- sub(\"^model-loss=([0-9.]+)\\\\.keras$\", \"\\\\1\",                              basename(checkpoints)) |> as.numeric()     best_checkpoint <- checkpoints[which.min(checkpoint_losses)]     load_model(best_checkpoint)   } else {     get_compiled_model()   } }  model <- make_or_restore_model() callbacks <- list(   # This callback saves the model every 100 batches.   # We include the training loss in the saved model name.   callback_model_checkpoint(     filepath = file.path(checkpoint_dir, \"model-loss={loss:.2f}.keras\"),     save_freq = 100   ) ) model |> fit(x_train, y_train, epochs = 1, callbacks = callbacks) ## 1563/1563 - 2s - 1ms/step - loss: 0.2949 - sparse_categorical_accuracy: 0.9148"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"using-learning-rate-schedules","dir":"Articles","previous_headings":"","what":"Using learning rate schedules","title":"Training & evaluation with the built-in methods","text":"common pattern training deep learning models gradually reduce learning training progresses. generally known “learning rate decay”. learning decay schedule static (fixed advance, function current epoch current batch index), dynamic (responding current behavior model, particular validation loss).","code":""},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"passing-a-schedule-to-an-optimizer","dir":"Articles","previous_headings":"Using learning rate schedules","what":"Passing a schedule to an optimizer","title":"Training & evaluation with the built-in methods","text":"can easily use static learning rate decay schedule passing schedule object learning_rate argument optimizer: Several built-schedules available: ExponentialDecay, PiecewiseConstantDecay, PolynomialDecay, InverseTimeDecay.","code":"initial_learning_rate <- 0.1 lr_schedule <- learning_rate_schedule_exponential_decay(     initial_learning_rate, decay_steps=100000, decay_rate=0.96,     staircase=TRUE )  optimizer <- optimizer_rmsprop(learning_rate = lr_schedule)"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"using-callbacks-to-implement-a-dynamic-learning-rate-schedule","dir":"Articles","previous_headings":"Using learning rate schedules","what":"Using callbacks to implement a dynamic learning rate schedule","title":"Training & evaluation with the built-in methods","text":"dynamic learning rate schedule (instance, decreasing learning rate validation loss longer improving) achieved schedule objects, since optimizer access validation metrics. However, callbacks access metrics, including validation metrics! can thus achieve pattern using callback modifies current learning rate optimizer. fact, even built-[callback_reduce_lr_on_plateau()].","code":""},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"visualizing-loss-and-metrics-during-training-with-tensorboard","dir":"Articles","previous_headings":"","what":"Visualizing loss and metrics during training with TensorBoard","title":"Training & evaluation with the built-in methods","text":"best way keep eye model training use TensorBoard – browser-based application can run locally provides : Live plots loss metrics training evaluation (optionally) Visualizations histograms layer activations (optionally) 3D visualizations embedding spaces learned layer_embedding() installed TensorFlow pip, able launch TensorBoard command line: R using:","code":"tensorboard --logdir=/full_path_to_your_logs tensorflow::tensorboard(logdir = \"/full_path_to_your_logs\")"},{"path":"https://keras.posit.co/articles/training_with_built_in_methods.html","id":"using-the-tensorboard-callback","dir":"Articles","previous_headings":"Visualizing loss and metrics during training with TensorBoard","what":"Using the TensorBoard callback","title":"Training & evaluation with the built-in methods","text":"easiest way use TensorBoard Keras model fit() method [callback_tensorboard()]. simplest case, just specify want callback write logs, ’re good go: information, see callback_tensorboard().","code":"tb_callback <- callback_tensorboard(   log_dir = \"/full_path_to_your_logs\",   histogram_freq = 0, # How often to log histogram visualizations   embeddings_freq = 0, # How often to log embedding visualizations   update_freq = \"epoch\", # How often to write logs (default: once per epoch) )"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Transfer learning & fine-tuning","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Transfer learning & fine-tuning","text":"Transfer learning consists taking features learned one problem, leveraging new, similar problem. instance, features model learned identify raccoon may useful kick-start model meant identify tanukis. Transfer learning usually done tasks dataset little data train full-scale model scratch. common incarnation transfer learning context deep learning following workflow: Take layers previously trained model. Freeze , avoid destroying information contain future training rounds. Add new, trainable layers top frozen layers. learn turn old features predictions new dataset. Train new layers dataset. last, optional step, fine-tuning, consists unfreezing entire model obtained (part ), re-training new data low learning rate. can potentially achieve meaningful improvements, incrementally adapting pretrained features new data. First, go Keras trainable API detail, underlies transfer learning & fine-tuning workflows. , ’ll demonstrate typical workflow taking model pretrained ImageNet dataset, retraining Kaggle “cats vs dogs” classification dataset. adapted Deep Learning Python 2016 blog post “building powerful image classification models using little data”.","code":""},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"freezing-layers-understanding-the-trainable-attribute","dir":"Articles","previous_headings":"","what":"Freezing layers: understanding the trainable attribute","title":"Transfer learning & fine-tuning","text":"Layers & models three weight attributes: weights list weights variables layer. trainable_weights list meant updated (via gradient descent) minimize loss training. non_trainable_weights list aren’t meant trained. Typically updated model forward pass. Example: Dense layer 2 trainable weights (kernel & bias) general, weights trainable weights. built-layer non-trainable weights [layer_batch_normalization()]. uses non-trainable weights keep track mean variance inputs training. learn use non-trainable weights custom layers, see guide writing new layers scratch. Example: BatchNormalization layer 2 trainable weights 2 non-trainable weights Layers & models also feature boolean attribute trainable. value can changed. Setting layer$trainable FALSE moves layer’s weights trainable non-trainable. called “freezing” layer: state frozen layer won’t updated training (either training fit() training custom loop relies trainable_weights apply gradient updates). Example: setting trainable False trainable weight becomes non-trainable, value longer updated training. confuse layer$trainable attribute argument training layer$call() (controls whether layer run forward pass inference mode training mode). information, see Keras FAQ.","code":"layer <- layer_dense(units = 3) layer$build(shape(NULL, 4))  # Create the weights  length(layer$weights) ## [1] 2 length(layer$trainable_weights) ## [1] 2 length(layer$non_trainable_weights) ## [1] 0 layer <- layer_batch_normalization() layer$build(shape(NA, 4))  # Create the weights  length(layer$weights) ## [1] 4 length(layer$trainable_weights) ## [1] 2 length(layer$non_trainable_weights) ## [1] 2 layer <- layer_dense(units = 3) layer$build(shape(NULL, 4))  # Create the weights layer$trainable <- FALSE  # Freeze the layer  length(layer$weights) ## [1] 2 length(layer$trainable_weights) ## [1] 0 length(layer$non_trainable_weights) ## [1] 2 # Make a model with 2 layers layer1 <- layer_dense(units = 3, activation = \"relu\") layer2 <- layer_dense(units = 3, activation = \"sigmoid\") model <- keras_model_sequential(input_shape = 3) |>   layer1() |>   layer2()  # Freeze the first layer layer1$trainable <- FALSE  # Keep a copy of the weights of layer1 for later reference # (get_weights() returns a list of R arrays, #  layer$weights returns a list of KerasVariables) initial_layer1_weights_values <- get_weights(layer1)  # Train the model model |> compile(optimizer = \"adam\", loss = \"mse\") model |> fit(random_normal(c(2, 3)), random_normal(c(2, 3)), epochs = 1) ## 1/1 - 1s - 561ms/step - loss: 2.1868 # Check that the weights of layer1 have not changed during training final_layer1_weights_values <- get_weights(layer1)  all.equal(initial_layer1_weights_values,           final_layer1_weights_values) ## [1] TRUE"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"recursive-setting-of-the-trainable-attribute","dir":"Articles","previous_headings":"","what":"Recursive setting of the trainable attribute","title":"Transfer learning & fine-tuning","text":"set $trainable <- FALSE model layer sublayers, children layers become non-trainable well. Example:","code":"inner_model <- keras_model_sequential(input_shape = 3) |>   layer_dense(units = 3, activation = \"relu\") |>   layer_dense(units = 3, activation = \"relu\")  model <- keras_model_sequential(input_shape = 3) |>   inner_model() |>   layer_dense(units = 3, activation = \"sigmoid\")  model$trainable <- FALSE  # Freeze the outer model  inner_model$trainable  # All layers in `model` are now frozen ## [1] FALSE inner_model$layers[[1]]$trainable  # `trainable` is propagated recursively ## [1] FALSE"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"the-typical-transfer-learning-workflow","dir":"Articles","previous_headings":"","what":"The typical transfer-learning workflow","title":"Transfer learning & fine-tuning","text":"leads us typical transfer learning workflow can implemented Keras: Instantiate base model load pre-trained weights . Freeze layers base model setting trainable <- FALSE. Create new model top output one (several) layers base model. Train new model new dataset. Note alternative, lightweight workflow also : Instantiate base model load pre-trained weights . Run new dataset record output one (several) layers base model. called feature extraction. Use output input data new, smaller model. key advantage second workflow run base model data, rather per epoch training. ’s lot faster & cheaper. issue second workflow, though, doesn’t allow dynamically modify input data new model training, required data augmentation, instance. Transfer learning typically used tasks new dataset little data train full-scale model scratch, scenarios data augmentation important. follows, focus first workflow. ’s first workflow looks like Keras: First, instantiate base model pre-trained weights. , freeze base model. Create new model top. Train model new data.","code":"base_model <- application_xception(   weights = 'imagenet', # Load weights pre-trained on ImageNet.   input_shape = c(150, 150, 3),   include_top = FALSE  # Do not include the ImageNet classifier at the top. ) base_model$trainable <- FALSE inputs <- keras_input(shape = c(150, 150, 3)) # We make sure that the base_model is running in inference mode here, # by passing `training <- FALSE`. This is important for fine-tuning, as you will # learn in a few paragraphs. outputs <- inputs |>   base_model(training = FALSE) |>   # Convert features of shape `base_model$output_shape[-1]` to vectors   layer_global_average_pooling_2d() |>   # A Dense classifier with a single unit (binary classification)   layer_dense(1)  model <- keras_model(inputs, outputs) model |> compile(   optimizer = optimizer_adam(),   loss = loss_binary_crossentropy(from_logits = TRUE),   metrics = list(metric_binary_accuracy()) ) model |> fit(new_dataset, epochs = 20,              callbacks = ..., validation_data = ...)"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"fine-tuning","dir":"Articles","previous_headings":"","what":"Fine-tuning","title":"Transfer learning & fine-tuning","text":"model converged new data, can try unfreeze part base model retrain whole model end--end low learning rate. optional last step can potentially give incremental improvements. also potentially lead quick overfitting – keep mind. critical step model frozen layers trained convergence. mix randomly-initialized trainable layers trainable layers hold pre-trained features, randomly-initialized layers cause large gradient updates training, destroy pre-trained features. ’s also critical use low learning rate stage, training much larger model first round training, dataset typically small. result, risk overfitting quickly apply large weight updates. , want readapt pretrained weights incremental way. implement fine-tuning whole base model: Important note compile() trainable Calling compile() model meant “freeze” behavior model. implies trainable attribute values time model compiled preserved throughout lifetime model, compile called . Hence, change trainable value, make sure call compile() model changes taken account. Important notes BatchNormalization layer Many image models contain BatchNormalization layers. layer special case every imaginable count. things keep mind. BatchNormalization contains 2 non-trainable weights get updated training. variables tracking mean variance inputs. set bn_layer$trainable <- FALSE, BatchNormalization layer run inference mode, update mean & variance statistics. case layers general, weight trainability & inference/training modes two orthogonal concepts. two tied case BatchNormalization layer. unfreeze model contains BatchNormalization layers order fine-tuning, keep BatchNormalization layers inference mode passing training = FALSE calling base model. Otherwise updates applied non-trainable weights suddenly destroy model learned. ’ll see pattern action end--end example end guide.","code":"# Unfreeze the base model base_model$trainable <- TRUE  # It's important to recompile your model after you make any changes # to the `trainable` attribute of any inner layer, so that your changes # are take into account model |> compile(   optimizer = optimizer_adam(1e-5), # Very low learning rate   loss = loss_binary_crossentropy(from_logits = TRUE),   metrics = c(metric_binary_accuracy()) )  # Train end-to-end. Be careful to stop before you overfit! model |> fit(new_dataset, epochs = 10,              callbacks = ..., validation_data = ...)"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"an-end-to-end-example-fine-tuning-an-image-classification-model-on-a-cats-vs--dogs-dataset","dir":"Articles","previous_headings":"","what":"An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset","title":"Transfer learning & fine-tuning","text":"solidify concepts, let’s walk concrete end--end transfer learning & fine-tuning example. load Xception model, pre-trained ImageNet, use Kaggle “cats vs. dogs” classification dataset.","code":""},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"getting-the-data","dir":"Articles","previous_headings":"An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset","what":"Getting the data","title":"Transfer learning & fine-tuning","text":"First, let’s fetch cats vs. dogs dataset using TFDS. dataset, ’ll probably want use utility [image_dataset_from_directory()] generate similar labeled dataset objects set images disk filed class-specific folders. Transfer learning useful working small datasets. keep dataset small, use 40% original training data (25,000 images) training, 10% validation, 10% testing. first 9 images training dataset – can see, ’re different sizes. can also see label 1 “dog” label 0 “cat”.","code":"# reticulate::py_install(\"tensorflow-datasets\") tfds <- reticulate::import(\"tensorflow_datasets\")  c(train_ds, validation_ds, test_ds) %<-% tfds$load(   \"cats_vs_dogs\",   # Reserve 10% for validation and 10% for test   split = c(\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"),   as_supervised = TRUE  # Include labels )  length(train_ds) ## [1] 9305 library(tfdatasets, exclude = \"shape\")  par(mfrow = c(3, 3), mar = c(1,0,1.5,0)) train_ds |>   dataset_take(9) |>   as_array_iterator() |>   iterate(function(batch) {     c(image, label) %<-% batch     plot(as.raster(image, max = 255L))     title(sprintf(       \"label: %s   size: %s\",       label, paste(dim(image), collapse = \" x \")))   })"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"standardizing-the-data","dir":"Articles","previous_headings":"An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset","what":"Standardizing the data","title":"Transfer learning & fine-tuning","text":"raw images variety sizes. addition, pixel consists 3 integer values 0 255 (RGB level values). isn’t great fit feeding neural network. need 2 things: Standardize fixed image size. pick 150x150. Normalize pixel values -1 1. ’ll using Normalization layer part model . general, ’s good practice develop models take raw data input, opposed models take already-preprocessed data. reason , model expects preprocessed data, time export model use elsewhere (web browser, mobile app), ’ll need reimplement exact preprocessing pipeline. gets tricky quickly. least possible amount preprocessing hitting model. , ’ll image resizing data pipeline (deep neural network can process contiguous batches data), ’ll input value scaling part model, create . Let’s resize images 150x150:","code":"resize_fn <- layer_resizing(width = 150, height = 150) resize_pair <- function(x, y) list(resize_fn(x), y)  train_ds <- train_ds |> dataset_map(resize_pair) validation_ds <- validation_ds |> dataset_map(resize_pair) test_ds <- test_ds |> dataset_map(resize_pair)"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"using-random-data-augmentation","dir":"Articles","previous_headings":"An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset","what":"Using random data augmentation","title":"Transfer learning & fine-tuning","text":"don’t large image dataset, ’s good practice artificially introduce sample diversity applying random yet realistic transformations training images, random horizontal flipping small random rotations. helps expose model different aspects training data slowing overfitting. Let’s batch data use prefetching optimize loading speed. Let’s visualize first image first batch looks like various random transformations:","code":"data_augmentation <- keras_model_sequential() |>   layer_random_flip(\"horizontal\") |>   layer_random_rotation(.1)  train_ds <- train_ds %>%   dataset_map(function(x, y) list(data_augmentation(x), y)) library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) batch_size <- 64  train_ds <- train_ds |>   dataset_batch(batch_size) |>   dataset_prefetch()  validation_ds <- validation_ds |>   dataset_batch(batch_size) |>   dataset_prefetch()  test_ds <- test_ds |>   dataset_batch(batch_size) |>   dataset_prefetch() batch <- train_ds |>   dataset_take(1) |>   as_iterator() |>   iter_next()  c(images, labels) %<-% batch first_image <- images[1, all_dims(), drop = TRUE] augmented_image <- data_augmentation(first_image, training = TRUE)  plot_image <- function(image, main = deparse1(substitute(image))) {   image |>     as.array() |> # convert from tensor to R array     as.raster(max = 255) |>     plot()    if(!is.null(main))     title(main) }  par(mfrow = c(2, 2), mar = c(1, 1, 1.5, 1)) plot_image(first_image) plot_image(augmented_image) plot_image(data_augmentation(first_image, training = TRUE), \"augmented 2\") plot_image(data_augmentation(first_image, training = TRUE), \"augmented 3\")"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"build-a-model","dir":"Articles","previous_headings":"","what":"Build a model","title":"Transfer learning & fine-tuning","text":"Now let’s built model follows blueprint ’ve explained earlier. Note : add Rescaling layer scale input values (initially [0, 255] range) [-1, 1] range. add Dropout layer classification layer, regularization. make sure pass training=FALSE calling base model, runs inference mode, batchnorm statistics don’t get updated even unfreeze base model fine-tuning.","code":"base_model <- application_xception(   weights = \"imagenet\", # Load weights pre-trained on ImageNet.   input_shape = c(150, 150, 3),   include_top = FALSE, # Do not include the ImageNet classifier at the top. )  # Freeze the base_model base_model$trainable <- FALSE  # Create new model on top inputs <- keras_input(shape = c(150, 150, 3))  # Pre-trained Xception weights requires that input be scaled # from (0, 255) to a range of (-1., +1.), the rescaling layer # outputs: `(inputs * scale) + offset` scale_layer <- layer_rescaling(scale = 1 / 127.5, offset = -1) x <- scale_layer(inputs)  # The base model contains batchnorm layers. We want to keep them in inference mode # when we unfreeze the base model for fine-tuning, so we make sure that the # base_model is running in inference mode here. outputs <- x |>   base_model(training = FALSE) |>   layer_global_average_pooling_2d() |>   layer_dropout(0.2) |>   layer_dense(1)  model <- keras_model(inputs, outputs)  summary(model, show_trainable = TRUE) ## Model: \"functional_10\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓ ## ┃ Layer (type)                ┃ Output Shape          ┃    Param # ┃ Trai… ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩ ## │ input_layer_7 (InputLayer)  │ (None, 150, 150, 3)   │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ rescaling (Rescaling)       │ (None, 150, 150, 3)   │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ xception (Functional)       │ (None, 5, 5, 2048)    │ 20,861,480 │   N   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ global_average_pooling2d_1  │ (None, 2048)          │          0 │   -   │ ## │ (GlobalAveragePooling2D)    │                       │            │       │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ dropout (Dropout)           │ (None, 2048)          │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ dense_8 (Dense)             │ (None, 1)             │      2,049 │   Y   │ ## └─────────────────────────────┴───────────────────────┴────────────┴───────┘ ##  Total params: 20,863,529 (79.59 MB) ##  Trainable params: 2,049 (8.00 KB) ##  Non-trainable params: 20,861,480 (79.58 MB)"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"train-the-top-layer","dir":"Articles","previous_headings":"","what":"Train the top layer","title":"Transfer learning & fine-tuning","text":"","code":"model |> compile(   optimizer = optimizer_adam(),   loss = loss_binary_crossentropy(from_logits = TRUE),   metrics = list(metric_binary_accuracy()) )  epochs <- 1 model |> fit(train_ds, epochs = epochs, validation_data = validation_ds) ## 146/146 - 41s - 279ms/step - binary_accuracy: 0.9104 - loss: 0.1951 - val_binary_accuracy: 0.9673 - val_loss: 0.0913"},{"path":"https://keras.posit.co/articles/transfer_learning.html","id":"do-a-round-of-fine-tuning-of-the-entire-model","dir":"Articles","previous_headings":"","what":"Do a round of fine-tuning of the entire model","title":"Transfer learning & fine-tuning","text":"Finally, let’s unfreeze base model train entire model end--end low learning rate. Importantly, although base model becomes trainable, still running inference mode since passed training=FALSE calling built model. means batch normalization layers inside won’t update batch statistics. , wreck havoc representations learned model far. 10 epochs, fine-tuning gains us nice improvement . Let’s evaluate model test dataset:","code":"# Unfreeze the base_model. Note that it keeps running in inference mode # since we passed `training=FALSE` when calling it. This means that # the batchnorm layers will not update their batch statistics. # This prevents the batchnorm layers from undoing all the training # we've done so far. base_model$trainable <- TRUE summary(model, show_trainable = TRUE) ## Model: \"functional_10\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓ ## ┃ Layer (type)                ┃ Output Shape          ┃    Param # ┃ Trai… ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩ ## │ input_layer_7 (InputLayer)  │ (None, 150, 150, 3)   │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ rescaling (Rescaling)       │ (None, 150, 150, 3)   │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ xception (Functional)       │ (None, 5, 5, 2048)    │ 20,861,480 │   Y   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ global_average_pooling2d_1  │ (None, 2048)          │          0 │   -   │ ## │ (GlobalAveragePooling2D)    │                       │            │       │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ dropout (Dropout)           │ (None, 2048)          │          0 │   -   │ ## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤ ## │ dense_8 (Dense)             │ (None, 1)             │      2,049 │   Y   │ ## └─────────────────────────────┴───────────────────────┴────────────┴───────┘ ##  Total params: 20,867,629 (79.60 MB) ##  Trainable params: 20,809,001 (79.38 MB) ##  Non-trainable params: 54,528 (213.00 KB) ##  Optimizer params: 4,100 (16.02 KB) model |> compile(   optimizer = optimizer_adam(1e-5), # Low learning rate   loss = loss_binary_crossentropy(from_logits = TRUE),   metrics = list(metric_binary_accuracy()) )  epochs <- 1 model |> fit(train_ds, epochs = epochs, validation_data = validation_ds) ## 146/146 - 85s - 580ms/step - binary_accuracy: 0.8710 - loss: 0.3231 - val_binary_accuracy: 0.9617 - val_loss: 0.1073 model |> evaluate(test_ds) ## 37/37 - 1s - 40ms/step - binary_accuracy: 0.9557 - loss: 0.1078 ## $binary_accuracy ## [1] 0.955718 ## ## $loss ## [1] 0.1077981"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Understanding masking & padding","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Understanding masking & padding","text":"Masking way tell sequence-processing layers certain timesteps input missing, thus skipped processing data. Padding special form masking masked steps start end sequence. Padding comes need encode sequence data contiguous batches: order make sequences batch fit given standard length, necessary pad truncate sequences. Let’s take close look.","code":""},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"padding-sequence-data","dir":"Articles","previous_headings":"","what":"Padding sequence data","title":"Understanding masking & padding","text":"processing sequence data, common individual samples different lengths. Consider following example (text tokenized words): vocabulary lookup, data might vectorized integers, e.g.: data nested list individual samples length 3, 5, 6, respectively. Since input data deep learning model must single tensor (shape e.g. (batch_size, 6, vocab_size) case), samples shorter longest item need padded placeholder value (alternatively, one might also truncate long samples padding short samples). Keras provides utility function truncate pad Python lists common length: pad_sequences.","code":"data <- list(   c(\"Hello\", \"world\", \"!\"),   c(\"How\", \"are\", \"you\", \"doing\", \"today\"),   c(\"The\", \"weather\", \"will\", \"be\", \"nice\", \"tomorrow\") ) data <- list(   c(71, 1331, 4231),   c(73, 8, 3215, 55, 927),   c(83, 91, 1, 645, 1253, 927) ) raw_inputs <- list(   c(711, 632, 71),   c(73, 8, 3215, 55, 927),   c(83, 91, 1, 645, 1253, 927) )  # By default, this will pad using 0s; it is configurable via the # \"value\" parameter. # Note that you could use \"pre\" padding (at the beginning) or # \"post\" padding (at the end). # We recommend using \"post\" padding when working with RNN layers # (in order to be able to use the # CuDNN implementation of the layers). padded_inputs <- pad_sequences(raw_inputs, padding=\"post\") padded_inputs ##      [,1] [,2] [,3] [,4] [,5] [,6] ## [1,]  711  632   71    0    0    0 ## [2,]   73    8 3215   55  927    0 ## [3,]   83   91    1  645 1253  927"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"masking","dir":"Articles","previous_headings":"","what":"Masking","title":"Understanding masking & padding","text":"Now samples uniform length, model must informed part data actually padding ignored. mechanism masking. three ways introduce input masks Keras models: Add layer_masking layer. Configure layer_embedding layer mask_zero=TRUE. Pass mask argument manually calling layers support argument (e.g. RNN layers).","code":""},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"mask-generating-layers-embedding-and-masking","dir":"Articles","previous_headings":"","what":"Mask-generating layers: Embedding and Masking","title":"Understanding masking & padding","text":"hood, layers create mask tensor (2D tensor shape (batch, sequence_length)), attach tensor output returned Masking Embedding layer. can see printed result, mask 2D boolean tensor shape (batch_size, sequence_length), individual FALSE entry indicates corresponding timestep ignored processing.","code":"embedding <- layer_embedding(input_dim=5000, output_dim=16, mask_zero=TRUE) masked_output <- embedding(padded_inputs)  masked_output$`_keras_mask` ## tf.Tensor( ## [[ True  True  True False False False] ##  [ True  True  True  True  True False] ##  [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool) masking_layer <- layer_masking() # Simulate the embedding lookup by expanding the 2D input to 3D, # with embedding dimension of 10. unmasked_embedding <- op_cast(     op_tile(op_expand_dims(padded_inputs, axis=-1), c(1L, 1L, 10L)),     dtype=\"float32\" )  masked_embedding <- masking_layer(unmasked_embedding) masked_embedding$`_keras_mask` ## tf.Tensor( ## [[ True  True  True False False False] ##  [ True  True  True  True  True False] ##  [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"mask-propagation-in-the-functional-api-and-sequential-api","dir":"Articles","previous_headings":"","what":"Mask propagation in the Functional API and Sequential API","title":"Understanding masking & padding","text":"using Functional API Sequential API, mask generated Embedding Masking layer propagated network layer capable using (example, RNN layers). Keras automatically fetch mask corresponding input pass layer knows use . instance, following Sequential model, LSTM layer automatically receive mask, means ignore padded values: also case following Functional API model:","code":"model <- keras_model_sequential() %>%   layer_embedding(input_dim=5000, output_dim=16, mask_zero=TRUE) %>%   layer_lstm(units=32) inputs <- keras_input(shape = shape(NULL), dtype=\"int32\") outputs <- inputs %>%   layer_embedding(input_dim=5000, output_dim=16, mask_zero=TRUE) %>%   layer_lstm(units=32)  model <- keras_model(inputs, outputs)"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"passing-mask-tensors-directly-to-layers","dir":"Articles","previous_headings":"","what":"Passing mask tensors directly to layers","title":"Understanding masking & padding","text":"Layers can handle masks (LSTM layer) mask argument call method. Meanwhile, layers produce mask (e.g. Embedding) expose compute_mask(input, previous_mask) method can call. Thus, can pass output compute_mask() method mask-producing layer call method mask-consuming layer, like :","code":"MyLayer <- new_layer_class(   \"MyLayer\",   initialize = function(...) {     super$initialize(...)     self$embedding <- layer_embedding(       input_dim=5000, output_dim=16, mask_zero=TRUE     )     self$lstm <- layer_lstm(units=32)   },   call = function(inputs) {     inputs %>%       self$embedding() %>%       # Note that you could also prepare a `mask` tensor manually.       # It only needs to be a boolean tensor       # with the right shape, i.e. (batch_size, timesteps).       self$lstm(mask=self$embedding$compute_mask(inputs))   } )  layer <- MyLayer() x <- random_integer(c(32, 10), 0, 100) layer(x) ## tf.Tensor( ## [[ 0.00130048 -0.00113368 -0.0071567  ... -0.00107615 -0.00162071 ##    0.00135018] ##  [-0.004185    0.00726349  0.00520932 ...  0.00119117  0.00230441 ##    0.00174123] ##  [-0.00537032 -0.00164898 -0.00238435 ... -0.00154158 -0.0038603 ##   -0.00105811] ##  ... ##  [ 0.00622132 -0.00905907 -0.00599518 ...  0.00025823 -0.00142478 ##   -0.00125036] ##  [-0.00523904  0.00336683 -0.00299453 ...  0.00876718  0.00172073 ##    0.00903089] ##  [-0.00393721  0.00058538  0.00503809 ... -0.00203075  0.00325884 ##   -0.00299755]], shape=(32, 32), dtype=float32)"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"supporting-masking-in-your-custom-layers","dir":"Articles","previous_headings":"","what":"Supporting masking in your custom layers","title":"Understanding masking & padding","text":"Sometimes, may need write layers generate mask (like Embedding), layers need modify current mask. instance, layer produces tensor different time dimension input, Concatenate layer concatenates time dimension, need modify current mask downstream layers able properly take masked timesteps account. , layer implement layer.compute_mask() method, produces new mask given input current mask. example TemporalSplit layer needs modify current mask. another example CustomEmbedding layer capable generating mask input values: Note: details format limitations related masking, see serialization guide.","code":"TemporalSplit <- new_layer_class(   \"TemporalSplit\",   call = function(inputs) {     # Expect the input to be 3D and mask to be 2D, split the input tensor into 2     # subtensors along the time axis (axis 1).     op_split(inputs, 2, axis=2)   },   compute_mask = function(inputs, mask = NULL) {     # Also split the mask into 2 if it presents.     if (!is.null(mask)) {       op_split(mask, 2, axis=2)     } else {       NULL     }   } )  c(first_half, second_half) %<-% TemporalSplit(masked_embedding) first_half$`_keras_mask` ## tf.Tensor( ## [[ True  True  True] ##  [ True  True  True] ##  [ True  True  True]], shape=(3, 3), dtype=bool) second_half$`_keras_mask` ## tf.Tensor( ## [[False False False] ##  [ True  True False] ##  [ True  True  True]], shape=(3, 3), dtype=bool) CustomEmbedding <- new_layer_class(   \"CustomEmbedding\",   initialize = function(input_dim, output_dim, mask_zero=FALSE, ...) {     super$initialize(...)     self$input_dim <- as.integer(input_dim)     self$output_dim <- as.integer(output_dim)     self$mask_zero <- mask_zero   },   build = function(input_shape) {     self$embeddings <- self$add_weight(       shape=c(self$input_dim, self$output_dim),       initializer=\"random_normal\",       dtype=\"float32\"     )   },   call = function(inputs) {     inputs <- op_cast(inputs, \"int32\")     op_take(self$embeddings, inputs)   },   compute_mask = function(inputs, mask=NULL) {     if (!self$mask_zero) {       NULL     } else {       op_not_equal(inputs, 0)     }   } )  layer <- CustomEmbedding(input_dim = 10, output_dim = 32, mask_zero=TRUE) x <- random_integer(c(3, 10), 0, 9)  y <- layer(x) mask <- layer$compute_mask(x)  mask ## tf.Tensor( ## [[ True  True  True  True  True  True  True  True  True  True] ##  [ True  True  True  True  True  True  True  True  True  True] ##  [False False  True  True  True  True  True  True  True  True]], shape=(3, 10), dtype=bool)"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"opting-in-to-mask-propagation-on-compatible-layers","dir":"Articles","previous_headings":"","what":"Opting-in to mask propagation on compatible layers","title":"Understanding masking & padding","text":"layers don’t modify time dimension, don’t need modify current mask. However, may still want able propagate current mask, unchanged, next layer. opt-behavior. default, custom layer destroy current mask (since framework way tell whether propagating mask safe ). custom layer modify time dimension, want able propagate current input mask, set self.supports_masking = True layer constructor. case, default behavior compute_mask() just pass current mask . ’s example layer whitelisted mask propagation: can now use custom layer -mask-generating layer (like Embedding) mask-consuming layer (like LSTM), pass mask along reaches mask-consuming layer.","code":"MyActivation <- new_layer_class(   \"MyActivation\",   initialize = function(...) {     super$initialize(...)     self$supports_masking <- TRUE   },   call = function(inputs) {     op_relu(inputs)   } ) inputs <- keras_input(shape = shape(NULL), dtype=\"int32\") outputs <- inputs %>%   layer_embedding(input_dim=5000, output_dim=16, mask_zero=TRUE) %>%   MyActivation() %>%   layer_lstm(units=32)  model <- keras_model(inputs, outputs) y <- model(random_integer(c(32, 100), 0, 5000))"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"writing-layers-that-need-mask-information","dir":"Articles","previous_headings":"","what":"Writing layers that need mask information","title":"Understanding masking & padding","text":"layers mask consumers: accept mask argument call use determine whether skip certain time steps. write layer, can simply add mask=None argument call signature. mask associated inputs passed layer whenever available. ’s simple example : layer computes softmax time dimension (axis 1) input sequence, discarding masked timesteps.","code":"TemporalSoftmax <- new_layer_class(   \"TemporalSoftmax\",   initialize = function(...) {     super$initialize(...)     self$supports_masking <- TRUE   },   call = function(inputs, mask=NULL) {     if (is.null(mask)) {       stop(\"`TemporalSoftmax` layer requires a previous layer to support masking.\")     }     broadcast_float_mask <- op_expand_dims(op_cast(mask, \"float32\"), -1)     inputs_exp <- op_exp(inputs) * broadcast_float_mask     inputs_sum <- op_sum(inputs_exp * broadcast_float_mask, axis=-1, keepdims=TRUE)     inputs_exp / inputs_sum   } )  inputs <- keras_input(shape = shape(NULL), dtype=\"int32\") outputs <- inputs %>%   layer_embedding(input_dim=10, output_dim=32, mask_zero=TRUE) %>%   layer_dense(1) %>%   TemporalSoftmax()  model <- keras_model(inputs, outputs) y <- model(random_integer(c(32, 100), 0, 10))"},{"path":"https://keras.posit.co/articles/understanding_masking_and_padding.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Understanding masking & padding","text":"need know padding & masking Keras. recap: “Masking” layers able know skip / ignore certain timesteps sequence inputs. layers mask-generators: Embedding can generate mask input values (mask_zero=TRUE), can Masking layer. layers mask-consumers: expose mask argument call method. case RNN layers. Functional API Sequential API, mask information propagated automatically. using layers standalone way, can pass mask arguments layers manually. can easily write layers modify current mask, generate new mask, consume mask associated inputs.","code":""},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Writing a training loop from scratch in JAX","text":"","code":"import os  # This guide can only be run with the jax backend. os.environ[\"KERAS_BACKEND\"] = \"jax\"  import jax  # We import TF so we can use tf.data. import tensorflow as tf import keras import numpy as np"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Writing a training loop from scratch in JAX","text":"Keras provides default training evaluation loops, fit() evaluate(). usage covered guide Training & evaluation built-methods. want customize learning algorithm model still leveraging convenience fit() (instance, train GAN using fit()), can subclass Model class implement train_step() method, called repeatedly fit(). Now, want low-level control training & evaluation, write training & evaluation loops scratch. guide .","code":""},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"a-first-end-to-end-example","dir":"Articles","previous_headings":"","what":"A first end-to-end example","title":"Writing a training loop from scratch in JAX","text":"write custom training loop, need following ingredients: model train, course. optimizer. either use optimizer keras.optimizers, one optax package. loss function. dataset. standard JAX ecosystem load data via tf.data, ’s ’ll use. Let’s line . First, let’s get model MNIST dataset: Next, ’s loss function optimizer. ’ll use Keras optimizer case.","code":"def get_model():     inputs = keras.Input(shape=(784,), name=\"digits\")     x1 = keras.layers.Dense(64, activation=\"relu\")(inputs)     x2 = keras.layers.Dense(64, activation=\"relu\")(x1)     outputs = keras.layers.Dense(10, name=\"predictions\")(x2)     model = keras.Model(inputs=inputs, outputs=outputs)     return model   model = get_model()  # Prepare the training dataset. batch_size = 32 (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = np.reshape(x_train, (-1, 784)).astype(\"float32\") x_test = np.reshape(x_test, (-1, 784)).astype(\"float32\") y_train = keras.utils.to_categorical(y_train) y_test = keras.utils.to_categorical(y_test)  # Reserve 10,000 samples for validation. x_val = x_train[-10000:] y_val = y_train[-10000:] x_train = x_train[:-10000] y_train = y_train[:-10000]  # Prepare the training dataset. train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)) train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)  # Prepare the validation dataset. val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)) val_dataset = val_dataset.batch(batch_size) # Instantiate a loss function. loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)  # Instantiate an optimizer. optimizer = keras.optimizers.Adam(learning_rate=1e-3)"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"getting-gradients-in-jax","dir":"Articles","previous_headings":"A first end-to-end example","what":"Getting gradients in JAX","title":"Writing a training loop from scratch in JAX","text":"Let’s train model using mini-batch gradient custom training loop. JAX, gradients computed via metaprogramming: call jax.grad (jax.value_and_grad function order create gradient-computing function first function. first thing need function returns loss value. ’s function ’ll use generate gradient function. Something like : function, can compute gradients via metaprogramming : Typically, don’t just want get gradient values, also want get loss value. can using jax.value_and_grad instead jax.grad:","code":"def compute_loss(x, y):     ...     return loss grad_fn = jax.grad(compute_loss) grads = grad_fn(x, y) grad_fn = jax.value_and_grad(compute_loss) loss, grads = grad_fn(x, y)"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"jax-computation-is-purely-stateless","dir":"Articles","previous_headings":"A first end-to-end example","what":"JAX computation is purely stateless","title":"Writing a training loop from scratch in JAX","text":"JAX, everything must stateless function – loss computation function must stateless well. means Keras variables (e.g. weight tensors) must passed function inputs, variable updated forward pass must returned function output. function side effect. forward pass, non-trainable variables Keras model might get updated. variables , instance, RNG seed state variables BatchNormalization statistics. ’re going need return . need something like : function, can get gradient function specifying hax_aux value_and_grad: tells JAX loss computation function returns outputs just loss. Note loss always first output. Now established basics, let’s implement compute_loss_and_updates function. Keras models stateless_call method come handy . works just like model.__call__, requires explicitly pass value variables model, returns just __call__ outputs also (potentially updated) non-trainable variables. Let’s get gradient function:","code":"def compute_loss_and_updates(trainable_variables, non_trainable_variables, x, y):     ...     return loss, non_trainable_variables grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True) (loss, non_trainable_variables), grads = grad_fn(     trainable_variables, non_trainable_variables, x, y ) def compute_loss_and_updates(     trainable_variables, non_trainable_variables, x, y ):     y_pred, non_trainable_variables = model.stateless_call(         trainable_variables, non_trainable_variables, x     )     loss = loss_fn(y, y_pred)     return loss, non_trainable_variables grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"the-training-step-function","dir":"Articles","previous_headings":"A first end-to-end example","what":"The training step function","title":"Writing a training loop from scratch in JAX","text":"Next, let’s implement end--end training step, function run forward pass, compute loss, compute gradients, also use optimizer update trainable variables. function also needs stateless, get input state tuple includes every state element ’re going use: trainable_variables non_trainable_variables: model’s variables. optimizer_variables: optimizer’s state variables, momentum accumulators. update trainable variables, use optimizer’s stateless method stateless_apply. ’s equivalent optimizer.apply(), requires always passing trainable_variables optimizer_variables. returns updated trainable variables updated optimizer_variables.","code":"def train_step(state, data):     trainable_variables, non_trainable_variables, optimizer_variables = state     x, y = data     (loss, non_trainable_variables), grads = grad_fn(         trainable_variables, non_trainable_variables, x, y     )     trainable_variables, optimizer_variables = optimizer.stateless_apply(         optimizer_variables, grads, trainable_variables     )     # Return updated state     return loss, (         trainable_variables,         non_trainable_variables,         optimizer_variables,     )"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"make-it-fast-with-jax-jit","dir":"Articles","previous_headings":"A first end-to-end example","what":"Make it fast with jax.jit","title":"Writing a training loop from scratch in JAX","text":"default, JAX operations run eagerly, just like TensorFlow eager mode PyTorch eager mode. just like TensorFlow eager mode PyTorch eager mode, ’s pretty slow – eager mode better used debugging environment, way actual work. let’s make train_step fast compiling . stateless JAX function, can compile XLA via @jax.jit decorator. get traced first execution, subsequent executions executing traced graph (just like @tf.function(jit_compile=True). Let’s try : ’re now ready train model. training loop trivial: just repeatedly call loss, state = train_step(state, data). Note: convert TF tensors yielded tf.data.Dataset NumPy passing JAX function. variables must built beforehand: model must built optimizer must built. Since ’re using Functional API model, ’s already built, subclassed model ’d need call batch data build . key thing notice loop entirely stateless – variables attached model (model.weights) never getting updated loop. new values stored state tuple. means point, saving model, attaching new variable values back model. Just call variable.assign(new_value) model variable want update:","code":"@jax.jit def train_step(state, data):     trainable_variables, non_trainable_variables, optimizer_variables = state     x, y = data     (loss, non_trainable_variables), grads = grad_fn(         trainable_variables, non_trainable_variables, x, y     )     trainable_variables, optimizer_variables = optimizer.stateless_apply(         optimizer_variables, grads, trainable_variables     )     # Return updated state     return loss, (         trainable_variables,         non_trainable_variables,         optimizer_variables,     ) # Build optimizer variables. optimizer.build(model.trainable_variables)  trainable_variables = model.trainable_variables non_trainable_variables = model.non_trainable_variables optimizer_variables = optimizer.variables state = trainable_variables, non_trainable_variables, optimizer_variables  # Training loop for step, data in enumerate(train_dataset):     data = (data[0].numpy(), data[1].numpy())     loss, state = train_step(state, data)     # Log every 100 batches.     if step % 100 == 0:         print(f\"Training loss (for 1 batch) at step {step}: {float(loss):.4f}\")         print(f\"Seen so far: {(step + 1) * batch_size} samples\") trainable_variables, non_trainable_variables, optimizer_variables = state for variable, value in zip(model.trainable_variables, trainable_variables):     variable.assign(value) for variable, value in zip(     model.non_trainable_variables, non_trainable_variables ):     variable.assign(value)"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"low-level-handling-of-metrics","dir":"Articles","previous_headings":"","what":"Low-level handling of metrics","title":"Writing a training loop from scratch in JAX","text":"Let’s add metrics monitoring basic training loop. can readily reuse built-Keras metrics (custom ones wrote) training loops written scratch. ’s flow: Instantiate metric start loop Include metric_variables train_step arguments compute_loss_and_updates arguments. Call metric.stateless_update_state() compute_loss_and_updates function. ’s equivalent update_state() – stateless. need display current value metric, outside train_step (eager scope), attach new metric variable values metric object vall metric.result(). Call metric.reset_state() need clear state metric (typically end epoch) Let’s use knowledge compute CategoricalAccuracy training validation data end training: ’ll also prepare evaluation step function: loops:","code":"# Get a fresh model model = get_model()  # Instantiate an optimizer to train the model. optimizer = keras.optimizers.Adam(learning_rate=1e-3) # Instantiate a loss function. loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)  # Prepare the metrics. train_acc_metric = keras.metrics.CategoricalAccuracy() val_acc_metric = keras.metrics.CategoricalAccuracy()   def compute_loss_and_updates(     trainable_variables, non_trainable_variables, metric_variables, x, y ):     y_pred, non_trainable_variables = model.stateless_call(         trainable_variables, non_trainable_variables, x     )     loss = loss_fn(y, y_pred)     metric_variables = train_acc_metric.stateless_update_state(         metric_variables, y, y_pred     )     return loss, (non_trainable_variables, metric_variables)   grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)   @jax.jit def train_step(state, data):     (         trainable_variables,         non_trainable_variables,         optimizer_variables,         metric_variables,     ) = state     x, y = data     (loss, (non_trainable_variables, metric_variables)), grads = grad_fn(         trainable_variables, non_trainable_variables, metric_variables, x, y     )     trainable_variables, optimizer_variables = optimizer.stateless_apply(         optimizer_variables, grads, trainable_variables     )     # Return updated state     return loss, (         trainable_variables,         non_trainable_variables,         optimizer_variables,         metric_variables,     ) @jax.jit def eval_step(state, data):     trainable_variables, non_trainable_variables, metric_variables = state     x, y = data     y_pred, non_trainable_variables = model.stateless_call(         trainable_variables, non_trainable_variables, x     )     loss = loss_fn(y, y_pred)     metric_variables = val_acc_metric.stateless_update_state(         metric_variables, y, y_pred     )     return loss, (         trainable_variables,         non_trainable_variables,         metric_variables,     ) # Build optimizer variables. optimizer.build(model.trainable_variables)  trainable_variables = model.trainable_variables non_trainable_variables = model.non_trainable_variables optimizer_variables = optimizer.variables metric_variables = train_acc_metric.variables state = (     trainable_variables,     non_trainable_variables,     optimizer_variables,     metric_variables, )  # Training loop for step, data in enumerate(train_dataset):     data = (data[0].numpy(), data[1].numpy())     loss, state = train_step(state, data)     # Log every 100 batches.     if step % 100 == 0:         print(f\"Training loss (for 1 batch) at step {step}: {float(loss):.4f}\")         _, _, _, metric_variables = state         for variable, value in zip(             train_acc_metric.variables, metric_variables         ):             variable.assign(value)         print(f\"Training accuracy: {train_acc_metric.result()}\")         print(f\"Seen so far: {(step + 1) * batch_size} samples\")  metric_variables = val_acc_metric.variables (     trainable_variables,     non_trainable_variables,     optimizer_variables,     metric_variables, ) = state state = trainable_variables, non_trainable_variables, metric_variables  # Eval loop for step, data in enumerate(val_dataset):     data = (data[0].numpy(), data[1].numpy())     loss, state = eval_step(state, data)     # Log every 100 batches.     if step % 100 == 0:         print(             f\"Validation loss (for 1 batch) at step {step}: {float(loss):.4f}\"         )         _, _, metric_variables = state         for variable, value in zip(val_acc_metric.variables, metric_variables):             variable.assign(value)         print(f\"Validation accuracy: {val_acc_metric.result()}\")         print(f\"Seen so far: {(step + 1) * batch_size} samples\")"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_jax.html","id":"low-level-handling-of-losses-tracked-by-the-model","dir":"Articles","previous_headings":"","what":"Low-level handling of losses tracked by the model","title":"Writing a training loop from scratch in JAX","text":"Layers & models recursively track losses created forward pass layers call self.add_loss(value). resulting list scalar loss values available via property model.losses end forward pass. want using loss components, sum add main loss training step. Consider layer, creates activity regularization loss: Let’s build really simple model uses : ’s compute_loss_and_updates function look like now: Pass return_losses=True model.stateless_call(). Sum resulting losses add main loss. ’s !","code":"class ActivityRegularizationLayer(keras.layers.Layer):     def call(self, inputs):         self.add_loss(1e-2 * jax.numpy.sum(inputs))         return inputs inputs = keras.Input(shape=(784,), name=\"digits\") x = keras.layers.Dense(64, activation=\"relu\")(inputs) # Insert activity regularization as a layer x = ActivityRegularizationLayer()(x) x = keras.layers.Dense(64, activation=\"relu\")(x) outputs = keras.layers.Dense(10, name=\"predictions\")(x)  model = keras.Model(inputs=inputs, outputs=outputs) def compute_loss_and_updates(     trainable_variables, non_trainable_variables, metric_variables, x, y ):     y_pred, non_trainable_variables, losses = model.stateless_call(         trainable_variables, non_trainable_variables, x, return_losses=True     )     loss = loss_fn(y, y_pred)     if losses:         loss += jax.numpy.sum(losses)     metric_variables = train_acc_metric.stateless_update_state(         metric_variables, y, y_pred     )     return loss, non_trainable_variables, metric_variables"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_tensorflow.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Writing a training loop from scratch in TensorFlow","text":"","code":"library(tensorflow, exclude = c(\"shape\", \"set_random_seed\")) library(tfdatasets, exclude = \"shape\") library(keras3)  # This guide can only be run with the TensorFlow backend. use_backend(\"tensorflow\")"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_tensorflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Writing a training loop from scratch in TensorFlow","text":"Keras provides default training evaluation loops, fit() evaluate(). usage covered guide Training & evaluation built-methods. want customize learning algorithm model still leveraging convenience fit() (instance, train GAN using fit()), can subclass Model class implement train_step() method, called repeatedly fit(). covered guide Customizing happens fit(). Now, want low-level control training & evaluation, write training & evaluation loops scratch. guide .","code":""},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_tensorflow.html","id":"using-the-gradienttape-a-first-end-to-end-example","dir":"Articles","previous_headings":"","what":"Using the GradientTape: a first end-to-end example","title":"Writing a training loop from scratch in TensorFlow","text":"Calling model inside GradientTape scope enables retrieve gradients trainable weights layer respect loss value. Using optimizer instance, can use gradients update variables (can retrieve using model$trainable_weights). Let’s consider simple MNIST model: Let’s train using mini-batch gradient custom training loop. First, ’re going need optimizer, loss function, dataset: ’s training loop: open loop iterates epochs epoch, iterate dataset, batches batch, open GradientTape() scope Inside scope, call model (forward pass) compute loss Outside scope, retrieve gradients weights model regard loss Finally, use optimizer update weights model based gradients","code":"get_model <- function() {   inputs <- keras_input(shape = 784, name = \"digits\")   outputs <- inputs |>     layer_dense(units = 64, activation = \"relu\") |>     layer_dense(units = 64, activation = \"relu\") |>     layer_dense(units = 10, name = \"predictions\")   keras_model(inputs = inputs, outputs = outputs) }  model <- get_model() # Instantiate an optimizer. optimizer <- optimizer_adam(learning_rate = 1e-3) # Instantiate a loss function. loss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)  # Prepare the training dataset. batch_size <- 64 c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist() x_train <- array_reshape(x_train, c(-1, 784)) x_test <- array_reshape(x_test, c(-1, 784))  # Reserve 10,000 samples for validation. val_i <- sample.int(nrow(x_train), 10000) x_val <- x_train[val_i,] y_val <- y_train[val_i] x_train %<>% .[-val_i,] y_train %<>% .[-val_i]  # Prepare the training dataset. train_dataset <- list(x_train, y_train) |>   tensor_slices_dataset() |>   dataset_shuffle(buffer_size = 1024) |>   dataset_batch(batch_size)  # Prepare the validation dataset. val_dataset <- list(x_val, y_val) |>   tensor_slices_dataset() |>   dataset_batch(batch_size) epochs <- 3 for (epoch in seq_len(epochs)) {   cat(\"Start of epoch \", epoch, \"\\n\")    # Iterate over the batches of the dataset.   step <- 0   iterator <- as_iterator(train_dataset)   while (!is.null(batch <- iter_next(iterator))) {     c(x_batch_train, y_batch_train) %<-% batch     step <- step + 1     # Open a GradientTape to record the operations run     # during the forward pass, which enables auto-differentiation.     with(tf$GradientTape() %as% tape, {       # Run the forward pass of the layer.       # The operations that the layer applies       # to its inputs are going to be recorded       # on the GradientTape.       logits <- model(x_batch_train, training = TRUE) # Logits for this minibatch        # Compute the loss value for this minibatch.       loss_value <- loss_fn(y_batch_train, logits)     })      # Use the gradient tape to automatically retrieve     # the gradients of the trainable variables with respect to the loss.     gradients <- tape$gradient(loss_value, model$trainable_weights)      # Run one step of gradient descent by updating     # the value of the variables to minimize the loss.     optimizer$apply(gradients, model$trainable_weights)      # Log every 200 batches.     if (step %% 200 == 0) {       cat(sprintf(\"Training loss (for one batch) at step %d: %.4f\\n\",                   step, loss_value))       cat(sprintf(\"Seen so far: %d samples\\n\", (step * batch_size)))     }   } } ## Start of epoch  1 ## Training loss (for one batch) at step 200: 3.3590 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 1.3350 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 1.0661 ## Seen so far: 38400 samples ## Start of epoch  2 ## Training loss (for one batch) at step 200: 0.4888 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 0.2022 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 0.4818 ## Seen so far: 38400 samples ## Start of epoch  3 ## Training loss (for one batch) at step 200: 0.2061 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 0.6720 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 0.2079 ## Seen so far: 38400 samples"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_tensorflow.html","id":"low-level-handling-of-metrics","dir":"Articles","previous_headings":"","what":"Low-level handling of metrics","title":"Writing a training loop from scratch in TensorFlow","text":"Let’s add metrics monitoring basic loop. can readily reuse built-metrics (custom ones wrote) training loops written scratch. ’s flow: Instantiate metric start loop Call metric$update_state() batch Call metric$result() need display current value metric Call metric$reset_state() need clear state metric (typically end epoch) Let’s use knowledge compute SparseCategoricalAccuracy validation data end epoch: ’s training & evaluation loop:","code":"# Get a fresh model model <- get_model()  # Instantiate an optimizer to train the model. optimizer <- optimizer_adam(learning_rate = 1e-3) # Instantiate a loss function. loss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)  # Prepare the metrics. train_acc_metric <- metric_sparse_categorical_accuracy() val_acc_metric <- metric_sparse_categorical_accuracy() epochs <- 2 time <- Sys.time() for (epoch in seq_len(epochs)) {   cat(\"Start of epoch \", epoch, \"\\n\")    # Iterate over the batches of the dataset.   step <- 0   train_dataset_iterator <- as_iterator(train_dataset)   while (!is.null(train_batch <- iter_next(train_dataset_iterator))) {     c(x_batch_train, y_batch_train) %<-% train_batch     step <- step + 1      with(tf$GradientTape() %as% tape, {       logits <- model(x_batch_train, training = TRUE)       loss_value <- loss_fn(y_batch_train, logits)     })     gradients <- tape$gradient(loss_value, model$trainable_weights)     optimizer$apply(gradients, model$trainable_weights)      # Update training metric.     train_acc_metric$update_state(y_batch_train, logits)     if (step %% 200 == 0) {       cat(sprintf(         \"Training loss (for one batch) at step %d: %.4f\\n\", step, loss_value))       cat(sprintf(\"Seen so far: %d samples \\n\", (step * batch_size)))     }   }    # Display metrics at the end of each epoch.   train_acc <- train_acc_metric$result()   cat(sprintf(\"Training acc over epoch: %.4f\\n\", train_acc))    # Reset training metrics at the end of each epoch   train_acc_metric$reset_state()    # Run a validation loop at the end of each epoch.   iterate(val_dataset, function(val_batch) {     c(x_batch_val, y_batch_val) %<-% val_batch     val_logits <- model(x_batch_val, training = FALSE)     val_acc_metric$update_state(y_batch_val, val_logits)   })   val_acc <- val_acc_metric$result()   val_acc_metric$reset_state()   cat(sprintf(\"Validation acc: %.4f\\n\", val_acc)) } ## Start of epoch  1 ## Training loss (for one batch) at step 200: 1.6122 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 1.9804 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 0.7561 ## Seen so far: 38400 samples ## Training acc over epoch: 0.8143 ## Validation acc: 0.8817 ## Start of epoch  2 ## Training loss (for one batch) at step 200: 0.5871 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 0.8091 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 0.3019 ## Seen so far: 38400 samples ## Training acc over epoch: 0.8967 ## Validation acc: 0.8969 Sys.time() - time ## Time difference of 38.69371 secs"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_tensorflow.html","id":"speeding-up-your-training-step-with-tf_function","dir":"Articles","previous_headings":"","what":"Speeding-up your training step with tf_function()","title":"Writing a training loop from scratch in TensorFlow","text":"default runtime TensorFlow 2 eager execution. , training loop executes eagerly. great debugging, graph compilation definite performance advantage. Describing computation static graph enables framework apply global performance optimizations. impossible framework constrained greedily execute one operation another, knowledge comes next. can compile static graph function takes tensors input. Just add @tf.function decorator , like : Let’s evaluation step: Now, let’s re-run training loop compiled training step: Much faster, isn’t ?","code":"train_step <- tf_function(function(x, y) {   with(tf$GradientTape() %as% tape, {     logits <- model(x, training = TRUE)     loss_value <- loss_fn(y, logits)   })   gradients <- tape$gradient(loss_value, model$trainable_weights)   optimizer$apply(gradients, model$trainable_weights)   train_acc_metric$update_state(y, logits)   invisible(NULL) # return nothing }) test_step <- tf_function(function(x, y) {   val_logits <- model(x, training=FALSE)   val_acc_metric$update_state(y, val_logits)   invisible(NULL) # return nothing }) epochs <- 2 time <- Sys.time() for (epoch in seq_len(epochs)) {   cat(\"Start of epoch \", epoch, \"\\n\")    # Iterate over the batches of the dataset.   step <- 0   while (!is.null(batch <- iter_next(iterator))) {     c(x_batch_train, y_batch_train) %<-% batch     step <- step + 1     train_step(x_batch_train, y_batch_train)      if (step %% 200 == 0) {       cat(sprintf(         \"Training loss (for one batch) at step %d: %.4f\\n\", step, loss_value       ))       cat(sprintf(\"Seen so far: %d samples \\n\", (step * batch_size)))     }   }    # Display metrics at the end of each epoch.   train_acc <- train_acc_metric$result()   cat(sprintf(\"Training acc over epoch: %.4f\\n\", train_acc))     # Reset training metrics at the end of each epoch   train_acc_metric$reset_state()    # Run a validation loop at the end of each epoch.    iterate(val_dataset, function(val_batch) {     c(x_batch_val, y_batch_val) %<-% val_batch     test_step(x_batch_val, y_batch_val)   })    val_acc <- val_acc_metric$result()   val_acc_metric$reset_state()   cat(sprintf(\"Validation acc: %.4f\\n\", val_acc)) } ## Start of epoch  1 ## Training acc over epoch: 0.0000 ## Validation acc: 0.8969 ## Start of epoch  2 ## Training acc over epoch: 0.0000 ## Validation acc: 0.8969 Sys.time() - time ## Time difference of 0.4174116 secs"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_tensorflow.html","id":"low-level-handling-of-losses-tracked-by-the-model","dir":"Articles","previous_headings":"","what":"Low-level handling of losses tracked by the model","title":"Writing a training loop from scratch in TensorFlow","text":"Layers models recursively track losses created forward pass layers call self$add_loss(value). resulting list scalar loss values available via property model$losses end forward pass. want using loss components, sum add main loss training step. Consider layer, creates activity regularization loss: Let’s build really simple model uses : ’s training step look like now:","code":"layer_activity_regularization <- Layer(   \"ActivityRegularizationLayer\",   call = function(inputs) {     self$add_loss(0.1 * op_mean(inputs))     inputs   } ) inputs <- keras_input(shape = 784, name=\"digits\") outputs <- inputs |>   layer_dense(units = 64, activation = \"relu\") |>   layer_activity_regularization() |>   layer_dense(units = 64, activation = \"relu\") |>   layer_dense(units = 10, name = \"predictions\") model <- keras_model(inputs = inputs, outputs = outputs) train_step <- tf_function(function(x, y) {   with(tf$GradientTape() %as% tape, {     logits <- model(x, training = TRUE)     loss_value <- Reduce(`+`, c(loss_fn(y, logits),                                 model$losses))   })   gradients <- tape$gradient(loss_value, model$trainable_weights)   optimizer$apply(gradients, model$trainable_weights)   train_acc_metric$update_state(y, logits)   invisible(NULL) })"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_tensorflow.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Writing a training loop from scratch in TensorFlow","text":"Now know everything know using built-training loops writing scratch. conclude, ’s simple end--end example ties together everything ’ve learned guide: DCGAN trained MNIST digits.","code":""},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_tensorflow.html","id":"end-to-end-example-a-gan-training-loop-from-scratch","dir":"Articles","previous_headings":"","what":"End-to-end example: a GAN training loop from scratch","title":"Writing a training loop from scratch in TensorFlow","text":"may familiar Generative Adversarial Networks (GANs). GANs can generate new images look almost real, learning latent distribution training dataset images (“latent space” images). GAN made two parts: “generator” model maps points latent space points image space, “discriminator” model, classifier can tell difference real images (training dataset) fake images (output generator network). GAN training loop looks like : Train discriminator. Sample batch random points latent space. Turn points fake images via “generator” model. Get batch real images combine generated images. Train “discriminator” model classify generated vs. real images. Train generator. Sample random points latent space. Turn points fake images via “generator” network. Get batch real images combine generated images. Train “generator” model “fool” discriminator classify fake images real. much detailed overview GANs works, see Deep Learning Python. Let’s implement training loop. First, create discriminator meant classify fake vs real digits: let’s create generator network, turns latent vectors outputs shape (28, 28, 1) (representing MNIST digits): ’s key bit: training loop. can see quite straightforward. training step function takes 17 lines. Let’s train GAN, repeatedly calling train_step batches images. Since discriminator generator convnets, ’re going want run code GPU. ’s ! ’ll get nice-looking fake MNIST digits just ~30s training GPU.","code":"# Create the discriminator discriminator <-   keras_model_sequential(name = \"discriminator\",                          input_shape = c(28, 28, 1)) |>   layer_conv_2d(filters = 64, kernel_size = c(3, 3),                 strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_conv_2d(filters = 128, kernel_size = c(3, 3),                 strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_global_max_pooling_2d() |>   layer_dense(units = 1)  summary(discriminator) ## Model: \"discriminator\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ conv2d_1 (Conv2D)               │ (None, 14, 14, 64)     │           640 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu_1 (LeakyReLU)       │ (None, 14, 14, 64)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 7, 7, 128)      │        73,856 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu (LeakyReLU)         │ (None, 7, 7, 128)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ global_max_pooling2d            │ (None, 128)            │             0 │ ## │ (GlobalMaxPooling2D)            │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_6 (Dense)                 │ (None, 1)              │           129 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 74,625 (291.50 KB) ##  Trainable params: 74,625 (291.50 KB) ##  Non-trainable params: 0 (0.00 B) latent_dim <- 128L  generator <-   keras_model_sequential(name = \"generator\",                          input_shape = latent_dim) |>   layer_dense(7 * 7 * 128) |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_reshape(target_shape = c(7, 7, 128)) |>   layer_conv_2d_transpose(filters = 128, kernel_size = c(4, 4),                           strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_conv_2d_transpose(filters = 128, kernel_size = c(4, 4),                           strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_conv_2d(filters = 1, kernel_size = c(7, 7), padding = \"same\",                 activation = \"sigmoid\")  summary(generator) ## Model: \"generator\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ dense_7 (Dense)                 │ (None, 6272)           │       809,088 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu_4 (LeakyReLU)       │ (None, 6272)           │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ reshape (Reshape)               │ (None, 7, 7, 128)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_1              │ (None, 14, 14, 128)    │       262,272 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu_3 (LeakyReLU)       │ (None, 14, 14, 128)    │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose                │ (None, 28, 28, 128)    │       262,272 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu_2 (LeakyReLU)       │ (None, 28, 28, 128)    │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_2 (Conv2D)               │ (None, 28, 28, 1)      │         6,273 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 1,339,905 (5.11 MB) ##  Trainable params: 1,339,905 (5.11 MB) ##  Non-trainable params: 0 (0.00 B) # Instantiate one optimizer for the discriminator and another for the generator. d_optimizer <- optimizer_adam(learning_rate = 0.0003) g_optimizer <- optimizer_adam(learning_rate = 0.0004)  # Instantiate a loss function. loss_fn <- loss_binary_crossentropy(from_logits = TRUE)  train_step <- tf_function(function(real_images) {   # Sample random points in the latent space   c(batch_size, ...) %<-% op_shape(real_images)   random_latent_vectors <-     tf$random$normal(shape(batch_size, latent_dim))    # Decode them to fake images   generated_images <- generator(random_latent_vectors)    # Combine them with real images   combined_images <- tf$concat(list(generated_images, real_images),                                axis = 0L)    # Assemble labels discriminating real from fake images   labels <- tf$concat(list(tf$ones(shape(batch_size, 1)),                            tf$zeros(shape(batch_size, 1))),                       axis = 0L)    # Add random noise to the labels - important trick!   labels %<>% `+`(tf$random$uniform(tf$shape(.), maxval = 0.05))    # Train the discriminator   with(tf$GradientTape() %as% tape, {     predictions <- discriminator(combined_images)     d_loss <- loss_fn(labels, predictions)   })   grads <- tape$gradient(d_loss, discriminator$trainable_weights)   d_optimizer$apply(grads, discriminator$trainable_weights)    # Sample random points in the latent space   random_latent_vectors <-     tf$random$normal(shape(batch_size, latent_dim))    # Assemble labels that say \"all real images\"   misleading_labels <- tf$zeros(shape(batch_size, 1))    # Train the generator (note that we should *not* update the weights   # of the discriminator)!   with(tf$GradientTape() %as% tape, {     predictions <- discriminator(generator(random_latent_vectors))     g_loss <- loss_fn(misleading_labels, predictions)   })    grads <- tape$gradient(g_loss, generator$trainable_weights)   g_optimizer$apply(grads, generator$trainable_weights)    list(d_loss, g_loss, generated_images) }) # Prepare the dataset. We use both the training & test MNIST digits. batch_size <- 64 c(c(x_train, .), c(x_test, .)) %<-% dataset_mnist() all_digits <- op_concatenate(list(x_train, x_test)) all_digits <- op_reshape(all_digits, c(-1, 28, 28, 1)) dataset <- all_digits |>   tensor_slices_dataset() |>   dataset_map(\\(x) op_cast(x, \"float32\") / 255) |>   dataset_shuffle(buffer_size = 1024) |>   dataset_batch(batch_size = batch_size)  epochs <- 1 # In practice you need at least 20 epochs to generate nice digits. save_dir <- \"./\"  for (epoch in seq_len(epochs)) {   cat(\"Start epoch: \", epoch, \"\\n\")   step <- 0   train_iterator <- as_iterator(dataset)   while (!is.null(real_images <- iter_next(train_iterator))) {     step <- step + 1     # Train the discriminator & generator on one batch of real images.     c(d_loss, g_loss, generated_images) %<-% train_step(real_images)      # Logging.     if (step %% 200 == 0) {       # Print metrics       cat(sprintf(\"discriminator loss at step %d: %.2f\\n\", step, d_loss))       cat(sprintf(\"adversarial loss at step %d: %.2f\\n\", step, g_loss))     }      # To limit execution time we stop after 10 steps.     # Remove the lines below to actually train the model!     if (step > 10)       break   } } ## Start epoch:  1"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_torch.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Writing a training loop from scratch in PyTorch","text":"","code":"import os  # This guide can only be run with the torch backend. os.environ[\"KERAS_BACKEND\"] = \"torch\"  import torch import keras import numpy as np"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_torch.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Writing a training loop from scratch in PyTorch","text":"Keras provides default training evaluation loops, fit() evaluate(). usage covered guide Training & evaluation built-methods. want customize learning algorithm model still leveraging convenience fit() (instance, train GAN using fit()), can subclass Model class implement train_step() method, called repeatedly fit(). Now, want low-level control training & evaluation, write training & evaluation loops scratch. guide .","code":""},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_torch.html","id":"a-first-end-to-end-example","dir":"Articles","previous_headings":"","what":"A first end-to-end example","title":"Writing a training loop from scratch in PyTorch","text":"write custom training loop, need following ingredients: model train, course. optimizer. either use keras.optimizers optimizer, native PyTorch optimizer torch.optim. loss function. either use keras.losses loss, native PyTorch loss torch.nn. dataset. use format: tf.data.Dataset, PyTorch DataLoader, Python generator, etc. Let’s line . ’ll use torch-native objects case – except, course, Keras model. First, let’s get model MNIST dataset: Next, ’s PyTorch optimizer PyTorch loss function: Let’s train model using mini-batch gradient custom training loop. Calling loss.backward() loss tensor triggers backpropagation. ’s done, optimizer magically aware gradients variable can update variables, done via optimizer.step(). Tensors, variables, optimizers interconnected one another via hidden global state. Also, don’t forget call model.zero_grad() loss.backward(), won’t get right gradients variables. ’s training loop, step step: open loop iterates epochs epoch, open loop iterates dataset, batches batch, call model input data retrive predictions, use compute loss value call loss.backward() Outside scope, retrieve gradients weights model regard loss Finally, use optimizer update weights model based gradients alternative, let’s look loop looks like using Keras optimizer Keras loss function. Important differences: retrieve gradients variables via v.value.grad, called trainable variable. update variables via optimizer.apply(), must called torch.no_grad() scope. Also, big gotcha: NumPy/TensorFlow/JAX/Keras APIs well Python unittest APIs use argument order convention fn(y_true, y_pred) (reference values first, predicted values second), PyTorch actually uses fn(y_pred, y_true) losses. make sure invert order logits targets.","code":"# Let's consider a simple MNIST model def get_model():     inputs = keras.Input(shape=(784,), name=\"digits\")     x1 = keras.layers.Dense(64, activation=\"relu\")(inputs)     x2 = keras.layers.Dense(64, activation=\"relu\")(x1)     outputs = keras.layers.Dense(10, name=\"predictions\")(x2)     model = keras.Model(inputs=inputs, outputs=outputs)     return model   # Create load up the MNIST dataset and put it in a torch DataLoader # Prepare the training dataset. batch_size = 32 (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = np.reshape(x_train, (-1, 784)).astype(\"float32\") x_test = np.reshape(x_test, (-1, 784)).astype(\"float32\") y_train = keras.utils.to_categorical(y_train) y_test = keras.utils.to_categorical(y_test)  # Reserve 10,000 samples for validation. x_val = x_train[-10000:] y_val = y_train[-10000:] x_train = x_train[:-10000] y_train = y_train[:-10000]  # Create torch Datasets train_dataset = torch.utils.data.TensorDataset(     torch.from_numpy(x_train), torch.from_numpy(y_train) ) val_dataset = torch.utils.data.TensorDataset(     torch.from_numpy(x_val), torch.from_numpy(y_val) )  # Create DataLoaders for the Datasets train_dataloader = torch.utils.data.DataLoader(     train_dataset, batch_size=batch_size, shuffle=True ) val_dataloader = torch.utils.data.DataLoader(     val_dataset, batch_size=batch_size, shuffle=False ) # Instantiate a torch optimizer model = get_model() optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Instantiate a torch loss function loss_fn = torch.nn.CrossEntropyLoss() epochs = 3 for epoch in range(epochs):     for step, (inputs, targets) in enumerate(train_dataloader):         # Forward pass         logits = model(inputs)         loss = loss_fn(logits, targets)          # Backward pass         model.zero_grad()         loss.backward()          # Optimizer variable updates         optimizer.step()          # Log every 100 batches.         if step % 100 == 0:             print(                 f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\"             )             print(f\"Seen so far: {(step + 1) * batch_size} samples\") model = get_model() optimizer = keras.optimizers.Adam(learning_rate=1e-3) loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)  for epoch in range(epochs):     print(f\"\\nStart of epoch {epoch}\")     for step, (inputs, targets) in enumerate(train_dataloader):         # Forward pass         logits = model(inputs)         loss = loss_fn(targets, logits)          # Backward pass         model.zero_grad()         trainable_weights = [v for v in model.trainable_weights]          # Call torch.Tensor.backward() on the loss to compute gradients         # for the weights.         loss.backward()         gradients = [v.value.grad for v in trainable_weights]          # Update weights         with torch.no_grad():             optimizer.apply(gradients, trainable_weights)          # Log every 100 batches.         if step % 100 == 0:             print(                 f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\"             )             print(f\"Seen so far: {(step + 1) * batch_size} samples\")"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_torch.html","id":"low-level-handling-of-metrics","dir":"Articles","previous_headings":"","what":"Low-level handling of metrics","title":"Writing a training loop from scratch in PyTorch","text":"Let’s add metrics monitoring basic training loop. can readily reuse built-Keras metrics (custom ones wrote) training loops written scratch. ’s flow: Instantiate metric start loop Call metric.update_state() batch Call metric.result() need display current value metric Call metric.reset_state() need clear state metric (typically end epoch) Let’s use knowledge compute CategoricalAccuracy training validation data end epoch: ’s training & evaluation loop:","code":"# Get a fresh model model = get_model()  # Instantiate an optimizer to train the model. optimizer = keras.optimizers.Adam(learning_rate=1e-3) # Instantiate a loss function. loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)  # Prepare the metrics. train_acc_metric = keras.metrics.CategoricalAccuracy() val_acc_metric = keras.metrics.CategoricalAccuracy() for epoch in range(epochs):     print(f\"\\nStart of epoch {epoch}\")     for step, (inputs, targets) in enumerate(train_dataloader):         # Forward pass         logits = model(inputs)         loss = loss_fn(targets, logits)          # Backward pass         model.zero_grad()         trainable_weights = [v for v in model.trainable_weights]          # Call torch.Tensor.backward() on the loss to compute gradients         # for the weights.         loss.backward()         gradients = [v.value.grad for v in trainable_weights]          # Update weights         with torch.no_grad():             optimizer.apply(gradients, trainable_weights)          # Update training metric.         train_acc_metric.update_state(targets, logits)          # Log every 100 batches.         if step % 100 == 0:             print(                 f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\"             )             print(f\"Seen so far: {(step + 1) * batch_size} samples\")      # Display metrics at the end of each epoch.     train_acc = train_acc_metric.result()     print(f\"Training acc over epoch: {float(train_acc):.4f}\")      # Reset training metrics at the end of each epoch     train_acc_metric.reset_state()      # Run a validation loop at the end of each epoch.     for x_batch_val, y_batch_val in val_dataloader:         val_logits = model(x_batch_val, training=False)         # Update val metrics         val_acc_metric.update_state(y_batch_val, val_logits)     val_acc = val_acc_metric.result()     val_acc_metric.reset_state()     print(f\"Validation acc: {float(val_acc):.4f}\")"},{"path":"https://keras.posit.co/articles/writing_a_custom_training_loop_in_torch.html","id":"low-level-handling-of-losses-tracked-by-the-model","dir":"Articles","previous_headings":"","what":"Low-level handling of losses tracked by the model","title":"Writing a training loop from scratch in PyTorch","text":"Layers & models recursively track losses created forward pass layers call self.add_loss(value). resulting list scalar loss values available via property model.losses end forward pass. want using loss components, sum add main loss training step. Consider layer, creates activity regularization loss: Let’s build really simple model uses : ’s training loop look like now: ’s !","code":"class ActivityRegularizationLayer(keras.layers.Layer):     def call(self, inputs):         self.add_loss(1e-2 * torch.sum(inputs))         return inputs inputs = keras.Input(shape=(784,), name=\"digits\") x = keras.layers.Dense(64, activation=\"relu\")(inputs) # Insert activity regularization as a layer x = ActivityRegularizationLayer()(x) x = keras.layers.Dense(64, activation=\"relu\")(x) outputs = keras.layers.Dense(10, name=\"predictions\")(x)  model = keras.Model(inputs=inputs, outputs=outputs) # Get a fresh model model = get_model()  # Instantiate an optimizer to train the model. optimizer = keras.optimizers.Adam(learning_rate=1e-3) # Instantiate a loss function. loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)  # Prepare the metrics. train_acc_metric = keras.metrics.CategoricalAccuracy() val_acc_metric = keras.metrics.CategoricalAccuracy()  for epoch in range(epochs):     print(f\"\\nStart of epoch {epoch}\")     for step, (inputs, targets) in enumerate(train_dataloader):         # Forward pass         logits = model(inputs)         loss = loss_fn(targets, logits)         if model.losses:             loss = loss + torch.sum(*model.losses)          # Backward pass         model.zero_grad()         trainable_weights = [v for v in model.trainable_weights]          # Call torch.Tensor.backward() on the loss to compute gradients         # for the weights.         loss.backward()         gradients = [v.value.grad for v in trainable_weights]          # Update weights         with torch.no_grad():             optimizer.apply(gradients, trainable_weights)          # Update training metric.         train_acc_metric.update_state(targets, logits)          # Log every 100 batches.         if step % 100 == 0:             print(                 f\"Training loss (for 1 batch) at step {step}: {loss.detach().numpy():.4f}\"             )             print(f\"Seen so far: {(step + 1) * batch_size} samples\")      # Display metrics at the end of each epoch.     train_acc = train_acc_metric.result()     print(f\"Training acc over epoch: {float(train_acc):.4f}\")      # Reset training metrics at the end of each epoch     train_acc_metric.reset_state()      # Run a validation loop at the end of each epoch.     for x_batch_val, y_batch_val in val_dataloader:         val_logits = model(x_batch_val, training=False)         # Update val metrics         val_acc_metric.update_state(y_batch_val, val_logits)     val_acc = val_acc_metric.result()     val_acc_metric.reset_state()     print(f\"Validation acc: {float(val_acc):.4f}\")"},{"path":"https://keras.posit.co/articles/writing_a_training_loop_from_scratch.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Writing a training loop from scratch in TensorFlow","text":"","code":"library(tensorflow) library(tfdatasets) library(keras3, warn.conflicts = FALSE)  # This guide can only be run with the TensorFlow backend. use_backend(\"tensorflow\")"},{"path":"https://keras.posit.co/articles/writing_a_training_loop_from_scratch.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Writing a training loop from scratch in TensorFlow","text":"Keras provides default training evaluation loops, fit() evaluate(). usage covered guide Training & evaluation built-methods. want customize learning algorithm model still leveraging convenience fit() (instance, train GAN using fit()), can subclass Model class implement train_step() method, called repeatedly fit(). covered guide Customizing happens fit(). Now, want low-level control training & evaluation, write training & evaluation loops scratch. guide .","code":""},{"path":"https://keras.posit.co/articles/writing_a_training_loop_from_scratch.html","id":"using-the-gradienttape-a-first-end-to-end-example","dir":"Articles","previous_headings":"","what":"Using the GradientTape: a first end-to-end example","title":"Writing a training loop from scratch in TensorFlow","text":"Calling model inside GradientTape scope enables retrieve gradients trainable weights layer respect loss value. Using optimizer instance, can use gradients update variables (can retrieve using model$trainable_weights). Let’s consider simple MNIST model: Let’s train using mini-batch gradient custom training loop. First, ’re going need optimizer, loss function, dataset: ’s training loop: open loop iterates epochs epoch, iterate dataset, batches batch, open GradientTape() scope Inside scope, call model (forward pass) compute loss Outside scope, retrieve gradients weights model regard loss Finally, use optimizer update weights model based gradients","code":"get_model <- function() {   inputs <- keras_input(shape = 784, name = \"digits\")   outputs <- inputs |>     layer_dense(units = 64, activation = \"relu\") |>     layer_dense(units = 64, activation = \"relu\") |>     layer_dense(units = 10, name = \"predictions\")   keras_model(inputs = inputs, outputs = outputs) }  model <- get_model() # Instantiate an optimizer. optimizer <- optimizer_adam(learning_rate = 1e-3) # Instantiate a loss function. loss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)  # Prepare the training dataset. batch_size <- 64 c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist() x_train <- array_reshape(x_train, c(-1, 784)) x_test <- array_reshape(x_test, c(-1, 784))  # Reserve 10,000 samples for validation. x_val <- x_train[1:10000, ] y_val <- y_train[1:10000] x_train = x_train[-c(1:10000), ] y_train = y_train[-c(1:10000)]  # Prepare the training dataset. train_dataset <- list(x_train, y_train) |>   tensor_slices_dataset() |>   dataset_shuffle(buffer_size = 1024) |>   dataset_batch(batch_size)  # Prepare the validation dataset. val_dataset <- list(x_val, y_val) |>   tensor_slices_dataset() |>   dataset_batch(batch_size) epochs <- 3 for (epoch in seq_len(epochs)) {   cat(\"\\nStart of epoch \", epoch, \"\\n\")    # Iterate over the batches of the dataset.   step <- 0   iterator <- as_iterator(train_dataset)   while (!is.null(batch <- iter_next(iterator))) {     c(x_batch_train, y_batch_train) %<-% batch     step <- step + 1     # Open a GradientTape to record the operations run     # during the forward pass, which enables auto-differentiation.     with(tf$GradientTape() %as% tape, {       # Run the forward pass of the layer.       # The operations that the layer applies       # to its inputs are going to be recorded       # on the GradientTape.       logits <- model(x_batch_train, training = TRUE) # Logits for this minibatch        # Compute the loss value for this minibatch.       loss_value <- loss_fn(y_batch_train, logits)     })      # Use the gradient tape to automatically retrieve     # the gradients of the trainable variables with respect to the loss.     gradients <- tape$gradient(loss_value, model$trainable_weights)      # Run one step of gradient descent by updating     # the value of the variables to minimize the loss.     optimizer$apply(gradients, model$trainable_weights)      # Log every 200 batches.     if (step %% 200 == 0) {       cat(sprintf(\"Training loss (for one batch) at step %d: %.4f\\n\",                   step, loss_value))       cat(sprintf(\"Seen so far: %d samples\\n\", (step * batch_size)))     }   } } ## ## Start of epoch  1 ## Training loss (for one batch) at step 200: 1.9342 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 0.8244 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 0.8011 ## Seen so far: 38400 samples ## ## Start of epoch  2 ## Training loss (for one batch) at step 200: 0.3505 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 0.6878 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 0.3928 ## Seen so far: 38400 samples ## ## Start of epoch  3 ## Training loss (for one batch) at step 200: 0.3366 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 0.1102 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 0.3629 ## Seen so far: 38400 samples"},{"path":"https://keras.posit.co/articles/writing_a_training_loop_from_scratch.html","id":"low-level-handling-of-metrics","dir":"Articles","previous_headings":"","what":"Low-level handling of metrics","title":"Writing a training loop from scratch in TensorFlow","text":"Let’s add metrics monitoring basic loop. can readily reuse built-metrics (custom ones wrote) training loops written scratch. ’s flow: Instantiate metric start loop Call metric$update_state() batch Call metric$result() need display current value metric Call metric$reset_state() need clear state metric (typically end epoch) Let’s use knowledge compute SparseCategoricalAccuracy validation data end epoch: ’s training & evaluation loop:","code":"# Get model model <- get_model()  # Instantiate an optimizer to train the model. optimizer <- optimizer_adam(learning_rate = 1e-3) # Instantiate a loss function. loss_fn <- loss_sparse_categorical_crossentropy(from_logits = TRUE)  # Prepare the metrics. train_acc_metric <- metric_sparse_categorical_accuracy() val_acc_metric <- metric_sparse_categorical_accuracy() epochs <- 2 time <- Sys.time() for (epoch in seq_len(epochs)) {   cat(\"Start of epoch \", epoch, \"\\n\")    # Iterate over the batches of the dataset.   step <- 0   iterator <- as_iterator(train_dataset)   while (!is.null(batch <- iter_next(iterator))) {     c(x_batch_train, y_batch_train) %<-% batch     step <- step + 1      with(tf$GradientTape() %as% tape, {       logits <- model(x_batch_train, training = TRUE)       loss_value <- loss_fn(y_batch_train, logits)     })     gradients <- tape$gradient(loss_value, model$trainable_weights)     optimizer$apply(gradients, model$trainable_weights)      # Update training metric.     train_acc_metric$update_state(y_batch_train, logits)     if (step %% 200 == 0) {       cat(sprintf(         \"Training loss (for one batch) at step %d: %.4f\\n\", step, loss_value))       cat(sprintf(\"Seen so far: %d samples \\n\", (step * batch_size)))     }   }    # Display metrics at the end of each epoch.   train_acc <- train_acc_metric$result()   cat(sprintf(\"Training acc over epoch: %.4f\\n\", train_acc))    # Reset training metrics at the end of each epoch   train_acc_metric$reset_state()    # Run a validation loop at the end of each epoch.   iterate(val_dataset, function(val_batch) {     c(x_batch_val, y_batch_val) %<-% val_batch     val_logits <- model(x_batch_val, training = FALSE)     val_acc_metric$update_state(y_batch_val, val_logits)   })   val_acc <- val_acc_metric$result()   val_acc_metric$reset_state()   cat(sprintf(\"Validation acc: %.4f\\n\", val_acc)) } ## Start of epoch  1 ## Training loss (for one batch) at step 200: 2.4070 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 0.8216 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 1.2056 ## Seen so far: 38400 samples ## Training acc over epoch: 0.8094 ## Validation acc: 0.8687 ## Start of epoch  2 ## Training loss (for one batch) at step 200: 0.1857 ## Seen so far: 12800 samples ## Training loss (for one batch) at step 400: 0.3803 ## Seen so far: 25600 samples ## Training loss (for one batch) at step 600: 0.3399 ## Seen so far: 38400 samples ## Training acc over epoch: 0.8859 ## Validation acc: 0.9002 Sys.time() - time ## Time difference of 44.61786 secs"},{"path":"https://keras.posit.co/articles/writing_a_training_loop_from_scratch.html","id":"speeding-up-your-training-step-with-tf_function","dir":"Articles","previous_headings":"","what":"Speeding-up your training step with tf_function()","title":"Writing a training loop from scratch in TensorFlow","text":"default runtime TensorFlow 2 eager execution. , training loop executes eagerly. great debugging, graph compilation definite performance advantage. Describing computation static graph enables framework apply global performance optimizations. impossible framework constrained greedily execute one operation another, knowledge comes next. can compile static graph function takes tensors input. Just add @tf.function decorator , like : Let’s evaluation step: Now, let’s re-run training loop compiled training step: Much faster, isn’t ?","code":"train_step <- tf_function(function(x, y) {   with(tf$GradientTape() %as% tape, {     logits <- model(x, training = TRUE)     loss_value <- loss_fn(y, logits)   })   gradients <- tape$gradient(loss_value, model$trainable_weights)   optimizer$apply(gradients, model$trainable_weights)   train_acc_metric$update_state(y, logits)   invisible(NULL) # return nothing }) test_step <- tf_function(function(x, y) {   val_logits <- model(x, training=FALSE)   val_acc_metric$update_state(y, val_logits)   invisible(NULL) # return nothing }) epochs <- 2 time <- Sys.time() for (epoch in seq_len(epochs)) {   cat(\"Start of epoch \", epoch, \"\\n\")    # Iterate over the batches of the dataset.   step <- 0   while (!is.null(batch <- iter_next(iterator))) {     c(x_batch_train, y_batch_train) %<-% batch     step <- step + 1     train_step(x_batch_train, y_batch_train)      if (step %% 200 == 0) {       cat(sprintf(         \"Training loss (for one batch) at step %d: %.4f\\n\", step, loss_value       ))       cat(sprintf(\"Seen so far: %d samples \\n\", (step * batch_size)))     }   }    # Display metrics at the end of each epoch.   train_acc <- train_acc_metric$result()   cat(sprintf(\"Training acc over epoch: %.4f\\n\", train_acc))     # Reset training metrics at the end of each epoch   train_acc_metric$reset_state()    # Run a validation loop at the end of each epoch.    iterate(val_dataset, function(val_batch) {     c(x_batch_val, y_batch_val) %<-% val_batch     test_step(x_batch_val, y_batch_val)   })    val_acc <- val_acc_metric$result()   val_acc_metric$reset_state()   cat(sprintf(\"Validation acc: %.4f\\n\", val_acc)) } ## Start of epoch  1 ## Training acc over epoch: 0.0000 ## Validation acc: 0.9002 ## Start of epoch  2 ## Training acc over epoch: 0.0000 ## Validation acc: 0.9002 Sys.time() - time ## Time difference of 0.5360565 secs"},{"path":"https://keras.posit.co/articles/writing_a_training_loop_from_scratch.html","id":"low-level-handling-of-losses-tracked-by-the-model","dir":"Articles","previous_headings":"","what":"Low-level handling of losses tracked by the model","title":"Writing a training loop from scratch in TensorFlow","text":"Layers models recursively track losses created forward pass layers call self$add_loss(value). resulting list scalar loss values available via property model$losses end forward pass. want using loss components, sum add main loss training step. Consider layer, creates activity regularization loss: Let’s build really simple model uses : ’s training step look like now:","code":"layer_activity_regularization <- Layer(   \"ActivityRegularizationLayer\",   call = function(inputs) {     self$add_loss(0.1 * op_mean(inputs))     inputs   } ) inputs <- keras_input(shape = 784, name=\"digits\") outputs <- inputs |>   layer_dense(units = 64, activation = \"relu\") |>   layer_activity_regularization() |>   layer_dense(units = 64, activation = \"relu\") |>   layer_dense(units = 10, name = \"predictions\") model <- keras_model(inputs = inputs, outputs = outputs) train_step <- tf_function(function(x, y) {   with(tf$GradientTape() %as% tape, {     logits <- model(x, training = TRUE)     loss_value <- Reduce(`+`, c(loss_fn(y, logits),                                 model$losses))   })   gradients <- tape$gradient(loss_value, model$trainable_weights)   optimizer$apply(gradients, model$trainable_weights)   train_acc_metric$update_state(y, logits)   invisible(NULL) })"},{"path":"https://keras.posit.co/articles/writing_a_training_loop_from_scratch.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Writing a training loop from scratch in TensorFlow","text":"Now know everything know using built-training loops writing scratch. conclude, ’s simple end--end example ties together everything ’ve learned guide: DCGAN trained MNIST digits.","code":""},{"path":"https://keras.posit.co/articles/writing_a_training_loop_from_scratch.html","id":"end-to-end-example-a-gan-training-loop-from-scratch","dir":"Articles","previous_headings":"","what":"End-to-end example: a GAN training loop from scratch","title":"Writing a training loop from scratch in TensorFlow","text":"may familiar Generative Adversarial Networks (GANs). GANs can generate new images look almost real, learning latent distribution training dataset images (“latent space” images). GAN made two parts: “generator” model maps points latent space points image space, “discriminator” model, classifier can tell difference real images (training dataset) fake images (output generator network). GAN training loop looks like : Train discriminator. Sample batch random points latent space. Turn points fake images via “generator” model. Get batch real images combine generated images. Train “discriminator” model classify generated vs. real images. Train generator. Sample random points latent space. Turn points fake images via “generator” network. Get batch real images combine generated images. Train “generator” model “fool” discriminator classify fake images real. much detailed overview GANs works, see Deep Learning Python. Let’s implement training loop. First, create discriminator meant classify fake vs real digits: let’s create generator network, turns latent vectors outputs shape (28, 28, 1) (representing MNIST digits): ’s key bit: training loop. can see quite straightforward. training step function takes 17 lines. Let’s train GAN, repeatedly calling train_step batches images. Since discriminator generator convnets, ’re going want run code GPU. ’s ! ’ll get nice-looking fake MNIST digits just ~30s training Colab GPU.","code":"# Create the discriminator discriminator <-   keras_model_sequential(name = \"discriminator\",                          input_shape = c(28, 28, 1)) |>   layer_conv_2d(filters = 64, kernel_size = c(3, 3),                 strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_conv_2d(filters = 128, kernel_size = c(3, 3),                 strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_global_max_pooling_2d() |>   layer_dense(units = 1)  summary(discriminator) ## Model: \"discriminator\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ conv2d_1 (Conv2D)               │ (None, 14, 14, 64)     │           640 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu_1 (LeakyReLU)       │ (None, 14, 14, 64)     │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d (Conv2D)                 │ (None, 7, 7, 128)      │        73,856 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu (LeakyReLU)         │ (None, 7, 7, 128)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ global_max_pooling2d            │ (None, 128)            │             0 │ ## │ (GlobalMaxPooling2D)            │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ dense_6 (Dense)                 │ (None, 1)              │           129 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 74,625 (291.50 KB) ##  Trainable params: 74,625 (291.50 KB) ##  Non-trainable params: 0 (0.00 B) latent_dim <- 128L  generator <-   keras_model_sequential(name = \"generator\",                          input_shape = latent_dim) |>   layer_dense(7 * 7 * 128) |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_reshape(target_shape = c(7, 7, 128)) |>   layer_conv_2d_transpose(filters = 128, kernel_size = c(4, 4),                           strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_conv_2d_transpose(filters = 128, kernel_size = c(4, 4),                           strides = c(2, 2), padding = \"same\") |>   layer_activation_leaky_relu(negative_slope = 0.2) |>   layer_conv_2d(filters = 1, kernel_size = c(7, 7), padding = \"same\",                 activation = \"sigmoid\")  summary(generator) ## Model: \"generator\" ## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ## ┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃ ## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ ## │ dense_7 (Dense)                 │ (None, 6272)           │       809,088 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu_4 (LeakyReLU)       │ (None, 6272)           │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ reshape (Reshape)               │ (None, 7, 7, 128)      │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose_1              │ (None, 14, 14, 128)    │       262,272 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu_3 (LeakyReLU)       │ (None, 14, 14, 128)    │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_transpose                │ (None, 28, 28, 128)    │       262,272 │ ## │ (Conv2DTranspose)               │                        │               │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ leaky_re_lu_2 (LeakyReLU)       │ (None, 28, 28, 128)    │             0 │ ## ├─────────────────────────────────┼────────────────────────┼───────────────┤ ## │ conv2d_2 (Conv2D)               │ (None, 28, 28, 1)      │         6,273 │ ## └─────────────────────────────────┴────────────────────────┴───────────────┘ ##  Total params: 1,339,905 (5.11 MB) ##  Trainable params: 1,339,905 (5.11 MB) ##  Non-trainable params: 0 (0.00 B) # Instantiate one optimizer for the discriminator and another for the generator. d_optimizer <- optimizer_adam(learning_rate = 0.0003) g_optimizer <- optimizer_adam(learning_rate = 0.0004)  # Instantiate a loss function. loss_fn <- loss_binary_crossentropy(from_logits = TRUE)  train_step <- tf_function(function(real_images) {   # Sample random points in the latent space   c(batch_size, ...) %<-% op_shape(real_images)   random_latent_vectors <-     tf$random$normal(shape(batch_size, latent_dim))    # Decode them to fake images   generated_images <- generator(random_latent_vectors)    # Combine them with real images   combined_images <- tf$concat(list(generated_images, real_images),                                axis = 0L)    # Assemble labels discriminating real from fake images   labels <- tf$concat(list(tf$ones(shape(batch_size, 1)),                            tf$zeros(shape(batch_size, 1))),                       axis = 0L)    # Add random noise to the labels - important trick!   labels %<>% `+`(tf$random$uniform(tf$shape(.), maxval = 0.05))    # Train the discriminator   with(tf$GradientTape() %as% tape, {     predictions <- discriminator(combined_images)     d_loss <- loss_fn(labels, predictions)   })   grads <- tape$gradient(d_loss, discriminator$trainable_weights)   d_optimizer$apply(grads, discriminator$trainable_weights)    # Sample random points in the latent space   random_latent_vectors <-     tf$random$normal(shape(batch_size, latent_dim))    # Assemble labels that say \"all real images\"   misleading_labels <- tf$zeros(shape(batch_size, 1))    # Train the generator (note that we should *not* update the weights   # of the discriminator)!   with(tf$GradientTape() %as% tape, {     predictions <- discriminator(generator(random_latent_vectors))     g_loss <- loss_fn(misleading_labels, predictions)   })    grads <- tape$gradient(g_loss, generator$trainable_weights)   g_optimizer$apply(grads, generator$trainable_weights)    list(d_loss, g_loss, generated_images) }) # Prepare the dataset. We use both the training & test MNIST digits. batch_size <- 64 c(c(x_train, .), c(x_test, .)) %<-% dataset_mnist() all_digits <- op_concatenate(list(x_train, x_test)) all_digits <- op_reshape(all_digits, c(-1, 28, 28, 1)) dataset <- all_digits |>   tfdatasets::tensor_slices_dataset() |>   tfdatasets::dataset_map(function(x) tf$cast(x, \"float\") / 255) |>   tfdatasets::dataset_shuffle(buffer_size = 1024) |>   tfdatasets::dataset_batch(batch_size = batch_size)  epochs <- 1 # In practice you need at least 20 epochs to generate nice digits. save_dir <- \"./\"  for (epoch in seq_len(epochs)) {   cat(\"Start epoch: \", epoch, \"\\n\")   step <- 0   train_iterator <- as_iterator(dataset)   while (!is.null(real_images <- iter_next(train_iterator))) {     step <- step + 1     # Train the discriminator & generator on one batch of real images.     c(d_loss, g_loss, generated_images) %<-% train_step(real_images)      # Logging.     if (step %% 200 == 0) {       # Print metrics       cat(sprintf(\"discriminator loss at step %d: %.2f\\n\", step, d_loss))       cat(sprintf(\"adversarial loss at step %d: %.2f\\n\", step, g_loss))     }      # To limit execution time we stop after 10 steps.     # Remove the lines below to actually train the model!     if (step > 10)       break   } } ## Start epoch:  1"},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Writing your own callbacks","text":"callback powerful tool customize behavior Keras model training, evaluation, inference. Examples include keras.callbacks.TensorBoard visualize training progress results TensorBoard, keras.callbacks.ModelCheckpoint periodically save model training. guide, learn Keras callback , can , can build . provide demos simple callback applications get started.","code":""},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Writing your own callbacks","text":"","code":"library(keras3)"},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"keras-callbacks-overview","dir":"Articles","previous_headings":"","what":"Keras callbacks overview","title":"Writing your own callbacks","text":"callbacks subclass keras.callbacks.Callback class, override set methods called various stages training, testing, predicting. Callbacks useful get view internal states statistics model training. can pass list callbacks (keyword argument callbacks) following model methods: fit() evaluate() predict()","code":""},{"path":[]},{"path":[]},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"on_traintestpredict_beginlogs-null","dir":"Articles","previous_headings":"An overview of callback methods > Global methods","what":"on_(train|test|predict)_begin(logs = NULL)","title":"Writing your own callbacks","text":"Called beginning fit/evaluate/predict.","code":""},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"on_traintestpredict_endlogs-null","dir":"Articles","previous_headings":"An overview of callback methods > Global methods","what":"on_(train|test|predict)_end(logs = NULL)","title":"Writing your own callbacks","text":"Called end fit/evaluate/predict.","code":""},{"path":[]},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"on_traintestpredict_batch_beginbatch-logs-null","dir":"Articles","previous_headings":"An overview of callback methods > Batch-level methods for training/testing/predicting","what":"on_(train|test|predict)_batch_begin(batch, logs = NULL)","title":"Writing your own callbacks","text":"Called right processing batch training/testing/predicting.","code":""},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"on_traintestpredict_batch_endbatch-logs-null","dir":"Articles","previous_headings":"An overview of callback methods > Batch-level methods for training/testing/predicting","what":"on_(train|test|predict)_batch_end(batch, logs = NULL)","title":"Writing your own callbacks","text":"Called end training/testing/predicting batch. Within method, logs named list containing metrics results.","code":""},{"path":[]},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"on_epoch_beginepoch-logs-null","dir":"Articles","previous_headings":"An overview of callback methods > Epoch-level methods (training only)","what":"on_epoch_begin(epoch, logs = NULL)","title":"Writing your own callbacks","text":"Called beginning epoch training.","code":""},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"on_epoch_endepoch-logs-null","dir":"Articles","previous_headings":"An overview of callback methods > Epoch-level methods (training only)","what":"on_epoch_end(epoch, logs = NULL)","title":"Writing your own callbacks","text":"Called end epoch training.","code":""},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"a-basic-example","dir":"Articles","previous_headings":"","what":"A basic example","title":"Writing your own callbacks","text":"Let’s take look concrete example. get started, let’s import tensorflow define simple Sequential Keras model: , load MNIST data training testing Keras datasets API: Now, define simple custom callback logs: fit/evaluate/predict starts & ends epoch starts & ends training batch starts & ends evaluation (test) batch starts & ends inference (prediction) batch starts & ends Let’s try :","code":"# Define the Keras model to add callbacks to get_model <- function() {   model <- keras_model_sequential()   model |> layer_dense(units = 1)   model |> compile(     optimizer = optimizer_rmsprop(learning_rate = 0.1),     loss = \"mean_squared_error\",     metrics = \"mean_absolute_error\"   )   model } # Load example MNIST data and pre-process it mnist <- dataset_mnist()  flatten_and_rescale <- function(x) {   x <- array_reshape(x, c(-1, 784))   x <- x / 255   x }  mnist$train$x <- flatten_and_rescale(mnist$train$x) mnist$test$x  <- flatten_and_rescale(mnist$test$x)  # limit to 1000 samples n <- 1000 mnist$train$x <- mnist$train$x[1:n,] mnist$train$y <- mnist$train$y[1:n] mnist$test$x  <- mnist$test$x[1:n,] mnist$test$y  <- mnist$test$y[1:n] show <- function(msg, logs) {   cat(glue::glue(msg, .envir = parent.frame()),       \"got logs: \", sep = \"; \")   str(logs); cat(\"\\n\") }  callback_custom <- Callback(   \"CustomCallback\",   on_train_begin         = \\(logs = NULL)        show(\"Starting training\", logs),   on_epoch_begin         = \\(epoch, logs = NULL) show(\"Start epoch {epoch} of training\", logs),   on_train_batch_begin   = \\(batch, logs = NULL) show(\"...Training: start of batch {batch}\", logs),   on_train_batch_end     = \\(batch, logs = NULL) show(\"...Training: end of batch {batch}\",  logs),   on_epoch_end           = \\(epoch, logs = NULL) show(\"End epoch {epoch} of training\", logs),   on_train_end           = \\(logs = NULL)        show(\"Stop training\", logs),     on_test_begin          = \\(logs = NULL)        show(\"Start testing\", logs),   on_test_batch_begin    = \\(batch, logs = NULL) show(\"...Evaluating: start of batch {batch}\", logs),   on_test_batch_end      = \\(batch, logs = NULL) show(\"...Evaluating: end of batch {batch}\", logs),   on_test_end            = \\(logs = NULL)        show(\"Stop testing\", logs),    on_predict_begin       = \\(logs = NULL)        show(\"Start predicting\", logs),   on_predict_end         = \\(logs = NULL)        show(\"Stop predicting\", logs),   on_predict_batch_begin = \\(batch, logs = NULL) show(\"...Predicting: start of batch {batch}\", logs),   on_predict_batch_end   = \\(batch, logs = NULL) show(\"...Predicting: end of batch {batch}\", logs), ) model <- get_model() model |> fit(   mnist$train$x, mnist$train$y,   batch_size = 128,   epochs = 2,   verbose = 0,   validation_split = 0.5,   callbacks = list(callback_custom()) ) ## Starting training; got logs:  Named list() ## ## Start epoch 1 of training; got logs:  Named list() ## ## ...Training: start of batch 1; got logs:  Named list() ## ## ...Training: end of batch 1; got logs: List of 2 ##  $ loss               : num 25.9 ##  $ mean_absolute_error: num 4.19 ## ## ...Training: start of batch 2; got logs:  Named list() ## ## ...Training: end of batch 2; got logs: List of 2 ##  $ loss               : num 433 ##  $ mean_absolute_error: num 15.5 ## ## ...Training: start of batch 3; got logs:  Named list() ## ## ...Training: end of batch 3; got logs: List of 2 ##  $ loss               : num 297 ##  $ mean_absolute_error: num 11.8 ## ## ...Training: start of batch 4; got logs:  Named list() ## ## ...Training: end of batch 4; got logs: List of 2 ##  $ loss               : num 226 ##  $ mean_absolute_error: num 9.68 ## ## Start testing; got logs:  Named list() ## ## ...Evaluating: start of batch 1; got logs:  Named list() ## ## ...Evaluating: end of batch 1; got logs: List of 2 ##  $ loss               : num 8.1 ##  $ mean_absolute_error: num 2.3 ## ## ...Evaluating: start of batch 2; got logs:  Named list() ## ## ...Evaluating: end of batch 2; got logs: List of 2 ##  $ loss               : num 7.58 ##  $ mean_absolute_error: num 2.23 ## ## ...Evaluating: start of batch 3; got logs:  Named list() ## ## ...Evaluating: end of batch 3; got logs: List of 2 ##  $ loss               : num 7.38 ##  $ mean_absolute_error: num 2.21 ## ## ...Evaluating: start of batch 4; got logs:  Named list() ## ## ...Evaluating: end of batch 4; got logs: List of 2 ##  $ loss               : num 7.29 ##  $ mean_absolute_error: num 2.21 ## ## Stop testing; got logs: List of 2 ##  $ loss               : num 7.29 ##  $ mean_absolute_error: num 2.21 ## ## End epoch 1 of training; got logs: List of 4 ##  $ loss                   : num 226 ##  $ mean_absolute_error    : num 9.68 ##  $ val_loss               : num 7.29 ##  $ val_mean_absolute_error: num 2.21 ## ## Start epoch 2 of training; got logs:  Named list() ## ## ...Training: start of batch 1; got logs:  Named list() ## ## ...Training: end of batch 1; got logs: List of 2 ##  $ loss               : num 7.44 ##  $ mean_absolute_error: num 2.27 ## ## ...Training: start of batch 2; got logs:  Named list() ## ## ...Training: end of batch 2; got logs: List of 2 ##  $ loss               : num 6.81 ##  $ mean_absolute_error: num 2.16 ## ## ...Training: start of batch 3; got logs:  Named list() ## ## ...Training: end of batch 3; got logs: List of 2 ##  $ loss               : num 6.12 ##  $ mean_absolute_error: num 2.06 ## ## ...Training: start of batch 4; got logs:  Named list() ## ## ...Training: end of batch 4; got logs: List of 2 ##  $ loss               : num 6.07 ##  $ mean_absolute_error: num 2.04 ## ## Start testing; got logs:  Named list() ## ## ...Evaluating: start of batch 1; got logs:  Named list() ## ## ...Evaluating: end of batch 1; got logs: List of 2 ##  $ loss               : num 5.54 ##  $ mean_absolute_error: num 1.92 ## ## ...Evaluating: start of batch 2; got logs:  Named list() ## ## ...Evaluating: end of batch 2; got logs: List of 2 ##  $ loss               : num 5.31 ##  $ mean_absolute_error: num 1.87 ## ## ...Evaluating: start of batch 3; got logs:  Named list() ## ## ...Evaluating: end of batch 3; got logs: List of 2 ##  $ loss               : num 5.11 ##  $ mean_absolute_error: num 1.8 ## ## ...Evaluating: start of batch 4; got logs:  Named list() ## ## ...Evaluating: end of batch 4; got logs: List of 2 ##  $ loss               : num 5.15 ##  $ mean_absolute_error: num 1.82 ## ## Stop testing; got logs: List of 2 ##  $ loss               : num 5.15 ##  $ mean_absolute_error: num 1.82 ## ## End epoch 2 of training; got logs: List of 4 ##  $ loss                   : num 6.07 ##  $ mean_absolute_error    : num 2.04 ##  $ val_loss               : num 5.15 ##  $ val_mean_absolute_error: num 1.82 ## ## Stop training; got logs: List of 4 ##  $ loss                   : num 6.07 ##  $ mean_absolute_error    : num 2.04 ##  $ val_loss               : num 5.15 ##  $ val_mean_absolute_error: num 1.82 res <- model |> evaluate(   mnist$test$x, mnist$test$y,   batch_size = 128, verbose = 0,   callbacks = list(callback_custom()) ) ## Start testing; got logs:  Named list() ## ## ...Evaluating: start of batch 1; got logs:  Named list() ## ## ...Evaluating: end of batch 1; got logs: List of 2 ##  $ loss               : num 5.2 ##  $ mean_absolute_error: num 1.84 ## ## ...Evaluating: start of batch 2; got logs:  Named list() ## ## ...Evaluating: end of batch 2; got logs: List of 2 ##  $ loss               : num 4.62 ##  $ mean_absolute_error: num 1.73 ## ## ...Evaluating: start of batch 3; got logs:  Named list() ## ## ...Evaluating: end of batch 3; got logs: List of 2 ##  $ loss               : num 4.61 ##  $ mean_absolute_error: num 1.74 ## ## ...Evaluating: start of batch 4; got logs:  Named list() ## ## ...Evaluating: end of batch 4; got logs: List of 2 ##  $ loss               : num 4.65 ##  $ mean_absolute_error: num 1.75 ## ## ...Evaluating: start of batch 5; got logs:  Named list() ## ## ...Evaluating: end of batch 5; got logs: List of 2 ##  $ loss               : num 4.84 ##  $ mean_absolute_error: num 1.77 ## ## ...Evaluating: start of batch 6; got logs:  Named list() ## ## ...Evaluating: end of batch 6; got logs: List of 2 ##  $ loss               : num 4.76 ##  $ mean_absolute_error: num 1.76 ## ## ...Evaluating: start of batch 7; got logs:  Named list() ## ## ...Evaluating: end of batch 7; got logs: List of 2 ##  $ loss               : num 4.74 ##  $ mean_absolute_error: num 1.76 ## ## ...Evaluating: start of batch 8; got logs:  Named list() ## ## ...Evaluating: end of batch 8; got logs: List of 2 ##  $ loss               : num 4.66 ##  $ mean_absolute_error: num 1.75 ## ## Stop testing; got logs: List of 2 ##  $ loss               : num 4.66 ##  $ mean_absolute_error: num 1.75 res <- model |> predict(   mnist$test$x,   batch_size = 128, verbose = 0,   callbacks = list(callback_custom()) ) ## Start predicting; got logs:  Named list() ## ## ...Predicting: start of batch 1; got logs:  Named list() ## ## ...Predicting: end of batch 1; got logs: List of 1 ##  $ outputs:<tf.Tensor: shape=(128, 1), dtype=float32, numpy=…> ## ## ...Predicting: start of batch 2; got logs:  Named list() ## ## ...Predicting: end of batch 2; got logs: List of 1 ##  $ outputs:<tf.Tensor: shape=(128, 1), dtype=float32, numpy=…> ## ## ...Predicting: start of batch 3; got logs:  Named list() ## ## ...Predicting: end of batch 3; got logs: List of 1 ##  $ outputs:<tf.Tensor: shape=(128, 1), dtype=float32, numpy=…> ## ## ...Predicting: start of batch 4; got logs:  Named list() ## ## ...Predicting: end of batch 4; got logs: List of 1 ##  $ outputs:<tf.Tensor: shape=(128, 1), dtype=float32, numpy=…> ## ## ...Predicting: start of batch 5; got logs:  Named list() ## ## ...Predicting: end of batch 5; got logs: List of 1 ##  $ outputs:<tf.Tensor: shape=(128, 1), dtype=float32, numpy=…> ## ## ...Predicting: start of batch 6; got logs:  Named list() ## ## ...Predicting: end of batch 6; got logs: List of 1 ##  $ outputs:<tf.Tensor: shape=(128, 1), dtype=float32, numpy=…> ## ## ...Predicting: start of batch 7; got logs:  Named list() ## ## ...Predicting: end of batch 7; got logs: List of 1 ##  $ outputs:<tf.Tensor: shape=(128, 1), dtype=float32, numpy=…> ## ## ...Predicting: start of batch 8; got logs:  Named list() ## ## ...Predicting: end of batch 8; got logs: List of 1 ##  $ outputs:<tf.Tensor: shape=(104, 1), dtype=float32, numpy=…> ## ## Stop predicting; got logs:  Named list()"},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"usage-of-logs-list","dir":"Articles","previous_headings":"A basic example","what":"Usage of logs list","title":"Writing your own callbacks","text":"logs named list contains loss value, metrics end batch epoch. Example includes loss mean absolute error. information callbacks, can check Keras callback API documentation.","code":"callback_print_loss_and_mae <- Callback(   \"LossAndErrorPrintingCallback\",    on_train_batch_end = function(batch, logs = NULL)     cat(sprintf(\"Up to batch %i, the average loss is %7.2f.\\n\",                 batch,  logs$loss)),    on_test_batch_end = function(batch, logs = NULL)     cat(sprintf(\"Up to batch %i, the average loss is %7.2f.\\n\",                 batch, logs$loss)),    on_epoch_end = function(epoch, logs = NULL)     cat(sprintf(       \"The average loss for epoch %2i is %9.2f and mean absolute error is %7.2f.\\n\",       epoch, logs$loss, logs$mean_absolute_error     )) )   model <- get_model() model |> fit(   mnist$train$x, mnist$train$y,   epochs = 2, verbose = 0, batch_size = 128,   callbacks = list(callback_print_loss_and_mae()) ) ## Up to batch 1, the average loss is   25.12. ## Up to batch 2, the average loss is  398.92. ## Up to batch 3, the average loss is  274.04. ## Up to batch 4, the average loss is  208.32. ## Up to batch 5, the average loss is  168.15. ## Up to batch 6, the average loss is  141.31. ## Up to batch 7, the average loss is  122.19. ## Up to batch 8, the average loss is  107.60. ## The average loss for epoch  1 is    107.60 and mean absolute error is    5.79. ## Up to batch 1, the average loss is    4.71. ## Up to batch 2, the average loss is    4.74. ## Up to batch 3, the average loss is    4.81. ## Up to batch 4, the average loss is    5.07. ## Up to batch 5, the average loss is    5.08. ## Up to batch 6, the average loss is    5.09. ## Up to batch 7, the average loss is    5.19. ## Up to batch 8, the average loss is    5.57. ## The average loss for epoch  2 is      5.57 and mean absolute error is    1.90. res = model |> evaluate(   mnist$test$x, mnist$test$y,   verbose = 0, batch_size = 128,   callbacks = list(callback_print_loss_and_mae()) ) ## Up to batch 1, the average loss is   15.86. ## Up to batch 2, the average loss is   16.13. ## Up to batch 3, the average loss is   16.02. ## Up to batch 4, the average loss is   16.11. ## Up to batch 5, the average loss is   16.23. ## Up to batch 6, the average loss is   16.68. ## Up to batch 7, the average loss is   16.61. ## Up to batch 8, the average loss is   16.53."},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"usage-of-selfmodel-attribute","dir":"Articles","previous_headings":"","what":"Usage of self$model attribute","title":"Writing your own callbacks","text":"addition receiving log information one methods called, callbacks access model associated current round training/evaluation/inference: self$model. things can self$model callback: Set self$model$stop_training <- TRUE immediately interrupt training. Mutate hyperparameters optimizer (available self$model$optimizer), self$model$optimizer$learning_rate. Save model period intervals. Record output model |> predict() test samples end epoch, use sanity check training. Extract visualizations intermediate features end epoch, monitor model learning time. etc. Let’s see action couple examples.","code":""},{"path":[]},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"early-stopping-at-minimum-loss","dir":"Articles","previous_headings":"Examples of Keras callback applications","what":"Early stopping at minimum loss","title":"Writing your own callbacks","text":"first example shows creation Callback stops training minimum loss reached, setting attribute self$model$stop_training (boolean). Optionally, can provide argument patience specify many epochs wait stopping reached local minimum. callback_early_stopping() provides complete general implementation.","code":"callback_early_stopping_at_min_loss <- Callback(   \"EarlyStoppingAtMinLoss\",   `__doc__` =     \"Stop training when the loss is at its min, i.e. the loss stops decreasing.      Arguments:         patience: Number of epochs to wait after min has been hit. After this         number of no improvement, training stops.     \",    initialize = function(patience = 0) {     super$initialize()     self$patience <- patience     # best_weights to store the weights at which the minimum loss occurs.     self$best_weights <- NULL   },    on_train_begin = function(logs = NULL) {     # The number of epoch it has waited when loss is no longer minimum.     self$wait <- 0     # The epoch the training stops at.     self$stopped_epoch <- 0     # Initialize the best as infinity.     self$best <- Inf   },    on_epoch_end = function(epoch, logs = NULL) {     current <- logs$loss     if (current < self$best) {       self$best <- current       self$wait <- 0L       # Record the best weights if current results is better (less).       self$best_weights <- get_weights(self$model)     } else {       add(self$wait) <- 1L       if (self$wait >= self$patience) {         self$stopped_epoch <- epoch         self$model$stop_training <- TRUE         cat(\"Restoring model weights from the end of the best epoch.\\n\")         model$set_weights(self$best_weights)       }     }   },    on_train_end = function(logs = NULL)     if (self$stopped_epoch > 0)       cat(sprintf(\"Epoch %05d: early stopping\\n\", self$stopped_epoch + 1)) ) `add<-` <- `+`   model <- get_model() model |> fit(   mnist$train$x,   mnist$train$y,   epochs = 30,   batch_size = 64,   verbose = 0,   callbacks = list(callback_print_loss_and_mae(),                    callback_early_stopping_at_min_loss()) ) ## Up to batch 1, the average loss is   30.54. ## Up to batch 2, the average loss is  513.27. ## Up to batch 3, the average loss is  352.60. ## Up to batch 4, the average loss is  266.37. ## Up to batch 5, the average loss is  214.68. ## Up to batch 6, the average loss is  179.97. ## Up to batch 7, the average loss is  155.06. ## Up to batch 8, the average loss is  136.59. ## Up to batch 9, the average loss is  121.96. ## Up to batch 10, the average loss is  110.28. ## Up to batch 11, the average loss is  100.72. ## Up to batch 12, the average loss is   92.71. ## Up to batch 13, the average loss is   85.95. ## Up to batch 14, the average loss is   80.21. ## Up to batch 15, the average loss is   75.17. ## Up to batch 16, the average loss is   70.97. ## The average loss for epoch  1 is     70.97 and mean absolute error is    4.08. ## Up to batch 1, the average loss is    7.98. ## Up to batch 2, the average loss is    9.92. ## Up to batch 3, the average loss is   12.88. ## Up to batch 4, the average loss is   16.61. ## Up to batch 5, the average loss is   20.49. ## Up to batch 6, the average loss is   26.14. ## Up to batch 7, the average loss is   30.44. ## Up to batch 8, the average loss is   33.76. ## Up to batch 9, the average loss is   36.32. ## Up to batch 10, the average loss is   35.26. ## Up to batch 11, the average loss is   34.22. ## Up to batch 12, the average loss is   33.53. ## Up to batch 13, the average loss is   32.84. ## Up to batch 14, the average loss is   31.80. ## Up to batch 15, the average loss is   31.39. ## Up to batch 16, the average loss is   31.49. ## The average loss for epoch  2 is     31.49 and mean absolute error is    4.82. ## Up to batch 1, the average loss is   39.60. ## Up to batch 2, the average loss is   41.95. ## Up to batch 3, the average loss is   41.29. ## Up to batch 4, the average loss is   36.77. ## Up to batch 5, the average loss is   32.08. ## Up to batch 6, the average loss is   28.17. ## Up to batch 7, the average loss is   25.33. ## Up to batch 8, the average loss is   23.56. ## Up to batch 9, the average loss is   22.28. ## Up to batch 10, the average loss is   21.22. ## Up to batch 11, the average loss is   20.87. ## Up to batch 12, the average loss is   22.25. ## Up to batch 13, the average loss is   25.08. ## Up to batch 14, the average loss is   27.87. ## Up to batch 15, the average loss is   31.72. ## Up to batch 16, the average loss is   34.05. ## The average loss for epoch  3 is     34.05 and mean absolute error is    4.79. ## Restoring model weights from the end of the best epoch. ## Epoch 00004: early stopping"},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"learning-rate-scheduling","dir":"Articles","previous_headings":"Examples of Keras callback applications","what":"Learning rate scheduling","title":"Writing your own callbacks","text":"example, show custom Callback can used dynamically change learning rate optimizer course training. See keras$callbacks$LearningRateScheduler general implementations (RStudio, press F1 cursor LearningRateScheduler browser open page).","code":"callback_custom_learning_rate_scheduler <- Callback(   \"CustomLearningRateScheduler\",   `__doc__` =   \"Learning rate scheduler which sets the learning rate according to schedule.      Arguments:         schedule: a function that takes an epoch index             (integer, indexed from 0) and current learning rate             as inputs and returns a new learning rate as output (float).     \",    initialize = function(schedule) {     super$initialize()     self$schedule <- schedule   },    on_epoch_begin = function(epoch, logs = NULL) {     ## When in doubt about what types of objects are in scope (e.g., self$model)     ## use a debugger to interact with the actual objects at the console!     # browser()      if (!\"learning_rate\" %in% names(self$model$optimizer))       stop('Optimizer must have a \"learning_rate\" attribute.')      # # Get the current learning rate from model's optimizer.     # use as.numeric() to convert the keras variablea to an R numeric     lr <- as.numeric(self$model$optimizer$learning_rate)     # # Call schedule function to get the scheduled learning rate.     scheduled_lr <- self$schedule(epoch, lr)     # # Set the value back to the optimizer before this epoch starts     optimizer <- self$model$optimizer     optimizer$learning_rate <- scheduled_lr     cat(sprintf(\"\\nEpoch %03d: Learning rate is %6.4f.\\n\", epoch, scheduled_lr))   } )  LR_SCHEDULE <- tibble::tribble(   ~start_epoch, ~learning_rate,              0,            0.1,              3,           0.05,              6,           0.01,              9,          0.005,             12,          0.001,   )  last <- function(x) x[length(x)] lr_schedule <- function(epoch, learning_rate) {   \"Helper function to retrieve the scheduled learning rate based on epoch.\"   with(LR_SCHEDULE, learning_rate[last(which(epoch >= start_epoch))]) }  model <- get_model() model |> fit(   mnist$train$x,   mnist$train$y,   epochs = 14,   batch_size = 64,   verbose = 0,   callbacks = list(     callback_print_loss_and_mae(),     callback_custom_learning_rate_scheduler(lr_schedule)   ) ) ## ## Epoch 001: Learning rate is 0.1000. ## Up to batch 1, the average loss is   29.36. ## Up to batch 2, the average loss is  513.95. ## Up to batch 3, the average loss is  352.70. ## Up to batch 4, the average loss is  266.46. ## Up to batch 5, the average loss is  214.73. ## Up to batch 6, the average loss is  180.00. ## Up to batch 7, the average loss is  155.05. ## Up to batch 8, the average loss is  136.64. ## Up to batch 9, the average loss is  121.97. ## Up to batch 10, the average loss is  110.30. ## Up to batch 11, the average loss is  100.76. ## Up to batch 12, the average loss is   92.74. ## Up to batch 13, the average loss is   85.95. ## Up to batch 14, the average loss is   80.18. ## Up to batch 15, the average loss is   75.11. ## Up to batch 16, the average loss is   70.84. ## The average loss for epoch  1 is     70.84 and mean absolute error is    4.04. ## ## Epoch 002: Learning rate is 0.1000. ## Up to batch 1, the average loss is    6.95. ## Up to batch 2, the average loss is    8.71. ## Up to batch 3, the average loss is   11.42. ## Up to batch 4, the average loss is   15.15. ## Up to batch 5, the average loss is   19.28. ## Up to batch 6, the average loss is   25.54. ## Up to batch 7, the average loss is   30.38. ## Up to batch 8, the average loss is   33.95. ## Up to batch 9, the average loss is   36.58. ## Up to batch 10, the average loss is   35.46. ## Up to batch 11, the average loss is   34.34. ## Up to batch 12, the average loss is   33.51. ## Up to batch 13, the average loss is   32.67. ## Up to batch 14, the average loss is   31.54. ## Up to batch 15, the average loss is   31.05. ## Up to batch 16, the average loss is   31.11. ## The average loss for epoch  2 is     31.11 and mean absolute error is    4.77. ## ## Epoch 003: Learning rate is 0.0500. ## Up to batch 1, the average loss is   40.40. ## Up to batch 2, the average loss is   22.33. ## Up to batch 3, the average loss is   16.18. ## Up to batch 4, the average loss is   13.09. ## Up to batch 5, the average loss is   11.48. ## Up to batch 6, the average loss is   10.21. ## Up to batch 7, the average loss is    9.22. ## Up to batch 8, the average loss is    8.70. ## Up to batch 9, the average loss is    8.16. ## Up to batch 10, the average loss is    7.80. ## Up to batch 11, the average loss is    7.50. ## Up to batch 12, the average loss is    7.17. ## Up to batch 13, the average loss is    6.89. ## Up to batch 14, the average loss is    6.70. ## Up to batch 15, the average loss is    6.52. ## Up to batch 16, the average loss is    6.56. ## The average loss for epoch  3 is      6.56 and mean absolute error is    1.93. ## ## Epoch 004: Learning rate is 0.0500. ## Up to batch 1, the average loss is    8.74. ## Up to batch 2, the average loss is    8.34. ## Up to batch 3, the average loss is    9.09. ## Up to batch 4, the average loss is    9.72. ## Up to batch 5, the average loss is   10.48. ## Up to batch 6, the average loss is   11.69. ## Up to batch 7, the average loss is   11.83. ## Up to batch 8, the average loss is   11.56. ## Up to batch 9, the average loss is   11.24. ## Up to batch 10, the average loss is   10.84. ## Up to batch 11, the average loss is   10.66. ## Up to batch 12, the average loss is   10.44. ## Up to batch 13, the average loss is   10.21. ## Up to batch 14, the average loss is   10.06. ## Up to batch 15, the average loss is   10.00. ## Up to batch 16, the average loss is   10.31. ## The average loss for epoch  4 is     10.31 and mean absolute error is    2.71. ## ## Epoch 005: Learning rate is 0.0500. ## Up to batch 1, the average loss is   17.26. ## Up to batch 2, the average loss is   14.09. ## Up to batch 3, the average loss is   12.67. ## Up to batch 4, the average loss is   11.44. ## Up to batch 5, the average loss is   10.54. ## Up to batch 6, the average loss is   10.10. ## Up to batch 7, the average loss is    9.53. ## Up to batch 8, the average loss is    9.17. ## Up to batch 9, the average loss is    8.78. ## Up to batch 10, the average loss is    8.49. ## Up to batch 11, the average loss is    8.50. ## Up to batch 12, the average loss is    8.59. ## Up to batch 13, the average loss is    8.68. ## Up to batch 14, the average loss is    8.86. ## Up to batch 15, the average loss is    9.17. ## Up to batch 16, the average loss is    9.74. ## The average loss for epoch  5 is      9.74 and mean absolute error is    2.58. ## ## Epoch 006: Learning rate is 0.0100. ## Up to batch 1, the average loss is   17.04. ## Up to batch 2, the average loss is   14.85. ## Up to batch 3, the average loss is   11.53. ## Up to batch 4, the average loss is    9.65. ## Up to batch 5, the average loss is    8.44. ## Up to batch 6, the average loss is    7.50. ## Up to batch 7, the average loss is    6.74. ## Up to batch 8, the average loss is    6.56. ## Up to batch 9, the average loss is    6.18. ## Up to batch 10, the average loss is    5.87. ## Up to batch 11, the average loss is    5.63. ## Up to batch 12, the average loss is    5.45. ## Up to batch 13, the average loss is    5.23. ## Up to batch 14, the average loss is    5.12. ## Up to batch 15, the average loss is    4.96. ## Up to batch 16, the average loss is    4.89. ## The average loss for epoch  6 is      4.89 and mean absolute error is    1.67. ## ## Epoch 007: Learning rate is 0.0100. ## Up to batch 1, the average loss is    3.65. ## Up to batch 2, the average loss is    3.04. ## Up to batch 3, the average loss is    2.88. ## Up to batch 4, the average loss is    2.85. ## Up to batch 5, the average loss is    2.88. ## Up to batch 6, the average loss is    2.81. ## Up to batch 7, the average loss is    2.70. ## Up to batch 8, the average loss is    2.96. ## Up to batch 9, the average loss is    2.96. ## Up to batch 10, the average loss is    2.93. ## Up to batch 11, the average loss is    2.95. ## Up to batch 12, the average loss is    2.98. ## Up to batch 13, the average loss is    2.97. ## Up to batch 14, the average loss is    3.01. ## Up to batch 15, the average loss is    3.00. ## Up to batch 16, the average loss is    3.08. ## The average loss for epoch  7 is      3.08 and mean absolute error is    1.34. ## ## Epoch 008: Learning rate is 0.0100. ## Up to batch 1, the average loss is    3.69. ## Up to batch 2, the average loss is    3.21. ## Up to batch 3, the average loss is    3.00. ## Up to batch 4, the average loss is    2.91. ## Up to batch 5, the average loss is    2.94. ## Up to batch 6, the average loss is    2.85. ## Up to batch 7, the average loss is    2.72. ## Up to batch 8, the average loss is    2.95. ## Up to batch 9, the average loss is    2.97. ## Up to batch 10, the average loss is    2.93. ## Up to batch 11, the average loss is    2.96. ## Up to batch 12, the average loss is    2.98. ## Up to batch 13, the average loss is    2.99. ## Up to batch 14, the average loss is    3.05. ## Up to batch 15, the average loss is    3.08. ## Up to batch 16, the average loss is    3.17. ## The average loss for epoch  8 is      3.17 and mean absolute error is    1.36. ## ## Epoch 009: Learning rate is 0.0050. ## Up to batch 1, the average loss is    3.71. ## Up to batch 2, the average loss is    2.93. ## Up to batch 3, the average loss is    2.76. ## Up to batch 4, the average loss is    2.70. ## Up to batch 5, the average loss is    2.76. ## Up to batch 6, the average loss is    2.69. ## Up to batch 7, the average loss is    2.57. ## Up to batch 8, the average loss is    2.79. ## Up to batch 9, the average loss is    2.80. ## Up to batch 10, the average loss is    2.77. ## Up to batch 11, the average loss is    2.79. ## Up to batch 12, the average loss is    2.80. ## Up to batch 13, the average loss is    2.78. ## Up to batch 14, the average loss is    2.81. ## Up to batch 15, the average loss is    2.80. ## Up to batch 16, the average loss is    2.84. ## The average loss for epoch  9 is      2.84 and mean absolute error is    1.28. ## ## Epoch 010: Learning rate is 0.0050. ## Up to batch 1, the average loss is    3.02. ## Up to batch 2, the average loss is    2.69. ## Up to batch 3, the average loss is    2.58. ## Up to batch 4, the average loss is    2.57. ## Up to batch 5, the average loss is    2.65. ## Up to batch 6, the average loss is    2.60. ## Up to batch 7, the average loss is    2.48. ## Up to batch 8, the average loss is    2.72. ## Up to batch 9, the average loss is    2.74. ## Up to batch 10, the average loss is    2.71. ## Up to batch 11, the average loss is    2.74. ## Up to batch 12, the average loss is    2.75. ## Up to batch 13, the average loss is    2.74. ## Up to batch 14, the average loss is    2.77. ## Up to batch 15, the average loss is    2.77. ## Up to batch 16, the average loss is    2.82. ## The average loss for epoch 10 is      2.82 and mean absolute error is    1.27. ## ## Epoch 011: Learning rate is 0.0050. ## Up to batch 1, the average loss is    3.01. ## Up to batch 2, the average loss is    2.69. ## Up to batch 3, the average loss is    2.58. ## Up to batch 4, the average loss is    2.56. ## Up to batch 5, the average loss is    2.63. ## Up to batch 6, the average loss is    2.58. ## Up to batch 7, the average loss is    2.47. ## Up to batch 8, the average loss is    2.70. ## Up to batch 9, the average loss is    2.72. ## Up to batch 10, the average loss is    2.69. ## Up to batch 11, the average loss is    2.71. ## Up to batch 12, the average loss is    2.72. ## Up to batch 13, the average loss is    2.71. ## Up to batch 14, the average loss is    2.75. ## Up to batch 15, the average loss is    2.74. ## Up to batch 16, the average loss is    2.79. ## The average loss for epoch 11 is      2.79 and mean absolute error is    1.27. ## ## Epoch 012: Learning rate is 0.0010. ## Up to batch 1, the average loss is    2.96. ## Up to batch 2, the average loss is    2.53. ## Up to batch 3, the average loss is    2.47. ## Up to batch 4, the average loss is    2.46. ## Up to batch 5, the average loss is    2.54. ## Up to batch 6, the average loss is    2.48. ## Up to batch 7, the average loss is    2.39. ## Up to batch 8, the average loss is    2.60. ## Up to batch 9, the average loss is    2.62. ## Up to batch 10, the average loss is    2.59. ## Up to batch 11, the average loss is    2.61. ## Up to batch 12, the average loss is    2.62. ## Up to batch 13, the average loss is    2.60. ## Up to batch 14, the average loss is    2.64. ## Up to batch 15, the average loss is    2.62. ## Up to batch 16, the average loss is    2.66. ## The average loss for epoch 12 is      2.66 and mean absolute error is    1.24. ## ## Epoch 013: Learning rate is 0.0010. ## Up to batch 1, the average loss is    2.82. ## Up to batch 2, the average loss is    2.46. ## Up to batch 3, the average loss is    2.42. ## Up to batch 4, the average loss is    2.42. ## Up to batch 5, the average loss is    2.50. ## Up to batch 6, the average loss is    2.45. ## Up to batch 7, the average loss is    2.36. ## Up to batch 8, the average loss is    2.57. ## Up to batch 9, the average loss is    2.59. ## Up to batch 10, the average loss is    2.57. ## Up to batch 11, the average loss is    2.59. ## Up to batch 12, the average loss is    2.60. ## Up to batch 13, the average loss is    2.59. ## Up to batch 14, the average loss is    2.62. ## Up to batch 15, the average loss is    2.61. ## Up to batch 16, the average loss is    2.64. ## The average loss for epoch 13 is      2.64 and mean absolute error is    1.23. ## ## Epoch 014: Learning rate is 0.0010. ## Up to batch 1, the average loss is    2.79. ## Up to batch 2, the average loss is    2.44. ## Up to batch 3, the average loss is    2.40. ## Up to batch 4, the average loss is    2.41. ## Up to batch 5, the average loss is    2.49. ## Up to batch 6, the average loss is    2.44. ## Up to batch 7, the average loss is    2.34. ## Up to batch 8, the average loss is    2.56. ## Up to batch 9, the average loss is    2.58. ## Up to batch 10, the average loss is    2.56. ## Up to batch 11, the average loss is    2.58. ## Up to batch 12, the average loss is    2.59. ## Up to batch 13, the average loss is    2.58. ## Up to batch 14, the average loss is    2.61. ## Up to batch 15, the average loss is    2.60. ## Up to batch 16, the average loss is    2.64. ## The average loss for epoch 14 is      2.64 and mean absolute error is    1.23."},{"path":"https://keras.posit.co/articles/writing_your_own_callbacks.html","id":"built-in-keras-callbacks","dir":"Articles","previous_headings":"Examples of Keras callback applications","what":"Built-in Keras callbacks","title":"Writing your own callbacks","text":"sure check existing Keras callbacks reading API docs. Applications include logging CSV, saving model, visualizing metrics TensorBoard, lot !","code":""},{"path":"https://keras.posit.co/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tomasz Kalinowski. Author, copyright holder, maintainer. Daniel Falbel. Contributor, copyright holder. JJ Allaire. Author, copyright holder. François Chollet. Author, copyright holder. Posit Software, PBC. Copyright holder, funder. Google. Copyright holder, funder. Yuan Tang. Contributor, copyright holder. Wouter Van Der Bijl. Contributor, copyright holder. Martin Studer. Contributor, copyright holder. Sigrid Keydana. Contributor.","code":""},{"path":"https://keras.posit.co/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kalinowski T, Allaire J, Chollet F (2024). keras3: R Interface 'Keras'. R package version 0.1.0.9000, https://github.com/rstudio/keras, https://keras.posit.co/.","code":"@Manual{,   title = {keras3: R Interface to 'Keras'},   author = {Tomasz Kalinowski and JJ Allaire and François Chollet},   year = {2024},   note = {R package version 0.1.0.9000, https://github.com/rstudio/keras},   url = {https://keras.posit.co/}, }"},{"path":"https://keras.posit.co/index.html","id":"r-interface-to-keras","dir":"","previous_headings":"","what":"R Interface to Keras","title":"R Interface to Keras","text":"Keras high-level neural networks API developed focus enabling fast experimentation. able go idea result least possible delay key good research. Keras following key features: Allows code run CPU GPU, seamlessly. User-friendly API makes easy quickly prototype deep learning models. Built-support convolutional networks (computer vision), recurrent networks (sequence processing), combination . Supports arbitrary network architectures: multi-input multi-output models, layer sharing, model sharing, etc. means Keras appropriate building essentially deep learning model, memory network neural Turing machine. See package website https://keras.posit.co complete documentation.","code":""},{"path":"https://keras.posit.co/reference/Callback.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a custom Callback class — Callback","title":"Define a custom Callback class — Callback","text":"Callbacks can passed keras methods fit(), evaluate(), predict() order hook various stages model training, evaluation, inference lifecycle. create custom callback, call Callback() override method associated stage interest.","code":""},{"path":"https://keras.posit.co/reference/Callback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a custom Callback class — Callback","text":"","code":"Callback(   classname,   on_epoch_begin = NULL,   on_epoch_end = NULL,   on_train_begin = NULL,   on_train_end = NULL,   on_train_batch_begin = NULL,   on_train_batch_end = NULL,   on_test_begin = NULL,   on_test_end = NULL,   on_test_batch_begin = NULL,   on_test_batch_end = NULL,   on_predict_begin = NULL,   on_predict_end = NULL,   on_predict_batch_begin = NULL,   on_predict_batch_end = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/Callback.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a custom Callback class — Callback","text":"classname String, name custom class. (Conventionally, CamelCase). on_epoch_begin   Called start epoch. Subclasses override actions run. function called TRAIN mode. Args: epoch: Integer, index epoch. logs: Named List. Currently data passed argument method may change future. on_epoch_end   Called end epoch. Subclasses override actions run. function called TRAIN mode. Args: epoch: Integer, index epoch. logs: Named List, metric results training epoch, validation epoch validation performed. Validation result keys prefixed val_. training epoch, values Model's metrics returned. Example: list(loss = 0.2, accuracy = 0.7). on_train_begin   Called beginning training. Subclasses override actions run. Args: logs: Named list. Currently data passed argument method may change future. on_train_end   Called end training. Subclasses override actions run. Args: logs: Named list. Currently output last call on_epoch_end() passed argument method may change future. on_train_batch_begin   Called beginning training batch fit() methods. Subclasses override actions run. Note steps_per_execution argument compile Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Currently data passed argument method may change future. on_train_batch_end   Called end training batch fit() methods. Subclasses override actions run. Note steps_per_execution argument compile Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Aggregated metric results batch. on_test_begin   Called beginning evaluation validation. Subclasses override actions run. Args: logs: Named list. Currently data passed argument method may change future. on_test_end   Called end evaluation validation. Subclasses override actions run. Args: logs: Named list. Currently output last call on_test_batch_end() passed argument method may change future. on_test_batch_begin   Called beginning batch evaluate() methods. Also called beginning validation batch fit() methods, validation data provided. Subclasses override actions run. Note steps_per_execution argument compile() Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Currently data passed argument method may change future. on_test_batch_end   Called end batch evaluate() methods. Also called end validation batch fit() methods, validation data provided. Subclasses override actions run. Note steps_per_execution argument compile() Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Aggregated metric results batch. on_predict_begin   Called beginning prediction. Subclasses override actions run. Args: logs: Named list. Currently data passed argument method may change future. on_predict_end   Called end prediction. Subclasses override actions run. Args: logs: Named list. Currently data passed argument method may change future. on_predict_batch_begin   Called beginning batch predict() methods. Subclasses override actions run. Note steps_per_execution argument compile() Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Currently data passed argument method may change future. on_predict_batch_end   Called end batch predict() methods. Subclasses override actions run. Note steps_per_execution argument compile Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Aggregated metric results batch. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":"\\(epoch, logs = NULL) \\(epoch, logs = NULL) \\(logs = NULL) \\(logs = NULL) \\(batch, logs = NULL) \\(batch, logs=NULL) \\(logs = NULL) \\(logs = NULL) \\(batch, logs = NULL) \\(batch, logs = NULL) \\(logs = NULL) \\(logs = NULL) \\(batch, logs = NULL) \\(batch, logs = NULL)"},{"path":"https://keras.posit.co/reference/Callback.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a custom Callback class — Callback","text":"function returns custom Callback instances, similar builtin callback functions.","code":""},{"path":"https://keras.posit.co/reference/Callback.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a custom Callback class — Callback","text":"R function custom methods (public private) following symbols scope: self: Layer instance. super: Layer superclass. private: R environment specific class instance. objects defined invisible Keras framework. __class__ current class type object. also available alias symbol, value supplied Layer(classname = )","code":"training_finished <- FALSE callback_mark_finished <- Callback(\"MarkFinished\",   on_train_end = function(logs = NULL) {     training_finished <<- TRUE   } )  model <- keras_model_sequential(input_shape = c(1)) |>   layer_dense(1) model |> compile(loss = 'mean_squared_error') model |> fit(op_ones(c(1, 1)), op_ones(c(1, 1)),              callbacks = callback_mark_finished()) stopifnot(isTRUE(training_finished))"},{"path":"https://keras.posit.co/reference/Callback.html","id":"attributes-accessible-via-self-","dir":"Reference","previous_headings":"","what":"Attributes (accessible via self$)","title":"Define a custom Callback class — Callback","text":"params: Named list, Training parameters (e.g. verbosity, batch size, number epochs, ...). model: Instance Model. Reference model trained. logs named list callback methods take argument contain keys quantities relevant current batch epoch (see method-specific docstrings).","code":""},{"path":"https://keras.posit.co/reference/Callback.html","id":"symbols-in-scope","dir":"Reference","previous_headings":"","what":"Symbols in scope","title":"Define a custom Callback class — Callback","text":"R function custom methods (public private) following symbols scope: self: custom class instance. super: custom class superclass. private: R environment specific class instance. objects assigned invisible Keras framework. __class__ .symbol(classname): custom class type object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/Constraint.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a custom Constraint class — Constraint","title":"Define a custom Constraint class — Constraint","text":"Base class weight constraints. Constraint() instance works like stateless function. Users subclass Constraint class override call() method, takes single weight parameter return projected version parameter (e.g. normalized clipped). Constraints can used various Keras layers via kernel_constraint bias_constraint arguments. simple example non-negative weight constraint:     Usage layer:","code":"constraint_nonnegative <- Constraint(\"NonNegative\",   call = function(w) {     w * op_cast(w >= 0, dtype = w$dtype)   } ) weight <- op_convert_to_tensor(c(-1, 1)) constraint_nonnegative()(weight) ## tf.Tensor([-0.  1.], shape=(2), dtype=float32) layer_dense(units = 4, kernel_constraint = constraint_nonnegative()) ## <Dense name=dense, built=False>"},{"path":"https://keras.posit.co/reference/Constraint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a custom Constraint class — Constraint","text":"","code":"Constraint(   classname,   call = NULL,   get_config = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/Constraint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a custom Constraint class — Constraint","text":"classname String, name custom class. (Conventionally, CamelCase). call   Applies constraint input weight variable. default, inputs weight variable modified. Users override method implement projection function. Args: w: Input weight variable. Returns: Projected variable (default, returns unmodified inputs). get_config   Function returns named list object config. constraint config named list (JSON-serializable) can used reinstantiate object (via .call(<constraint_class>, <config>)). ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":"\\(w) \\()"},{"path":"https://keras.posit.co/reference/Constraint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a custom Constraint class — Constraint","text":"function returns Constraint instances, similar builtin constraint functions like constraint_maxnorm().","code":""},{"path":"https://keras.posit.co/reference/Constraint.html","id":"symbols-in-scope","dir":"Reference","previous_headings":"","what":"Symbols in scope","title":"Define a custom Constraint class — Constraint","text":"R function custom methods (public private) following symbols scope: self: custom class instance. super: custom class superclass. private: R environment specific class instance. objects assigned invisible Keras framework. __class__ .symbol(classname): custom class type object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/Layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a custom Layer class. — Layer","title":"Define a custom Layer class. — Layer","text":"layer callable object takes input one tensors outputs one tensors. involves computation, defined call() method, state (weight variables). State can created: initialize(), instance via self$add_weight(); optional build() method, invoked first call() layer, supplies shape(s) input(s), may known initialization time. Layers recursively composable: assign Layer instance attribute another Layer, outer layer start tracking weights created inner layer. Nested layers instantiated initialize() method build() method. Users just instantiate layer treat callable.","code":""},{"path":"https://keras.posit.co/reference/Layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a custom Layer class. — Layer","text":"","code":"Layer(   classname,   initialize = NULL,   call = NULL,   build = NULL,   get_config = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/Layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a custom Layer class. — Layer","text":"classname String, name custom class. (Conventionally, CamelCase). initialize, call, build, get_config Recommended methods implement. See description details sections. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":""},{"path":"https://keras.posit.co/reference/Layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a custom Layer class. — Layer","text":"composing layer constructor, similar behavior layer functions like layer_dense(). first argument returned function object, enabling initialize()ing call() layer one step composing layer pipe, like   initialize() layer instance call() , pass missing NULL value object, pass arguments initialize() name.","code":"layer_foo <- Layer(\"Foo\", ....) output <- inputs |> layer_foo() layer <- layer_dense(units = 2, activation = \"relu\") layer <- layer_dense(NULL, 2, activation = \"relu\") layer <- layer_dense(, 2, activation = \"relu\")  # then you can call() the layer in a separate step outputs <- inputs |> layer()"},{"path":"https://keras.posit.co/reference/Layer.html","id":"symbols-in-scope","dir":"Reference","previous_headings":"","what":"Symbols in scope","title":"Define a custom Layer class. — Layer","text":"R function custom methods (public private) following symbols scope: self: custom class instance. super: custom class superclass. private: R environment specific class instance. objects assigned invisible Keras framework. __class__ .symbol(classname): custom class type object.","code":""},{"path":"https://keras.posit.co/reference/Layer.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Define a custom Layer class. — Layer","text":"name: name layer (string). dtype: Dtype layer's weights. Alias layer$variable_dtype. variable_dtype: Dtype layer's weights. compute_dtype: dtype layer's computations. Layers automatically cast inputs dtype, causes computations output also dtype. mixed precision used keras$mixed_precision$DTypePolicy, different variable_dtype. trainable_weights: List variables included backprop. non_trainable_weights: List variables included backprop. weights: concatenation lists trainable_weights non_trainable_weights (order). trainable: Whether layer trained (boolean), .e. whether potentially-trainable weights returned part layer$trainable_weights. input_spec: Optional (list ) InputSpec object(s) specifying constraints inputs can accepted layer. recommend custom Layers implement following methods: initialize(): Defines custom layer attributes, creates layer weights depend input shapes, using add_weight(), state. build(input_shape): method can used create weights depend shape(s) input(s), using add_weight(), state. Calling call() automatically build layer (built yet) calling build(). call(...): Method called making sure build() called. call() performs logic applying layer input arguments. Two reserved arguments can optionally use call() : training (boolean, whether call inference mode training mode). mask (boolean tensor encoding masked timesteps input, used e.g. RNN layers). typical signature method call(inputs), user optionally add training mask layer need . get_config(): Returns named list containing configuration used initialize layer. list names differ arguments initialize(), override from_config() well. method used saving layer model contains layer.","code":""},{"path":"https://keras.posit.co/reference/Layer.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a custom Layer class. — Layer","text":"basic example: layer two variables, w b, returns y <- (w %*% x) + b. shows implement build() call(). Variables set attributes layer tracked weights layers (layer$weights).   Besides trainable weights, updated via backpropagation training, layers can also non-trainable weights. weights meant updated manually call(). example layer computes running sum inputs:","code":"layer_simple_dense <- Layer(   \"SimpleDense\",   initialize = function(units = 32) {     super$initialize()     self$units <- units   },    # Create the state of the layer (weights)   build = function(input_shape) {     self$kernel <- self$add_weight(       shape = shape(tail(input_shape, 1), self$units),       initializer = \"glorot_uniform\",       trainable = TRUE,       name = \"kernel\"     )     self$bias = self$add_weight(       shape = shape(self$units),       initializer = \"zeros\",       trainable = TRUE,       name = \"bias\"     )   },    # Defines the computation   call = function(self, inputs) {     op_matmul(inputs, self$kernel) + self$bias   } )  # Instantiates the layer. # Supply missing `object` arg to skip invoking `call()` and instead return # the Layer instance linear_layer <- layer_simple_dense(, 4)  # This will call `build(input_shape)` and create the weights, # and then invoke `call()`. y <- linear_layer(op_ones(c(2, 2))) stopifnot(length(linear_layer$weights) == 2)  # These weights are trainable, so they're listed in `trainable_weights`: stopifnot(length(linear_layer$trainable_weights) == 2) layer_compute_sum <- Layer(   classname = \"ComputeSum\",    initialize = function(input_dim) {     super$initialize()      # Create a non-trainable weight.     self$total <- self$add_weight(       shape = shape(),       initializer = \"zeros\",       trainable = FALSE,       name = \"total\"     )   },    call = function(inputs) {     self$total$assign(self$total + op_sum(inputs))     self$total   } )  my_sum <- layer_compute_sum(, 2) x <- op_ones(c(2, 2)) y <- my_sum(x)  stopifnot(exprs = {   all.equal(my_sum$weights,               list(my_sum$total))   all.equal(my_sum$non_trainable_weights, list(my_sum$total))   all.equal(my_sum$trainable_weights,     list()) })"},{"path":"https://keras.posit.co/reference/Layer.html","id":"methods-available","dir":"Reference","previous_headings":"","what":"Methods available","title":"Define a custom Layer class. — Layer","text":"Initialize self. method typically called custom initialize() method. Example:   Args: trainable: Boolean, whether layer's variables trainable. name: String name layer. dtype: dtype layer's computations weights. Can also keras$DTypePolicy, allows computation weight dtype differ. Defaults NULL. NULL means use config_dtype_policy(), \"float32\" policy unless set different value (via config_set_dtype_policy()).    Can called inside call() method add scalar loss. Example:         Alias add_weight().    Add weight variable layer. Args: shape: shape variable (defined shape()) Must fully-defined (NA/NULL/-1 entries). Defaults () (scalar) unspecified. initializer: Initializer object use populate initial variable value, string name built-initializer (e.g. \"random_normal\"). unspecified, defaults \"glorot_uniform\" floating-point variables \"zeros\" types (e.g. int, bool). dtype: Dtype variable create, e.g. \"float32\". unspecified, defaults layer's variable dtype (defaults \"float32\" unspecified). trainable: Boolean, whether variable trainable via backprop whether updates managed manually. constraint: Constraint object call variable optimizer update, string name built-constraint. name: String name variable. Useful debugging purposes. Returns: backend tensor, wrapped KerasVariable class. KerasVariable class Methods: assign(value) assign_add(value) assign_sub(value) numpy() (calling .array(<variable>) preferred) Properties/Attributes: value dtype ndim shape (calling shape(<variable>) preferred) trainable       Builds layer's states supplied config (named list args). default, method calls .call(build, config$input_shape) method, creates weights based layer's input shape supplied config. config contains information needed load layer's state, override method. Args: config: Named list containing input shape associated layer.    See description             Count total number scalars composing weights. Returns: integer count.    Returns named list layer's input shape. method returns config (named list) can used build_from_config(config) create states (e.g. Variables Lookup tables) needed layer. default, config contains input shape layer built . writing custom layer creates state unusual way, override method make sure state already created Keras attempts load value upon model loading. Returns: named list containing input shape associated layer.    Returns config object. object config named list (serializable) containing information needed re-instantiate . config expected serializable JSON, expected consist (potentially complex, nested) structure names lists consisting simple objects like strings, ints.    Return values layer$weights list R NumPy arrays.    Currently, Dense EinsumDense layers support -place quantization via quantize() method. Example:         Loads state layer. can override method take full control state layer loaded upon calling load_model(). Args: store: Named list state model loaded.    Saves state layer. can override method take full control state layer saved upon calling save_model(). Args: store: Named list state model saved.    Sets values weights list R NumPy arrays.    Call layer without side effects. Args: trainable_variables: List trainable variables model. non_trainable_variables: List non-trainable variables model. ...: Positional named arguments passed call(). return_losses: TRUE, stateless_call() return list losses created call() part return values. Returns: unnamed list. default, returns list(outputs, non_trainable_variables). return_losses = TRUE, returns list(outputs, non_trainable_variables, losses). Note: non_trainable_variables include non-trainable weights BatchNormalization statistics, also RNG seed state (random operations part layer, dropout), Metric state (metrics attached layer). elements state layer. Example:         Creates layer config. class method, meaning, R function self symbol (class instance) scope. Use __class__ classname symbol provided Layer() constructed) resolve class definition. default implementation :   method reverse get_config(), capable instantiating layer config named list. handle layer connectivity (handled Network), weights (handled set_weights()). Args: config: named list, typically output get_config(). Returns: layer instance.","code":"initialize(...,            activity_regularizer = NULL,            trainable = TRUE,            dtype = NULL,            autocast = TRUE,            name = NULL) layer_my_layer <- Layer(\"MyLayer\",   initialize = function(units, ..., dtype = NULL, name = NULL) {     super$initialize(..., dtype = dtype, name = name)     # .... finish initializing `self` instance   } ) add_loss(loss) Layer(\"MyLayer\",   ...   call = function(x) {     self$add_loss(op_sum(x))     x   } add_metric() add_variable(...) add_weight(shape = NULL,            initializer = NULL,            dtype = NULL,            trainable = TRUE,            regularizer = NULL,            constraint = NULL,            name = NULL) build(input_shape) build_from_config(config) call(...) compute_mask(inputs, previous_mask) compute_output_shape(...) compute_output_spec(...) count_params() get_build_config() get_config() get_weights() quantize(mode) model$quantize(\"int8\") # quantize model in-place model |> predict(data) # faster inference quantized_call(...) load_own_variables(store) save_own_variables(store) set_weights(weights) stateless_call(trainable_variables, non_trainable_variables,                ..., return_losses = FALSE) model <- ... data <- ... trainable_variables <- model$trainable_variables non_trainable_variables <- model$non_trainable_variables # Call the model with zero side effects c(outputs, non_trainable_variables) %<-% model$stateless_call(     trainable_variables,     non_trainable_variables,     data ) # Attach the updated state to the model # (until you do this, the model is still in its pre-call state). purrr::walk2(   model$non_trainable_variables, non_trainable_variables,   \\(variable, value) variable$assign(value)) symbolic_call(...) from_config(config) from_config = function(config) {   do.call(`__class__`, config) }"},{"path":"https://keras.posit.co/reference/Layer.html","id":"readonly-properties-","dir":"Reference","previous_headings":"","what":"Readonly properties:","title":"Define a custom Layer class. — Layer","text":"compute_dtype dtype computations performed layer. dtype Alias layer$variable_dtype. input_dtype dtype layer inputs converted . losses List scalar losses add_loss(), regularizers sublayers. metrics_variables List metric variables. non_trainable_variables List non-trainable layer state. extends layer$non_trainable_weights include state used layer including state metrics SeedGenerators. non_trainable_weights List non-trainable weight variables layer. weights updated optimizer training. Unlike, layer$non_trainable_variables excludes metric state random seeds. trainable_variables List trainable layer state. equivalent layer$trainable_weights. trainable_weights List trainable weight variables layer. weights get updated optimizer training. variable_dtype dtype state (weights) layer. variables List layer state, including random seeds. extends layer$weights include state used layer including SeedGenerators. Note metrics variables included , use metrics_variables visit metric variables. weights List weight variables layer. Unlike, layer$variables excludes metric state random seeds. input Retrieves input tensor(s) symbolic operation. returns tensor(s) corresponding first time operation called. Returns: Input tensor list input tensors. output Retrieves output tensor(s) layer. returns tensor(s) corresponding first time operation called. Returns: Output tensor list output tensors.","code":""},{"path":"https://keras.posit.co/reference/Layer.html","id":"data-descriptors-attributes-","dir":"Reference","previous_headings":"","what":"Data descriptors (Attributes):","title":"Define a custom Layer class. — Layer","text":"input_spec supports_masking Whether layer supports computing mask using compute_mask. trainable Settable boolean, whether layer trainable .","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/LearningRateSchedule.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a custom LearningRateSchedule class — LearningRateSchedule","title":"Define a custom LearningRateSchedule class — LearningRateSchedule","text":"Subclass keras learning rate schedule base class. can use learning rate schedule modulate learning rate optimizer changes time. Several built-learning rate schedules available, learning_rate_schedule_exponential_decay() learning_rate_schedule_piecewise_constant_decay():   LearningRateSchedule() instance can passed learning_rate argument optimizer. implement schedule object, implement call method, takes step argument (scalar integer backend tensor, current training step count). Note step 0-based (.e., first step 0). Like Keras object, can also optionally make object serializable implementing get_config() from_config() methods.","code":"lr_schedule <- learning_rate_schedule_exponential_decay(   initial_learning_rate = 1e-2,   decay_steps = 10000,   decay_rate = 0.9 ) optimizer <- optimizer_sgd(learning_rate = lr_schedule)"},{"path":"https://keras.posit.co/reference/LearningRateSchedule.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a custom LearningRateSchedule class — LearningRateSchedule","text":"","code":"LearningRateSchedule(   classname,   call = NULL,   initialize = NULL,   get_config = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/LearningRateSchedule.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a custom LearningRateSchedule class — LearningRateSchedule","text":"classname String, name custom class. (Conventionally, CamelCase). call, initialize, get_config Recommended methods implement. See description details sections. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":""},{"path":"https://keras.posit.co/reference/LearningRateSchedule.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a custom LearningRateSchedule class — LearningRateSchedule","text":"function returns LearningRateSchedule instances, similar built-learning_rate_schedule_* family functions.","code":""},{"path":"https://keras.posit.co/reference/LearningRateSchedule.html","id":"example","dir":"Reference","previous_headings":"","what":"Example","title":"Define a custom LearningRateSchedule class — LearningRateSchedule","text":"","code":"my_custom_learning_rate_schedule <- LearningRateSchedule(   classname = \"MyLRSchedule\",   initialize = function( initial_learning_rate) {      self$initial_learning_rate <- initial_learning_rate   },     call = function(step) {     # note that `step` is a tensor     # and call() will be traced via tf_function() or similar.      str(step) # <KerasVariable shape=(), dtype=int64, path=SGD/iteration>      # print 'step' every 1000 steps     op_cond((step %% 1000) == 0,             \\() {tensorflow::tf$print(step); NULL},             \\() {NULL})     self$initial_learning_rate / (step + 1)   } )  optimizer <- optimizer_sgd(   learning_rate = my_custom_learning_rate_schedule(0.1) )  # You can also call schedule instances directly # (e.g., for interactive testing, or if implementing a custom optimizer) schedule <- my_custom_learning_rate_schedule(0.1) step <- keras$Variable(initializer = op_ones,                        shape = shape(),                        dtype = \"int64\") schedule(step) ## <KerasVariable shape=(), dtype=int64, path=variable> ## tf.Tensor(0.0, shape=(), dtype=float64)"},{"path":"https://keras.posit.co/reference/LearningRateSchedule.html","id":"methods-available-","dir":"Reference","previous_headings":"","what":"Methods available:","title":"Define a custom LearningRateSchedule class — LearningRateSchedule","text":"","code":"get_config()"},{"path":"https://keras.posit.co/reference/LearningRateSchedule.html","id":"symbols-in-scope","dir":"Reference","previous_headings":"","what":"Symbols in scope","title":"Define a custom LearningRateSchedule class — LearningRateSchedule","text":"R function custom methods (public private) following symbols scope: self: custom class instance. super: custom class superclass. private: R environment specific class instance. objects assigned invisible Keras framework. __class__ .symbol(classname): custom class type object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/Loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Subclass the base Loss class — Loss","title":"Subclass the base Loss class — Loss","text":"Use define custom loss class. Note, cases need subclass Loss define custom loss: can also pass bare R function, named R function defined custom_metric(), loss function compile().","code":""},{"path":"https://keras.posit.co/reference/Loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subclass the base Loss class — Loss","text":"","code":"Loss(   classname,   call = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/Loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subclass the base Loss class — Loss","text":"classname String, name custom class. (Conventionally, CamelCase). call   Method implemented subclasses: Function contains logic loss calculation using y_true, y_pred. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":"function(y_true, y_pred)"},{"path":"https://keras.posit.co/reference/Loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subclass the base Loss class — Loss","text":"function returns Loss instances, similar builtin loss functions.","code":""},{"path":"https://keras.posit.co/reference/Loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subclass the base Loss class — Loss","text":"Example subclass implementation:","code":"loss_custom_mse <- Loss(   classname = \"CustomMeanSquaredError\",   call = function(y_true, y_pred) {     op_mean(op_square(y_pred - y_true), axis = -1)   } )  # Usage in compile() model <- keras_model_sequential(input_shape = 10) |> layer_dense(10) model |> compile(loss = loss_custom_mse())  # Standalone usage mse <- loss_custom_mse(name = \"my_custom_mse_instance\")  y_true <- op_arange(20) |> op_reshape(c(4, 5)) y_pred <- op_arange(20) |> op_reshape(c(4, 5)) * 2 (loss <- mse(y_true, y_pred)) ## tf.Tensor(123.5, shape=(), dtype=float32) loss2 <- (y_pred - y_true)^2 |>   op_mean(axis = -1) |>   op_mean()  stopifnot(all.equal(as.array(loss), as.array(loss2)))  sample_weight <-array(c(.25, .25, 1, 1)) (weighted_loss <- mse(y_true, y_pred, sample_weight = sample_weight)) ## tf.Tensor(112.8125, shape=(), dtype=float32) weighted_loss2 <- (y_true - y_pred)^2 |>   op_mean(axis = -1) |>   op_multiply(sample_weight) |>   op_mean()  stopifnot(all.equal(as.array(weighted_loss),                     as.array(weighted_loss2)))"},{"path":"https://keras.posit.co/reference/Loss.html","id":"methods-defined-by-base-loss-class-","dir":"Reference","previous_headings":"","what":"Methods defined by base Loss class:","title":"Subclass the base Loss class — Loss","text":"Args: name reduction: Valid values one {\"sum_over_batch_size\", \"sum\", NULL, \"none\"} dtype    Call loss instance function, optionally sample_weight.","code":"initialize(name=NULL, reduction=\"sum_over_batch_size\", dtype=NULL) __call__(y_true, y_pred, sample_weight=NULL) get_config()"},{"path":"https://keras.posit.co/reference/Loss.html","id":"symbols-in-scope","dir":"Reference","previous_headings":"","what":"Symbols in scope","title":"Subclass the base Loss class — Loss","text":"R function custom methods (public private) following symbols scope: self: custom class instance. super: custom class superclass. private: R environment specific class instance. objects assigned invisible Keras framework. __class__ .symbol(classname): custom class type object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/Metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Subclass the base Metric class — Metric","title":"Subclass the base Metric class — Metric","text":"Metric object encapsulates metric logic state can used track model performance training. returned family metric functions start prefix metric_*, well returned custom metrics defined Metric().","code":""},{"path":"https://keras.posit.co/reference/Metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subclass the base Metric class — Metric","text":"","code":"Metric(   classname,   initialize = NULL,   update_state = NULL,   result = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/Metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subclass the base Metric class — Metric","text":"classname String, name custom class. (Conventionally, CamelCase). initialize, update_state, result Recommended methods implement. See description section. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":""},{"path":"https://keras.posit.co/reference/Metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subclass the base Metric class — Metric","text":"function returns Metric instances, similar builtin metric functions.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/Metric.html","id":"usage-with-compile-","dir":"Reference","previous_headings":"","what":"Usage with compile():","title":"Subclass the base Metric class — Metric","text":"","code":"model |> compile(   optimizer = 'sgd',   loss = 'mse',   metrics = c(metric_SOME_METRIC(), metric_SOME_OTHER_METRIC()) )"},{"path":"https://keras.posit.co/reference/Metric.html","id":"standalone-usage-","dir":"Reference","previous_headings":"","what":"Standalone usage:","title":"Subclass the base Metric class — Metric","text":"","code":"m <- metric_SOME_METRIC() for (e in seq(epochs)) {   for (i in seq(train_steps)) {     c(y_true, y_pred, sample_weight = NULL) %<-% ...     m$update_state(y_true, y_pred, sample_weight)   }   cat('Final epoch result: ', as.numeric(m$result()), \"\\n\")   m$reset_state() }"},{"path":[]},{"path":"https://keras.posit.co/reference/Metric.html","id":"usage-with-compile--1","dir":"Reference","previous_headings":"","what":"Usage with compile():","title":"Subclass the base Metric class — Metric","text":"implemented subclasses (custom metrics): initialize(): state variables created method calling self$add_variable() like: self$var <- self$add_variable(...). update_state(): Updates state variables like: self$var$assign(...). result(): Computes returns scalar value named list scalar values metric state variables. Example subclass implementation:","code":"model <- keras_model_sequential() model |>   layer_dense(64, activation = \"relu\") |>   layer_dense(64, activation = \"relu\") |>   layer_dense(10, activation = \"softmax\") model |>   compile(optimizer = optimizer_rmsprop(0.01),           loss = loss_categorical_crossentropy(),           metrics = metric_categorical_accuracy())  data <- random_uniform(c(1000, 32)) labels <- random_uniform(c(1000, 10))  model |> fit(data, labels, verbose = 0) metric_binary_true_positives <- Metric(   classname = \"BinaryTruePositives\",    initialize = function(name = 'binary_true_positives', ...) {     super$initialize(name = name, ...)     self$true_positives <-       self$add_weight(shape = shape(),                       initializer = 'zeros',                       name = 'true_positives')   },    update_state = function(y_true, y_pred, sample_weight = NULL) {     y_true <- op_cast(y_true, \"bool\")     y_pred <- op_cast(y_pred, \"bool\")      values <- y_true & y_pred # `&` calls op_logical_and()     values <- op_cast(values, self$dtype)     if (!is.null(sample_weight)) {       sample_weight <- op_cast(sample_weight, self$dtype)       sample_weight <- op_broadcast_to(sample_weight, shape(values))       values <- values * sample_weight # `*` calls op_multiply()     }     self$true_positives$assign(self$true_positives + op_sum(values))   },    result = function() {     self$true_positives   } ) model <- keras_model_sequential(input_shape = 32) |> layer_dense(10) model |> compile(loss = loss_binary_crossentropy(),                  metrics = list(metric_binary_true_positives())) model |> fit(data, labels, verbose = 0)"},{"path":"https://keras.posit.co/reference/Metric.html","id":"methods-defined-by-the-base-metric-class-","dir":"Reference","previous_headings":"","what":"Methods defined by the base Metric class:","title":"Subclass the base Metric class — Metric","text":"Calling metric instance self like m(...) equivalent calling:      Initialize self. Args: name: (Optional) string name metric instance. dtype: (Optional) data type metric result.          Return serializable config metric.    Reset metric state variables. function called epochs/steps, metric evaluated training.    Compute current metric value. Returns: scalar tensor, named list scalar tensors.             Accumulate statistics metric.","code":"__call__(...) function(...) {   m$update_state(...)   m$result() } initialize(dtype=NULL, name=NULL) add_variable(shape, initializer, dtype=NULL, name=NULL) add_weight(shape=shape(), initializer=NULL, dtype=NULL, name=NULL) get_config() reset_state() result() stateless_result(metric_variables) stateless_reset_state() stateless_update_state(metric_variables, ...) update_state(...)"},{"path":"https://keras.posit.co/reference/Metric.html","id":"readonly-properties","dir":"Reference","previous_headings":"","what":"Readonly properties","title":"Subclass the base Metric class — Metric","text":"dtype variables","code":""},{"path":"https://keras.posit.co/reference/Metric.html","id":"symbols-in-scope","dir":"Reference","previous_headings":"","what":"Symbols in scope","title":"Subclass the base Metric class — Metric","text":"R function custom methods (public private) following symbols scope: self: custom class instance. super: custom class superclass. private: R environment specific class instance. objects assigned invisible Keras framework. __class__ .symbol(classname): custom class type object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Subclass the base Keras Model Class — Model","title":"Subclass the base Keras Model Class — Model","text":"advanced use cases need subclass base Model type, e.g., want override train_step() method. just want create define keras model, prefer keras_model() keras_model_sequential(). just want encapsulate custom logic state, need customize training behavior (besides calling self$add_loss() call() method), prefer Layer().","code":""},{"path":"https://keras.posit.co/reference/Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subclass the base Keras Model Class — Model","text":"","code":"Model(   classname,   initialize = NULL,   call = NULL,   train_step = NULL,   predict_step = NULL,   test_step = NULL,   compute_loss = NULL,   compute_metrics = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subclass the base Keras Model Class — Model","text":"classname String, name custom class. (Conventionally, CamelCase). initialize, call, train_step, predict_step, test_step, compute_loss, compute_metrics Optional methods can overridden. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":""},{"path":"https://keras.posit.co/reference/Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subclass the base Keras Model Class — Model","text":"model constructor function, can call create instance new model type.","code":""},{"path":"https://keras.posit.co/reference/Model.html","id":"symbols-in-scope","dir":"Reference","previous_headings":"","what":"Symbols in scope","title":"Subclass the base Keras Model Class — Model","text":"R function custom methods (public private) following symbols scope: self: custom class instance. super: custom class superclass. private: R environment specific class instance. objects assigned invisible Keras framework. __class__ .symbol(classname): custom class type object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_elu.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential Linear Unit. — activation_elu","title":"Exponential Linear Unit. — activation_elu","text":"exponential linear unit (ELU) alpha > 0 defined : x x > 0 alpha * exp(x) - 1 x < 0 ELUs negative values pushes mean activations closer zero. Mean activations closer zero enable faster learning bring gradient closer natural gradient. ELUs saturate negative value argument gets smaller. Saturation means small derivative decreases variation information propagated next layer.","code":""},{"path":"https://keras.posit.co/reference/activation_elu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential Linear Unit. — activation_elu","text":"","code":"activation_elu(x, alpha = 1)"},{"path":"https://keras.posit.co/reference/activation_elu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential Linear Unit. — activation_elu","text":"x Input tensor. alpha Numeric. See description details.","code":""},{"path":"https://keras.posit.co/reference/activation_elu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exponential Linear Unit. — activation_elu","text":"tensor, result applying activation input tensor x.","code":""},{"path":"https://keras.posit.co/reference/activation_elu.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Exponential Linear Unit. — activation_elu","text":"Clevert et al., 2016","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_exponential.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential activation function. — activation_exponential","title":"Exponential activation function. — activation_exponential","text":"Exponential activation function.","code":""},{"path":"https://keras.posit.co/reference/activation_exponential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential activation function. — activation_exponential","text":"","code":"activation_exponential(x)"},{"path":"https://keras.posit.co/reference/activation_exponential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential activation function. — activation_exponential","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_exponential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exponential activation function. — activation_exponential","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_gelu.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian error linear unit (GELU) activation function. — activation_gelu","title":"Gaussian error linear unit (GELU) activation function. — activation_gelu","text":"Gaussian error linear unit (GELU) defined : gelu(x) = x * P(X <= x) P(X) ~ N(0, 1), .e. gelu(x) = 0.5 * x * (1 + erf(x / sqrt(2))). GELU weights inputs value, rather gating inputs sign ReLU.","code":""},{"path":"https://keras.posit.co/reference/activation_gelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian error linear unit (GELU) activation function. — activation_gelu","text":"","code":"activation_gelu(x, approximate = FALSE)"},{"path":"https://keras.posit.co/reference/activation_gelu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian error linear unit (GELU) activation function. — activation_gelu","text":"x Input tensor. approximate bool, whether enable approximation.","code":""},{"path":"https://keras.posit.co/reference/activation_gelu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian error linear unit (GELU) activation function. — activation_gelu","text":"tensor, result applying activation input tensor x.","code":""},{"path":"https://keras.posit.co/reference/activation_gelu.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Gaussian error linear unit (GELU) activation function. — activation_gelu","text":"Hendrycks et al., 2016","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_hard_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Hard sigmoid activation function. — activation_hard_sigmoid","title":"Hard sigmoid activation function. — activation_hard_sigmoid","text":"hard sigmoid activation defined : 0 x < -2.5 1 x > 2.5 0.2 * x + 0.5 -2.5 <= x <= 2.5 faster, piecewise linear approximation sigmoid activation.","code":""},{"path":"https://keras.posit.co/reference/activation_hard_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hard sigmoid activation function. — activation_hard_sigmoid","text":"","code":"activation_hard_sigmoid(x)"},{"path":"https://keras.posit.co/reference/activation_hard_sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hard sigmoid activation function. — activation_hard_sigmoid","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_hard_sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hard sigmoid activation function. — activation_hard_sigmoid","text":"tensor, result applying activation input tensor x.","code":""},{"path":"https://keras.posit.co/reference/activation_hard_sigmoid.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Hard sigmoid activation function. — activation_hard_sigmoid","text":"Wikipedia \"Hard sigmoid\"","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_hard_silu.html","id":null,"dir":"Reference","previous_headings":"","what":"Hard SiLU activation function, also known as Hard Swish. — activation_hard_silu","title":"Hard SiLU activation function, also known as Hard Swish. — activation_hard_silu","text":"defined : 0 x < -3 x x > 3 x * (x + 3) / 6 -3 <= x <= 3 faster, piecewise linear approximation silu activation.","code":""},{"path":"https://keras.posit.co/reference/activation_hard_silu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hard SiLU activation function, also known as Hard Swish. — activation_hard_silu","text":"","code":"activation_hard_silu(x)  activation_hard_swish(x)"},{"path":"https://keras.posit.co/reference/activation_hard_silu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hard SiLU activation function, also known as Hard Swish. — activation_hard_silu","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_hard_silu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hard SiLU activation function, also known as Hard Swish. — activation_hard_silu","text":"tensor, result applying activation input tensor x.","code":""},{"path":"https://keras.posit.co/reference/activation_hard_silu.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Hard SiLU activation function, also known as Hard Swish. — activation_hard_silu","text":"Howard, 2019","code":""},{"path":"https://keras.posit.co/reference/activation_leaky_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaky relu activation function. — activation_leaky_relu","title":"Leaky relu activation function. — activation_leaky_relu","text":"Leaky relu activation function.","code":""},{"path":"https://keras.posit.co/reference/activation_leaky_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leaky relu activation function. — activation_leaky_relu","text":"","code":"activation_leaky_relu(x, negative_slope = 0.2)"},{"path":"https://keras.posit.co/reference/activation_leaky_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leaky relu activation function. — activation_leaky_relu","text":"x Input tensor. negative_slope float controls slope values lower threshold.","code":""},{"path":"https://keras.posit.co/reference/activation_leaky_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leaky relu activation function. — activation_leaky_relu","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear activation function (pass-through). — activation_linear","title":"Linear activation function (pass-through). — activation_linear","text":"\"linear\" activation identity function: returns input, unmodified.","code":""},{"path":"https://keras.posit.co/reference/activation_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear activation function (pass-through). — activation_linear","text":"","code":"activation_linear(x)"},{"path":"https://keras.posit.co/reference/activation_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear activation function (pass-through). — activation_linear","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear activation function (pass-through). — activation_linear","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_log_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Softmax activation function. — activation_log_softmax","title":"Log-Softmax activation function. — activation_log_softmax","text":"input vector handled independently. axis argument sets axis input function applied along.","code":""},{"path":"https://keras.posit.co/reference/activation_log_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Softmax activation function. — activation_log_softmax","text":"","code":"activation_log_softmax(x, axis = -1L)"},{"path":"https://keras.posit.co/reference/activation_log_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Softmax activation function. — activation_log_softmax","text":"x Input tensor. axis Integer, axis along softmax applied.","code":""},{"path":"https://keras.posit.co/reference/activation_log_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Softmax activation function. — activation_log_softmax","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_mish.html","id":null,"dir":"Reference","previous_headings":"","what":"Mish activation function. — activation_mish","title":"Mish activation function. — activation_mish","text":"defined : mish(x) = x * tanh(softplus(x)) softplus defined : softplus(x) = log(exp(x) + 1)","code":""},{"path":"https://keras.posit.co/reference/activation_mish.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mish activation function. — activation_mish","text":"","code":"activation_mish(x)"},{"path":"https://keras.posit.co/reference/activation_mish.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mish activation function. — activation_mish","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_mish.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mish activation function. — activation_mish","text":"tensor, result applying activation input tensor x.","code":""},{"path":"https://keras.posit.co/reference/activation_mish.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Mish activation function. — activation_mish","text":"Misra, 2019","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies the rectified linear unit activation function. — activation_relu","title":"Applies the rectified linear unit activation function. — activation_relu","text":"default values, returns standard ReLU activation: max(x, 0), element-wise maximum 0 input tensor. Modifying default parameters allows use non-zero thresholds, change max value activation, use non-zero multiple input values threshold.","code":""},{"path":"https://keras.posit.co/reference/activation_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies the rectified linear unit activation function. — activation_relu","text":"","code":"activation_relu(x, negative_slope = 0, max_value = NULL, threshold = 0)"},{"path":"https://keras.posit.co/reference/activation_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies the rectified linear unit activation function. — activation_relu","text":"x Input tensor. negative_slope numeric controls slope values lower threshold. max_value numeric sets saturation threshold (largest value function return). threshold numeric giving threshold value activation function values damped set zero.","code":""},{"path":"https://keras.posit.co/reference/activation_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Applies the rectified linear unit activation function. — activation_relu","text":"tensor shape dtype input x.","code":""},{"path":"https://keras.posit.co/reference/activation_relu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies the rectified linear unit activation function. — activation_relu","text":"","code":"x <- c(-10, -5, 0, 5, 10) activation_relu(x) ## tf.Tensor([ 0.  0.  0.  5. 10.], shape=(5), dtype=float32) activation_relu(x, negative_slope = 0.5) ## tf.Tensor([-5.  -2.5  0.   5.  10. ], shape=(5), dtype=float32) activation_relu(x, max_value = 5) ## tf.Tensor([0. 0. 0. 5. 5.], shape=(5), dtype=float32) activation_relu(x, threshold = 5) ## tf.Tensor([-0. -0.  0.  0. 10.], shape=(5), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/activation_relu6.html","id":null,"dir":"Reference","previous_headings":"","what":"Relu6 activation function. — activation_relu6","title":"Relu6 activation function. — activation_relu6","text":"ReLU function, truncated maximum value 6.","code":""},{"path":"https://keras.posit.co/reference/activation_relu6.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relu6 activation function. — activation_relu6","text":"","code":"activation_relu6(x)"},{"path":"https://keras.posit.co/reference/activation_relu6.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relu6 activation function. — activation_relu6","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_relu6.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relu6 activation function. — activation_relu6","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_selu.html","id":null,"dir":"Reference","previous_headings":"","what":"Scaled Exponential Linear Unit (SELU). — activation_selu","title":"Scaled Exponential Linear Unit (SELU). — activation_selu","text":"Scaled Exponential Linear Unit (SELU) activation function defined : scale * x x > 0 scale * alpha * (exp(x) - 1) x < 0 alpha scale pre-defined constants (alpha = 1.67326324 scale = 1.05070098). Basically, SELU activation function multiplies scale (> 1) output activation_elu function ensure slope larger one positive inputs. values alpha scale chosen mean variance inputs preserved two consecutive layers long weights initialized correctly (see initializer_lecun_normal()) number input units \"large enough\" (see reference paper information).","code":""},{"path":"https://keras.posit.co/reference/activation_selu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scaled Exponential Linear Unit (SELU). — activation_selu","text":"","code":"activation_selu(x)"},{"path":"https://keras.posit.co/reference/activation_selu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scaled Exponential Linear Unit (SELU). — activation_selu","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_selu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scaled Exponential Linear Unit (SELU). — activation_selu","text":"tensor, result applying activation input tensor x.","code":""},{"path":"https://keras.posit.co/reference/activation_selu.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Scaled Exponential Linear Unit (SELU). — activation_selu","text":"used together initializer_lecun_normal(). used together dropout variant layer_alpha_dropout() (legacy, depracated).","code":""},{"path":"https://keras.posit.co/reference/activation_selu.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Scaled Exponential Linear Unit (SELU). — activation_selu","text":"Klambauer et al., 2017","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid activation function. — activation_sigmoid","title":"Sigmoid activation function. — activation_sigmoid","text":"defined : sigmoid(x) = 1 / (1 + exp(-x)). small values (<-5), sigmoid returns value close zero, large values (>5) result function gets close 1. Sigmoid equivalent 2-element softmax, second element assumed zero. sigmoid function always returns value 0 1.","code":""},{"path":"https://keras.posit.co/reference/activation_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid activation function. — activation_sigmoid","text":"","code":"activation_sigmoid(x)"},{"path":"https://keras.posit.co/reference/activation_sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sigmoid activation function. — activation_sigmoid","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sigmoid activation function. — activation_sigmoid","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_silu.html","id":null,"dir":"Reference","previous_headings":"","what":"Swish (or Silu) activation function. — activation_silu","title":"Swish (or Silu) activation function. — activation_silu","text":"defined : swish(x) = x * sigmoid(x). Swish (Silu) activation function smooth, non-monotonic function unbounded bounded .","code":""},{"path":"https://keras.posit.co/reference/activation_silu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swish (or Silu) activation function. — activation_silu","text":"","code":"activation_silu(x)"},{"path":"https://keras.posit.co/reference/activation_silu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Swish (or Silu) activation function. — activation_silu","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_silu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Swish (or Silu) activation function. — activation_silu","text":"tensor, result applying activation input tensor x.","code":""},{"path":"https://keras.posit.co/reference/activation_silu.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Swish (or Silu) activation function. — activation_silu","text":"Ramachandran et al., 2017","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax converts a vector of values to a probability distribution. — activation_softmax","title":"Softmax converts a vector of values to a probability distribution. — activation_softmax","text":"elements output vector range [0, 1] sum 1. input vector handled independently. axis argument sets axis input function applied along. Softmax often used activation last layer classification network result interpreted probability distribution. softmax vector x computed exp(x) / sum(exp(x)). input values log-odds resulting probability.","code":""},{"path":"https://keras.posit.co/reference/activation_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax converts a vector of values to a probability distribution. — activation_softmax","text":"","code":"activation_softmax(x, axis = -1L)"},{"path":"https://keras.posit.co/reference/activation_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax converts a vector of values to a probability distribution. — activation_softmax","text":"x Input tensor. axis Integer, axis along softmax applied.","code":""},{"path":"https://keras.posit.co/reference/activation_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax converts a vector of values to a probability distribution. — activation_softmax","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_softplus.html","id":null,"dir":"Reference","previous_headings":"","what":"Softplus activation function. — activation_softplus","title":"Softplus activation function. — activation_softplus","text":"defined : softplus(x) = log(exp(x) + 1).","code":""},{"path":"https://keras.posit.co/reference/activation_softplus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softplus activation function. — activation_softplus","text":"","code":"activation_softplus(x)"},{"path":"https://keras.posit.co/reference/activation_softplus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softplus activation function. — activation_softplus","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_softplus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softplus activation function. — activation_softplus","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_softsign.html","id":null,"dir":"Reference","previous_headings":"","what":"Softsign activation function. — activation_softsign","title":"Softsign activation function. — activation_softsign","text":"Softsign defined : softsign(x) = x / (abs(x) + 1).","code":""},{"path":"https://keras.posit.co/reference/activation_softsign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softsign activation function. — activation_softsign","text":"","code":"activation_softsign(x)"},{"path":"https://keras.posit.co/reference/activation_softsign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softsign activation function. — activation_softsign","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_softsign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softsign activation function. — activation_softsign","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/activation_tanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperbolic tangent activation function. — activation_tanh","title":"Hyperbolic tangent activation function. — activation_tanh","text":"defined : tanh(x) = sinh(x) / cosh(x), .e. tanh(x) = ((exp(x) - exp(-x)) / (exp(x) + exp(-x))).","code":""},{"path":"https://keras.posit.co/reference/activation_tanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperbolic tangent activation function. — activation_tanh","text":"","code":"activation_tanh(x)"},{"path":"https://keras.posit.co/reference/activation_tanh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperbolic tangent activation function. — activation_tanh","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/activation_tanh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperbolic tangent activation function. — activation_tanh","text":"tensor, result applying activation input tensor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/active_property.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an active property class method — active_property","title":"Create an active property class method — active_property","text":"Create active property class method","code":""},{"path":"https://keras.posit.co/reference/active_property.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an active property class method — active_property","text":"","code":"active_property(fn)"},{"path":"https://keras.posit.co/reference/active_property.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an active property class method — active_property","text":"fn R function","code":""},{"path":"https://keras.posit.co/reference/active_property.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an active property class method — active_property","text":"fn, additional R attribute cause fn converted active property converted method custom subclass.","code":""},{"path":"https://keras.posit.co/reference/active_property.html","id":"example","dir":"Reference","previous_headings":"","what":"Example","title":"Create an active property class method — active_property","text":"","code":"layer_foo <- Model(\"Foo\", ...,   metrics = active_property(function() {     list(self$d_loss_metric,          self$g_loss_metric)   }))"},{"path":"https://keras.posit.co/reference/adapt.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits the state of the preprocessing layer to the data being passed — adapt","title":"Fits the state of the preprocessing layer to the data being passed — adapt","text":"Fits state preprocessing layer data passed","code":""},{"path":"https://keras.posit.co/reference/adapt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits the state of the preprocessing layer to the data being passed — adapt","text":"","code":"adapt(object, data, ..., batch_size = NULL, steps = NULL)"},{"path":"https://keras.posit.co/reference/adapt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits the state of the preprocessing layer to the data being passed — adapt","text":"object Preprocessing layer object data data train . can passed either tf.data.Dataset R array. ... Used forwards backwards compatibility. Passed underlying method. batch_size Integer NULL. Number asamples per state update. unspecified, batch_size default 32. specify batch_size data form TF Dataset generator (since generate batches). steps Integer NULL. Total number steps (batches samples) training input tensors TensorFlow data tensors, default NULL equal number samples dataset divided batch size, 1 determined. x tf.data.Dataset, steps NULL, epoch run input dataset exhausted. passing infinitely repeating dataset, must specify steps argument. argument supported array inputs.","code":""},{"path":"https://keras.posit.co/reference/adapt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits the state of the preprocessing layer to the data being passed — adapt","text":"Returns object, invisibly.","code":""},{"path":"https://keras.posit.co/reference/adapt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fits the state of the preprocessing layer to the data being passed — adapt","text":"calling adapt layer, preprocessing layer's state update training. order make preprocessing layers efficient distribution context, kept constant respect compiled tf.Graphs call layer. affect layer use adapting layer , adapt layer multiple times need take care re-compile compiled functions follows: adding preprocessing layer keras model, need call compile(model) subsequent call adapt(). calling preprocessing layer inside tfdatasets::dataset_map(), call dataset_map() input Dataset adapt(). using tensorflow::tf_function() directly calls preprocessing layer, need call tf_function() callable subsequent call adapt(). keras_model() example multiple adapts:         tfdatasets example multiple adapts:","code":"layer <- layer_normalization(axis = NULL) adapt(layer, c(0, 2)) model <- keras_model_sequential() |> layer() predict(model, c(0, 1, 2), verbose = FALSE) # [1] -1  0  1 ## [1] -1  0  1 adapt(layer, c(-1, 1)) compile(model)  # This is needed to re-compile model.predict! predict(model, c(0, 1, 2), verbose = FALSE) # [1] 0 1 2 ## [1] 0 1 2 layer <- layer_normalization(axis = NULL) adapt(layer, c(0, 2)) input_ds <- tfdatasets::range_dataset(0, 3) normalized_ds <- input_ds |>   tfdatasets::dataset_map(layer) str(tfdatasets::iterate(normalized_ds)) ## List of 3 ##  $ :<tf.Tensor: shape=(1), dtype=float32, numpy=array([-1.], dtype=float32)> ##  $ :<tf.Tensor: shape=(1), dtype=float32, numpy=array([0.], dtype=float32)> ##  $ :<tf.Tensor: shape=(1), dtype=float32, numpy=array([1.], dtype=float32)> adapt(layer, c(-1, 1)) normalized_ds <- input_ds |>   tfdatasets::dataset_map(layer) # Re-map over the input dataset.  normalized_ds |>   tfdatasets::as_array_iterator() |>   tfdatasets::iterate(simplify = FALSE) |>   str() ## List of 3 ##  $ : num [1(1d)] 0 ##  $ : num [1(1d)] 1 ##  $ : num [1(1d)] 2"},{"path":"https://keras.posit.co/reference/application_convnext_base.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ConvNeXtBase architecture. — application_convnext_base","title":"Instantiates the ConvNeXtBase architecture. — application_convnext_base","text":"Instantiates ConvNeXtBase architecture.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_base.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ConvNeXtBase architecture. — application_convnext_base","text":"","code":"application_convnext_base(   model_name = \"convnext_base\",   include_top = TRUE,   include_preprocessing = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_convnext_base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ConvNeXtBase architecture. — application_convnext_base","text":"model_name String, name model. include_top Whether include fully-connected layer top network. Defaults TRUE. include_preprocessing Boolean, whether include preprocessing layer bottom network. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet-1k), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_convnext_base.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ConvNeXtBase architecture. — application_convnext_base","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_base.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Instantiates the ConvNeXtBase architecture. — application_convnext_base","text":"ConvNet 2020s (CVPR 2022) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning. base, large, xlarge models first pre-trained ImageNet-21k dataset fine-tuned ImageNet-1k dataset. pre-trained parameters models assembled official repository. get sense parameters converted Keras compatible parameters, please refer repository.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_base.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ConvNeXtBase architecture. — application_convnext_base","text":"Keras Application expects specific kind input preprocessing. ConvNeXt, preprocessing included model using Normalization layer.  ConvNeXt models expect inputs float uint8 tensors pixels values [0-255] range. calling summary() method instantiating ConvNeXt model, prefer setting expand_nested argument summary() TRUE better investigate instantiated model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_convnext_large.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ConvNeXtLarge architecture. — application_convnext_large","title":"Instantiates the ConvNeXtLarge architecture. — application_convnext_large","text":"Instantiates ConvNeXtLarge architecture.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_large.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ConvNeXtLarge architecture. — application_convnext_large","text":"","code":"application_convnext_large(   model_name = \"convnext_large\",   include_top = TRUE,   include_preprocessing = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_convnext_large.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ConvNeXtLarge architecture. — application_convnext_large","text":"model_name String, name model. include_top Whether include fully-connected layer top network. Defaults TRUE. include_preprocessing Boolean, whether include preprocessing layer bottom network. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet-1k), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_convnext_large.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ConvNeXtLarge architecture. — application_convnext_large","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_large.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Instantiates the ConvNeXtLarge architecture. — application_convnext_large","text":"ConvNet 2020s (CVPR 2022) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning. base, large, xlarge models first pre-trained ImageNet-21k dataset fine-tuned ImageNet-1k dataset. pre-trained parameters models assembled official repository. get sense parameters converted Keras compatible parameters, please refer repository.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_large.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ConvNeXtLarge architecture. — application_convnext_large","text":"Keras Application expects specific kind input preprocessing. ConvNeXt, preprocessing included model using Normalization layer.  ConvNeXt models expect inputs float uint8 tensors pixels values [0-255] range. calling summary() method instantiating ConvNeXt model, prefer setting expand_nested argument summary() TRUE better investigate instantiated model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_convnext_small.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ConvNeXtSmall architecture. — application_convnext_small","title":"Instantiates the ConvNeXtSmall architecture. — application_convnext_small","text":"Instantiates ConvNeXtSmall architecture.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_small.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ConvNeXtSmall architecture. — application_convnext_small","text":"","code":"application_convnext_small(   model_name = \"convnext_small\",   include_top = TRUE,   include_preprocessing = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_convnext_small.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ConvNeXtSmall architecture. — application_convnext_small","text":"model_name String, name model. include_top Whether include fully-connected layer top network. Defaults TRUE. include_preprocessing Boolean, whether include preprocessing layer bottom network. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet-1k), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_convnext_small.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ConvNeXtSmall architecture. — application_convnext_small","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_small.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Instantiates the ConvNeXtSmall architecture. — application_convnext_small","text":"ConvNet 2020s (CVPR 2022) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning. base, large, xlarge models first pre-trained ImageNet-21k dataset fine-tuned ImageNet-1k dataset. pre-trained parameters models assembled official repository. get sense parameters converted Keras compatible parameters, please refer repository.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_small.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ConvNeXtSmall architecture. — application_convnext_small","text":"Keras Application expects specific kind input preprocessing. ConvNeXt, preprocessing included model using Normalization layer.  ConvNeXt models expect inputs float uint8 tensors pixels values [0-255] range. calling summary() method instantiating ConvNeXt model, prefer setting expand_nested argument summary() TRUE better investigate instantiated model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_convnext_tiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ConvNeXtTiny architecture. — application_convnext_tiny","title":"Instantiates the ConvNeXtTiny architecture. — application_convnext_tiny","text":"Instantiates ConvNeXtTiny architecture.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_tiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ConvNeXtTiny architecture. — application_convnext_tiny","text":"","code":"application_convnext_tiny(   model_name = \"convnext_tiny\",   include_top = TRUE,   include_preprocessing = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_convnext_tiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ConvNeXtTiny architecture. — application_convnext_tiny","text":"model_name String, name model. include_top Whether include fully-connected layer top network. Defaults TRUE. include_preprocessing Boolean, whether include preprocessing layer bottom network. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet-1k), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_convnext_tiny.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ConvNeXtTiny architecture. — application_convnext_tiny","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_tiny.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Instantiates the ConvNeXtTiny architecture. — application_convnext_tiny","text":"ConvNet 2020s (CVPR 2022) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning. base, large, xlarge models first pre-trained ImageNet-21k dataset fine-tuned ImageNet-1k dataset. pre-trained parameters models assembled official repository. get sense parameters converted Keras compatible parameters, please refer repository.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_tiny.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ConvNeXtTiny architecture. — application_convnext_tiny","text":"Keras Application expects specific kind input preprocessing. ConvNeXt, preprocessing included model using Normalization layer.  ConvNeXt models expect inputs float uint8 tensors pixels values [0-255] range. calling summary() method instantiating ConvNeXt model, prefer setting expand_nested argument summary() TRUE better investigate instantiated model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_convnext_xlarge.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ConvNeXtXLarge architecture. — application_convnext_xlarge","title":"Instantiates the ConvNeXtXLarge architecture. — application_convnext_xlarge","text":"Instantiates ConvNeXtXLarge architecture.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_xlarge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ConvNeXtXLarge architecture. — application_convnext_xlarge","text":"","code":"application_convnext_xlarge(   model_name = \"convnext_xlarge\",   include_top = TRUE,   include_preprocessing = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_convnext_xlarge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ConvNeXtXLarge architecture. — application_convnext_xlarge","text":"model_name String, name model. include_top Whether include fully-connected layer top network. Defaults TRUE. include_preprocessing Boolean, whether include preprocessing layer bottom network. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet-1k), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_convnext_xlarge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ConvNeXtXLarge architecture. — application_convnext_xlarge","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_xlarge.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Instantiates the ConvNeXtXLarge architecture. — application_convnext_xlarge","text":"ConvNet 2020s (CVPR 2022) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning. base, large, xlarge models first pre-trained ImageNet-21k dataset fine-tuned ImageNet-1k dataset. pre-trained parameters models assembled official repository. get sense parameters converted Keras compatible parameters, please refer repository.","code":""},{"path":"https://keras.posit.co/reference/application_convnext_xlarge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ConvNeXtXLarge architecture. — application_convnext_xlarge","text":"Keras Application expects specific kind input preprocessing. ConvNeXt, preprocessing included model using Normalization layer.  ConvNeXt models expect inputs float uint8 tensors pixels values [0-255] range. calling summary() method instantiating ConvNeXt model, prefer setting expand_nested argument summary() TRUE better investigate instantiated model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_densenet121.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the Densenet121 architecture. — application_densenet121","title":"Instantiates the Densenet121 architecture. — application_densenet121","text":"Instantiates Densenet121 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_densenet121.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the Densenet121 architecture. — application_densenet121","text":"","code":"application_densenet121(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_densenet121.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the Densenet121 architecture. — application_densenet121","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) ('channels_last' data format) (3, 224, 224) ('channels_first' data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_densenet121.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the Densenet121 architecture. — application_densenet121","text":"Keras model instance.","code":""},{"path":"https://keras.posit.co/reference/application_densenet121.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the Densenet121 architecture. — application_densenet121","text":"Densely Connected Convolutional Networks (CVPR 2017) Optionally loads weights pre-trained ImageNet. Note data format convention used model one specified Keras config ~/.keras/keras.json.","code":""},{"path":"https://keras.posit.co/reference/application_densenet121.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the Densenet121 architecture. — application_densenet121","text":"Keras Application expects specific kind input preprocessing. DenseNet, call application_preprocess_inputs() inputs passing model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_densenet169.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the Densenet169 architecture. — application_densenet169","title":"Instantiates the Densenet169 architecture. — application_densenet169","text":"Instantiates Densenet169 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_densenet169.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the Densenet169 architecture. — application_densenet169","text":"","code":"application_densenet169(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_densenet169.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the Densenet169 architecture. — application_densenet169","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) ('channels_last' data format) (3, 224, 224) ('channels_first' data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_densenet169.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the Densenet169 architecture. — application_densenet169","text":"Keras model instance.","code":""},{"path":"https://keras.posit.co/reference/application_densenet169.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the Densenet169 architecture. — application_densenet169","text":"Densely Connected Convolutional Networks (CVPR 2017) Optionally loads weights pre-trained ImageNet. Note data format convention used model one specified Keras config ~/.keras/keras.json.","code":""},{"path":"https://keras.posit.co/reference/application_densenet169.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the Densenet169 architecture. — application_densenet169","text":"Keras Application expects specific kind input preprocessing. DenseNet, call application_preprocess_inputs() inputs passing model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_densenet201.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the Densenet201 architecture. — application_densenet201","title":"Instantiates the Densenet201 architecture. — application_densenet201","text":"Instantiates Densenet201 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_densenet201.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the Densenet201 architecture. — application_densenet201","text":"","code":"application_densenet201(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_densenet201.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the Densenet201 architecture. — application_densenet201","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) ('channels_last' data format) (3, 224, 224) ('channels_first' data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_densenet201.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the Densenet201 architecture. — application_densenet201","text":"Keras model instance.","code":""},{"path":"https://keras.posit.co/reference/application_densenet201.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the Densenet201 architecture. — application_densenet201","text":"Densely Connected Convolutional Networks (CVPR 2017) Optionally loads weights pre-trained ImageNet. Note data format convention used model one specified Keras config ~/.keras/keras.json.","code":""},{"path":"https://keras.posit.co/reference/application_densenet201.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the Densenet201 architecture. — application_densenet201","text":"Keras Application expects specific kind input preprocessing. DenseNet, call application_preprocess_inputs() inputs passing model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_b0.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetB0 architecture. — application_efficientnet_b0","title":"Instantiates the EfficientNetB0 architecture. — application_efficientnet_b0","text":"Instantiates EfficientNetB0 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetB0 architecture. — application_efficientnet_b0","text":"","code":"application_efficientnet_b0(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   ... )"},{"path":"https://keras.posit.co/reference/application_efficientnet_b0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetB0 architecture. — application_efficientnet_b0","text":"include_top Whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. 1000 many ImageNet classes . Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults 'softmax'. loading pretrained weights, classifier_activation can NULL \"softmax\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetB0 architecture. — application_efficientnet_b0","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b0.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetB0 architecture. — application_efficientnet_b0","text":"EfficientNet: Rethinking Model Scaling Convolutional Neural Networks (ICML 2019) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b0.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetB0 architecture. — application_efficientnet_b0","text":"Keras Application expects specific kind input preprocessing. EfficientNet, input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. EfficientNet models expect inputs float tensors pixels values [0-255] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_b1.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetB1 architecture. — application_efficientnet_b1","title":"Instantiates the EfficientNetB1 architecture. — application_efficientnet_b1","text":"Instantiates EfficientNetB1 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetB1 architecture. — application_efficientnet_b1","text":"","code":"application_efficientnet_b1(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   ... )"},{"path":"https://keras.posit.co/reference/application_efficientnet_b1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetB1 architecture. — application_efficientnet_b1","text":"include_top Whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. 1000 many ImageNet classes . Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults 'softmax'. loading pretrained weights, classifier_activation can NULL \"softmax\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetB1 architecture. — application_efficientnet_b1","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b1.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetB1 architecture. — application_efficientnet_b1","text":"EfficientNet: Rethinking Model Scaling Convolutional Neural Networks (ICML 2019) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b1.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetB1 architecture. — application_efficientnet_b1","text":"Keras Application expects specific kind input preprocessing. EfficientNet, input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. EfficientNet models expect inputs float tensors pixels values [0-255] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_b2.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetB2 architecture. — application_efficientnet_b2","title":"Instantiates the EfficientNetB2 architecture. — application_efficientnet_b2","text":"Instantiates EfficientNetB2 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetB2 architecture. — application_efficientnet_b2","text":"","code":"application_efficientnet_b2(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   ... )"},{"path":"https://keras.posit.co/reference/application_efficientnet_b2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetB2 architecture. — application_efficientnet_b2","text":"include_top Whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. 1000 many ImageNet classes . Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults 'softmax'. loading pretrained weights, classifier_activation can NULL \"softmax\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetB2 architecture. — application_efficientnet_b2","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b2.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetB2 architecture. — application_efficientnet_b2","text":"EfficientNet: Rethinking Model Scaling Convolutional Neural Networks (ICML 2019) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetB2 architecture. — application_efficientnet_b2","text":"Keras Application expects specific kind input preprocessing. EfficientNet, input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. EfficientNet models expect inputs float tensors pixels values [0-255] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_b3.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetB3 architecture. — application_efficientnet_b3","title":"Instantiates the EfficientNetB3 architecture. — application_efficientnet_b3","text":"Instantiates EfficientNetB3 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetB3 architecture. — application_efficientnet_b3","text":"","code":"application_efficientnet_b3(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   ... )"},{"path":"https://keras.posit.co/reference/application_efficientnet_b3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetB3 architecture. — application_efficientnet_b3","text":"include_top Whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. 1000 many ImageNet classes . Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults 'softmax'. loading pretrained weights, classifier_activation can NULL \"softmax\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetB3 architecture. — application_efficientnet_b3","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b3.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetB3 architecture. — application_efficientnet_b3","text":"EfficientNet: Rethinking Model Scaling Convolutional Neural Networks (ICML 2019) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b3.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetB3 architecture. — application_efficientnet_b3","text":"Keras Application expects specific kind input preprocessing. EfficientNet, input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. EfficientNet models expect inputs float tensors pixels values [0-255] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_b4.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetB4 architecture. — application_efficientnet_b4","title":"Instantiates the EfficientNetB4 architecture. — application_efficientnet_b4","text":"Instantiates EfficientNetB4 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetB4 architecture. — application_efficientnet_b4","text":"","code":"application_efficientnet_b4(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   ... )"},{"path":"https://keras.posit.co/reference/application_efficientnet_b4.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetB4 architecture. — application_efficientnet_b4","text":"include_top Whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. 1000 many ImageNet classes . Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults 'softmax'. loading pretrained weights, classifier_activation can NULL \"softmax\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b4.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetB4 architecture. — application_efficientnet_b4","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b4.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetB4 architecture. — application_efficientnet_b4","text":"EfficientNet: Rethinking Model Scaling Convolutional Neural Networks (ICML 2019) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b4.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetB4 architecture. — application_efficientnet_b4","text":"Keras Application expects specific kind input preprocessing. EfficientNet, input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. EfficientNet models expect inputs float tensors pixels values [0-255] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_b5.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetB5 architecture. — application_efficientnet_b5","title":"Instantiates the EfficientNetB5 architecture. — application_efficientnet_b5","text":"Instantiates EfficientNetB5 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetB5 architecture. — application_efficientnet_b5","text":"","code":"application_efficientnet_b5(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   ... )"},{"path":"https://keras.posit.co/reference/application_efficientnet_b5.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetB5 architecture. — application_efficientnet_b5","text":"include_top Whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. 1000 many ImageNet classes . Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults 'softmax'. loading pretrained weights, classifier_activation can NULL \"softmax\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b5.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetB5 architecture. — application_efficientnet_b5","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b5.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetB5 architecture. — application_efficientnet_b5","text":"EfficientNet: Rethinking Model Scaling Convolutional Neural Networks (ICML 2019) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b5.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetB5 architecture. — application_efficientnet_b5","text":"Keras Application expects specific kind input preprocessing. EfficientNet, input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. EfficientNet models expect inputs float tensors pixels values [0-255] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_b6.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetB6 architecture. — application_efficientnet_b6","title":"Instantiates the EfficientNetB6 architecture. — application_efficientnet_b6","text":"Instantiates EfficientNetB6 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b6.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetB6 architecture. — application_efficientnet_b6","text":"","code":"application_efficientnet_b6(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   ... )"},{"path":"https://keras.posit.co/reference/application_efficientnet_b6.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetB6 architecture. — application_efficientnet_b6","text":"include_top Whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. 1000 many ImageNet classes . Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults 'softmax'. loading pretrained weights, classifier_activation can NULL \"softmax\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b6.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetB6 architecture. — application_efficientnet_b6","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b6.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetB6 architecture. — application_efficientnet_b6","text":"EfficientNet: Rethinking Model Scaling Convolutional Neural Networks (ICML 2019) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b6.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetB6 architecture. — application_efficientnet_b6","text":"Keras Application expects specific kind input preprocessing. EfficientNet, input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. EfficientNet models expect inputs float tensors pixels values [0-255] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_b7.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetB7 architecture. — application_efficientnet_b7","title":"Instantiates the EfficientNetB7 architecture. — application_efficientnet_b7","text":"Instantiates EfficientNetB7 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b7.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetB7 architecture. — application_efficientnet_b7","text":"","code":"application_efficientnet_b7(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   ... )"},{"path":"https://keras.posit.co/reference/application_efficientnet_b7.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetB7 architecture. — application_efficientnet_b7","text":"include_top Whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. 1000 many ImageNet classes . Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults 'softmax'. loading pretrained weights, classifier_activation can NULL \"softmax\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b7.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetB7 architecture. — application_efficientnet_b7","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b7.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetB7 architecture. — application_efficientnet_b7","text":"EfficientNet: Rethinking Model Scaling Convolutional Neural Networks (ICML 2019) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_b7.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetB7 architecture. — application_efficientnet_b7","text":"Keras Application expects specific kind input preprocessing. EfficientNet, input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. EfficientNet models expect inputs float tensors pixels values [0-255] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b0.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetV2B0 architecture. — application_efficientnet_v2b0","title":"Instantiates the EfficientNetV2B0 architecture. — application_efficientnet_v2b0","text":"Instantiates EfficientNetV2B0 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetV2B0 architecture. — application_efficientnet_v2b0","text":"","code":"application_efficientnet_v2b0(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetV2B0 architecture. — application_efficientnet_v2b0","text":"include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. \"avg\" means global average pooling applied output last convolutional layer, thus output model 2D tensor. \"max\" means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation string callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer bottom network.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetV2B0 architecture. — application_efficientnet_v2b0","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b0.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetV2B0 architecture. — application_efficientnet_v2b0","text":"EfficientNetV2: Smaller Models Faster Training (ICML 2021) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b0.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetV2B0 architecture. — application_efficientnet_v2b0","text":"Keras Application expects specific kind input preprocessing. EfficientNetV2, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, EfficientNetV2 models expect inputs float tensors pixels values [0, 255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled EfficientNetV2 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b1.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetV2B1 architecture. — application_efficientnet_v2b1","title":"Instantiates the EfficientNetV2B1 architecture. — application_efficientnet_v2b1","text":"Instantiates EfficientNetV2B1 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetV2B1 architecture. — application_efficientnet_v2b1","text":"","code":"application_efficientnet_v2b1(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetV2B1 architecture. — application_efficientnet_v2b1","text":"include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. \"avg\" means global average pooling applied output last convolutional layer, thus output model 2D tensor. \"max\" means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation string callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer bottom network.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetV2B1 architecture. — application_efficientnet_v2b1","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b1.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetV2B1 architecture. — application_efficientnet_v2b1","text":"EfficientNetV2: Smaller Models Faster Training (ICML 2021) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b1.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetV2B1 architecture. — application_efficientnet_v2b1","text":"Keras Application expects specific kind input preprocessing. EfficientNetV2, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, EfficientNetV2 models expect inputs float tensors pixels values [0, 255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled EfficientNetV2 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b2.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetV2B2 architecture. — application_efficientnet_v2b2","title":"Instantiates the EfficientNetV2B2 architecture. — application_efficientnet_v2b2","text":"Instantiates EfficientNetV2B2 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetV2B2 architecture. — application_efficientnet_v2b2","text":"","code":"application_efficientnet_v2b2(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetV2B2 architecture. — application_efficientnet_v2b2","text":"include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. \"avg\" means global average pooling applied output last convolutional layer, thus output model 2D tensor. \"max\" means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation string callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer bottom network.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetV2B2 architecture. — application_efficientnet_v2b2","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b2.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetV2B2 architecture. — application_efficientnet_v2b2","text":"EfficientNetV2: Smaller Models Faster Training (ICML 2021) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetV2B2 architecture. — application_efficientnet_v2b2","text":"Keras Application expects specific kind input preprocessing. EfficientNetV2, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, EfficientNetV2 models expect inputs float tensors pixels values [0, 255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled EfficientNetV2 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b3.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetV2B3 architecture. — application_efficientnet_v2b3","title":"Instantiates the EfficientNetV2B3 architecture. — application_efficientnet_v2b3","text":"Instantiates EfficientNetV2B3 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetV2B3 architecture. — application_efficientnet_v2b3","text":"","code":"application_efficientnet_v2b3(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetV2B3 architecture. — application_efficientnet_v2b3","text":"include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. \"avg\" means global average pooling applied output last convolutional layer, thus output model 2D tensor. \"max\" means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation string callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer bottom network.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetV2B3 architecture. — application_efficientnet_v2b3","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b3.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetV2B3 architecture. — application_efficientnet_v2b3","text":"EfficientNetV2: Smaller Models Faster Training (ICML 2021) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2b3.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetV2B3 architecture. — application_efficientnet_v2b3","text":"Keras Application expects specific kind input preprocessing. EfficientNetV2, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, EfficientNetV2 models expect inputs float tensors pixels values [0, 255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled EfficientNetV2 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_v2l.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetV2L architecture. — application_efficientnet_v2l","title":"Instantiates the EfficientNetV2L architecture. — application_efficientnet_v2l","text":"Instantiates EfficientNetV2L architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2l.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetV2L architecture. — application_efficientnet_v2l","text":"","code":"application_efficientnet_v2l(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_efficientnet_v2l.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetV2L architecture. — application_efficientnet_v2l","text":"include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. \"avg\" means global average pooling applied output last convolutional layer, thus output model 2D tensor. \"max\" means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation string callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer bottom network.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2l.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetV2L architecture. — application_efficientnet_v2l","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2l.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetV2L architecture. — application_efficientnet_v2l","text":"EfficientNetV2: Smaller Models Faster Training (ICML 2021) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2l.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetV2L architecture. — application_efficientnet_v2l","text":"Keras Application expects specific kind input preprocessing. EfficientNetV2, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, EfficientNetV2 models expect inputs float tensors pixels values [0, 255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled EfficientNetV2 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_v2m.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetV2M architecture. — application_efficientnet_v2m","title":"Instantiates the EfficientNetV2M architecture. — application_efficientnet_v2m","text":"Instantiates EfficientNetV2M architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2m.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetV2M architecture. — application_efficientnet_v2m","text":"","code":"application_efficientnet_v2m(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_efficientnet_v2m.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetV2M architecture. — application_efficientnet_v2m","text":"include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. \"avg\" means global average pooling applied output last convolutional layer, thus output model 2D tensor. \"max\" means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation string callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer bottom network.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2m.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetV2M architecture. — application_efficientnet_v2m","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2m.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetV2M architecture. — application_efficientnet_v2m","text":"EfficientNetV2: Smaller Models Faster Training (ICML 2021) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2m.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetV2M architecture. — application_efficientnet_v2m","text":"Keras Application expects specific kind input preprocessing. EfficientNetV2, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, EfficientNetV2 models expect inputs float tensors pixels values [0, 255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled EfficientNetV2 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_efficientnet_v2s.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the EfficientNetV2S architecture. — application_efficientnet_v2s","title":"Instantiates the EfficientNetV2S architecture. — application_efficientnet_v2s","text":"Instantiates EfficientNetV2S architecture.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2s.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the EfficientNetV2S architecture. — application_efficientnet_v2s","text":"","code":"application_efficientnet_v2s(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_efficientnet_v2s.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the EfficientNetV2S architecture. — application_efficientnet_v2s","text":"include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_shape Optional shape tuple, specified include_top FALSE. exactly 3 inputs channels. pooling Optional pooling mode feature extraction include_top FALSE. Defaults NULL. NULL means output model 4D tensor output last convolutional layer. \"avg\" means global average pooling applied output last convolutional layer, thus output model 2D tensor. \"max\" means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000 (number ImageNet classes). classifier_activation string callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. Defaults \"softmax\". loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer bottom network.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2s.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the EfficientNetV2S architecture. — application_efficientnet_v2s","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2s.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the EfficientNetV2S architecture. — application_efficientnet_v2s","text":"EfficientNetV2: Smaller Models Faster Training (ICML 2021) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_efficientnet_v2s.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the EfficientNetV2S architecture. — application_efficientnet_v2s","text":"Keras Application expects specific kind input preprocessing. EfficientNetV2, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, EfficientNetV2 models expect inputs float tensors pixels values [0, 255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled EfficientNetV2 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_inception_resnet_v2.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the Inception-ResNet v2 architecture. — application_inception_resnet_v2","title":"Instantiates the Inception-ResNet v2 architecture. — application_inception_resnet_v2","text":"Instantiates Inception-ResNet v2 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_inception_resnet_v2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the Inception-ResNet v2 architecture. — application_inception_resnet_v2","text":"","code":"application_inception_resnet_v2(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_inception_resnet_v2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the Inception-ResNet v2 architecture. — application_inception_resnet_v2","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (299, 299, 3) ('channels_last' data format) (3, 299, 299) ('channels_first' data format). exactly 3 inputs channels, width height smaller 75. E.g. (150, 150, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. 'avg' means global average pooling applied output last convolutional block, thus output model 2D tensor. 'max' means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_inception_resnet_v2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the Inception-ResNet v2 architecture. — application_inception_resnet_v2","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_inception_resnet_v2.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the Inception-ResNet v2 architecture. — application_inception_resnet_v2","text":"Inception-v4, Inception-ResNet Impact Residual Connections Learning (AAAI 2017) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_inception_resnet_v2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the Inception-ResNet v2 architecture. — application_inception_resnet_v2","text":"Keras Application expects specific kind input preprocessing. InceptionResNetV2, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() scale input pixels -1 1.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_inception_v3.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the Inception v3 architecture. — application_inception_v3","title":"Instantiates the Inception v3 architecture. — application_inception_v3","text":"Instantiates Inception v3 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_inception_v3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the Inception v3 architecture. — application_inception_v3","text":"","code":"application_inception_v3(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_inception_v3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the Inception v3 architecture. — application_inception_v3","text":"include_top Boolean, whether include fully-connected layer top, last layer network. Defaults TRUE. weights One NULL (random initialization), imagenet (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_tensor useful sharing inputs multiple different networks. Defaults NULL. input_shape Optional shape tuple, specified include_top FALSE (otherwise input shape (299, 299, 3) (channels_last data format) (3, 299, 299) (channels_first data format). exactly 3 inputs channels, width height smaller 75. E.g. (150, 150, 3) one valid value. input_shape ignored input_tensor provided. pooling Optional pooling mode feature extraction include_top FALSE. NULL (default) means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_inception_v3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the Inception v3 architecture. — application_inception_v3","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_inception_v3.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the Inception v3 architecture. — application_inception_v3","text":"Rethinking Inception Architecture Computer Vision (CVPR 2016) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_inception_v3.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the Inception v3 architecture. — application_inception_v3","text":"Keras Application expects specific kind input preprocessing. InceptionV3, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() scale input pixels -1 1.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_mobilenet.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the MobileNet architecture. — application_mobilenet","title":"Instantiates the MobileNet architecture. — application_mobilenet","text":"Instantiates MobileNet architecture.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the MobileNet architecture. — application_mobilenet","text":"","code":"application_mobilenet(   input_shape = NULL,   alpha = 1,   depth_multiplier = 1L,   dropout = 0.001,   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_mobilenet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the MobileNet architecture. — application_mobilenet","text":"input_shape Optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (\"channels_last\" data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. Defaults NULL. input_shape ignored input_tensor provided. alpha Controls width network. known width multiplier MobileNet paper. alpha < 1.0, proportionally decreases number filters layer. alpha > 1.0, proportionally increases number filters layer. alpha == 1, default number filters paper used layer. Defaults 1.0. depth_multiplier Depth multiplier depthwise convolution. called resolution multiplier MobileNet paper. Defaults 1.0. dropout Dropout rate. Defaults 0.001. include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_tensor useful sharing inputs multiple different networks. Defaults NULL. pooling Optional pooling mode feature extraction include_top FALSE. NULL (default) means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the MobileNet architecture. — application_mobilenet","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the MobileNet architecture. — application_mobilenet","text":"MobileNets: Efficient Convolutional Neural Networks Mobile Vision Applications function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the MobileNet architecture. — application_mobilenet","text":"Keras Application expects specific kind input preprocessing. MobileNet, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() scale input pixels -1 1.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_mobilenet_v2.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the MobileNetV2 architecture. — application_mobilenet_v2","title":"Instantiates the MobileNetV2 architecture. — application_mobilenet_v2","text":"MobileNetV2 similar original MobileNet, except uses inverted residual blocks bottlenecking features. drastically lower parameter count original MobileNet. MobileNets support input size greater 32 x 32, larger image sizes offering better performance.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the MobileNetV2 architecture. — application_mobilenet_v2","text":"","code":"application_mobilenet_v2(   input_shape = NULL,   alpha = 1,   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_mobilenet_v2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the MobileNetV2 architecture. — application_mobilenet_v2","text":"input_shape Optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (\"channels_last\" data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. Defaults NULL. input_shape ignored input_tensor provided. alpha Controls width network. known width multiplier MobileNet paper. alpha < 1.0, proportionally decreases number filters layer. alpha > 1.0, proportionally increases number filters layer. alpha == 1, default number filters paper used layer. Defaults 1.0. include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights One NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. Defaults \"imagenet\". input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. input_tensor useful sharing inputs multiple different networks. Defaults NULL. pooling Optional pooling mode feature extraction include_top FALSE. NULL (default) means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. Defaults 1000. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the MobileNetV2 architecture. — application_mobilenet_v2","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v2.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the MobileNetV2 architecture. — application_mobilenet_v2","text":"MobileNetV2: Inverted Residuals Linear Bottlenecks (CVPR 2018) function returns Keras image classification model, optionally loaded weights pre-trained ImageNet. image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the MobileNetV2 architecture. — application_mobilenet_v2","text":"Keras Application expects specific kind input preprocessing. MobileNetV2, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() scale input pixels -1 1.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_large.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","title":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","text":"Instantiates MobileNetV3Large architecture.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_large.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","text":"","code":"application_mobilenet_v3_large(   input_shape = NULL,   alpha = 1,   minimalistic = FALSE,   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   classes = 1000L,   pooling = NULL,   dropout_rate = 0.2,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_large.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","text":"input_shape Optional shape tuple, specified like use model input image resolution (224, 224, 3). exactly 3 inputs channels. can also omit option like infer input_shape input_tensor. choose include input_tensor input_shape input_shape used match, shapes match throw error. E.g. (160, 160, 3) one valid value. alpha controls width network. known depth multiplier MobileNetV3 paper, name kept consistency MobileNetV1 Keras. alpha < 1.0, proportionally decreases number filters layer. alpha > 1.0, proportionally increases number filters layer. alpha == 1, default number filters paper used layer. minimalistic addition large small models module also contains -called minimalistic models, models per-layer dimensions characteristic MobilenetV3 however, utilize advanced blocks (squeeze--excite units, hard-swish, 5x5 convolutions). models less efficient CPU, much performant GPU/DSP. include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights String, one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. classes Integer, optional number classes classify images , specified include_top TRUE, weights argument specified. pooling String, optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. dropout_rate fraction input units drop last layer. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer (Rescaling) bottom network. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_large.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_large.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","text":"Searching MobileNetV3 (ICCV 2019)","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_large.html","id":"the-following-table-describes-the-performance-of-mobilenets-v-","dir":"Reference","previous_headings":"","what":"The following table describes the performance of MobileNets v3:","title":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","text":"MACs stands Multiply Adds image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_large.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","text":"Keras Application expects specific kind input preprocessing. MobileNetV3, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, MobileNetV3 models expect inputs float tensors pixels values [0-255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled MobileNetV3 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_large.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Instantiates the MobileNetV3Large architecture. — application_mobilenet_v3_large","text":"inputs: floating point numpy.array backend-native tensor, 4D 3 color channels, values range [0, 255] include_preprocessing TRUE range [-1, 1] otherwise.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_small.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","title":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","text":"Instantiates MobileNetV3Small architecture.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_small.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","text":"","code":"application_mobilenet_v3_small(   input_shape = NULL,   alpha = 1,   minimalistic = FALSE,   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   classes = 1000L,   pooling = NULL,   dropout_rate = 0.2,   classifier_activation = \"softmax\",   include_preprocessing = TRUE )"},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_small.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","text":"input_shape Optional shape tuple, specified like use model input image resolution (224, 224, 3). exactly 3 inputs channels. can also omit option like infer input_shape input_tensor. choose include input_tensor input_shape input_shape used match, shapes match throw error. E.g. (160, 160, 3) one valid value. alpha controls width network. known depth multiplier MobileNetV3 paper, name kept consistency MobileNetV1 Keras. alpha < 1.0, proportionally decreases number filters layer. alpha > 1.0, proportionally increases number filters layer. alpha == 1, default number filters paper used layer. minimalistic addition large small models module also contains -called minimalistic models, models per-layer dimensions characteristic MobilenetV3 however, utilize advanced blocks (squeeze--excite units, hard-swish, 5x5 convolutions). models less efficient CPU, much performant GPU/DSP. include_top Boolean, whether include fully-connected layer top network. Defaults TRUE. weights String, one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. classes Integer, optional number classes classify images , specified include_top TRUE, weights argument specified. pooling String, optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. dropout_rate fraction input units drop last layer. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\". include_preprocessing Boolean, whether include preprocessing layer (Rescaling) bottom network. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_small.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_small.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","text":"Searching MobileNetV3 (ICCV 2019)","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_small.html","id":"the-following-table-describes-the-performance-of-mobilenets-v-","dir":"Reference","previous_headings":"","what":"The following table describes the performance of MobileNets v3:","title":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","text":"MACs stands Multiply Adds image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_small.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","text":"Keras Application expects specific kind input preprocessing. MobileNetV3, default input preprocessing included part model (Rescaling layer), thus application_preprocess_inputs() actually pass-function. use case, MobileNetV3 models expect inputs float tensors pixels values [0-255] range. time, preprocessing part model (.e. Rescaling layer) can disabled setting include_preprocessing argument FALSE. preprocessing disabled MobileNetV3 models expect inputs float tensors pixels values [-1, 1] range.","code":""},{"path":"https://keras.posit.co/reference/application_mobilenet_v3_small.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Instantiates the MobileNetV3Small architecture. — application_mobilenet_v3_small","text":"inputs: floating point numpy.array backend-native tensor, 4D 3 color channels, values range [0, 255] include_preprocessing TRUE range [-1, 1] otherwise.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_nasnetlarge.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates a NASNet model in ImageNet mode. — application_nasnetlarge","title":"Instantiates a NASNet model in ImageNet mode. — application_nasnetlarge","text":"Instantiates NASNet model ImageNet mode.","code":""},{"path":"https://keras.posit.co/reference/application_nasnetlarge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates a NASNet model in ImageNet mode. — application_nasnetlarge","text":"","code":"application_nasnetlarge(   input_shape = NULL,   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_nasnetlarge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates a NASNet model in ImageNet mode. — application_nasnetlarge","text":"input_shape Optional shape tuple, specified include_top FALSE (otherwise input shape (331, 331, 3) NASNetLarge. exactly 3 inputs channels, width height smaller 32. E.g. (224, 224, 3) one valid value. include_top Whether include fully-connected layer top network. weights NULL (random initialization) imagenet (ImageNet weights).  loading imagenet weights, input_shape (331, 331, 3) input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer.  loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_nasnetlarge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates a NASNet model in ImageNet mode. — application_nasnetlarge","text":"Keras model instance.","code":""},{"path":"https://keras.posit.co/reference/application_nasnetlarge.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates a NASNet model in ImageNet mode. — application_nasnetlarge","text":"Learning Transferable Architectures Scalable Image Recognition (CVPR 2018) Optionally loads weights pre-trained ImageNet. Note data format convention used model one specified Keras config ~/.keras/keras.json.","code":""},{"path":"https://keras.posit.co/reference/application_nasnetlarge.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates a NASNet model in ImageNet mode. — application_nasnetlarge","text":"Keras Application expects specific kind input preprocessing. NASNet, call application_preprocess_inputs() inputs passing model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_nasnetmobile.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates a Mobile NASNet model in ImageNet mode. — application_nasnetmobile","title":"Instantiates a Mobile NASNet model in ImageNet mode. — application_nasnetmobile","text":"Instantiates Mobile NASNet model ImageNet mode.","code":""},{"path":"https://keras.posit.co/reference/application_nasnetmobile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates a Mobile NASNet model in ImageNet mode. — application_nasnetmobile","text":"","code":"application_nasnetmobile(   input_shape = NULL,   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_nasnetmobile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates a Mobile NASNet model in ImageNet mode. — application_nasnetmobile","text":"input_shape Optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) NASNetMobile exactly 3 inputs channels, width height smaller 32. E.g. (224, 224, 3) one valid value. include_top Whether include fully-connected layer top network. weights NULL (random initialization) imagenet (ImageNet weights). loading imagenet weights, input_shape (224, 224, 3) input_tensor Optional Keras tensor (.e. output layers.Input()) use image input model. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional layer. avg means global average pooling applied output last convolutional layer, thus output model 2D tensor. max means global max pooling applied. classes Optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer.  loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_nasnetmobile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates a Mobile NASNet model in ImageNet mode. — application_nasnetmobile","text":"Keras model instance.","code":""},{"path":"https://keras.posit.co/reference/application_nasnetmobile.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates a Mobile NASNet model in ImageNet mode. — application_nasnetmobile","text":"Learning Transferable Architectures Scalable Image Recognition (CVPR 2018) Optionally loads weights pre-trained ImageNet. Note data format convention used model one specified Keras config ~/.keras/keras.json.","code":""},{"path":"https://keras.posit.co/reference/application_nasnetmobile.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates a Mobile NASNet model in ImageNet mode. — application_nasnetmobile","text":"Keras Application expects specific kind input preprocessing. NASNet, call application_preprocess_inputs() inputs passing model.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_resnet101.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ResNet101 architecture. — application_resnet101","title":"Instantiates the ResNet101 architecture. — application_resnet101","text":"Instantiates ResNet101 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_resnet101.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ResNet101 architecture. — application_resnet101","text":"","code":"application_resnet101(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_resnet101.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ResNet101 architecture. — application_resnet101","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (\"channels_last\" data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_resnet101.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ResNet101 architecture. — application_resnet101","text":"Model instance.","code":""},{"path":"https://keras.posit.co/reference/application_resnet101.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the ResNet101 architecture. — application_resnet101","text":"Deep Residual Learning Image Recognition (CVPR 2015) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_resnet101.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ResNet101 architecture. — application_resnet101","text":"Keras Application expects specific kind input preprocessing. ResNet, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() convert input images RGB BGR, zero-center color channel respect ImageNet dataset, without scaling.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_resnet101_v2.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ResNet101V2 architecture. — application_resnet101_v2","title":"Instantiates the ResNet101V2 architecture. — application_resnet101_v2","text":"Instantiates ResNet101V2 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_resnet101_v2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ResNet101V2 architecture. — application_resnet101_v2","text":"","code":"application_resnet101_v2(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_resnet101_v2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ResNet101V2 architecture. — application_resnet101_v2","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (\"channels_last\" data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_resnet101_v2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ResNet101V2 architecture. — application_resnet101_v2","text":"Model instance.","code":""},{"path":"https://keras.posit.co/reference/application_resnet101_v2.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the ResNet101V2 architecture. — application_resnet101_v2","text":"Identity Mappings Deep Residual Networks (CVPR 2016) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_resnet101_v2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ResNet101V2 architecture. — application_resnet101_v2","text":"Keras Application expects specific kind input preprocessing. ResNet, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() scale input pixels -1 1.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_resnet152.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ResNet152 architecture. — application_resnet152","title":"Instantiates the ResNet152 architecture. — application_resnet152","text":"Instantiates ResNet152 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_resnet152.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ResNet152 architecture. — application_resnet152","text":"","code":"application_resnet152(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_resnet152.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ResNet152 architecture. — application_resnet152","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (\"channels_last\" data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_resnet152.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ResNet152 architecture. — application_resnet152","text":"Model instance.","code":""},{"path":"https://keras.posit.co/reference/application_resnet152.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the ResNet152 architecture. — application_resnet152","text":"Deep Residual Learning Image Recognition (CVPR 2015) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_resnet152.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ResNet152 architecture. — application_resnet152","text":"Keras Application expects specific kind input preprocessing. ResNet, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() convert input images RGB BGR, zero-center color channel respect ImageNet dataset, without scaling.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_resnet152_v2.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ResNet152V2 architecture. — application_resnet152_v2","title":"Instantiates the ResNet152V2 architecture. — application_resnet152_v2","text":"Instantiates ResNet152V2 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_resnet152_v2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ResNet152V2 architecture. — application_resnet152_v2","text":"","code":"application_resnet152_v2(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_resnet152_v2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ResNet152V2 architecture. — application_resnet152_v2","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (\"channels_last\" data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_resnet152_v2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ResNet152V2 architecture. — application_resnet152_v2","text":"Model instance.","code":""},{"path":"https://keras.posit.co/reference/application_resnet152_v2.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the ResNet152V2 architecture. — application_resnet152_v2","text":"Identity Mappings Deep Residual Networks (CVPR 2016) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_resnet152_v2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ResNet152V2 architecture. — application_resnet152_v2","text":"Keras Application expects specific kind input preprocessing. ResNet, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() scale input pixels -1 1.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_resnet50.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ResNet50 architecture. — application_resnet50","title":"Instantiates the ResNet50 architecture. — application_resnet50","text":"Instantiates ResNet50 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_resnet50.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ResNet50 architecture. — application_resnet50","text":"","code":"application_resnet50(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_resnet50.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ResNet50 architecture. — application_resnet50","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (\"channels_last\" data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_resnet50.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ResNet50 architecture. — application_resnet50","text":"Model instance.","code":""},{"path":"https://keras.posit.co/reference/application_resnet50.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the ResNet50 architecture. — application_resnet50","text":"Deep Residual Learning Image Recognition (CVPR 2015) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_resnet50.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ResNet50 architecture. — application_resnet50","text":"Keras Application expects specific kind input preprocessing. ResNet, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() convert input images RGB BGR, zero-center color channel respect ImageNet dataset, without scaling.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_resnet50_v2.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the ResNet50V2 architecture. — application_resnet50_v2","title":"Instantiates the ResNet50V2 architecture. — application_resnet50_v2","text":"Instantiates ResNet50V2 architecture.","code":""},{"path":"https://keras.posit.co/reference/application_resnet50_v2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the ResNet50V2 architecture. — application_resnet50_v2","text":"","code":"application_resnet50_v2(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_resnet50_v2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the ResNet50V2 architecture. — application_resnet50_v2","text":"include_top whether include fully-connected layer top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (\"channels_last\" data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 inputs channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer. loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_resnet50_v2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the ResNet50V2 architecture. — application_resnet50_v2","text":"Model instance.","code":""},{"path":"https://keras.posit.co/reference/application_resnet50_v2.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the ResNet50V2 architecture. — application_resnet50_v2","text":"Identity Mappings Deep Residual Networks (CVPR 2016) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning.","code":""},{"path":"https://keras.posit.co/reference/application_resnet50_v2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the ResNet50V2 architecture. — application_resnet50_v2","text":"Keras Application expects specific kind input preprocessing. ResNet, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() scale input pixels -1 1.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_vgg16.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the VGG16 model. — application_vgg16","title":"Instantiates the VGG16 model. — application_vgg16","text":"Instantiates VGG16 model.","code":""},{"path":"https://keras.posit.co/reference/application_vgg16.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the VGG16 model. — application_vgg16","text":"","code":"application_vgg16(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_vgg16.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the VGG16 model. — application_vgg16","text":"include_top whether include 3 fully-connected layers top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (channels_last data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 input channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer.  loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_vgg16.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the VGG16 model. — application_vgg16","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_vgg16.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the VGG16 model. — application_vgg16","text":"Deep Convolutional Networks Large-Scale Image Recognition (ICLR 2015) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning. default input size model 224x224.","code":""},{"path":"https://keras.posit.co/reference/application_vgg16.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the VGG16 model. — application_vgg16","text":"Keras Application expects specific kind input preprocessing. VGG16, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() convert input images RGB BGR, zero-center color channel respect ImageNet dataset, without scaling.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_vgg19.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the VGG19 model. — application_vgg19","title":"Instantiates the VGG19 model. — application_vgg19","text":"Instantiates VGG19 model.","code":""},{"path":"https://keras.posit.co/reference/application_vgg19.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the VGG19 model. — application_vgg19","text":"","code":"application_vgg19(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_vgg19.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the VGG19 model. — application_vgg19","text":"include_top whether include 3 fully-connected layers top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (224, 224, 3) (channels_last data format) (3, 224, 224) (\"channels_first\" data format). exactly 3 input channels, width height smaller 32. E.g. (200, 200, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer.  loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_vgg19.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the VGG19 model. — application_vgg19","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_vgg19.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the VGG19 model. — application_vgg19","text":"Deep Convolutional Networks Large-Scale Image Recognition (ICLR 2015) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning. default input size model 224x224.","code":""},{"path":"https://keras.posit.co/reference/application_vgg19.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the VGG19 model. — application_vgg19","text":"Keras Application expects specific kind input preprocessing. VGG19, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() convert input images RGB BGR, zero-center color channel respect ImageNet dataset, without scaling.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/application_xception.html","id":null,"dir":"Reference","previous_headings":"","what":"Instantiates the Xception architecture. — application_xception","title":"Instantiates the Xception architecture. — application_xception","text":"Instantiates Xception architecture.","code":""},{"path":"https://keras.posit.co/reference/application_xception.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instantiates the Xception architecture. — application_xception","text":"","code":"application_xception(   include_top = TRUE,   weights = \"imagenet\",   input_tensor = NULL,   input_shape = NULL,   pooling = NULL,   classes = 1000L,   classifier_activation = \"softmax\" )"},{"path":"https://keras.posit.co/reference/application_xception.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instantiates the Xception architecture. — application_xception","text":"include_top whether include 3 fully-connected layers top network. weights one NULL (random initialization), \"imagenet\" (pre-training ImageNet), path weights file loaded. input_tensor optional Keras tensor (.e. output layers.Input()) use image input model. input_shape optional shape tuple, specified include_top FALSE (otherwise input shape (299, 299, 3). exactly 3 inputs channels, width height smaller 71. E.g. (150, 150, 3) one valid value. pooling Optional pooling mode feature extraction include_top FALSE. NULL means output model 4D tensor output last convolutional block. avg means global average pooling applied output last convolutional block, thus output model 2D tensor. max means global max pooling applied. classes optional number classes classify images , specified include_top TRUE, weights argument specified. classifier_activation str callable. activation function use \"top\" layer. Ignored unless include_top=TRUE. Set classifier_activation=NULL return logits \"top\" layer.  loading pretrained weights, classifier_activation can NULL \"softmax\".","code":""},{"path":"https://keras.posit.co/reference/application_xception.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Instantiates the Xception architecture. — application_xception","text":"model instance.","code":""},{"path":"https://keras.posit.co/reference/application_xception.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Instantiates the Xception architecture. — application_xception","text":"Xception: Deep Learning Depthwise Separable Convolutions (CVPR 2017) image classification use cases, see page detailed examples. transfer learning use cases, make sure read guide transfer learning & fine-tuning. default input image size model 299x299.","code":""},{"path":"https://keras.posit.co/reference/application_xception.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Instantiates the Xception architecture. — application_xception","text":"Keras Application expects specific kind input preprocessing. Xception, call application_preprocess_inputs() inputs passing model. application_preprocess_inputs() scale input pixels -1 1.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/audio_dataset_from_directory.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates a tf.data.Dataset from audio files in a directory. — audio_dataset_from_directory","title":"Generates a tf.data.Dataset from audio files in a directory. — audio_dataset_from_directory","text":"directory structure :   calling audio_dataset_from_directory(main_directory, labels = 'inferred') return tf.data.Dataset yields batches audio files subdirectories class_a class_b, together labels 0 1 (0 corresponding class_a 1 corresponding class_b). .wav files supported time.","code":"main_directory/ ...class_a/ ......a_audio_1.wav ......a_audio_2.wav ...class_b/ ......b_audio_1.wav ......b_audio_2.wav"},{"path":"https://keras.posit.co/reference/audio_dataset_from_directory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates a tf.data.Dataset from audio files in a directory. — audio_dataset_from_directory","text":"","code":"audio_dataset_from_directory(   directory,   labels = \"inferred\",   label_mode = \"int\",   class_names = NULL,   batch_size = 32L,   sampling_rate = NULL,   output_sequence_length = NULL,   ragged = FALSE,   shuffle = TRUE,   seed = NULL,   validation_split = NULL,   subset = NULL,   follow_links = FALSE,   verbose = TRUE )"},{"path":"https://keras.posit.co/reference/audio_dataset_from_directory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates a tf.data.Dataset from audio files in a directory. — audio_dataset_from_directory","text":"directory Directory data located. labels \"inferred\", contain subdirectories, containing audio files class. Otherwise, directory structure ignored. labels Either \"inferred\" (labels generated directory structure), NULL (labels), list/tuple integer labels size number audio files found directory. Labels sorted according alphanumeric order audio file paths (obtained via os.walk(directory) Python). label_mode String describing encoding labels. Options : \"int\": means labels encoded integers (e.g. sparse_categorical_crossentropy loss). \"categorical\" means labels encoded categorical vector (e.g. categorical_crossentropy loss) \"binary\" means labels (can 2) encoded float32 scalars values 0 1 (e.g. binary_crossentropy). NULL (labels). class_names valid \"labels\" \"inferred\". explicit list class names (must match names subdirectories). Used control order classes (otherwise alphanumerical order used). batch_size Size batches data. Default: 32. NULL, data batched (dataset yield individual samples). sampling_rate Audio sampling rate (samples per second). output_sequence_length Maximum length audio sequence. Audio files longer truncated output_sequence_length. set NULL, sequences batch padded length longest sequence batch. ragged Whether return Ragged dataset (sequence length). Defaults FALSE. shuffle Whether shuffle data. Defaults TRUE. set FALSE, sorts data alphanumeric order. seed Optional random seed shuffling transformations. validation_split Optional float 0 1, fraction data reserve validation. subset Subset data return. One \"training\", \"validation\" \"\". used validation_split set. follow_links Whether visits subdirectories pointed symlinks. Defaults FALSE. verbose Whether display number information classes number files found. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/audio_dataset_from_directory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates a tf.data.Dataset from audio files in a directory. — audio_dataset_from_directory","text":"tf.data.Dataset object. label_mode NULL, yields string tensors shape (batch_size,), containing contents batch audio files. Otherwise, yields tuple (audio, labels), audio shape (batch_size, sequence_length, num_channels) labels follows format described . Rules regarding labels format: label_mode int, labels int32 tensor shape (batch_size,). label_mode binary, labels float32 tensor 1s 0s shape (batch_size, 1). label_mode categorical, labels float32 tensor shape (batch_size, num_classes), representing one-hot encoding class index.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/bidirectional.html","id":null,"dir":"Reference","previous_headings":"","what":"layer_bidirectional — bidirectional","title":"layer_bidirectional — bidirectional","text":"bidirectional() alias layer_bidirectional(). See ?layer_bidirectional() full documentation.","code":""},{"path":"https://keras.posit.co/reference/bidirectional.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"layer_bidirectional — bidirectional","text":"","code":"bidirectional(   object,   layer,   merge_mode = \"concat\",   weights = NULL,   backward_layer = NULL,   ... )"},{"path":"https://keras.posit.co/reference/bidirectional.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"layer_bidirectional — bidirectional","text":"object Object compose layer . tensor, array, sequential model. layer RNN instance, layer_lstm() layer_gru(). also Layer() instance meets following criteria: sequence-processing layer (accepts 3D+ inputs). go_backwards, return_sequences return_state attribute (semantics RNN class). input_spec attribute. Implement serialization via get_config() from_config(). Note recommended way create new RNN layers write custom RNN cell use layer_rnn(), instead subclassing Layer() directly. return_sequences TRUE, output masked timestep zero regardless layer's original zero_output_for_mask value. merge_mode Mode outputs forward backward RNNs combined. One {\"sum\", \"mul\", \"concat\", \"ave\", NULL}. NULL, outputs combined, returned list. Defaults \"concat\". weights see description backward_layer Optional RNN, Layer() instance used handle backwards input processing. backward_layer provided, layer instance passed layer argument used generate backward layer automatically. Note provided backward_layer layer properties matching layer argument, particular values stateful, return_states, return_sequences, etc. addition, backward_layer layer different go_backwards argument values. ValueError raised requirements met. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/bidirectional.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"layer_bidirectional — bidirectional","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/callback_backup_and_restore.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback to back up and restore the training state. — callback_backup_and_restore","title":"Callback to back up and restore the training state. — callback_backup_and_restore","text":"callback_backup_and_restore() callback intended recover training interruption happened middle fit execution, backing training states temporary checkpoint file, end epoch. backup overwrites previously written checkpoint file, given time one checkpoint file backup/restoring purpose. training restarts completion, training state (includes model weights epoch number) restored recently saved state beginning new fit run. completion fit run, temporary checkpoint file deleted. Note user responsible bring jobs back interruption. callback important backup restore mechanism fault tolerance purpose, model restored previous checkpoint expected one used back . user changes arguments passed compile fit, checkpoint saved fault tolerance can become invalid.","code":""},{"path":"https://keras.posit.co/reference/callback_backup_and_restore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Callback to back up and restore the training state. — callback_backup_and_restore","text":"","code":"callback_backup_and_restore(   backup_dir,   save_freq = \"epoch\",   delete_checkpoint = TRUE )"},{"path":"https://keras.posit.co/reference/callback_backup_and_restore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback to back up and restore the training state. — callback_backup_and_restore","text":"backup_dir String, path directory store data needed restore model. directory reused elsewhere store files, e.g. backup_and_restore callback another training run, another callback (e.g. callback_model_checkpoint) training run. save_freq \"epoch\", integer, FALSE. set \"epoch\", callback saves checkpoint end epoch. set integer, callback saves checkpoint every save_freq batches. Set save_freq = FALSE using preemption checkpointing (.e. save_before_preemption = TRUE). delete_checkpoint Boolean, defaults TRUE. backup_and_restore callback works saving checkpoint back training state. delete_checkpoint = TRUE, checkpoint deleted training finished. Use FALSE like keep checkpoint future usage.","code":""},{"path":"https://keras.posit.co/reference/callback_backup_and_restore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Callback to back up and restore the training state. — callback_backup_and_restore","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_backup_and_restore.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Callback to back up and restore the training state. — callback_backup_and_restore","text":"","code":"callback_interrupting <- new_callback_class(   \"InterruptingCallback\",   on_epoch_begin = function(epoch, logs = NULL) {     if (epoch == 4) {       stop('Interrupting!')     }   } )  backup_dir <- tempfile() callback <- callback_backup_and_restore(backup_dir = backup_dir) model <- keras_model_sequential() %>%   layer_dense(10) model %>% compile(optimizer = optimizer_sgd(), loss = 'mse')  tryCatch({   model %>% fit(x = op_ones(c(5, 20)),                 y = op_zeros(5),                 epochs = 10, batch_size = 1,                 callbacks = list(callback, callback_interrupting()),                 verbose = 0) }, python.builtin.RuntimeError = function(e) message(\"Interrupted!\")) ## Interrupted! model$history$epoch ## [1] 0 1 2 # model$history %>% keras3:::to_keras_training_history() %>% as.data.frame() %>% print()  history <- model %>% fit(x = op_ones(c(5, 20)),                          y = op_zeros(5),                          epochs = 10, batch_size = 1,                          callbacks = list(callback),                          verbose = 0)  # Only 6 more epochs are run, since first training got interrupted at # zero-indexed epoch 4, second training will continue from 4 to 9. nrow(as.data.frame(history)) ## [1] 10"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_csv_logger.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback that streams epoch results to a CSV file. — callback_csv_logger","title":"Callback that streams epoch results to a CSV file. — callback_csv_logger","text":"Supports values can represented string, including 1D iterables atomic vectors.","code":""},{"path":"https://keras.posit.co/reference/callback_csv_logger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Callback that streams epoch results to a CSV file. — callback_csv_logger","text":"","code":"callback_csv_logger(filename, separator = \",\", append = FALSE)"},{"path":"https://keras.posit.co/reference/callback_csv_logger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback that streams epoch results to a CSV file. — callback_csv_logger","text":"filename Filename CSV file, e.g. 'run/log.csv'. separator String used separate elements CSV file. append Boolean. TRUE: append file exists (useful continuing training). FALSE: overwrite existing file.","code":""},{"path":"https://keras.posit.co/reference/callback_csv_logger.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Callback that streams epoch results to a CSV file. — callback_csv_logger","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_csv_logger.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Callback that streams epoch results to a CSV file. — callback_csv_logger","text":"","code":"csv_logger <- callback_csv_logger('training.log') model %>% fit(X_train, Y_train, callbacks = list(csv_logger))"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_early_stopping.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop training when a monitored metric has stopped improving. — callback_early_stopping","title":"Stop training when a monitored metric has stopped improving. — callback_early_stopping","text":"Assuming goal training minimize loss. , metric monitored 'loss', mode 'min'. model$fit() training loop check end every epoch whether loss longer decreasing, considering min_delta patience applicable. found longer decreasing, model$stop_training marked TRUE training terminates. quantity monitored needs available logs list. make , pass loss metrics model$compile().","code":""},{"path":"https://keras.posit.co/reference/callback_early_stopping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop training when a monitored metric has stopped improving. — callback_early_stopping","text":"","code":"callback_early_stopping(   monitor = \"val_loss\",   min_delta = 0L,   patience = 0L,   verbose = 0L,   mode = \"auto\",   baseline = NULL,   restore_best_weights = FALSE,   start_from_epoch = 0L )"},{"path":"https://keras.posit.co/reference/callback_early_stopping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stop training when a monitored metric has stopped improving. — callback_early_stopping","text":"monitor Quantity monitored. Defaults \"val_loss\". min_delta Minimum change monitored quantity qualify improvement, .e. absolute change less min_delta, count improvement. Defaults 0. patience Number epochs improvement training stopped. Defaults 0. verbose Verbosity mode, 0 1. Mode 0 silent, mode 1 displays messages callback takes action. Defaults 0. mode One {\"auto\", \"min\", \"max\"}. min mode, training stop quantity monitored stopped decreasing; \"max\" mode stop quantity monitored stopped increasing; \"auto\" mode, direction automatically inferred name monitored quantity. Defaults \"auto\". baseline Baseline value monitored quantity. NULL, training stop model show improvement baseline. Defaults NULL. restore_best_weights Whether restore model weights epoch best value monitored quantity. FALSE, model weights obtained last step training used. epoch restored regardless performance relative baseline. epoch improves baseline, training run patience epochs restore weights best epoch set. Defaults FALSE. start_from_epoch Number epochs wait starting monitor improvement. allows warm-period improvement expected thus training stopped. Defaults 0.","code":""},{"path":"https://keras.posit.co/reference/callback_early_stopping.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stop training when a monitored metric has stopped improving. — callback_early_stopping","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_early_stopping.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stop training when a monitored metric has stopped improving. — callback_early_stopping","text":"","code":"callback <- callback_early_stopping(monitor = 'loss',                                    patience = 3) # This callback will stop the training when there is no improvement in # the loss for three consecutive epochs. model <- keras_model_sequential() %>%   layer_dense(10) model %>% compile(optimizer = optimizer_sgd(), loss = 'mse') history <- model %>% fit(x = op_ones(c(5, 20)),                          y = op_zeros(5),                          epochs = 10, batch_size = 1,                          callbacks = list(callback),                          verbose = 0) nrow(as.data.frame(history))  # Only 4 epochs are run. ## [1] 10"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback for creating simple, custom callbacks on-the-fly. — callback_lambda","title":"Callback for creating simple, custom callbacks on-the-fly. — callback_lambda","text":"callback constructed anonymous functions called appropriate time (Model.{fit | evaluate | predict}). Note callbacks expects positional arguments, : on_epoch_begin on_epoch_end expect two positional arguments: epoch, logs on_train_begin on_train_end expect one positional argument: logs on_train_batch_begin on_train_batch_end expect two positional arguments: batch, logs See Callback class definition full list functions expected arguments.","code":""},{"path":"https://keras.posit.co/reference/callback_lambda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Callback for creating simple, custom callbacks on-the-fly. — callback_lambda","text":"","code":"callback_lambda(   on_epoch_begin = NULL,   on_epoch_end = NULL,   on_train_begin = NULL,   on_train_end = NULL,   on_train_batch_begin = NULL,   on_train_batch_end = NULL,   ... )"},{"path":"https://keras.posit.co/reference/callback_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback for creating simple, custom callbacks on-the-fly. — callback_lambda","text":"on_epoch_begin called beginning every epoch. on_epoch_end called end every epoch. on_train_begin called beginning model training. on_train_end called end model training. on_train_batch_begin called beginning every train batch. on_train_batch_end called end every train batch. ... function Callback() want override passing function_name = function. example, callback_lambda(.., on_train_end = train_end_fn). custom function needs arguments ones defined Callback().","code":""},{"path":"https://keras.posit.co/reference/callback_lambda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Callback for creating simple, custom callbacks on-the-fly. — callback_lambda","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_lambda.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Callback for creating simple, custom callbacks on-the-fly. — callback_lambda","text":"","code":"# Print the batch number at the beginning of every batch. batch_print_callback <- callback_lambda(   on_train_batch_begin = function(batch, logs) {     print(batch)   } )  # Stream the epoch loss to a file in new-line delimited JSON format # (one valid JSON object per line) json_log <- file('loss_log.json', open = 'wt') json_logging_callback <- callback_lambda(   on_epoch_end = function(epoch, logs) {     jsonlite::write_json(       list(epoch = epoch, loss = logs$loss),       json_log,       append = TRUE     )   },   on_train_end = function(logs) {     close(json_log)   } )  # Terminate some processes after having finished model training. processes <- ... cleanup_callback <- callback_lambda(   on_train_end = function(logs) {     for (p in processes) {       if (is_alive(p)) {         terminate(p)       }     }   } )  model %>% fit(   ...,   callbacks = list(     batch_print_callback,     json_logging_callback,     cleanup_callback   ) )"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_learning_rate_scheduler.html","id":null,"dir":"Reference","previous_headings":"","what":"Learning rate scheduler. — callback_learning_rate_scheduler","title":"Learning rate scheduler. — callback_learning_rate_scheduler","text":"beginning every epoch, callback gets updated learning rate value schedule function provided, current epoch current learning rate, applies updated learning rate optimizer.","code":""},{"path":"https://keras.posit.co/reference/callback_learning_rate_scheduler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Learning rate scheduler. — callback_learning_rate_scheduler","text":"","code":"callback_learning_rate_scheduler(schedule, verbose = 0L)"},{"path":"https://keras.posit.co/reference/callback_learning_rate_scheduler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Learning rate scheduler. — callback_learning_rate_scheduler","text":"schedule function takes epoch index (integer, indexed 0) current learning rate (float) inputs returns new learning rate output (float). verbose Integer. 0: quiet, 1: log update messages.","code":""},{"path":"https://keras.posit.co/reference/callback_learning_rate_scheduler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Learning rate scheduler. — callback_learning_rate_scheduler","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_learning_rate_scheduler.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Learning rate scheduler. — callback_learning_rate_scheduler","text":"","code":"# This function keeps the initial learning rate steady for the first ten epochs # and decreases it exponentially after that. scheduler <- function(epoch, lr) {   if (epoch < 10)     return(lr)   else     return(lr * exp(-0.1)) }  model <- keras_model_sequential() |> layer_dense(units = 10) model |> compile(optimizer = optimizer_sgd(), loss = 'mse') model$optimizer$learning_rate |> as.array() |> round(5) ## [1] 0.01 callback <- callback_learning_rate_scheduler(schedule = scheduler) history <- model |> fit(x = array(runif(100), c(5, 20)),                         y = array(0, c(5, 1)),                         epochs = 15, callbacks = list(callback), verbose = 0) model$optimizer$learning_rate |> as.array() |> round(5) ## [1] 0.00607"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_model_checkpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback to save the Keras model or model weights at some frequency. — callback_model_checkpoint","title":"Callback to save the Keras model or model weights at some frequency. — callback_model_checkpoint","text":"callback_model_checkpoint() used conjunction training using model |> fit() save model weights (checkpoint file) interval, model weights can loaded later continue training state saved. options callback provides include: Whether keep model achieved \"best performance\" far, whether save model end every epoch regardless performance. Definition \"best\"; quantity monitor whether maximized minimized. frequency save . Currently, callback supports saving end every epoch, fixed number training batches. Whether weights saved, whole model saved.","code":""},{"path":"https://keras.posit.co/reference/callback_model_checkpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Callback to save the Keras model or model weights at some frequency. — callback_model_checkpoint","text":"","code":"callback_model_checkpoint(   filepath,   monitor = \"val_loss\",   verbose = 0L,   save_best_only = FALSE,   save_weights_only = FALSE,   mode = \"auto\",   save_freq = \"epoch\",   initial_value_threshold = NULL )"},{"path":"https://keras.posit.co/reference/callback_model_checkpoint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback to save the Keras model or model weights at some frequency. — callback_model_checkpoint","text":"filepath string, path save model file. filepath can contain named formatting options, filled value epoch keys logs (passed on_epoch_end). filepath name needs end \".weights.h5\" save_weights_only = TRUE end \".keras\" checkpoint saving whole model (default). example: filepath \"{epoch:02d}-{val_loss:.2f}.keras\", model checkpoints saved epoch number validation loss filename. directory filepath reused callbacks avoid conflicts. monitor metric name monitor. Typically metrics set model |> compile() method. Note: Prefix name \"val_\" monitor validation metrics. Use \"loss\" \"val_loss\" monitor model's total loss. specify metrics strings, like \"accuracy\", pass string (without \"val_\" prefix). pass Metric objects (created one metric_*()), monitor set metric$name. sure metric names can check contents history$metrics list returned history <- model |> fit() Multi-output models set additional prefixes metric names. verbose Verbosity mode, 0 1. Mode 0 silent, mode 1 displays messages callback takes action. save_best_only save_best_only = TRUE, saves model considered \"best\" latest best model according quantity monitored overwritten. filepath contain formatting options like {epoch} filepath overwritten new better model. save_weights_only TRUE, model's weights saved (model |> save_model_weights(filepath)), else full model saved (model |> save_model(filepath)). mode one {\"auto\", \"min\", \"max\"}. save_best_only = TRUE, decision overwrite current save file made based either maximization minimization monitored quantity. val_acc, \"max\", val_loss \"min\", etc. \"auto\" mode, mode set \"max\" quantities monitored \"acc\" start \"fmeasure\" set \"min\" rest quantities. save_freq \"epoch\" integer. using \"epoch\", callback saves model epoch. using integer, callback saves model end many batches. Model compiled steps_per_execution = N, saving criteria checked every Nth batch. Note saving aligned epochs, monitored metric may potentially less reliable (reflect little 1 batch, since metrics get reset every epoch). Defaults \"epoch\". initial_value_threshold Floating point initial \"best\" value metric monitored. applies save_best_value = TRUE. overwrites model weights already saved performance current model better value.","code":""},{"path":"https://keras.posit.co/reference/callback_model_checkpoint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Callback to save the Keras model or model weights at some frequency. — callback_model_checkpoint","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_model_checkpoint.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Callback to save the Keras model or model weights at some frequency. — callback_model_checkpoint","text":"","code":"model <- keras_model_sequential(input_shape = c(10)) |>   layer_dense(1, activation = \"sigmoid\") |>   compile(loss = \"binary_crossentropy\", optimizer = \"adam\",           metrics = c('accuracy'))  EPOCHS <- 10 checkpoint_filepath <- tempfile('checkpoint-model-', fileext = \".keras\") model_checkpoint_callback <- callback_model_checkpoint(   filepath = checkpoint_filepath,   monitor = 'val_accuracy',   mode = 'max',   save_best_only = TRUE )  # Model is saved at the end of every epoch, if it's the best seen so far. model |> fit(x = random_uniform(c(2, 10)), y = op_ones(2, 1),              epochs = EPOCHS, validation_split = .5, verbose = 0,              callbacks = list(model_checkpoint_callback))  # The model (that are considered the best) can be loaded as - load_model(checkpoint_filepath) ## Model: \"sequential\" ## +---------------------------------+------------------------+---------------+ ## | Layer (type)                    | Output Shape           |       Param # | ## +=================================+========================+===============+ ## | dense (Dense)                   | (None, 1)              |            11 | ## +---------------------------------+------------------------+---------------+ ##  Total params: 35 (144.00 B) ##  Trainable params: 11 (44.00 B) ##  Non-trainable params: 0 (0.00 B) ##  Optimizer params: 24 (100.00 B) # Alternatively, one could checkpoint just the model weights as - checkpoint_filepath <- tempfile('checkpoint-', fileext = \".weights.h5\") model_checkpoint_callback <- callback_model_checkpoint(   filepath = checkpoint_filepath,   save_weights_only = TRUE,   monitor = 'val_accuracy',   mode = 'max',   save_best_only = TRUE )  # Model weights are saved at the end of every epoch, if it's the best seen # so far. # same as above model |> fit(x = random_uniform(c(2, 10)), y = op_ones(2, 1),              epochs = EPOCHS, validation_split = .5, verbose = 0,              callbacks = list(model_checkpoint_callback))  # The model weights (that are considered the best) can be loaded model |> load_model_weights(checkpoint_filepath)"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_reduce_lr_on_plateau.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce learning rate when a metric has stopped improving. — callback_reduce_lr_on_plateau","title":"Reduce learning rate when a metric has stopped improving. — callback_reduce_lr_on_plateau","text":"Models often benefit reducing learning rate factor 2-10 learning stagnates. callback monitors quantity improvement seen 'patience' number epochs, learning rate reduced.","code":""},{"path":"https://keras.posit.co/reference/callback_reduce_lr_on_plateau.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce learning rate when a metric has stopped improving. — callback_reduce_lr_on_plateau","text":"","code":"callback_reduce_lr_on_plateau(   monitor = \"val_loss\",   factor = 0.1,   patience = 10L,   verbose = 0L,   mode = \"auto\",   min_delta = 1e-04,   cooldown = 0L,   min_lr = 0,   ... )"},{"path":"https://keras.posit.co/reference/callback_reduce_lr_on_plateau.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce learning rate when a metric has stopped improving. — callback_reduce_lr_on_plateau","text":"monitor String. Quantity monitored. factor Float. Factor learning rate reduced. new_lr = lr * factor. patience Integer. Number epochs improvement learning rate reduced. verbose Integer. 0: quiet, 1: update messages. mode String. One {'auto', 'min', 'max'}. 'min' mode, learning rate reduced quantity monitored stopped decreasing; 'max' mode reduced quantity monitored stopped increasing; 'auto' mode, direction automatically inferred name monitored quantity. min_delta Float. Threshold measuring new optimum, focus significant changes. cooldown Integer. Number epochs wait resuming normal operation learning rate reduced. min_lr Float. Lower bound learning rate. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/callback_reduce_lr_on_plateau.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce learning rate when a metric has stopped improving. — callback_reduce_lr_on_plateau","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_reduce_lr_on_plateau.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce learning rate when a metric has stopped improving. — callback_reduce_lr_on_plateau","text":"","code":"reduce_lr <- callback_reduce_lr_on_plateau(monitor = 'val_loss', factor = 0.2,                                            patience = 5, min_lr = 0.001) model %>% fit(x_train, y_train, callbacks = list(reduce_lr))"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_remote_monitor.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback used to stream events to a server. — callback_remote_monitor","title":"Callback used to stream events to a server. — callback_remote_monitor","text":"Requires requests library. Events sent root + '/publish/epoch/end/' default. Calls HTTP POST, data argument JSON-encoded named list event data. send_as_json = TRUE, content type request \"application/json\". Otherwise serialized JSON sent within form.","code":""},{"path":"https://keras.posit.co/reference/callback_remote_monitor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Callback used to stream events to a server. — callback_remote_monitor","text":"","code":"callback_remote_monitor(   root = \"http://localhost:9000\",   path = \"/publish/epoch/end/\",   field = \"data\",   headers = NULL,   send_as_json = FALSE )"},{"path":"https://keras.posit.co/reference/callback_remote_monitor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback used to stream events to a server. — callback_remote_monitor","text":"root String; root url target server. path String; path relative root events sent. field String; JSON field data stored. field used payload sent within form (.e. send_as_json set FALSE). headers Named list; optional custom HTTP headers. send_as_json Boolean; whether request sent \"application/json\".","code":""},{"path":"https://keras.posit.co/reference/callback_remote_monitor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Callback used to stream events to a server. — callback_remote_monitor","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/callback_swap_ema_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Swaps model weights and EMA weights before and after evaluation. — callback_swap_ema_weights","title":"Swaps model weights and EMA weights before and after evaluation. — callback_swap_ema_weights","text":"callbacks replaces model's weight values values optimizer's EMA weights (exponential moving average past model weights values, implementing \"Polyak averaging\") model evaluation, restores previous weights evaluation. SwapEMAWeights callback used conjunction optimizer sets use_ema = TRUE. Note weights swapped -place order save memory. behavior undefined modify EMA weights model weights callbacks.","code":""},{"path":"https://keras.posit.co/reference/callback_swap_ema_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swaps model weights and EMA weights before and after evaluation. — callback_swap_ema_weights","text":"","code":"callback_swap_ema_weights(swap_on_epoch = FALSE)"},{"path":"https://keras.posit.co/reference/callback_swap_ema_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Swaps model weights and EMA weights before and after evaluation. — callback_swap_ema_weights","text":"swap_on_epoch Whether perform swapping on_epoch_begin() on_epoch_end(). useful want use EMA weights callbacks callback_model_checkpoint(). Defaults FALSE.","code":""},{"path":"https://keras.posit.co/reference/callback_swap_ema_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Swaps model weights and EMA weights before and after evaluation. — callback_swap_ema_weights","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_swap_ema_weights.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Swaps model weights and EMA weights before and after evaluation. — callback_swap_ema_weights","text":"","code":"# Remember to set `use_ema=TRUE` in the optimizer optimizer <- optimizer_sgd(use_ema = TRUE) model |> compile(optimizer = optimizer, loss = ..., metrics = ...)  # Metrics will be computed with EMA weights model |> fit(X_train, Y_train,              callbacks = c(callback_swap_ema_weights()))  # If you want to save model checkpoint with EMA weights, you can set # `swap_on_epoch=TRUE` and place ModelCheckpoint after SwapEMAWeights. model |> fit(   X_train, Y_train,   callbacks = c(     callback_swap_ema_weights(swap_on_epoch = TRUE),     callback_model_checkpoint(...)   ) )"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_tensorboard.html","id":null,"dir":"Reference","previous_headings":"","what":"Enable visualizations for TensorBoard. — callback_tensorboard","title":"Enable visualizations for TensorBoard. — callback_tensorboard","text":"TensorBoard visualization tool provided TensorFlow. TensorFlow installation required use callback. callback logs events TensorBoard, including: Metrics summary plots Training graph visualization Weight histograms Sampled profiling used model |> evaluate() regular validation addition epoch summaries, summary records evaluation metrics vs model$optimizer$iterations written. metric names prepended evaluation, model$optimizer$iterations step visualized TensorBoard. installed TensorFlow pip reticulate::py_install(), able launch TensorBoard command line:   R tensorflow::tensorboard(). can find information TensorBoard .","code":"tensorboard --logdir=path_to_your_logs"},{"path":"https://keras.posit.co/reference/callback_tensorboard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enable visualizations for TensorBoard. — callback_tensorboard","text":"","code":"callback_tensorboard(   log_dir = \"logs\",   histogram_freq = 0L,   write_graph = TRUE,   write_images = FALSE,   write_steps_per_second = FALSE,   update_freq = \"epoch\",   profile_batch = 0L,   embeddings_freq = 0L,   embeddings_metadata = NULL )"},{"path":"https://keras.posit.co/reference/callback_tensorboard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enable visualizations for TensorBoard. — callback_tensorboard","text":"log_dir path directory save log files parsed TensorBoard. e.g., log_dir = file.path(working_dir, 'logs'). directory reused callbacks. histogram_freq frequency (epochs) compute weight histograms layers model. set 0, histograms computed. Validation data (split) must specified histogram visualizations. write_graph (supported time) Whether visualize graph TensorBoard. Note log file can become quite large write_graph set TRUE. write_images whether write model weights visualize image TensorBoard. write_steps_per_second whether log training steps per second TensorBoard. supports epoch batch frequency logging. update_freq \"batch\" \"epoch\" integer. using \"epoch\", writes losses metrics TensorBoard every epoch. using integer, say 1000, metrics losses (including custom ones added Model.compile) logged TensorBoard every 1000 batches. \"batch\" synonym 1, meaning written every batch. Note however writing frequently TensorBoard can slow training, especially used distribution strategies incur additional synchronization overhead. Batch-level summary writing also available via train_step override. Please see TensorBoard Scalars tutorial  # noqa: E501 details. profile_batch (supported time) Profile batch(es) sample compute characteristics. profile_batch must non-negative integer tuple integers. pair positive integers signify range batches profile. default, profiling disabled. embeddings_freq frequency (epochs) embedding layers visualized. set 0, embeddings visualized. embeddings_metadata Named list maps embedding layer names filename file save metadata embedding layer. case metadata file used embedding layers, single filename can passed.","code":""},{"path":"https://keras.posit.co/reference/callback_tensorboard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enable visualizations for TensorBoard. — callback_tensorboard","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":"https://keras.posit.co/reference/callback_tensorboard.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enable visualizations for TensorBoard. — callback_tensorboard","text":"Basic usage:   Custom batch-level summaries subclassed Model:   Custom batch-level summaries Functional API Model:   Profiling:","code":"tensorboard_callback <- callback_tensorboard(log_dir = \"./logs\") model %>% fit(x_train, y_train, epochs = 2, callbacks = list(tensorboard_callback)) # Then run the tensorboard command to view the visualizations. MyModel <- new_model_class(\"MyModel\",   initialize = function() {     self$dense <- layer_dense(units = 10)   },   call = function(x) {     outputs <- x |> self$dense()     tf$summary$histogram('outputs', outputs)     outputs   } )  model <- MyModel() model |> compile(optimizer = 'sgd', loss = 'mse')  # Make sure to set `update_freq = N` to log a batch-level summary every N # batches. In addition to any `tf$summary` contained in `model$call()`, # metrics added in `model |>compile` will be logged every N batches. tb_callback <- callback_tensorboard(log_dir = './logs', update_freq = 1) model |> fit(x_train, y_train, callbacks = list(tb_callback)) my_summary <- function(x) {   tf$summary$histogram('x', x)   x }  inputs <- layer_input(10) outputs <- inputs |>   layer_dense(10) |>   layer_lambda(my_summary)  model <- keras_model(inputs, outputs) model |> compile(optimizer = 'sgd', loss = 'mse')  # Make sure to set `update_freq = N` to log a batch-level summary every N # batches. In addition to any `tf.summary` contained in `Model.call`, # metrics added in `Model.compile` will be logged every N batches. tb_callback <- callback_tensorboard(log_dir = './logs', update_freq = 1) model |> fit(x_train, y_train, callbacks = list(tb_callback)) # Profile a single batch, e.g. the 5th batch. tensorboard_callback <- callback_tensorboard(   log_dir = './logs', profile_batch = 5) model |> fit(x_train, y_train, epochs = 2,              callbacks = list(tensorboard_callback))  # Profile a range of batches, e.g. from 10 to 20. tensorboard_callback <- callback_tensorboard(   log_dir = './logs', profile_batch = c(10, 20)) model |> fit(x_train, y_train, epochs = 2,              callbacks = list(tensorboard_callback))"},{"path":[]},{"path":"https://keras.posit.co/reference/callback_terminate_on_nan.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback that terminates training when a NaN loss is encountered. — callback_terminate_on_nan","title":"Callback that terminates training when a NaN loss is encountered. — callback_terminate_on_nan","text":"Callback terminates training NaN loss encountered.","code":""},{"path":"https://keras.posit.co/reference/callback_terminate_on_nan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Callback that terminates training when a NaN loss is encountered. — callback_terminate_on_nan","text":"","code":"callback_terminate_on_nan()"},{"path":"https://keras.posit.co/reference/callback_terminate_on_nan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Callback that terminates training when a NaN loss is encountered. — callback_terminate_on_nan","text":"Callback instance can passed fit.keras.src.models.model.Model().","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/clear_session.html","id":null,"dir":"Reference","previous_headings":"","what":"Resets all state generated by Keras. — clear_session","title":"Resets all state generated by Keras. — clear_session","text":"Keras manages global state, uses implement Functional model-building API uniquify autogenerated layer names. creating many models loop, global state consume increasing amount memory time, may want clear . Calling clear_session() releases global state: helps avoid clutter old models layers, especially memory limited. Example 1: calling clear_session() creating models loop   Example 2: resetting layer name generation counter","code":"for (i in 1:100) {   # Without `clear_session()`, each iteration of this loop will   # slightly increase the size of the global state managed by Keras   model <- keras_model_sequential()   for (j in 1:10) {     model <- model |> layer_dense(units = 10)   } }  for (i in 1:100) {   # With `clear_session()` called at the beginning,   # Keras starts with a blank state at each iteration   # and memory consumption is constant over time.   clear_session()   model <- keras_model_sequential()   for (j in 1:10) {     model <- model |> layer_dense(units = 10)   } } layers <- lapply(1:10, \\(i) layer_dense(units = 10))  new_layer <- layer_dense(units = 10) print(new_layer$name) ## [1] \"dense_10\" clear_session() new_layer <- layer_dense(units = 10) print(new_layer$name) ## [1] \"dense\""},{"path":"https://keras.posit.co/reference/clear_session.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resets all state generated by Keras. — clear_session","text":"","code":"clear_session()"},{"path":"https://keras.posit.co/reference/clear_session.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resets all state generated by Keras. — clear_session","text":"NULL, invisibly, called side effects.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/clone_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Clone a model instance. — clone_model","title":"Clone a model instance. — clone_model","text":"Model cloning similar calling model new inputs, except creates new layers (thus new weights) instead sharing weights existing layers.","code":""},{"path":"https://keras.posit.co/reference/clone_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clone a model instance. — clone_model","text":"","code":"clone_model(model, input_tensors = NULL, clone_function = NULL)"},{"path":"https://keras.posit.co/reference/clone_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clone a model instance. — clone_model","text":"model Instance Keras model (functional model Sequential model). input_tensors Optional list input tensors build model upon. provided, placeholders created. clone_function Callable used clone layer target model (except InputLayer instances). takes argument layer instance cloned, returns corresponding layer instance used model copy. unspecified, callable defaults following serialization/deserialization function: function(layer) layer$`__class__`$from_config(layer$get_config()) passing custom callable, can customize copy model, e.g. wrapping certain layers interest (might want replace LSTM instances equivalent Bidirectional(LSTM(...)) instances, example).","code":""},{"path":"https://keras.posit.co/reference/clone_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clone a model instance. — clone_model","text":"new model instance.","code":""},{"path":"https://keras.posit.co/reference/compile.keras.src.models.model.Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Configure a model for training. — compile.keras.src.models.model.Model","title":"Configure a model for training. — compile.keras.src.models.model.Model","text":"Configure model training.","code":""},{"path":"https://keras.posit.co/reference/compile.keras.src.models.model.Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Configure a model for training. — compile.keras.src.models.model.Model","text":"","code":"# S3 method for keras.src.models.model.Model compile(   object,   optimizer = \"rmsprop\",   loss = NULL,   metrics = NULL,   ...,   loss_weights = NULL,   weighted_metrics = NULL,   run_eagerly = FALSE,   steps_per_execution = 1L,   jit_compile = \"auto\",   auto_scale_loss = TRUE )"},{"path":"https://keras.posit.co/reference/compile.keras.src.models.model.Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Configure a model for training. — compile.keras.src.models.model.Model","text":"object Keras model object optimizer String (name optimizer) optimizer instance. See optimizer_* family. loss Loss function. May : string (name builtin loss function), custom function, Loss instance (returned loss_* family functions). loss function callable signature loss = fn(y_true, y_pred), y_true ground truth values, y_pred model's predictions. y_true shape (batch_size, d1, .. dN) (except case sparse loss functions sparse categorical crossentropy expects integer arrays shape (batch_size, d1, .. dN-1)). y_pred shape (batch_size, d1, .. dN). loss function return float tensor. metrics List metrics evaluated model training testing. can : string (name built-function), function, optionally \"name\" attribute Metric() instance. See metric_* family functions. Typically use metrics = c('accuracy'). function callable signature result = fn(y_true, y_pred). specify different metrics different outputs multi-output model, also pass named list, metrics = list(= 'accuracy', b = c('accuracy', 'mse')). can also pass list specify metric list metrics output, metrics = list(c('accuracy'), c('accuracy', 'mse')) metrics = list('accuracy', c('accuracy', 'mse')). pass strings 'accuracy' 'acc', convert one metric_binary_accuracy(), metric_categorical_accuracy(), metric_sparse_categorical_accuracy() based shapes targets model output. similar conversion done strings \"crossentropy\" \"ce\" well. metrics passed evaluated without sample weighting; like sample weighting apply, can specify metrics via weighted_metrics argument instead. providing anonymous R function, can customize printed name training assigning attr(<fn>, \"name\") <- \"my_custom_metric_name\", calling custom_metric(\"my_custom_metric_name\", <fn>) ... Additional arguments passed compile() model method. loss_weights Optional list (named unnamed) specifying scalar coefficients (R numerics) weight loss contributions different model outputs. loss value minimized model weighted sum individual losses, weighted loss_weights coefficients.  unnamed list, expected 1:1 mapping model's outputs. named list, expected map output names (strings) scalar coefficients. weighted_metrics List metrics evaluated weighted sample_weight class_weight training testing. run_eagerly Bool. TRUE, model's forward pass never compiled. recommended leave FALSE training (best performance), set TRUE debugging. steps_per_execution Int. number batches run single compiled function call. Running multiple batches inside single compiled function call can greatly improve performance TPUs small models large R/Python overhead. , one full epoch run execution. number larger size epoch passed, execution truncated size epoch. Note steps_per_execution set N, Callback$on_batch_begin Callback$on_batch_end methods called every N batches (.e. /compiled function execution). supported PyTorch backend. jit_compile Bool \"auto\". Whether use XLA compilation compiling model. jax tensorflow backends, jit_compile=\"auto\" enables XLA compilation model supports , disabled otherwise. torch backend, \"auto\" default eager execution jit_compile=True run torch.compile \"inductor\" backend. auto_scale_loss Bool. TRUE model dtype policy \"mixed_float16\", passed optimizer automatically wrapped LossScaleOptimizer, dynamically scale loss prevent underflow.","code":""},{"path":"https://keras.posit.co/reference/compile.keras.src.models.model.Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Configure a model for training. — compile.keras.src.models.model.Model","text":"called primarily side effect modifying object -place. first argument object also returned, invisibly, enable usage pipe.","code":""},{"path":"https://keras.posit.co/reference/compile.keras.src.models.model.Model.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Configure a model for training. — compile.keras.src.models.model.Model","text":"","code":"model |> compile(   optimizer = optimizer_adam(learning_rate = 1e-3),   loss = loss_binary_crossentropy(),   metrics = c(metric_binary_accuracy(),               metric_false_negatives()) )"},{"path":[]},{"path":"https://keras.posit.co/reference/config_backend.html","id":null,"dir":"Reference","previous_headings":"","what":"Publicly accessible method for determining the current backend. — config_backend","title":"Publicly accessible method for determining the current backend. — config_backend","text":"Publicly accessible method determining current backend.","code":""},{"path":"https://keras.posit.co/reference/config_backend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Publicly accessible method for determining the current backend. — config_backend","text":"","code":"config_backend()"},{"path":"https://keras.posit.co/reference/config_backend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Publicly accessible method for determining the current backend. — config_backend","text":"String, name backend Keras currently using. One \"tensorflow\", \"torch\", \"jax\".","code":""},{"path":"https://keras.posit.co/reference/config_backend.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Publicly accessible method for determining the current backend. — config_backend","text":"","code":"config_backend() ## [1] \"tensorflow\""},{"path":[]},{"path":"https://keras.posit.co/reference/config_disable_interactive_logging.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn off interactive logging. — config_disable_interactive_logging","title":"Turn off interactive logging. — config_disable_interactive_logging","text":"interactive logging disabled, Keras sends logs absl.logging. best option using Keras non-interactive way, running training inference job server.","code":""},{"path":"https://keras.posit.co/reference/config_disable_interactive_logging.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn off interactive logging. — config_disable_interactive_logging","text":"","code":"config_disable_interactive_logging()"},{"path":"https://keras.posit.co/reference/config_disable_interactive_logging.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn off interactive logging. — config_disable_interactive_logging","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_disable_traceback_filtering.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn off traceback filtering. — config_disable_traceback_filtering","title":"Turn off traceback filtering. — config_disable_traceback_filtering","text":"Raw Keras tracebacks (also known stack traces) involve many internal frames, can challenging read , actionable end users. default, Keras filters internal frames exceptions raises, keep traceback short, readable, focused actionable (code). See also config_enable_traceback_filtering() config_is_traceback_filtering_enabled(). previously disabled traceback filtering via config_disable_traceback_filtering(), can re-enable via config_enable_traceback_filtering().","code":""},{"path":"https://keras.posit.co/reference/config_disable_traceback_filtering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn off traceback filtering. — config_disable_traceback_filtering","text":"","code":"config_disable_traceback_filtering()"},{"path":"https://keras.posit.co/reference/config_disable_traceback_filtering.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn off traceback filtering. — config_disable_traceback_filtering","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_dtype_policy.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the current default dtype policy object. — config_dtype_policy","title":"Returns the current default dtype policy object. — config_dtype_policy","text":"Returns current default dtype policy object.","code":""},{"path":"https://keras.posit.co/reference/config_dtype_policy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the current default dtype policy object. — config_dtype_policy","text":"","code":"config_dtype_policy()"},{"path":"https://keras.posit.co/reference/config_dtype_policy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the current default dtype policy object. — config_dtype_policy","text":"DTypePolicy object.","code":""},{"path":"https://keras.posit.co/reference/config_enable_interactive_logging.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn on interactive logging. — config_enable_interactive_logging","title":"Turn on interactive logging. — config_enable_interactive_logging","text":"interactive logging enabled, Keras displays logs via stdout. provides best experience using Keras interactive environment shell notebook.","code":""},{"path":"https://keras.posit.co/reference/config_enable_interactive_logging.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn on interactive logging. — config_enable_interactive_logging","text":"","code":"config_enable_interactive_logging()"},{"path":"https://keras.posit.co/reference/config_enable_interactive_logging.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn on interactive logging. — config_enable_interactive_logging","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_enable_traceback_filtering.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn on traceback filtering. — config_enable_traceback_filtering","title":"Turn on traceback filtering. — config_enable_traceback_filtering","text":"Raw Keras tracebacks (also known stack traces) involve many internal frames, can challenging read , actionable end users. default, Keras filters internal frames exceptions raises, keep traceback short, readable, focused actionable (code). See also config_disable_traceback_filtering() config_is_traceback_filtering_enabled(). previously disabled traceback filtering via config_disable_traceback_filtering(), can re-enable via config_enable_traceback_filtering().","code":""},{"path":"https://keras.posit.co/reference/config_enable_traceback_filtering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn on traceback filtering. — config_enable_traceback_filtering","text":"","code":"config_enable_traceback_filtering()"},{"path":"https://keras.posit.co/reference/config_enable_traceback_filtering.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn on traceback filtering. — config_enable_traceback_filtering","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_enable_unsafe_deserialization.html","id":null,"dir":"Reference","previous_headings":"","what":"Disables safe mode globally, allowing deserialization of lambdas. — config_enable_unsafe_deserialization","title":"Disables safe mode globally, allowing deserialization of lambdas. — config_enable_unsafe_deserialization","text":"Disables safe mode globally, allowing deserialization lambdas.","code":""},{"path":"https://keras.posit.co/reference/config_enable_unsafe_deserialization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Disables safe mode globally, allowing deserialization of lambdas. — config_enable_unsafe_deserialization","text":"","code":"config_enable_unsafe_deserialization()"},{"path":"https://keras.posit.co/reference/config_enable_unsafe_deserialization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Disables safe mode globally, allowing deserialization of lambdas. — config_enable_unsafe_deserialization","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_epsilon.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the value of the fuzz factor used in numeric expressions. — config_epsilon","title":"Return the value of the fuzz factor used in numeric expressions. — config_epsilon","text":"Return value fuzz factor used numeric expressions.","code":""},{"path":"https://keras.posit.co/reference/config_epsilon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the value of the fuzz factor used in numeric expressions. — config_epsilon","text":"","code":"config_epsilon()"},{"path":"https://keras.posit.co/reference/config_epsilon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the value of the fuzz factor used in numeric expressions. — config_epsilon","text":"float.","code":""},{"path":"https://keras.posit.co/reference/config_epsilon.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return the value of the fuzz factor used in numeric expressions. — config_epsilon","text":"","code":"config_epsilon() ## [1] 1e-07"},{"path":[]},{"path":"https://keras.posit.co/reference/config_floatx.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the default float type, as a string. — config_floatx","title":"Return the default float type, as a string. — config_floatx","text":"E.g. 'bfloat16' 'float16', 'float32', 'float64'.","code":""},{"path":"https://keras.posit.co/reference/config_floatx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the default float type, as a string. — config_floatx","text":"","code":"config_floatx()"},{"path":"https://keras.posit.co/reference/config_floatx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the default float type, as a string. — config_floatx","text":"String, current default float type.","code":""},{"path":"https://keras.posit.co/reference/config_floatx.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return the default float type, as a string. — config_floatx","text":"","code":"keras3::config_floatx() ## [1] \"float32\""},{"path":[]},{"path":"https://keras.posit.co/reference/config_image_data_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the default image data format convention. — config_image_data_format","title":"Return the default image data format convention. — config_image_data_format","text":"Return default image data format convention.","code":""},{"path":"https://keras.posit.co/reference/config_image_data_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the default image data format convention. — config_image_data_format","text":"","code":"config_image_data_format()"},{"path":"https://keras.posit.co/reference/config_image_data_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the default image data format convention. — config_image_data_format","text":"string, either 'channels_first' 'channels_last'.","code":""},{"path":"https://keras.posit.co/reference/config_image_data_format.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return the default image data format convention. — config_image_data_format","text":"","code":"config_image_data_format() ## [1] \"channels_last\""},{"path":[]},{"path":"https://keras.posit.co/reference/config_is_interactive_logging_enabled.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if interactive logging is enabled. — config_is_interactive_logging_enabled","title":"Check if interactive logging is enabled. — config_is_interactive_logging_enabled","text":"switch writing logs stdout absl.logging, may use config_enable_interactive_logging() config_disable_interactive_logging().","code":""},{"path":"https://keras.posit.co/reference/config_is_interactive_logging_enabled.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if interactive logging is enabled. — config_is_interactive_logging_enabled","text":"","code":"config_is_interactive_logging_enabled()"},{"path":"https://keras.posit.co/reference/config_is_interactive_logging_enabled.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if interactive logging is enabled. — config_is_interactive_logging_enabled","text":"Boolean, TRUE interactive logging enabled, FALSE otherwise.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_is_traceback_filtering_enabled.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if traceback filtering is enabled. — config_is_traceback_filtering_enabled","title":"Check if traceback filtering is enabled. — config_is_traceback_filtering_enabled","text":"Raw Keras tracebacks (also known stack traces) involve many internal frames, can challenging read , actionable end users. default, Keras filters internal frames exceptions raises, keep traceback short, readable, focused actionable (code). See also config_enable_traceback_filtering() config_disable_traceback_filtering(). previously disabled traceback filtering via config_disable_traceback_filtering(), can re-enable via config_enable_traceback_filtering().","code":""},{"path":"https://keras.posit.co/reference/config_is_traceback_filtering_enabled.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if traceback filtering is enabled. — config_is_traceback_filtering_enabled","text":"","code":"config_is_traceback_filtering_enabled()"},{"path":"https://keras.posit.co/reference/config_is_traceback_filtering_enabled.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if traceback filtering is enabled. — config_is_traceback_filtering_enabled","text":"Boolean, TRUE traceback filtering enabled, FALSE otherwise.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_set_backend.html","id":null,"dir":"Reference","previous_headings":"","what":"Reload the backend (and the Keras package). — config_set_backend","title":"Reload the backend (and the Keras package). — config_set_backend","text":"Reload backend (Keras package).","code":""},{"path":"https://keras.posit.co/reference/config_set_backend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reload the backend (and the Keras package). — config_set_backend","text":"","code":"config_set_backend(backend)"},{"path":"https://keras.posit.co/reference/config_set_backend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reload the backend (and the Keras package). — config_set_backend","text":"backend String","code":""},{"path":"https://keras.posit.co/reference/config_set_backend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reload the backend (and the Keras package). — config_set_backend","text":"Nothing, function called side effect.","code":""},{"path":"https://keras.posit.co/reference/config_set_backend.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reload the backend (and the Keras package). — config_set_backend","text":"","code":"config_set_backend(\"jax\")"},{"path":"https://keras.posit.co/reference/config_set_backend.html","id":"warning","dir":"Reference","previous_headings":"","what":"WARNING","title":"Reload the backend (and the Keras package). — config_set_backend","text":"Using function dangerous done carefully. Changing backend convert type already-instantiated objects. Thus, layers / tensors / etc. already created longer usable without errors. strongly recommended keep around Keras-originated objects instances created calling config_set_backend(). includes function class instance uses Keras functionality. code needs re-executed calling config_set_backend().","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_set_dtype_policy.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets the default dtype policy globally. — config_set_dtype_policy","title":"Sets the default dtype policy globally. — config_set_dtype_policy","text":"Sets default dtype policy globally.","code":""},{"path":"https://keras.posit.co/reference/config_set_dtype_policy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets the default dtype policy globally. — config_set_dtype_policy","text":"","code":"config_set_dtype_policy(policy)"},{"path":"https://keras.posit.co/reference/config_set_dtype_policy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets the default dtype policy globally. — config_set_dtype_policy","text":"policy string DTypePolicy object.","code":""},{"path":"https://keras.posit.co/reference/config_set_dtype_policy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets the default dtype policy globally. — config_set_dtype_policy","text":"return value, called side effects.","code":""},{"path":"https://keras.posit.co/reference/config_set_dtype_policy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets the default dtype policy globally. — config_set_dtype_policy","text":"","code":"config_set_dtype_policy(\"mixed_float16\")"},{"path":"https://keras.posit.co/reference/config_set_epsilon.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the value of the fuzz factor used in numeric expressions. — config_set_epsilon","title":"Set the value of the fuzz factor used in numeric expressions. — config_set_epsilon","text":"Set value fuzz factor used numeric expressions.","code":""},{"path":"https://keras.posit.co/reference/config_set_epsilon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the value of the fuzz factor used in numeric expressions. — config_set_epsilon","text":"","code":"config_set_epsilon(value)"},{"path":"https://keras.posit.co/reference/config_set_epsilon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the value of the fuzz factor used in numeric expressions. — config_set_epsilon","text":"value float. New value epsilon.","code":""},{"path":"https://keras.posit.co/reference/config_set_epsilon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set the value of the fuzz factor used in numeric expressions. — config_set_epsilon","text":"return value, called side effects.","code":""},{"path":"https://keras.posit.co/reference/config_set_epsilon.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the value of the fuzz factor used in numeric expressions. — config_set_epsilon","text":"","code":"config_epsilon() ## [1] 1e-07 config_set_epsilon(1e-5) config_epsilon() ## [1] 1e-05 # Set it back to the default value. config_set_epsilon(1e-7)"},{"path":[]},{"path":"https://keras.posit.co/reference/config_set_floatx.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the default float dtype. — config_set_floatx","title":"Set the default float dtype. — config_set_floatx","text":"Set default float dtype.","code":""},{"path":"https://keras.posit.co/reference/config_set_floatx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the default float dtype. — config_set_floatx","text":"","code":"config_set_floatx(value)"},{"path":"https://keras.posit.co/reference/config_set_floatx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the default float dtype. — config_set_floatx","text":"value String; 'bfloat16', 'float16', 'float32', 'float64'.","code":""},{"path":"https://keras.posit.co/reference/config_set_floatx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set the default float dtype. — config_set_floatx","text":"return value, called side effects.","code":""},{"path":"https://keras.posit.co/reference/config_set_floatx.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Set the default float dtype. — config_set_floatx","text":"recommended set \"float16\" training, likely cause numeric stability issues. Instead, mixed precision, leverages mix float16 float32. can configured calling keras3::keras$mixed_precision$set_dtype_policy('mixed_float16').","code":""},{"path":"https://keras.posit.co/reference/config_set_floatx.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the default float dtype. — config_set_floatx","text":"","code":"config_floatx() ## [1] \"float32\" config_set_floatx('float64') config_floatx() ## [1] \"float64\" # Set it back to float32 config_set_floatx('float32')"},{"path":"https://keras.posit.co/reference/config_set_floatx.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"Set the default float dtype. — config_set_floatx","text":"ValueError: case invalid value.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/config_set_image_data_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the value of the image data format convention. — config_set_image_data_format","title":"Set the value of the image data format convention. — config_set_image_data_format","text":"Set value image data format convention.","code":""},{"path":"https://keras.posit.co/reference/config_set_image_data_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the value of the image data format convention. — config_set_image_data_format","text":"","code":"config_set_image_data_format(data_format)"},{"path":"https://keras.posit.co/reference/config_set_image_data_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the value of the image data format convention. — config_set_image_data_format","text":"data_format string. 'channels_first' 'channels_last'.","code":""},{"path":"https://keras.posit.co/reference/config_set_image_data_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set the value of the image data format convention. — config_set_image_data_format","text":"return value, called side effects.","code":""},{"path":"https://keras.posit.co/reference/config_set_image_data_format.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the value of the image data format convention. — config_set_image_data_format","text":"","code":"config_image_data_format() ## [1] \"channels_last\" # 'channels_last' keras3::config_set_image_data_format('channels_first') config_image_data_format() ## [1] \"channels_first\" # Set it back to `'channels_last'` keras3::config_set_image_data_format('channels_last')"},{"path":[]},{"path":"https://keras.posit.co/reference/constraint_maxnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"MaxNorm weight constraint. — constraint_maxnorm","title":"MaxNorm weight constraint. — constraint_maxnorm","text":"Constrains weights incident hidden unit norm less equal desired value.","code":""},{"path":"https://keras.posit.co/reference/constraint_maxnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MaxNorm weight constraint. — constraint_maxnorm","text":"","code":"constraint_maxnorm(max_value = 2L, axis = 1L)"},{"path":"https://keras.posit.co/reference/constraint_maxnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MaxNorm weight constraint. — constraint_maxnorm","text":"max_value maximum norm value incoming weights. axis integer, axis along calculate weight norms. instance, Dense layer weight matrix shape (input_dim, output_dim), set axis 0 constrain weight vector length (input_dim,). Conv2D layer data_format = \"channels_last\", weight tensor shape (rows, cols, input_depth, output_depth), set axis [0, 1, 2] constrain weights filter tensor size (rows, cols, input_depth).","code":""},{"path":"https://keras.posit.co/reference/constraint_maxnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MaxNorm weight constraint. — constraint_maxnorm","text":"Constraint instance, callable can passed layer constructors used directly calling tensors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/constraint_minmaxnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"MinMaxNorm weight constraint. — constraint_minmaxnorm","title":"MinMaxNorm weight constraint. — constraint_minmaxnorm","text":"Constrains weights incident hidden unit norm lower bound upper bound.","code":""},{"path":"https://keras.posit.co/reference/constraint_minmaxnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MinMaxNorm weight constraint. — constraint_minmaxnorm","text":"","code":"constraint_minmaxnorm(min_value = 0, max_value = 1, rate = 1, axis = 1L)"},{"path":"https://keras.posit.co/reference/constraint_minmaxnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MinMaxNorm weight constraint. — constraint_minmaxnorm","text":"min_value minimum norm incoming weights. max_value maximum norm incoming weights. rate rate enforcing constraint: weights rescaled yield op_clip? (1 - rate) * norm + rate * op_clip(norm, min_value, max_value). Effectively, means rate = 1.0 stands strict enforcement constraint, rate<1.0 means weights rescaled step slowly move towards value inside desired interval. axis integer, axis along calculate weight norms. instance, Dense layer weight matrix shape (input_dim, output_dim), set axis 0 constrain weight vector length (input_dim,). Conv2D layer data_format = \"channels_last\", weight tensor shape (rows, cols, input_depth, output_depth), set axis [0, 1, 2] constrain weights filter tensor size (rows, cols, input_depth).","code":""},{"path":"https://keras.posit.co/reference/constraint_minmaxnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MinMaxNorm weight constraint. — constraint_minmaxnorm","text":"Constraint instance, callable can passed layer constructors used directly calling tensors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/constraint_nonneg.html","id":null,"dir":"Reference","previous_headings":"","what":"Constrains the weights to be non-negative. — constraint_nonneg","title":"Constrains the weights to be non-negative. — constraint_nonneg","text":"Constrains weights non-negative.","code":""},{"path":"https://keras.posit.co/reference/constraint_nonneg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constrains the weights to be non-negative. — constraint_nonneg","text":"","code":"constraint_nonneg()"},{"path":"https://keras.posit.co/reference/constraint_nonneg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constrains the weights to be non-negative. — constraint_nonneg","text":"Constraint instance, callable can passed layer constructors used directly calling tensors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/constraint_unitnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Constrains the weights incident to each hidden unit to have unit norm. — constraint_unitnorm","title":"Constrains the weights incident to each hidden unit to have unit norm. — constraint_unitnorm","text":"Constrains weights incident hidden unit unit norm.","code":""},{"path":"https://keras.posit.co/reference/constraint_unitnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constrains the weights incident to each hidden unit to have unit norm. — constraint_unitnorm","text":"","code":"constraint_unitnorm(axis = 1L)"},{"path":"https://keras.posit.co/reference/constraint_unitnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constrains the weights incident to each hidden unit to have unit norm. — constraint_unitnorm","text":"axis integer, axis along calculate weight norms. instance, Dense layer weight matrix shape (input_dim, output_dim), set axis 0 constrain weight vector length (input_dim,). Conv2D layer data_format = \"channels_last\", weight tensor shape (rows, cols, input_depth, output_depth), set axis [0, 1, 2] constrain weights filter tensor size (rows, cols, input_depth).","code":""},{"path":"https://keras.posit.co/reference/constraint_unitnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Constrains the weights incident to each hidden unit to have unit norm. — constraint_unitnorm","text":"Constraint instance, callable can passed layer constructors used directly calling tensors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/count_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Count the total number of scalars composing the weights. — count_params","title":"Count the total number of scalars composing the weights. — count_params","text":"Count total number scalars composing weights.","code":""},{"path":"https://keras.posit.co/reference/count_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count the total number of scalars composing the weights. — count_params","text":"","code":"count_params(object)"},{"path":"https://keras.posit.co/reference/count_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count the total number of scalars composing the weights. — count_params","text":"object Layer model object","code":""},{"path":"https://keras.posit.co/reference/count_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count the total number of scalars composing the weights. — count_params","text":"integer count","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/custom_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Custom metric function — custom_metric","title":"Custom metric function — custom_metric","text":"Custom metric function","code":""},{"path":"https://keras.posit.co/reference/custom_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Custom metric function — custom_metric","text":"","code":"custom_metric(name, metric_fn)"},{"path":"https://keras.posit.co/reference/custom_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Custom metric function — custom_metric","text":"name name used show training progress output metric_fn R function signature function(y_true, y_pred) accepts tensors.","code":""},{"path":"https://keras.posit.co/reference/custom_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Custom metric function — custom_metric","text":"callable function __name__ attribute.","code":""},{"path":"https://keras.posit.co/reference/custom_metric.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Custom metric function — custom_metric","text":"can provide arbitrary R function custom metric. Note y_true y_pred parameters tensors, computations use op_* tensor functions. Use custom_metric() function define custom metric. Note name ('mean_pred') provided custom metric function: name used within training progress output. want save load model custom metrics, also call register_keras_serializable(), specify metric call load_model(). example: load_model(\"my_model.keras\", c('mean_pred' = metric_mean_pred)). Alternatively, can wrap code call with_custom_object_scope() allow refer metric name just like built keras metrics. Alternative ways supplying custom metrics: custom_metric(): Arbitrary R function. metric_mean_wrapper(): Wrap arbitrary R function Metric instance. Create custom Metric() subclass.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/dataset_boston_housing.html","id":null,"dir":"Reference","previous_headings":"","what":"Boston housing price regression dataset — dataset_boston_housing","title":"Boston housing price regression dataset — dataset_boston_housing","text":"Dataset taken StatLib library maintained Carnegie Mellon University.","code":""},{"path":"https://keras.posit.co/reference/dataset_boston_housing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Boston housing price regression dataset — dataset_boston_housing","text":"","code":"dataset_boston_housing(   path = \"boston_housing.npz\",   test_split = 0.2,   seed = 113L )"},{"path":"https://keras.posit.co/reference/dataset_boston_housing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Boston housing price regression dataset — dataset_boston_housing","text":"path Path cache dataset locally (relative ~/.keras/datasets). test_split fraction data reserve test set. seed Random seed shuffling data computing test split.","code":""},{"path":"https://keras.posit.co/reference/dataset_boston_housing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Boston housing price regression dataset — dataset_boston_housing","text":"Lists training test data: train$x, train$y, test$x, test$y. Samples contain 13 attributes houses different locations around Boston suburbs late 1970s. Targets median values houses location (k$).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/dataset_cifar10.html","id":null,"dir":"Reference","previous_headings":"","what":"CIFAR10 small image classification — dataset_cifar10","title":"CIFAR10 small image classification — dataset_cifar10","text":"Dataset 50,000 32x32 color training images, labeled 10 categories, 10,000 test images.","code":""},{"path":"https://keras.posit.co/reference/dataset_cifar10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CIFAR10 small image classification — dataset_cifar10","text":"","code":"dataset_cifar10()"},{"path":"https://keras.posit.co/reference/dataset_cifar10.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CIFAR10 small image classification — dataset_cifar10","text":"Lists training test data: train$x, train$y, test$x, test$y. x data array RGB image data shape (num_samples, 3, 32, 32). y data array category labels (integers range 0-9) shape (num_samples).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/dataset_cifar100.html","id":null,"dir":"Reference","previous_headings":"","what":"CIFAR100 small image classification — dataset_cifar100","title":"CIFAR100 small image classification — dataset_cifar100","text":"Dataset 50,000 32x32 color training images, labeled 100 categories, 10,000 test images.","code":""},{"path":"https://keras.posit.co/reference/dataset_cifar100.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CIFAR100 small image classification — dataset_cifar100","text":"","code":"dataset_cifar100(label_mode = c(\"fine\", \"coarse\"))"},{"path":"https://keras.posit.co/reference/dataset_cifar100.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CIFAR100 small image classification — dataset_cifar100","text":"label_mode one \"fine\", \"coarse\".","code":""},{"path":"https://keras.posit.co/reference/dataset_cifar100.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CIFAR100 small image classification — dataset_cifar100","text":"Lists training test data: train$x, train$y, test$x, test$y. x data array RGB image data shape (num_samples, 3, 32, 32). y data array category labels shape (num_samples).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/dataset_fashion_mnist.html","id":null,"dir":"Reference","previous_headings":"","what":"Fashion-MNIST database of fashion articles — dataset_fashion_mnist","title":"Fashion-MNIST database of fashion articles — dataset_fashion_mnist","text":"Dataset 60,000 28x28 grayscale images 10 fashion article classes, along test set 10,000 images. dataset can used drop-replacement MNIST. class labels encoded integers 0-9 correspond T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt,","code":""},{"path":"https://keras.posit.co/reference/dataset_fashion_mnist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fashion-MNIST database of fashion articles — dataset_fashion_mnist","text":"","code":"dataset_fashion_mnist()"},{"path":"https://keras.posit.co/reference/dataset_fashion_mnist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fashion-MNIST database of fashion articles — dataset_fashion_mnist","text":"Lists training test data: train$x, train$y, test$x, test$y, x array grayscale image data shape (num_samples, 28, 28) y array article labels (integers range 0-9) shape (num_samples).","code":""},{"path":"https://keras.posit.co/reference/dataset_fashion_mnist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fashion-MNIST database of fashion articles — dataset_fashion_mnist","text":"Dataset 60,000 28x28 grayscale images 10 fashion categories, along test set 10,000 images. dataset can used drop-replacement MNIST. class labels : 0 - T-shirt/top 1 - Trouser 2 - Pullover 3 - Dress 4 - Coat 5 - Sandal 6 - Shirt 7 - Sneaker 8 - Bag 9 - Ankle boot","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/dataset_imdb.html","id":null,"dir":"Reference","previous_headings":"","what":"IMDB Movie reviews sentiment classification — dataset_imdb","title":"IMDB Movie reviews sentiment classification — dataset_imdb","text":"Dataset 25,000 movies reviews IMDB, labeled sentiment (positive/negative). Reviews preprocessed, review encoded sequence word indexes (integers). convenience, words indexed overall frequency dataset, instance integer \"3\" encodes 3rd frequent word data. allows quick filtering operations : \"consider top 10,000 common words, eliminate top 20 common words\".","code":""},{"path":"https://keras.posit.co/reference/dataset_imdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"IMDB Movie reviews sentiment classification — dataset_imdb","text":"","code":"dataset_imdb(   path = \"imdb.npz\",   num_words = NULL,   skip_top = 0L,   maxlen = NULL,   seed = 113L,   start_char = 1L,   oov_char = 2L,   index_from = 3L )  dataset_imdb_word_index(path = \"imdb_word_index.json\")"},{"path":"https://keras.posit.co/reference/dataset_imdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"IMDB Movie reviews sentiment classification — dataset_imdb","text":"path cache data (relative ~/.keras/dataset). num_words Max number words include. Words ranked often occur (training set) frequent words kept skip_top Skip top N frequently occuring words (may informative). maxlen sequences longer filtered . seed random seed sample shuffling. start_char start sequence marked character. Set 1 0 usually padding character. oov_char Words cut num_words skip_top limit replaced character. index_from Index actual words index higher.","code":""},{"path":"https://keras.posit.co/reference/dataset_imdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"IMDB Movie reviews sentiment classification — dataset_imdb","text":"Lists training test data: train$x, train$y, test$x, test$y. x data includes integer sequences. num_words argument specific, maximum possible index value num_words-1. maxlen argument specified, largest possible sequence length maxlen. y data includes set integer labels (0 1). dataset_imdb_word_index() function returns list names words values integer.","code":""},{"path":"https://keras.posit.co/reference/dataset_imdb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"IMDB Movie reviews sentiment classification — dataset_imdb","text":"convention, \"0\" stand specific word, instead used encode unknown word.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/dataset_mnist.html","id":null,"dir":"Reference","previous_headings":"","what":"MNIST database of handwritten digits — dataset_mnist","title":"MNIST database of handwritten digits — dataset_mnist","text":"Dataset 60,000 28x28 grayscale images 10 digits, along test set 10,000 images.","code":""},{"path":"https://keras.posit.co/reference/dataset_mnist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MNIST database of handwritten digits — dataset_mnist","text":"","code":"dataset_mnist(path = \"mnist.npz\")"},{"path":"https://keras.posit.co/reference/dataset_mnist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MNIST database of handwritten digits — dataset_mnist","text":"path Path cache dataset locally (relative ~/.keras/datasets).","code":""},{"path":"https://keras.posit.co/reference/dataset_mnist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MNIST database of handwritten digits — dataset_mnist","text":"Lists training test data: train$x, train$y, test$x, test$y, x array grayscale image data shape (num_samples, 28, 28) y array digit labels (integers range 0-9) shape (num_samples).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/dataset_reuters.html","id":null,"dir":"Reference","previous_headings":"","what":"Reuters newswire topics classification — dataset_reuters","title":"Reuters newswire topics classification — dataset_reuters","text":"Dataset 11,228 newswires Reuters, labeled 46 topics. dataset_imdb() , wire encoded sequence word indexes (conventions).","code":""},{"path":"https://keras.posit.co/reference/dataset_reuters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reuters newswire topics classification — dataset_reuters","text":"","code":"dataset_reuters(   path = \"reuters.npz\",   num_words = NULL,   skip_top = 0L,   maxlen = NULL,   test_split = 0.2,   seed = 113L,   start_char = 1L,   oov_char = 2L,   index_from = 3L )  dataset_reuters_word_index(path = \"reuters_word_index.pkl\")"},{"path":"https://keras.posit.co/reference/dataset_reuters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reuters newswire topics classification — dataset_reuters","text":"path cache data (relative ~/.keras/dataset). num_words Max number words include. Words ranked often occur (training set) frequent words kept skip_top Skip top N frequently occuring words (may informative). maxlen Truncate sequences length. test_split Fraction dataset used test data. seed Random seed sample shuffling. start_char start sequence marked character. Set 1 0 usually padding character. oov_char words cut num_words skip_top limit replaced character. index_from index actual words index higher.","code":""},{"path":"https://keras.posit.co/reference/dataset_reuters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reuters newswire topics classification — dataset_reuters","text":"Lists training test data: train$x, train$y, test$x, test$y format dataset_imdb(). dataset_reuters_word_index() function returns list names words values integer. e.g. word_index[[\"giraffe\"]] might return 1234.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/deserialize_keras_object.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the object by deserializing the config dict. — deserialize_keras_object","title":"Retrieve the object by deserializing the config dict. — deserialize_keras_object","text":"config dict Python dictionary consists set key-value pairs, represents Keras object, Optimizer, Layer, Metrics, etc. saving loading library uses following keys record information Keras object: class_name: String. name class, exactly defined source code, \"LossesContainer\". config: Named List. Library-defined user-defined key-value pairs store configuration object, obtained object$get_config(). module: String. path python module. Built-Keras classes expect prefix keras. registered_name: String. key class registered via register_keras_serializable(package, name) API. key format '{package}>{name}', package name arguments passed register_keras_serializable(). name provided, uses class name. registered_name successfully resolves class (registered), class_name config values config dict used. registered_name used non-built-classes. example, following config list represents built-Adam optimizer relevant config:     class exported Keras namespace, library tracks module class_name. example:   following config represents user-customized MeanSquaredError loss:","code":"config <- list(   class_name = \"Adam\",   config = list(     amsgrad = FALSE,     beta_1 = 0.8999999761581421,     beta_2 = 0.9990000128746033,     epsilon = 1e-07,     learning_rate = 0.0010000000474974513,     name = \"Adam\"   ),   module = \"keras.optimizers\",   registered_name = NULL ) # Returns an `Adam` instance identical to the original one. deserialize_keras_object(config) ## <keras.src.optimizers.adam.Adam object> config <- list(   class_name = \"MetricsList\",   config =  list(     ...   ),   module = \"keras.trainers.compile_utils\",   registered_name = \"MetricsList\" )  # Returns a `MetricsList` instance identical to the original one. deserialize_keras_object(config) # define a custom object loss_modified_mse <- Loss(   \"ModifiedMeanSquaredError\",   inherit = loss_mean_squared_error)  # register the custom object register_keras_serializable(loss_modified_mse)  # confirm object is registered get_custom_objects() ## $`keras3>ModifiedMeanSquaredError` ## <class '<r-namespace:keras3>.ModifiedMeanSquaredError'> get_registered_name(loss_modified_mse) ## [1] \"keras3>ModifiedMeanSquaredError\" # now custom object instances can be serialized full_config <- serialize_keras_object(loss_modified_mse())  # the `config` arguments will be passed to loss_modified_mse() str(full_config) ## List of 4 ##  $ module         : chr \"<r-namespace:keras3>\" ##  $ class_name     : chr \"ModifiedMeanSquaredError\" ##  $ config         :List of 2 ##   ..$ name     : chr \"mean_squared_error\" ##   ..$ reduction: chr \"sum_over_batch_size\" ##  $ registered_name: chr \"keras3>ModifiedMeanSquaredError\" # and custom object instances can be deserialized deserialize_keras_object(full_config) ## <<r-namespace:keras3>.ModifiedMeanSquaredError object> # Returns the `ModifiedMeanSquaredError` object"},{"path":"https://keras.posit.co/reference/deserialize_keras_object.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the object by deserializing the config dict. — deserialize_keras_object","text":"","code":"deserialize_keras_object(config, custom_objects = NULL, safe_mode = TRUE, ...)"},{"path":"https://keras.posit.co/reference/deserialize_keras_object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the object by deserializing the config dict. — deserialize_keras_object","text":"config Named list describing object. custom_objects Named list containing mapping custom object names corresponding classes functions. safe_mode Boolean, whether disallow unsafe lambda deserialization. safe_mode=FALSE, loading object potential trigger arbitrary code execution. argument applicable Keras v3 model format. Defaults TRUE. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/deserialize_keras_object.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the object by deserializing the config dict. — deserialize_keras_object","text":"object described config dictionary.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/evaluate.keras.src.models.model.Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a Keras Model — evaluate.keras.src.models.model.Model","title":"Evaluate a Keras Model — evaluate.keras.src.models.model.Model","text":"functions returns loss value metrics values model test mode. Computation done batches (see batch_size arg.)","code":""},{"path":"https://keras.posit.co/reference/evaluate.keras.src.models.model.Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a Keras Model — evaluate.keras.src.models.model.Model","text":"","code":"# S3 method for keras.src.models.model.Model evaluate(   object,   x = NULL,   y = NULL,   ...,   batch_size = NULL,   verbose = getOption(\"keras.verbose\", default = \"auto\"),   sample_weight = NULL,   steps = NULL,   callbacks = NULL )"},{"path":"https://keras.posit.co/reference/evaluate.keras.src.models.model.Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a Keras Model — evaluate.keras.src.models.model.Model","text":"object Keras model object x Input data. : R array (array-like), list arrays (case model multiple inputs). tensor, list tensors (case model multiple inputs). named list mapping input names corresponding array/tensors, model named inputs. tf.data.Dataset. return tuple either (inputs, targets) (inputs, targets, sample_weights). generator returning (inputs, targets) (inputs, targets, sample_weights). y Target data. Like input data x, either R array(s) backend-native tensor(s). x tf.data.Dataset generator function, y specified (since targets obtained iterator/dataset). ... forward/backward compatability. batch_size Integer NULL. Number samples per batch computation. unspecified, batch_size default 32. specify batch_size data form tf dataset generator (since generate batches). verbose \"auto\", 0, 1, 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = single line. \"auto\" becomes 1 cases, 2 knitr render running distributed training server. Note progress bar particularly useful logged file, verbose=2 recommended running interactively (e.g. production environment). Defaults \"auto\". sample_weight Optional array weights test samples, used weighting loss function. can either pass flat (1D) R array length input samples (1:1 mapping weights samples), case temporal data, can pass 2D array shape (samples, sequence_length), apply different weight every timestep every sample. argument supported x tfdataset, instead pass sample weights third element x. steps Integer NULL. Total number steps (batches samples) declaring evaluation round finished. Ignored default value NULL. x tf.data.Dataset steps NULL, evaluation run dataset exhausted. callbacks List Callback instances. List callbacks apply evaluation.","code":""},{"path":"https://keras.posit.co/reference/evaluate.keras.src.models.model.Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a Keras Model — evaluate.keras.src.models.model.Model","text":"Scalar test loss (model single output metrics) list scalars (model multiple outputs /metrics). attribute model$metrics_names give display labels scalar outputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/export_savedmodel.keras.src.models.model.Model.html","id":null,"dir":"Reference","previous_headings":"","what":"[TF backend only] Create a TF SavedModel artifact for inference — export_savedmodel.keras.src.models.model.Model","title":"[TF backend only] Create a TF SavedModel artifact for inference — export_savedmodel.keras.src.models.model.Model","text":"(e.g. via TF-Serving). Note: can currently used TF backend. method lets export model lightweight SavedModel artifact contains model's forward pass (call() method) can served via e.g. TF-Serving. forward pass registered name serve() (see example ). original code model (including custom layers may used) longer necessary reload artifact -- entirely standalone.","code":""},{"path":"https://keras.posit.co/reference/export_savedmodel.keras.src.models.model.Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"[TF backend only] Create a TF SavedModel artifact for inference — export_savedmodel.keras.src.models.model.Model","text":"","code":"# S3 method for keras.src.models.model.Model export_savedmodel(object, export_dir_base, ...)"},{"path":"https://keras.posit.co/reference/export_savedmodel.keras.src.models.model.Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"[TF backend only] Create a TF SavedModel artifact for inference — export_savedmodel.keras.src.models.model.Model","text":"object keras model. export_dir_base string, file path save artifact. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/export_savedmodel.keras.src.models.model.Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"[TF backend only] Create a TF SavedModel artifact for inference — export_savedmodel.keras.src.models.model.Model","text":"called primarily side effect exporting object. first argument, object also returned, invisibly, enable usage pipe.","code":""},{"path":"https://keras.posit.co/reference/export_savedmodel.keras.src.models.model.Model.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"[TF backend only] Create a TF SavedModel artifact for inference — export_savedmodel.keras.src.models.model.Model","text":"","code":"# Create the artifact model |> tensorflow::export_savedmodel(\"path/to/location\")  # Later, in a different process / environment... library(tensorflow) reloaded_artifact <- tf$saved_model$load(\"path/to/location\") predictions <- reloaded_artifact$serve(input_data)  # see tfdeploy::serve_savedmodel() for serving a model over a local web api."},{"path":[]},{"path":"https://keras.posit.co/reference/fit.keras.src.models.model.Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Train a model for a fixed number of epochs (dataset iterations). — fit.keras.src.models.model.Model","title":"Train a model for a fixed number of epochs (dataset iterations). — fit.keras.src.models.model.Model","text":"Train model fixed number epochs (dataset iterations).","code":""},{"path":"https://keras.posit.co/reference/fit.keras.src.models.model.Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train a model for a fixed number of epochs (dataset iterations). — fit.keras.src.models.model.Model","text":"","code":"# S3 method for keras.src.models.model.Model fit(   object,   x = NULL,   y = NULL,   ...,   batch_size = NULL,   epochs = 1L,   callbacks = NULL,   validation_split = 0,   validation_data = NULL,   shuffle = TRUE,   class_weight = NULL,   sample_weight = NULL,   initial_epoch = 1L,   steps_per_epoch = NULL,   validation_steps = NULL,   validation_batch_size = NULL,   validation_freq = 1L,   verbose = getOption(\"keras.verbose\", default = \"auto\"),   view_metrics = getOption(\"keras.view_metrics\", default = \"auto\") )"},{"path":"https://keras.posit.co/reference/fit.keras.src.models.model.Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train a model for a fixed number of epochs (dataset iterations). — fit.keras.src.models.model.Model","text":"object Keras model object x Input data. : array (array-like), list arrays (case model multiple inputs). tensor, list tensors (case model multiple inputs). named list mapping input names corresponding array/tensors, model named inputs. tf.data.Dataset. return tuple either (inputs, targets) (inputs, targets, sample_weights). generator returning (inputs, targets) (inputs, targets, sample_weights). y Target data. Like input data x, either array(s) backend-native tensor(s). x TF Dataset generator, y specified (since targets obtained x). ... Additional arguments passed model fit() method. batch_size Integer NULL. Number samples per gradient update. unspecified, batch_size default 32. specify batch_size data form TF Datasets generators, (since generate batches). epochs Integer. Number epochs train model. epoch iteration entire x y data provided (unless steps_per_epoch flag set something NULL). Note conjunction initial_epoch, epochs understood \"final epoch\". model trained number iterations given epochs, merely epoch index epochs reached. callbacks List Callback() instances. List callbacks apply training. See callback_*. validation_split Float 0 1. Fraction training data used validation data. model set apart fraction training data, train , evaluate loss model metrics data end epoch. validation data selected last samples x y data provided, shuffling. argument supported x TF Dataset generator. validation_data validation_split provided, validation_data override validation_split. validation_data Data evaluate loss model metrics end epoch. model trained data. Thus, note fact validation loss data provided using validation_split validation_data affected regularization layers like noise dropout. validation_data override validation_split. : tuple (x_val, y_val) arrays tensors. tuple (x_val, y_val, val_sample_weights) arrays. generator returning (inputs, targets) (inputs, targets, sample_weights). shuffle Boolean, whether shuffle training data epoch. argument ignored x generator TF Dataset. class_weight Optional named list mapping class indices (integers, 0-based) weight (float) value, used weighting loss function (training ). can useful tell model \"pay attention\" samples -represented class. class_weight specified targets rank 2 greater, either y must one-hot encoded, explicit final dimension 1 must included sparse class labels. sample_weight Optional array weights training samples, used weighting loss function (training ). can either pass flat (1D) array/vector length input samples (1:1 mapping weights samples), case temporal data, can pass 2D array (matrix) shape (samples, sequence_length), apply different weight every timestep every sample. argument supported x TF Dataset generator, instead provide sample_weights third element x. Note sample weighting apply metrics specified via metrics argument compile(). apply sample weighting metrics, can specify via weighted_metrics compile() instead. initial_epoch Integer. Epoch start training (useful resuming previous training run). steps_per_epoch Integer NULL. Total number steps (batches samples) declaring one epoch finished starting next epoch. training input tensors backend-native tensors, default NULL equal number samples dataset divided batch size, 1 determined. x TF Dataset, steps_per_epoch NULL, epoch run input dataset exhausted.  passing infinitely repeating dataset, must specify steps_per_epoch argument. steps_per_epoch = -1 training run indefinitely infinitely repeating dataset. validation_steps relevant validation_data provided. Total number steps (batches samples) draw stopping performing validation end every epoch. validation_steps NULL, validation run validation_data dataset exhausted. case infinitely repeated dataset, run infinite loop. validation_steps specified part dataset consumed, evaluation start beginning dataset epoch. ensures validation samples used every time. validation_batch_size Integer NULL. Number samples per validation batch. unspecified, default batch_size. specify validation_batch_size data form TF Datasets generator instances (since generate batches). validation_freq relevant validation data provided. Specifies many training epochs run new validation run performed, e.g. validation_freq=2 runs validation every 2 epochs. verbose \"auto\", 0, 1, 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. \"auto\" becomes 1 cases, 2 knitr render running distributed training server. Note progress bar particularly useful logged file, verbose=2 recommended running interactively (e.g., production environment). Defaults \"auto\". view_metrics View realtime plot training metrics (epoch). default (\"auto\") display plot running within RStudio, metrics specified model compile(), epochs > 1 verbose > 0. Set global options(keras.view_metrics = ) option establish different default.","code":""},{"path":"https://keras.posit.co/reference/fit.keras.src.models.model.Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train a model for a fixed number of epochs (dataset iterations). — fit.keras.src.models.model.Model","text":"keras_training_history object, named list: list(params = <params>, metrics = <metrics>\"), S3 methods print(), plot(), .data.frame(). metrics field record training loss values metrics values successive epochs, well validation loss values validation metrics values (applicable).","code":""},{"path":"https://keras.posit.co/reference/fit.keras.src.models.model.Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Train a model for a fixed number of epochs (dataset iterations). — fit.keras.src.models.model.Model","text":"Unpacking behavior iterator-like inputs: common pattern pass iterator like object tf.data.Dataset generator fit(), fact yield features (x) optionally targets (y) sample weights (sample_weight). Keras requires output iterator-likes unambiguous. iterator return tuple() length 1, 2, 3, optional second third elements used y sample_weight respectively. type provided wrapped length-one tuple(), effectively treating everything x. yielding named lists, still adhere top-level tuple structure, e.g. tuple(list(x0 = x0, x = x1), y). Keras attempt separate features, targets, weights keys single dict.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/freeze_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Freeze and unfreeze weights — freeze_weights","title":"Freeze and unfreeze weights — freeze_weights","text":"Freeze weights model layer longer trainable.","code":""},{"path":"https://keras.posit.co/reference/freeze_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Freeze and unfreeze weights — freeze_weights","text":"","code":"freeze_weights(object, from = NULL, to = NULL, which = NULL)  unfreeze_weights(object, from = NULL, to = NULL, which = NULL)"},{"path":"https://keras.posit.co/reference/freeze_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Freeze and unfreeze weights — freeze_weights","text":"object Keras model layer object Layer instance, layer name, layer index within model Layer instance, layer name, layer index within model layer names, integer positions, layers, logical vector (length(object$layers)), function returning logical vector.","code":""},{"path":"https://keras.posit.co/reference/freeze_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Freeze and unfreeze weights — freeze_weights","text":"input object frozen weights returned, invisibly. Note, object modified place, return value provided make usage pipe convenient.","code":""},{"path":"https://keras.posit.co/reference/freeze_weights.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Freeze and unfreeze weights — freeze_weights","text":"layer arguments inclusive. applied model, freeze unfreeze global operation layers model (.e. layers within specified range set opposite value, e.g. unfrozen call freeze). Models must compiled weights frozen unfrozen.","code":""},{"path":"https://keras.posit.co/reference/freeze_weights.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Freeze and unfreeze weights — freeze_weights","text":"","code":"# instantiate a VGG16 model conv_base <- application_vgg16(   weights = \"imagenet\",   include_top = FALSE,   input_shape = c(150, 150, 3) )  # freeze it's weights freeze_weights(conv_base)  # Note the \"Trainable\" column conv_base ## Model: \"vgg16\" ## +-----------------------------+-----------------------+------------+-------+ ## | Layer (type)                | Output Shape          |    Param # | Trai… | ## +=============================+=======================+============+=======+ ## | input_layer (InputLayer)    | (None, 150, 150, 3)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_conv1 (Conv2D)       | (None, 150, 150, 64)  |      1,792 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_conv2 (Conv2D)       | (None, 150, 150, 64)  |     36,928 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_pool (MaxPooling2D)  | (None, 75, 75, 64)    |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_conv1 (Conv2D)       | (None, 75, 75, 128)   |     73,856 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_conv2 (Conv2D)       | (None, 75, 75, 128)   |    147,584 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_pool (MaxPooling2D)  | (None, 37, 37, 128)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv1 (Conv2D)       | (None, 37, 37, 256)   |    295,168 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv2 (Conv2D)       | (None, 37, 37, 256)   |    590,080 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv3 (Conv2D)       | (None, 37, 37, 256)   |    590,080 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_pool (MaxPooling2D)  | (None, 18, 18, 256)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv1 (Conv2D)       | (None, 18, 18, 512)   |  1,180,160 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv2 (Conv2D)       | (None, 18, 18, 512)   |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv3 (Conv2D)       | (None, 18, 18, 512)   |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_pool (MaxPooling2D)  | (None, 9, 9, 512)     |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv1 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv2 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv3 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_pool (MaxPooling2D)  | (None, 4, 4, 512)     |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ##  Total params: 14,714,688 (56.13 MB) ##  Trainable params: 0 (0.00 B) ##  Non-trainable params: 14,714,688 (56.13 MB) # create a composite model that includes the base + more layers model <- keras_model_sequential(input_batch_shape = shape(conv_base$input)) |>   conv_base() |>   layer_flatten() |>   layer_dense(units = 256, activation = \"relu\") |>   layer_dense(units = 1, activation = \"sigmoid\")  # compile model |> compile(   loss = \"binary_crossentropy\",   optimizer = optimizer_rmsprop(learning_rate = 2e-5),   metrics = c(\"accuracy\") )  model ## Model: \"sequential\" ## +-----------------------------+-----------------------+------------+-------+ ## | Layer (type)                | Output Shape          |    Param # | Trai… | ## +=============================+=======================+============+=======+ ## | vgg16 (Functional)          | (None, 4, 4, 512)     | 14,714,688 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | flatten (Flatten)           | (None, 8192)          |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | dense_1 (Dense)             | (None, 256)           |  2,097,408 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | dense (Dense)               | (None, 1)             |        257 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ##  Total params: 16,812,353 (64.13 MB) ##  Trainable params: 2,097,665 (8.00 MB) ##  Non-trainable params: 14,714,688 (56.13 MB) print(model, expand_nested = TRUE) ## Model: \"sequential\" ## +-----------------------------+-----------------------+------------+-------+ ## | Layer (type)                | Output Shape          |    Param # | Trai… | ## +=============================+=======================+============+=======+ ## | vgg16 (Functional)          | (None, 4, 4, 512)     | 14,714,688 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > input_layer            | (None, 150, 150, 3)   |          0 |   -   | ## | (InputLayer)                |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block1_conv1 (Conv2D)  | (None, 150, 150, 64)  |      1,792 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block1_conv2 (Conv2D)  | (None, 150, 150, 64)  |     36,928 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block1_pool            | (None, 75, 75, 64)    |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block2_conv1 (Conv2D)  | (None, 75, 75, 128)   |     73,856 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block2_conv2 (Conv2D)  | (None, 75, 75, 128)   |    147,584 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block2_pool            | (None, 37, 37, 128)   |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block3_conv1 (Conv2D)  | (None, 37, 37, 256)   |    295,168 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block3_conv2 (Conv2D)  | (None, 37, 37, 256)   |    590,080 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block3_conv3 (Conv2D)  | (None, 37, 37, 256)   |    590,080 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block3_pool            | (None, 18, 18, 256)   |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block4_conv1 (Conv2D)  | (None, 18, 18, 512)   |  1,180,160 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block4_conv2 (Conv2D)  | (None, 18, 18, 512)   |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block4_conv3 (Conv2D)  | (None, 18, 18, 512)   |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block4_pool            | (None, 9, 9, 512)     |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block5_conv1 (Conv2D)  | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block5_conv2 (Conv2D)  | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block5_conv3 (Conv2D)  | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block5_pool            | (None, 4, 4, 512)     |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## | flatten (Flatten)           | (None, 8192)          |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | dense_1 (Dense)             | (None, 256)           |  2,097,408 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | dense (Dense)               | (None, 1)             |        257 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ##  Total params: 16,812,353 (64.13 MB) ##  Trainable params: 2,097,665 (8.00 MB) ##  Non-trainable params: 14,714,688 (56.13 MB) # unfreeze weights from \"block5_conv1\" on unfreeze_weights(conv_base, from = \"block5_conv1\")  # compile again since we froze or unfroze weights model |> compile(   loss = \"binary_crossentropy\",   optimizer = optimizer_rmsprop(learning_rate = 2e-5),   metrics = c(\"accuracy\") )  conv_base ## Model: \"vgg16\" ## +-----------------------------+-----------------------+------------+-------+ ## | Layer (type)                | Output Shape          |    Param # | Trai… | ## +=============================+=======================+============+=======+ ## | input_layer (InputLayer)    | (None, 150, 150, 3)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_conv1 (Conv2D)       | (None, 150, 150, 64)  |      1,792 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_conv2 (Conv2D)       | (None, 150, 150, 64)  |     36,928 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_pool (MaxPooling2D)  | (None, 75, 75, 64)    |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_conv1 (Conv2D)       | (None, 75, 75, 128)   |     73,856 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_conv2 (Conv2D)       | (None, 75, 75, 128)   |    147,584 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_pool (MaxPooling2D)  | (None, 37, 37, 128)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv1 (Conv2D)       | (None, 37, 37, 256)   |    295,168 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv2 (Conv2D)       | (None, 37, 37, 256)   |    590,080 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv3 (Conv2D)       | (None, 37, 37, 256)   |    590,080 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_pool (MaxPooling2D)  | (None, 18, 18, 256)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv1 (Conv2D)       | (None, 18, 18, 512)   |  1,180,160 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv2 (Conv2D)       | (None, 18, 18, 512)   |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv3 (Conv2D)       | (None, 18, 18, 512)   |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_pool (MaxPooling2D)  | (None, 9, 9, 512)     |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv1 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv2 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv3 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_pool (MaxPooling2D)  | (None, 4, 4, 512)     |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ##  Total params: 14,714,688 (56.13 MB) ##  Trainable params: 7,079,424 (27.01 MB) ##  Non-trainable params: 7,635,264 (29.13 MB) print(model, expand_nested = TRUE) ## Model: \"sequential\" ## +-----------------------------+-----------------------+------------+-------+ ## | Layer (type)                | Output Shape          |    Param # | Trai… | ## +=============================+=======================+============+=======+ ## | vgg16 (Functional)          | (None, 4, 4, 512)     | 14,714,688 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > input_layer            | (None, 150, 150, 3)   |          0 |   -   | ## | (InputLayer)                |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block1_conv1 (Conv2D)  | (None, 150, 150, 64)  |      1,792 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block1_conv2 (Conv2D)  | (None, 150, 150, 64)  |     36,928 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block1_pool            | (None, 75, 75, 64)    |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block2_conv1 (Conv2D)  | (None, 75, 75, 128)   |     73,856 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block2_conv2 (Conv2D)  | (None, 75, 75, 128)   |    147,584 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block2_pool            | (None, 37, 37, 128)   |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block3_conv1 (Conv2D)  | (None, 37, 37, 256)   |    295,168 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block3_conv2 (Conv2D)  | (None, 37, 37, 256)   |    590,080 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block3_conv3 (Conv2D)  | (None, 37, 37, 256)   |    590,080 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block3_pool            | (None, 18, 18, 256)   |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block4_conv1 (Conv2D)  | (None, 18, 18, 512)   |  1,180,160 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block4_conv2 (Conv2D)  | (None, 18, 18, 512)   |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block4_conv3 (Conv2D)  | (None, 18, 18, 512)   |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block4_pool            | (None, 9, 9, 512)     |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block5_conv1 (Conv2D)  | (None, 9, 9, 512)     |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block5_conv2 (Conv2D)  | (None, 9, 9, 512)     |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block5_conv3 (Conv2D)  | (None, 9, 9, 512)     |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## |    > block5_pool            | (None, 4, 4, 512)     |          0 |   -   | ## | (MaxPooling2D)              |                       |            |       | ## +-----------------------------+-----------------------+------------+-------+ ## | flatten (Flatten)           | (None, 8192)          |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | dense_1 (Dense)             | (None, 256)           |  2,097,408 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | dense (Dense)               | (None, 1)             |        257 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ##  Total params: 16,812,353 (64.13 MB) ##  Trainable params: 9,177,089 (35.01 MB) ##  Non-trainable params: 7,635,264 (29.13 MB) # freeze only the last 5 layers freeze_weights(conv_base, from = -5) conv_base ## Model: \"vgg16\" ## +-----------------------------+-----------------------+------------+-------+ ## | Layer (type)                | Output Shape          |    Param # | Trai… | ## +=============================+=======================+============+=======+ ## | input_layer (InputLayer)    | (None, 150, 150, 3)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_conv1 (Conv2D)       | (None, 150, 150, 64)  |      1,792 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_conv2 (Conv2D)       | (None, 150, 150, 64)  |     36,928 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_pool (MaxPooling2D)  | (None, 75, 75, 64)    |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_conv1 (Conv2D)       | (None, 75, 75, 128)   |     73,856 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_conv2 (Conv2D)       | (None, 75, 75, 128)   |    147,584 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_pool (MaxPooling2D)  | (None, 37, 37, 128)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv1 (Conv2D)       | (None, 37, 37, 256)   |    295,168 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv2 (Conv2D)       | (None, 37, 37, 256)   |    590,080 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv3 (Conv2D)       | (None, 37, 37, 256)   |    590,080 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_pool (MaxPooling2D)  | (None, 18, 18, 256)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv1 (Conv2D)       | (None, 18, 18, 512)   |  1,180,160 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv2 (Conv2D)       | (None, 18, 18, 512)   |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv3 (Conv2D)       | (None, 18, 18, 512)   |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_pool (MaxPooling2D)  | (None, 9, 9, 512)     |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv1 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv2 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv3 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_pool (MaxPooling2D)  | (None, 4, 4, 512)     |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ##  Total params: 14,714,688 (56.13 MB) ##  Trainable params: 7,635,264 (29.13 MB) ##  Non-trainable params: 7,079,424 (27.01 MB) # freeze only the last 5 layers, a different way unfreeze_weights(conv_base, to = -6) conv_base ## Model: \"vgg16\" ## +-----------------------------+-----------------------+------------+-------+ ## | Layer (type)                | Output Shape          |    Param # | Trai… | ## +=============================+=======================+============+=======+ ## | input_layer (InputLayer)    | (None, 150, 150, 3)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_conv1 (Conv2D)       | (None, 150, 150, 64)  |      1,792 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_conv2 (Conv2D)       | (None, 150, 150, 64)  |     36,928 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block1_pool (MaxPooling2D)  | (None, 75, 75, 64)    |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_conv1 (Conv2D)       | (None, 75, 75, 128)   |     73,856 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_conv2 (Conv2D)       | (None, 75, 75, 128)   |    147,584 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block2_pool (MaxPooling2D)  | (None, 37, 37, 128)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv1 (Conv2D)       | (None, 37, 37, 256)   |    295,168 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv2 (Conv2D)       | (None, 37, 37, 256)   |    590,080 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_conv3 (Conv2D)       | (None, 37, 37, 256)   |    590,080 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block3_pool (MaxPooling2D)  | (None, 18, 18, 256)   |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv1 (Conv2D)       | (None, 18, 18, 512)   |  1,180,160 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv2 (Conv2D)       | (None, 18, 18, 512)   |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_conv3 (Conv2D)       | (None, 18, 18, 512)   |  2,359,808 |   Y   | ## +-----------------------------+-----------------------+------------+-------+ ## | block4_pool (MaxPooling2D)  | (None, 9, 9, 512)     |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv1 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv2 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_conv3 (Conv2D)       | (None, 9, 9, 512)     |  2,359,808 |   N   | ## +-----------------------------+-----------------------+------------+-------+ ## | block5_pool (MaxPooling2D)  | (None, 4, 4, 512)     |          0 |   -   | ## +-----------------------------+-----------------------+------------+-------+ ##  Total params: 14,714,688 (56.13 MB) ##  Trainable params: 7,635,264 (29.13 MB) ##  Non-trainable params: 7,079,424 (27.01 MB) # Freeze only layers of a certain type, e.g, BatchNorm layers batch_norm_layer_class_name <- class(layer_batch_normalization())[1] is_batch_norm_layer <- function(x) inherits(x, batch_norm_layer_class_name)  model <- application_efficientnet_b0() freeze_weights(model, which = is_batch_norm_layer) # print(model)  # equivalent to: for(layer in model$layers) {   if(is_batch_norm_layer(layer))     layer$trainable <- FALSE   else     layer$trainable <- TRUE }"},{"path":"https://keras.posit.co/reference/get_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer/Model configuration — get_config","title":"Layer/Model configuration — get_config","text":"layer config object returned get_config() contains configuration layer model. layer model can reinstantiated later (without trained weights) configuration using from_config(). config include connectivity information, class name (handled externally).","code":""},{"path":"https://keras.posit.co/reference/get_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer/Model configuration — get_config","text":"","code":"get_config(object)  from_config(config, custom_objects = NULL)"},{"path":"https://keras.posit.co/reference/get_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer/Model configuration — get_config","text":"object Layer model object config Object layer model configuration custom_objects list custom objects needed instantiate layer, e.g., custom layers defined new_layer_class() similar.","code":""},{"path":"https://keras.posit.co/reference/get_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer/Model configuration — get_config","text":"get_config() returns object configuration, from_config() returns re-instantiation object.","code":""},{"path":"https://keras.posit.co/reference/get_config.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Layer/Model configuration — get_config","text":"Objects returned get_config() serializable via RDS. want save restore model across sessions, can use save_model_config() (model configuration , weights) save_model() save model configuration weights filesystem.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/get_custom_objects.html","id":null,"dir":"Reference","previous_headings":"","what":"Get/set the currently registered custom objects. — get_custom_objects","title":"Get/set the currently registered custom objects. — get_custom_objects","text":"Custom objects set using custom_object_scope() added global list custom objects, appear returned list.","code":""},{"path":"https://keras.posit.co/reference/get_custom_objects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get/set the currently registered custom objects. — get_custom_objects","text":"","code":"get_custom_objects()  set_custom_objects(objects = named_list(), clear = TRUE)"},{"path":"https://keras.posit.co/reference/get_custom_objects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get/set the currently registered custom objects. — get_custom_objects","text":"objects named list custom objects, returned get_custom_objects() set_custom_objects(). clear bool, whether clear custom object registry populating objects.","code":""},{"path":"https://keras.posit.co/reference/get_custom_objects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get/set the currently registered custom objects. — get_custom_objects","text":"R named list mapping registered names registered objects. set_custom_objects() returns registry values updating, invisibly.","code":""},{"path":"https://keras.posit.co/reference/get_custom_objects.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Get/set the currently registered custom objects. — get_custom_objects","text":"register_keras_serializable() preferred set_custom_objects() registering new objects.","code":""},{"path":"https://keras.posit.co/reference/get_custom_objects.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get/set the currently registered custom objects. — get_custom_objects","text":"can use set_custom_objects() restore previous registry state.","code":"get_custom_objects() # within a function, if you want to temporarily modify the registry, function() {   orig_objects <- set_custom_objects(clear = TRUE)   on.exit(set_custom_objects(orig_objects))    ## temporarily modify the global registry   # register_keras_serializable(....)   # ....  <do work>   # on.exit(), the previous registry state is restored. }"},{"path":[]},{"path":"https://keras.posit.co/reference/get_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Downloads a file from a URL if it not already in the cache. — get_file","title":"Downloads a file from a URL if it not already in the cache. — get_file","text":"default file url origin downloaded cache_dir ~/.keras, placed cache_subdir datasets, given filename fname. final location file example.txt therefore ~/.keras/datasets/example.txt. Files .tar, .tar.gz, .tar.bz, .zip formats can also extracted. Passing hash verify file download. command line programs shasum sha256sum can compute hash.","code":""},{"path":"https://keras.posit.co/reference/get_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Downloads a file from a URL if it not already in the cache. — get_file","text":"","code":"get_file(   fname = NULL,   origin = NULL,   ...,   file_hash = NULL,   cache_subdir = \"datasets\",   hash_algorithm = \"auto\",   extract = FALSE,   archive_format = \"auto\",   cache_dir = NULL,   force_download = FALSE )"},{"path":"https://keras.posit.co/reference/get_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Downloads a file from a URL if it not already in the cache. — get_file","text":"fname Name file. absolute path, e.g. \"/path//file.txt\" specified, file saved location. NULL, name file origin used. origin Original URL file. ... forward/backward compatability. file_hash expected hash string file download. sha256 md5 hash algorithms supported. cache_subdir Subdirectory Keras cache dir file saved. absolute path, e.g. \"/path//folder\" specified, file saved location. hash_algorithm Select hash algorithm verify file. options \"md5', \"sha256', \"auto'. default 'auto' detects hash algorithm use. extract TRUE tries extracting file Archive, like tar zip. archive_format Archive format try extracting file. Options \"auto', \"tar', \"zip', NULL. \"tar\" includes tar, tar.gz, tar.bz files. default \"auto\" corresponds c(\"tar\", \"zip\"). NULL empty list return matches found. cache_dir Location store cached files, NULL defaults Sys.getenv(\"KERAS_HOME\", \"~/.keras/\"). force_download TRUE, file always re-downloaded regardless cache state.","code":""},{"path":"https://keras.posit.co/reference/get_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Downloads a file from a URL if it not already in the cache. — get_file","text":"Path downloaded file. ** Warning malicious downloads ** Downloading something Internet carries risk. NEVER download file/archive trust source. recommend specify file_hash argument (hash source file known) make sure file getting one expect.","code":""},{"path":"https://keras.posit.co/reference/get_file.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Downloads a file from a URL if it not already in the cache. — get_file","text":"","code":"path_to_downloaded_file <- get_file(     origin = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\",     extract = TRUE )"},{"path":[]},{"path":"https://keras.posit.co/reference/get_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieves a layer based on either its name (unique) or index. — get_layer","title":"Retrieves a layer based on either its name (unique) or index. — get_layer","text":"Indices based order horizontal graph traversal (bottom-) 1-based. name index provided, index take precedence.","code":""},{"path":"https://keras.posit.co/reference/get_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieves a layer based on either its name (unique) or index. — get_layer","text":"","code":"get_layer(object, name = NULL, index = NULL)"},{"path":"https://keras.posit.co/reference/get_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieves a layer based on either its name (unique) or index. — get_layer","text":"object Keras model object name String, name layer. index Integer, index layer (1-based). Also valid negative values, count end model.","code":""},{"path":"https://keras.posit.co/reference/get_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieves a layer based on either its name (unique) or index. — get_layer","text":"layer instance.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/get_registered_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the name registered to an object within the Keras framework. — get_registered_name","title":"Returns the name registered to an object within the Keras framework. — get_registered_name","text":"function part Keras serialization deserialization framework. maps objects string names associated objects serialization/deserialization.","code":""},{"path":"https://keras.posit.co/reference/get_registered_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the name registered to an object within the Keras framework. — get_registered_name","text":"","code":"get_registered_name(obj)"},{"path":"https://keras.posit.co/reference/get_registered_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the name registered to an object within the Keras framework. — get_registered_name","text":"obj object look .","code":""},{"path":"https://keras.posit.co/reference/get_registered_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the name registered to an object within the Keras framework. — get_registered_name","text":"name associated object, default name object registered.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/get_registered_object.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the class associated with name if it is registered with Keras. — get_registered_object","title":"Returns the class associated with name if it is registered with Keras. — get_registered_object","text":"function part Keras serialization deserialization framework. maps strings objects associated serialization/deserialization.","code":""},{"path":"https://keras.posit.co/reference/get_registered_object.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the class associated with name if it is registered with Keras. — get_registered_object","text":"","code":"get_registered_object(name, custom_objects = NULL, module_objects = NULL)"},{"path":"https://keras.posit.co/reference/get_registered_object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the class associated with name if it is registered with Keras. — get_registered_object","text":"name name look . custom_objects named list custom objects look name . Generally, custom_objects provided user. module_objects named list custom objects look name . Generally, module_objects provided midlevel library implementers.","code":""},{"path":"https://keras.posit.co/reference/get_registered_object.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the class associated with name if it is registered with Keras. — get_registered_object","text":"instantiable class associated name, NULL class exists.","code":""},{"path":"https://keras.posit.co/reference/get_registered_object.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the class associated with name if it is registered with Keras. — get_registered_object","text":"","code":"from_config <- function(cls, config, custom_objects = NULL) {   if ('my_custom_object_name' \\%in\\% names(config)) {     config$hidden_cls <- get_registered_object(       config$my_custom_object_name,       custom_objects = custom_objects)   } }"},{"path":[]},{"path":"https://keras.posit.co/reference/get_source_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the list of input tensors necessary to compute tensor. — get_source_inputs","title":"Returns the list of input tensors necessary to compute tensor. — get_source_inputs","text":"Output always list tensors (potentially 1 element).","code":""},{"path":"https://keras.posit.co/reference/get_source_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the list of input tensors necessary to compute tensor. — get_source_inputs","text":"","code":"get_source_inputs(tensor)"},{"path":"https://keras.posit.co/reference/get_source_inputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the list of input tensors necessary to compute tensor. — get_source_inputs","text":"tensor tensor start .","code":""},{"path":"https://keras.posit.co/reference/get_source_inputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the list of input tensors necessary to compute tensor. — get_source_inputs","text":"List input tensors.","code":""},{"path":"https://keras.posit.co/reference/get_source_inputs.html","id":"example","dir":"Reference","previous_headings":"","what":"Example","title":"Returns the list of input tensors necessary to compute tensor. — get_source_inputs","text":"","code":"input <- keras_input(c(3)) output <- input |> layer_dense(4) |> op_multiply(5) reticulate::py_id(get_source_inputs(output)[[1]]) == reticulate::py_id(input) ## [1] TRUE"},{"path":[]},{"path":"https://keras.posit.co/reference/get_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer/Model weights as R arrays — get_weights","title":"Layer/Model weights as R arrays — get_weights","text":"Layer/Model weights R arrays","code":""},{"path":"https://keras.posit.co/reference/get_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer/Model weights as R arrays — get_weights","text":"","code":"get_weights(object, trainable = NA)  set_weights(object, weights)"},{"path":"https://keras.posit.co/reference/get_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer/Model weights as R arrays — get_weights","text":"object Layer model object trainable NA (default), weights returned. TRUE, weights trainable variables returned. FALSE, weights non-trainable variables returned. weights Weights R array","code":""},{"path":"https://keras.posit.co/reference/get_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer/Model weights as R arrays — get_weights","text":"list R arrays.","code":""},{"path":"https://keras.posit.co/reference/get_weights.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Layer/Model weights as R arrays — get_weights","text":"can access Layer/Model KerasVariables (also backend-native tensors like tf.Variable) object$weights, object$trainable_weights, object$non_trainable_weights","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/grapes-py_class-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a python class constructor — %py_class%","title":"Make a python class constructor — %py_class%","text":"Make python class constructor","code":""},{"path":"https://keras.posit.co/reference/grapes-py_class-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a python class constructor — %py_class%","text":"","code":"spec %py_class% body"},{"path":"https://keras.posit.co/reference/grapes-py_class-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a python class constructor — %py_class%","text":"spec bare symbol MyClassName, call MyClassName(SuperClass) body expression can evaluated construct class methods.","code":""},{"path":"https://keras.posit.co/reference/grapes-py_class-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a python class constructor — %py_class%","text":"python class constructor, invisibly. Note, constructor also assigned parent frame.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/grapes-py_class-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a python class constructor — %py_class%","text":"","code":"if (FALSE) { MyClass %py_class% {   initialize <- function(x) {     print(\"Hi from MyClass$initialize()!\")     self$x <- x   }   my_method <- function() {     self$x   } }  my_class_instance <- MyClass(42) my_class_instance$my_method()  MyClass2(MyClass) %py_class% {   \"This will be a __doc__ string for MyClass2\"    initialize <- function(...) {     \"This will be the __doc__ string for the MyClass2.__init__() method\"     print(\"Hi from MyClass2$initialize()!\")     super$initialize(...)   } }  my_class_instance2 <- MyClass2(42) my_class_instance2$my_method()  reticulate::py_help(MyClass2) # see the __doc__ strings and more!  # In addition to `self`, there is also `private` available. # This is an R environment unique to each class instance, where you can # store objects that you don't want converted to Python, but still want # available from methods. You can also assign methods to private, and # `self` and `private` will be available in private methods.  MyClass %py_class% {    initialize <- function(x) {     print(\"Hi from MyClass$initialize()!\")     private$y <- paste(\"A Private field:\", x)   }    get_private_field <- function() {     private$y   }    private$a_private_method <- function() {     cat(\"a_private_method() was called.\\n\")     cat(\"private$y is \", sQuote(private$y), \"\\n\")   }    call_private_method <- function()     private$a_private_method()    # equivalent of @property decorator in python   an_active_property %<-active% function(x = NULL) {     if(!is.null(x)) {       cat(\"`an_active_property` was assigned\", x, \"\\n\")       return(x)     } else {       cat(\"`an_active_property` was accessed\\n\")       return(42)     }   } }  inst1 <- MyClass(1) inst2 <- MyClass(2) inst1$get_private_field() inst2$get_private_field() inst1$call_private_method() inst2$call_private_method() inst1$an_active_property inst1$an_active_property <- 11 }"},{"path":"https://keras.posit.co/reference/grapes-set-active-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Make an Active Binding — %<-active%","title":"Make an Active Binding — %<-active%","text":"Make Active Binding","code":""},{"path":"https://keras.posit.co/reference/grapes-set-active-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make an Active Binding — %<-active%","text":"","code":"sym %<-active% value"},{"path":"https://keras.posit.co/reference/grapes-set-active-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make an Active Binding — %<-active%","text":"sym symbol bind value function call value sym accessed.","code":""},{"path":"https://keras.posit.co/reference/grapes-set-active-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make an Active Binding — %<-active%","text":"value, invisibly","code":""},{"path":"https://keras.posit.co/reference/grapes-set-active-grapes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make an Active Binding — %<-active%","text":"Active bindings defined %py_class% converted @property decorated methods.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/grapes-set-active-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make an Active Binding — %<-active%","text":"","code":"set.seed(1234) x %<-active% function(value) {   message(\"Evaluating function of active binding\")   if(missing(value))     runif(1)   else    message(\"Received: \", value) } x #> Evaluating function of active binding #> [1] 0.1137034 x #> Evaluating function of active binding #> [1] 0.6222994 x <- \"foo\" #> Evaluating function of active binding #> Received: foo x <- \"foo\" #> Evaluating function of active binding #> Received: foo x #> Evaluating function of active binding #> [1] 0.6092747 rm(x) # cleanup"},{"path":"https://keras.posit.co/reference/image_array_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves an image stored as an array to a path or file object. — image_array_save","title":"Saves an image stored as an array to a path or file object. — image_array_save","text":"Saves image stored array path file object.","code":""},{"path":"https://keras.posit.co/reference/image_array_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves an image stored as an array to a path or file object. — image_array_save","text":"","code":"image_array_save(   x,   path,   data_format = NULL,   file_format = NULL,   scale = TRUE,   ... )"},{"path":"https://keras.posit.co/reference/image_array_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves an image stored as an array to a path or file object. — image_array_save","text":"x array. path Path file object. data_format Image data format, either \"channels_first\" \"channels_last\". file_format Optional file format override. omitted, format use determined filename extension. file object used instead filename, parameter always used. scale Whether rescale image values within [0, 255]. ... Additional keyword arguments passed PIL.Image.save().","code":""},{"path":"https://keras.posit.co/reference/image_array_save.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Saves an image stored as an array to a path or file object. — image_array_save","text":"Called primarily side effects. input x returned, invisibly, enable usage pipe.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/image_dataset_from_directory.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates a tf.data.Dataset from image files in a directory. — image_dataset_from_directory","title":"Generates a tf.data.Dataset from image files in a directory. — image_dataset_from_directory","text":"directory structure :   calling image_dataset_from_directory(main_directory, labels = 'inferred') return tf.data.Dataset yields batches images subdirectories class_a class_b, together labels 0 1 (0 corresponding class_a 1 corresponding class_b). Supported image formats: .jpeg, .jpg, .png, .bmp, .gif. Animated gifs truncated first frame.","code":"main_directory/ ...class_a/ ......a_image_1.jpg ......a_image_2.jpg ...class_b/ ......b_image_1.jpg ......b_image_2.jpg"},{"path":"https://keras.posit.co/reference/image_dataset_from_directory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates a tf.data.Dataset from image files in a directory. — image_dataset_from_directory","text":"","code":"image_dataset_from_directory(   directory,   labels = \"inferred\",   label_mode = \"int\",   class_names = NULL,   color_mode = \"rgb\",   batch_size = 32L,   image_size = c(256L, 256L),   shuffle = TRUE,   seed = NULL,   validation_split = NULL,   subset = NULL,   interpolation = \"bilinear\",   follow_links = FALSE,   crop_to_aspect_ratio = FALSE,   pad_to_aspect_ratio = FALSE,   data_format = NULL,   verbose = TRUE )"},{"path":"https://keras.posit.co/reference/image_dataset_from_directory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates a tf.data.Dataset from image files in a directory. — image_dataset_from_directory","text":"directory Directory data located. labels \"inferred\", contain subdirectories, containing images class. Otherwise, directory structure ignored. labels Either \"inferred\" (labels generated directory structure), NULL (labels), list/tuple integer labels size number image files found directory. Labels sorted according alphanumeric order image file paths (obtained via os.walk(directory) Python). label_mode String describing encoding labels. Options : \"int\": means labels encoded integers (e.g. sparse_categorical_crossentropy loss). \"categorical\" means labels encoded categorical vector (e.g. categorical_crossentropy loss). \"binary\" means labels (can 2) encoded float32 scalars values 0 1 (e.g. binary_crossentropy). NULL (labels). class_names valid labels \"inferred\". explicit list class names (must match names subdirectories). Used control order classes (otherwise alphanumerical order used). color_mode One \"grayscale\", \"rgb\", \"rgba\". Defaults \"rgb\". Whether images converted 1, 3, 4 channels. batch_size Size batches data. Defaults 32. NULL, data batched (dataset yield individual samples). image_size Size resize images read disk, specified (height, width). Defaults (256, 256). Since pipeline processes batches images must size, must provided. shuffle Whether shuffle data. Defaults TRUE. set FALSE, sorts data alphanumeric order. seed Optional random seed shuffling transformations. validation_split Optional float 0 1, fraction data reserve validation. subset Subset data return. One \"training\", \"validation\", \"\". used validation_split set. subset = \"\", utility returns tuple two datasets (training validation datasets respectively). interpolation String, interpolation method used resizing images. Defaults \"bilinear\". Supports \"bilinear\", \"nearest\", \"bicubic\", \"area\", \"lanczos3\", \"lanczos5\", \"gaussian\", \"mitchellcubic\". follow_links Whether visit subdirectories pointed symlinks. Defaults FALSE. crop_to_aspect_ratio TRUE, resize images without aspect ratio distortion. original aspect ratio differs target aspect ratio, output image cropped return largest possible window image (size image_size) matches target aspect ratio. default (crop_to_aspect_ratio = FALSE), aspect ratio may preserved. pad_to_aspect_ratio TRUE, resize images without aspect ratio distortion. original aspect ratio differs target aspect ratio, output image padded return largest possible window image (size image_size) matches target aspect ratio. default (pad_to_aspect_ratio=FALSE), aspect ratio may preserved. data_format NULL uses config_image_data_format() otherwise either 'channel_last' 'channel_first'. verbose Whether display number information classes number files found. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/image_dataset_from_directory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates a tf.data.Dataset from image files in a directory. — image_dataset_from_directory","text":"tf.data.Dataset object. label_mode NULL, yields float32 tensors shape (batch_size, image_size[1], image_size[2], num_channels), encoding images (see rules regarding num_channels). Otherwise, yields tuple (images, labels), images shape (batch_size, image_size[1], image_size[2], num_channels), labels follows format described . Rules regarding labels format: label_mode \"int\", labels int32 tensor shape (batch_size,). label_mode \"binary\", labels float32 tensor 1s 0s shape (batch_size, 1). label_mode \"categorical\", labels float32 tensor shape (batch_size, num_classes), representing one-hot encoding class index. Rules regarding number channels yielded images: color_mode \"grayscale\", 1 channel image tensors. color_mode \"rgb\", 3 channels image tensors. color_mode \"rgba\", 4 channels image tensors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/image_from_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts a 3D array to a PIL Image instance. — image_from_array","title":"Converts a 3D array to a PIL Image instance. — image_from_array","text":"Converts 3D array PIL Image instance.","code":""},{"path":"https://keras.posit.co/reference/image_from_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts a 3D array to a PIL Image instance. — image_from_array","text":"","code":"image_from_array(x, data_format = NULL, scale = TRUE, dtype = NULL)"},{"path":"https://keras.posit.co/reference/image_from_array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts a 3D array to a PIL Image instance. — image_from_array","text":"x Input data, form can converted array. data_format Image data format, can either \"channels_first\" \"channels_last\". Defaults NULL, case global setting config_image_data_format() used (unless changed , defaults \"channels_last\"). scale Whether rescale image minimum maximum values 0 255 respectively. Defaults TRUE. dtype Dtype use. NULL means global setting config_floatx() used (unless changed , defaults \"float32\"). Defaults NULL.","code":""},{"path":"https://keras.posit.co/reference/image_from_array.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts a 3D array to a PIL Image instance. — image_from_array","text":"PIL Image instance.","code":""},{"path":"https://keras.posit.co/reference/image_from_array.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts a 3D array to a PIL Image instance. — image_from_array","text":"","code":"img <- array(runif(30000), dim = c(100, 100, 3)) pil_img <- image_from_array(img) pil_img ## <PIL.Image.Image image mode=RGB size=100x100>"},{"path":[]},{"path":"https://keras.posit.co/reference/image_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads an image into PIL format. — image_load","title":"Loads an image into PIL format. — image_load","text":"Loads image PIL format.","code":""},{"path":"https://keras.posit.co/reference/image_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loads an image into PIL format. — image_load","text":"","code":"image_load(   path,   color_mode = \"rgb\",   target_size = NULL,   interpolation = \"nearest\",   keep_aspect_ratio = FALSE )"},{"path":"https://keras.posit.co/reference/image_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loads an image into PIL format. — image_load","text":"path Path image file. color_mode One \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\". desired image format. target_size Either NULL (default original size) tuple ints (img_height, img_width). interpolation Interpolation method used resample image target size different loaded image. Supported methods \"nearest\", \"bilinear\", \"bicubic\". PIL version 1.1.3 newer installed, \"lanczos\" also supported. PIL version 3.4.0 newer installed, \"box\" \"hamming\" also supported. default, \"nearest\" used. keep_aspect_ratio Boolean, whether resize images target size without aspect ratio distortion. image cropped center target aspect ratio resizing.","code":""},{"path":"https://keras.posit.co/reference/image_load.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loads an image into PIL format. — image_load","text":"PIL Image instance.","code":""},{"path":"https://keras.posit.co/reference/image_load.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loads an image into PIL format. — image_load","text":"","code":"image_path <- get_file(origin = \"https://www.r-project.org/logo/Rlogo.png\") (image <- image_load(image_path)) ## <PIL.Image.Image image mode=RGB size=724x561> input_arr <- image_to_array(image) str(input_arr) ##  num [1:561, 1:724, 1:3] 0 0 0 0 0 0 0 0 0 0 ... input_arr %<>% array_reshape(dim = c(1, dim(input_arr))) # Convert single image to a batch. model |> predict(input_arr)"},{"path":[]},{"path":"https://keras.posit.co/reference/image_smart_resize.html","id":null,"dir":"Reference","previous_headings":"","what":"Resize images to a target size without aspect ratio distortion. — image_smart_resize","title":"Resize images to a target size without aspect ratio distortion. — image_smart_resize","text":"Image datasets typically yield images different size. However, images need batched can processed Keras layers. batched, images need share height width. simply , TF (JAX equivalent):   However, , distort aspect ratio images, since general aspect ratio size. fine many cases, always (e.g. image generation models can problem). Note passing argument preserve_aspect_ratio = TRUE tf$image$resize() preserve aspect ratio, cost longer respecting provided target size. calls :   output images actually (200, 200), distorted. Instead, parts image fit within target size get cropped . resizing process : Take largest centered crop image aspect ratio target size. instance, size = c(200, 200) input image size (340, 500), take crop (340, 340) centered along width. Resize cropped image target size. example , resize (340, 340) crop (200, 200).","code":"size <- c(200, 200) ds <- ds$map(\\(img) tf$image$resize(img, size)) size <- c(200, 200) ds <- ds$map(\\(img) image_smart_resize(img, size))"},{"path":"https://keras.posit.co/reference/image_smart_resize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resize images to a target size without aspect ratio distortion. — image_smart_resize","text":"","code":"image_smart_resize(   x,   size,   interpolation = \"bilinear\",   data_format = \"channels_last\",   backend_module = NULL )"},{"path":"https://keras.posit.co/reference/image_smart_resize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resize images to a target size without aspect ratio distortion. — image_smart_resize","text":"x Input image batch images (tensor array). Must format (height, width, channels) (batch_size, height, width, channels). size Tuple (height, width) integer. Target size. interpolation String, interpolation use resizing. Defaults 'bilinear'. Supports bilinear, nearest, bicubic, lanczos3, lanczos5. data_format \"channels_last\" \"channels_first\". backend_module Backend module use (different default backend).","code":""},{"path":"https://keras.posit.co/reference/image_smart_resize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resize images to a target size without aspect ratio distortion. — image_smart_resize","text":"Array shape (size[1], size[2], channels). input image array, output array, backend-native tensor, output backend-native tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/image_to_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts a PIL Image instance to a matrix. — image_to_array","title":"Converts a PIL Image instance to a matrix. — image_to_array","text":"Converts PIL Image instance matrix.","code":""},{"path":"https://keras.posit.co/reference/image_to_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts a PIL Image instance to a matrix. — image_to_array","text":"","code":"image_to_array(img, data_format = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/image_to_array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts a PIL Image instance to a matrix. — image_to_array","text":"img Input PIL Image instance. data_format Image data format, can either \"channels_first\" \"channels_last\". Defaults NULL, case global setting config_image_data_format() used (unless changed , defaults \"channels_last\"). dtype Dtype use. NULL means global setting config_floatx() used (unless changed , defaults \"float32\").","code":""},{"path":"https://keras.posit.co/reference/image_to_array.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts a PIL Image instance to a matrix. — image_to_array","text":"3D array.","code":""},{"path":"https://keras.posit.co/reference/image_to_array.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts a PIL Image instance to a matrix. — image_to_array","text":"","code":"image_path <- get_file(origin = \"https://www.r-project.org/logo/Rlogo.png\") (img <- image_load(image_path)) ## <PIL.Image.Image image mode=RGB size=724x561> array <- image_to_array(img) str(array) ##  num [1:561, 1:724, 1:3] 0 0 0 0 0 0 0 0 0 0 ..."},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_constant.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializer that generates tensors with constant values. — initializer_constant","title":"Initializer that generates tensors with constant values. — initializer_constant","text":"scalar values allowed. constant value provided must convertible dtype requested calling initializer.","code":""},{"path":"https://keras.posit.co/reference/initializer_constant.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializer that generates tensors with constant values. — initializer_constant","text":"","code":"initializer_constant(value = 0)"},{"path":"https://keras.posit.co/reference/initializer_constant.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializer that generates tensors with constant values. — initializer_constant","text":"value numeric scalar.","code":""},{"path":"https://keras.posit.co/reference/initializer_constant.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializer that generates tensors with constant values. — initializer_constant","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_constant.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializer that generates tensors with constant values. — initializer_constant","text":"","code":"# Standalone usage: initializer <- initializer_constant(10) values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_constant(10) layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_glorot_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"The Glorot normal initializer, also called Xavier normal initializer. — initializer_glorot_normal","title":"The Glorot normal initializer, also called Xavier normal initializer. — initializer_glorot_normal","text":"Draws samples truncated normal distribution centered 0 stddev = sqrt(2 / (fan_in + fan_out)) fan_in number input units weight tensor fan_out number output units weight tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_glorot_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Glorot normal initializer, also called Xavier normal initializer. — initializer_glorot_normal","text":"","code":"initializer_glorot_normal(seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_glorot_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Glorot normal initializer, also called Xavier normal initializer. — initializer_glorot_normal","text":"seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_glorot_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Glorot normal initializer, also called Xavier normal initializer. — initializer_glorot_normal","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_glorot_normal.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Glorot normal initializer, also called Xavier normal initializer. — initializer_glorot_normal","text":"","code":"# Standalone usage: initializer <- initializer_glorot_normal() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_glorot_normal() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":"https://keras.posit.co/reference/initializer_glorot_normal.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"The Glorot normal initializer, also called Xavier normal initializer. — initializer_glorot_normal","text":"Glorot et al., 2010","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_glorot_uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"The Glorot uniform initializer, also called Xavier uniform initializer. — initializer_glorot_uniform","title":"The Glorot uniform initializer, also called Xavier uniform initializer. — initializer_glorot_uniform","text":"Draws samples uniform distribution within [-limit, limit], limit = sqrt(6 / (fan_in + fan_out)) (fan_in number input units weight tensor fan_out number output units).","code":""},{"path":"https://keras.posit.co/reference/initializer_glorot_uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Glorot uniform initializer, also called Xavier uniform initializer. — initializer_glorot_uniform","text":"","code":"initializer_glorot_uniform(seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_glorot_uniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Glorot uniform initializer, also called Xavier uniform initializer. — initializer_glorot_uniform","text":"seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_glorot_uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Glorot uniform initializer, also called Xavier uniform initializer. — initializer_glorot_uniform","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_glorot_uniform.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Glorot uniform initializer, also called Xavier uniform initializer. — initializer_glorot_uniform","text":"","code":"# Standalone usage: initializer <- initializer_glorot_uniform() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_glorot_uniform() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":"https://keras.posit.co/reference/initializer_glorot_uniform.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"The Glorot uniform initializer, also called Xavier uniform initializer. — initializer_glorot_uniform","text":"Glorot et al., 2010","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_he_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"He normal initializer. — initializer_he_normal","title":"He normal initializer. — initializer_he_normal","text":"draws samples truncated normal distribution centered 0 stddev = sqrt(2 / fan_in) fan_in number input units weight tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_he_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"He normal initializer. — initializer_he_normal","text":"","code":"initializer_he_normal(seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_he_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"He normal initializer. — initializer_he_normal","text":"seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_he_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"He normal initializer. — initializer_he_normal","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_he_normal.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"He normal initializer. — initializer_he_normal","text":"","code":"# Standalone usage: initializer <- initializer_he_normal() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_he_normal() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":"https://keras.posit.co/reference/initializer_he_normal.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"He normal initializer. — initializer_he_normal","text":"et al., 2015","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_he_uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"He uniform variance scaling initializer. — initializer_he_uniform","title":"He uniform variance scaling initializer. — initializer_he_uniform","text":"Draws samples uniform distribution within [-limit, limit], limit = sqrt(6 / fan_in) (fan_in number input units weight tensor).","code":""},{"path":"https://keras.posit.co/reference/initializer_he_uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"He uniform variance scaling initializer. — initializer_he_uniform","text":"","code":"initializer_he_uniform(seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_he_uniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"He uniform variance scaling initializer. — initializer_he_uniform","text":"seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_he_uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"He uniform variance scaling initializer. — initializer_he_uniform","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_he_uniform.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"He uniform variance scaling initializer. — initializer_he_uniform","text":"","code":"# Standalone usage: initializer <- initializer_he_uniform() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_he_uniform() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":"https://keras.posit.co/reference/initializer_he_uniform.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"He uniform variance scaling initializer. — initializer_he_uniform","text":"et al., 2015","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializer that generates the identity matrix. — initializer_identity","title":"Initializer that generates the identity matrix. — initializer_identity","text":"usable generating 2D matrices.","code":""},{"path":"https://keras.posit.co/reference/initializer_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializer that generates the identity matrix. — initializer_identity","text":"","code":"initializer_identity(gain = 1)"},{"path":"https://keras.posit.co/reference/initializer_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializer that generates the identity matrix. — initializer_identity","text":"gain Multiplicative factor apply identity matrix.","code":""},{"path":"https://keras.posit.co/reference/initializer_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializer that generates the identity matrix. — initializer_identity","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_identity.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializer that generates the identity matrix. — initializer_identity","text":"","code":"# Standalone usage: initializer <- initializer_identity() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_identity() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_lecun_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Lecun normal initializer. — initializer_lecun_normal","title":"Lecun normal initializer. — initializer_lecun_normal","text":"Initializers allow pre-specify initialization strategy, encoded Initializer object, without knowing shape dtype variable initialized. Draws samples truncated normal distribution centered 0 stddev = sqrt(1 / fan_in) fan_in number input units weight tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_lecun_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lecun normal initializer. — initializer_lecun_normal","text":"","code":"initializer_lecun_normal(seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_lecun_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lecun normal initializer. — initializer_lecun_normal","text":"seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_lecun_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lecun normal initializer. — initializer_lecun_normal","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_lecun_normal.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lecun normal initializer. — initializer_lecun_normal","text":"","code":"# Standalone usage: initializer <- initializer_lecun_normal() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_lecun_normal() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":"https://keras.posit.co/reference/initializer_lecun_normal.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Lecun normal initializer. — initializer_lecun_normal","text":"Klambauer et al., 2017","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_lecun_uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"Lecun uniform initializer. — initializer_lecun_uniform","title":"Lecun uniform initializer. — initializer_lecun_uniform","text":"Draws samples uniform distribution within [-limit, limit], limit = sqrt(3 / fan_in) (fan_in number input units weight tensor).","code":""},{"path":"https://keras.posit.co/reference/initializer_lecun_uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lecun uniform initializer. — initializer_lecun_uniform","text":"","code":"initializer_lecun_uniform(seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_lecun_uniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lecun uniform initializer. — initializer_lecun_uniform","text":"seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_lecun_uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lecun uniform initializer. — initializer_lecun_uniform","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_lecun_uniform.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lecun uniform initializer. — initializer_lecun_uniform","text":"","code":"# Standalone usage: initializer <- initializer_lecun_uniform() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_lecun_uniform() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":"https://keras.posit.co/reference/initializer_lecun_uniform.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Lecun uniform initializer. — initializer_lecun_uniform","text":"Klambauer et al., 2017","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_ones.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializer that generates tensors initialized to 1. — initializer_ones","title":"Initializer that generates tensors initialized to 1. — initializer_ones","text":"Also available via shortcut function ones.","code":""},{"path":"https://keras.posit.co/reference/initializer_ones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializer that generates tensors initialized to 1. — initializer_ones","text":"","code":"initializer_ones()"},{"path":"https://keras.posit.co/reference/initializer_ones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializer that generates tensors initialized to 1. — initializer_ones","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_ones.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializer that generates tensors initialized to 1. — initializer_ones","text":"","code":"# Standalone usage: initializer <- initializer_ones() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_ones() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_orthogonal.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializer that generates an orthogonal matrix. — initializer_orthogonal","title":"Initializer that generates an orthogonal matrix. — initializer_orthogonal","text":"shape tensor initialize two-dimensional, initialized orthogonal matrix obtained QR decomposition matrix random numbers drawn normal distribution. matrix fewer rows columns output orthogonal rows. Otherwise, output orthogonal columns. shape tensor initialize two-dimensional, matrix shape (shape[1] * ... * shape[n - 1], shape[n]) initialized, n length shape vector. matrix subsequently reshaped give tensor desired shape.","code":""},{"path":"https://keras.posit.co/reference/initializer_orthogonal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializer that generates an orthogonal matrix. — initializer_orthogonal","text":"","code":"initializer_orthogonal(gain = 1, seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_orthogonal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializer that generates an orthogonal matrix. — initializer_orthogonal","text":"gain Multiplicative factor apply orthogonal matrix. seed integer. Used make behavior initializer deterministic.","code":""},{"path":"https://keras.posit.co/reference/initializer_orthogonal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializer that generates an orthogonal matrix. — initializer_orthogonal","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_orthogonal.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializer that generates an orthogonal matrix. — initializer_orthogonal","text":"","code":"# Standalone usage: initializer <- initializer_orthogonal() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_orthogonal() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":"https://keras.posit.co/reference/initializer_orthogonal.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Initializer that generates an orthogonal matrix. — initializer_orthogonal","text":"Saxe et al., 2014","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_random_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Random normal initializer. — initializer_random_normal","title":"Random normal initializer. — initializer_random_normal","text":"Draws samples normal distribution given parameters.","code":""},{"path":"https://keras.posit.co/reference/initializer_random_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random normal initializer. — initializer_random_normal","text":"","code":"initializer_random_normal(mean = 0, stddev = 0.05, seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_random_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random normal initializer. — initializer_random_normal","text":"mean numeric scalar. Mean random values generate. stddev numeric scalar. Standard deviation random values generate. seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_random_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random normal initializer. — initializer_random_normal","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_random_normal.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random normal initializer. — initializer_random_normal","text":"","code":"# Standalone usage: initializer <- initializer_random_normal(mean = 0.0, stddev = 1.0) values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_random_normal(mean = 0.0, stddev = 1.0) layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_random_uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"Random uniform initializer. — initializer_random_uniform","title":"Random uniform initializer. — initializer_random_uniform","text":"Draws samples uniform distribution given parameters.","code":""},{"path":"https://keras.posit.co/reference/initializer_random_uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random uniform initializer. — initializer_random_uniform","text":"","code":"initializer_random_uniform(minval = -0.05, maxval = 0.05, seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_random_uniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random uniform initializer. — initializer_random_uniform","text":"minval numeric scalar scalar keras tensor. Lower bound range random values generate (inclusive). maxval numeric scalar scalar keras tensor. Upper bound range random values generate (exclusive). seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_random_uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random uniform initializer. — initializer_random_uniform","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_random_uniform.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random uniform initializer. — initializer_random_uniform","text":"","code":"# Standalone usage: initializer <- initializer_random_uniform(minval = 0.0, maxval = 1.0) values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_random_uniform(minval = 0.0, maxval = 1.0) layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_truncated_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializer that generates a truncated normal distribution. — initializer_truncated_normal","title":"Initializer that generates a truncated normal distribution. — initializer_truncated_normal","text":"values generated similar values RandomNormal initializer, except values two standard deviations mean discarded re-drawn.","code":""},{"path":"https://keras.posit.co/reference/initializer_truncated_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializer that generates a truncated normal distribution. — initializer_truncated_normal","text":"","code":"initializer_truncated_normal(mean = 0, stddev = 0.05, seed = NULL)"},{"path":"https://keras.posit.co/reference/initializer_truncated_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializer that generates a truncated normal distribution. — initializer_truncated_normal","text":"mean numeric scalar. Mean random values generate. stddev numeric scalar. Standard deviation random values generate. seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_truncated_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializer that generates a truncated normal distribution. — initializer_truncated_normal","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_truncated_normal.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializer that generates a truncated normal distribution. — initializer_truncated_normal","text":"","code":"# Standalone usage: initializer <- initializer_truncated_normal(mean = 0, stddev = 1) values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_truncated_normal(mean = 0, stddev = 1) layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_variance_scaling.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializer that adapts its scale to the shape of its input tensors. — initializer_variance_scaling","title":"Initializer that adapts its scale to the shape of its input tensors. — initializer_variance_scaling","text":"distribution = \"truncated_normal\" \"untruncated_normal\", samples drawn truncated/untruncated normal distribution mean zero standard deviation (truncation, used) stddev = sqrt(scale / n), n : number input units weight tensor, mode = \"fan_in\" number output units, mode = \"fan_out\" average numbers input output units, mode = \"fan_avg\" distribution = \"uniform\", samples drawn uniform distribution within [-limit, limit], limit = sqrt(3 * scale / n).","code":""},{"path":"https://keras.posit.co/reference/initializer_variance_scaling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializer that adapts its scale to the shape of its input tensors. — initializer_variance_scaling","text":"","code":"initializer_variance_scaling(   scale = 1,   mode = \"fan_in\",   distribution = \"truncated_normal\",   seed = NULL )"},{"path":"https://keras.posit.co/reference/initializer_variance_scaling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializer that adapts its scale to the shape of its input tensors. — initializer_variance_scaling","text":"scale Scaling factor (positive float). mode One \"fan_in\", \"fan_out\", \"fan_avg\". distribution Random distribution use. One \"truncated_normal\", \"untruncated_normal\", \"uniform\". seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/initializer_variance_scaling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializer that adapts its scale to the shape of its input tensors. — initializer_variance_scaling","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_variance_scaling.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializer that adapts its scale to the shape of its input tensors. — initializer_variance_scaling","text":"","code":"# Standalone usage: initializer <- initializer_variance_scaling(scale = 0.1, mode = 'fan_in',                                             distribution = 'uniform') values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_variance_scaling(scale = 0.1, mode = 'fan_in',                                             distribution = 'uniform') layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":[]},{"path":"https://keras.posit.co/reference/initializer_zeros.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializer that generates tensors initialized to 0. — initializer_zeros","title":"Initializer that generates tensors initialized to 0. — initializer_zeros","text":"Initializer generates tensors initialized 0.","code":""},{"path":"https://keras.posit.co/reference/initializer_zeros.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializer that generates tensors initialized to 0. — initializer_zeros","text":"","code":"initializer_zeros()"},{"path":"https://keras.posit.co/reference/initializer_zeros.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializer that generates tensors initialized to 0. — initializer_zeros","text":"Initializer instance can passed layer variable constructors, called directly shape return Tensor.","code":""},{"path":"https://keras.posit.co/reference/initializer_zeros.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initializer that generates tensors initialized to 0. — initializer_zeros","text":"","code":"# Standalone usage: initializer <- initializer_zeros() values <- initializer(shape = c(2, 2)) # Usage in a Keras layer: initializer <- initializer_zeros() layer <- layer_dense(units = 3, kernel_initializer = initializer)"},{"path":[]},{"path":"https://keras.posit.co/reference/install_keras.html","id":null,"dir":"Reference","previous_headings":"","what":"Install Keras — install_keras","title":"Install Keras — install_keras","text":"function install Keras along selected backend, including Python dependencies.","code":""},{"path":"https://keras.posit.co/reference/install_keras.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install Keras — install_keras","text":"","code":"install_keras(   envname = \"r-keras\",   ...,   extra_packages = c(\"scipy\", \"pandas\", \"Pillow\", \"pydot\", \"ipython\",     \"tensorflow_datasets\"),   python_version = \">=3.9,<=3.11\",   backend = c(\"tensorflow\", \"jax\"),   gpu = NA,   restart_session = TRUE )"},{"path":"https://keras.posit.co/reference/install_keras.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install Keras — install_keras","text":"envname Name path Python virtual environment ... reserved future compatability. extra_packages Additional Python packages install alongside Keras python_version Passed reticulate::virtualenv_starter() backend backend(s) install. Accepted values include \"tensorflow\", \"jax\" \"pytorch\" gpu whether install GPU capable version backend. restart_session Whether restart R session installing (note occur within RStudio).","code":""},{"path":"https://keras.posit.co/reference/install_keras.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Install Keras — install_keras","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/keras.html","id":null,"dir":"Reference","previous_headings":"","what":"Main Keras module — keras","title":"Main Keras module — keras","text":"keras module object equivalent reticulate::import(\"keras\") provided mainly convenience.","code":""},{"path":"https://keras.posit.co/reference/keras.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Main Keras module — keras","text":"object class python.builtin.module","code":""},{"path":"https://keras.posit.co/reference/keras.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Main Keras module — keras","text":"keras Python module","code":""},{"path":"https://keras.posit.co/reference/keras3-package.html","id":null,"dir":"Reference","previous_headings":"","what":"keras3: R Interface to 'Keras' — keras3-package","title":"keras3: R Interface to 'Keras' — keras3-package","text":"Interface 'Keras' https://keras.io, high-level neural networks API. 'Keras' developed focus enabling fast experimentation, supports convolution based networks recurrent networks (well combinations two), runs seamlessly CPU GPU devices. Keras high-level neural networks API, developed focus enabling fast experimentation. Keras following key features:","code":""},{"path":"https://keras.posit.co/reference/keras3-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"keras3: R Interface to 'Keras' — keras3-package","text":"Allows code run CPU GPU, seamlessly. User-friendly API makes easy quickly prototype deep learning models. Built-support convolutional networks (computer vision), recurrent networks (sequence processing), combination . Supports arbitrary network architectures: multi-input multi-output models, layer sharing, model sharing, etc. means Keras appropriate building essentially deep learning model, memory network neural Turing machine. capable running top multiple back-ends including TensorFlow, Jax, PyTorch. See package website https://keras.posit.co complete documentation.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/keras3-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"keras3: R Interface to 'Keras' — keras3-package","text":"Maintainer: Tomasz Kalinowski tomasz@posit.co [copyright holder] Authors: JJ Allaire [copyright holder] François Chollet [copyright holder] contributors: Daniel Falbel daniel@posit.co [contributor, copyright holder] Posit Software, PBC [copyright holder, funder] Google [copyright holder, funder] Yuan Tang terrytangyuan@gmail.com (ORCID) [contributor, copyright holder] Wouter Van Der Bijl [contributor, copyright holder] Martin Studer [contributor, copyright holder] Sigrid Keydana [contributor]","code":""},{"path":"https://keras.posit.co/reference/keras_input.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Keras tensor (Functional API input). — keras_input","title":"Create a Keras tensor (Functional API input). — keras_input","text":"Keras tensor symbolic tensor-like object, augment certain attributes allow us build Keras model just knowing inputs outputs model. instance, , b c Keras tensors, becomes possible : model <- keras_model(input = c(, b), output = c)","code":""},{"path":"https://keras.posit.co/reference/keras_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Keras tensor (Functional API input). — keras_input","text":"","code":"keras_input(   shape = NULL,   batch_size = NULL,   dtype = NULL,   sparse = NULL,   batch_shape = NULL,   name = NULL,   tensor = NULL )"},{"path":"https://keras.posit.co/reference/keras_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Keras tensor (Functional API input). — keras_input","text":"shape shape list (list integers NULL objects), including batch size. instance, shape = c(32) indicates expected input batches 32-dimensional vectors. Elements list can NULL NA; NULL/NA elements represent dimensions shape known may vary (e.g. sequence length). batch_size Optional static batch size (integer). dtype data type expected input, string (e.g. \"float32\", \"int32\"...) sparse boolean specifying whether expected input sparse tensors. Note , sparse FALSE, sparse tensors can still passed input - densified default value 0. feature supported TensorFlow backend. Defaults FALSE. batch_shape Shape, including batch dim. name Optional name string layer. unique model (reuse name twice). autogenerated provided. tensor Optional existing tensor wrap Input layer. set, layer use tensor rather creating new placeholder tensor.","code":""},{"path":"https://keras.posit.co/reference/keras_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Keras tensor (Functional API input). — keras_input","text":"Keras tensor, can passed inputs argument (keras_model()).","code":""},{"path":"https://keras.posit.co/reference/keras_input.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Keras tensor (Functional API input). — keras_input","text":"","code":"# This is a logistic regression in Keras input <- layer_input(shape=c(32)) output <- input |> layer_dense(16, activation='softmax') model <- keras_model(input, output)"},{"path":[]},{"path":"https://keras.posit.co/reference/keras_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Keras Model (Functional API) — keras_model","title":"Keras Model (Functional API) — keras_model","text":"model directed acyclic graph layers.","code":""},{"path":"https://keras.posit.co/reference/keras_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Keras Model (Functional API) — keras_model","text":"","code":"keras_model(inputs = NULL, outputs = NULL, ...)"},{"path":"https://keras.posit.co/reference/keras_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Keras Model (Functional API) — keras_model","text":"inputs Input tensor(s) (keras_input()) outputs Output tensors (calling layers inputs) ... additional arguments","code":""},{"path":"https://keras.posit.co/reference/keras_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Keras Model (Functional API) — keras_model","text":"Model instance.","code":""},{"path":"https://keras.posit.co/reference/keras_model.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Keras Model (Functional API) — keras_model","text":"","code":"library(keras3)  # input tensor inputs <- keras_input(shape = c(784))  # outputs compose input + dense layers predictions <- inputs |>   layer_dense(units = 64, activation = 'relu') |>   layer_dense(units = 64, activation = 'relu') |>   layer_dense(units = 10, activation = 'softmax')  # create and compile model model <- keras_model(inputs = inputs, outputs = predictions) model |> compile(   optimizer = 'rmsprop',   loss = 'categorical_crossentropy',   metrics = c('accuracy') )"},{"path":[]},{"path":"https://keras.posit.co/reference/keras_model_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Keras Model composed of a linear stack of layers — keras_model_sequential","title":"Keras Model composed of a linear stack of layers — keras_model_sequential","text":"Keras Model composed linear stack layers","code":""},{"path":"https://keras.posit.co/reference/keras_model_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Keras Model composed of a linear stack of layers — keras_model_sequential","text":"","code":"keras_model_sequential(   input_shape = NULL,   name = NULL,   ...,   input_dtype = NULL,   input_batch_size = NULL,   input_sparse = NULL,   input_batch_shape = NULL,   input_name = NULL,   input_tensor = NULL,   trainable = TRUE,   layers = list() )"},{"path":"https://keras.posit.co/reference/keras_model_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Keras Model composed of a linear stack of layers — keras_model_sequential","text":"input_shape shape integer vector, including batch size. instance, shape=c(32) indicates expected input batches 32-dimensional vectors. Elements shape can NA; NA elements represent dimensions shape known may vary (e.g. sequence length). name Name model ... additional arguments passed keras.layers.InputLayer. input_dtype data type expected input, string (e.g. \"float32\", \"int32\"...) input_batch_size Optional static batch size (integer). input_sparse boolean specifying whether expected input sparse tensors. Note , sparse FALSE, sparse tensors can still passed input - densified default value 0. feature supported TensorFlow backend. Defaults FALSE. input_batch_shape optional way specify batch_size input_shape one argument. input_name Optional name string input layer. unique model (reuse name twice). autogenerated provided. input_tensor Optional existing tensor wrap InputLayer. set, layer use tensor rather creating new placeholder tensor. trainable Boolean, whether model's variables trainable. can also change trainable status model/layer freeze_weights() unfreeze_weights(). layers List layers add model.","code":""},{"path":"https://keras.posit.co/reference/keras_model_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Keras Model composed of a linear stack of layers — keras_model_sequential","text":"Sequential model instance.","code":""},{"path":"https://keras.posit.co/reference/keras_model_sequential.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Keras Model composed of a linear stack of layers — keras_model_sequential","text":"input_shape omitted, model layer shapes, including final model output shape, known model built, either calling model input tensor/array like model(input), (possibly via fit()/evaluate()/predict()), explicitly calling model$build(input_shape).","code":""},{"path":"https://keras.posit.co/reference/keras_model_sequential.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Keras Model composed of a linear stack of layers — keras_model_sequential","text":"","code":"model <- keras_model_sequential(input_shape = c(784)) model |>   layer_dense(units = 32) |>   layer_activation('relu') |>   layer_dense(units = 10) |>   layer_activation('softmax')  model |> compile(   optimizer = 'rmsprop',   loss = 'categorical_crossentropy',   metrics = c('accuracy') )  model ## Model: \"sequential\" ## +---------------------------------+------------------------+---------------+ ## | Layer (type)                    | Output Shape           |       Param # | ## +=================================+========================+===============+ ## | dense_1 (Dense)                 | (None, 32)             |        25,120 | ## +---------------------------------+------------------------+---------------+ ## | activation_1 (Activation)       | (None, 32)             |             0 | ## +---------------------------------+------------------------+---------------+ ## | dense (Dense)                   | (None, 10)             |           330 | ## +---------------------------------+------------------------+---------------+ ## | activation (Activation)         | (None, 10)             |             0 | ## +---------------------------------+------------------------+---------------+ ##  Total params: 25,450 (99.41 KB) ##  Trainable params: 25,450 (99.41 KB) ##  Non-trainable params: 0 (0.00 B)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_activation.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies an activation function to an output. — layer_activation","title":"Applies an activation function to an output. — layer_activation","text":"Applies activation function output.","code":""},{"path":"https://keras.posit.co/reference/layer_activation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies an activation function to an output. — layer_activation","text":"","code":"layer_activation(object, activation, ...)"},{"path":"https://keras.posit.co/reference/layer_activation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies an activation function to an output. — layer_activation","text":"object Object compose layer . tensor, array, sequential model. activation Activation function. callable, name activation keras3::activation_* namespace. ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_activation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Applies an activation function to an output. — layer_activation","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_activation.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies an activation function to an output. — layer_activation","text":"","code":"x <- array(c(-3, -1, 0, 2)) layer <- layer_activation(activation = 'relu') layer(x) ## tf.Tensor([0. 0. 0. 2.], shape=(4), dtype=float32) layer <- layer_activation(activation = activation_relu) layer(x) ## tf.Tensor([0. 0. 0. 2.], shape=(4), dtype=float32) layer <- layer_activation(activation = op_relu) layer(x) ## tf.Tensor([0. 0. 0. 2.], shape=(4), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_activation_elu.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies an Exponential Linear Unit function to an output. — layer_activation_elu","title":"Applies an Exponential Linear Unit function to an output. — layer_activation_elu","text":"Formula:","code":"f(x) = alpha * (exp(x) - 1.) for x < 0 f(x) = x for x >= 0"},{"path":"https://keras.posit.co/reference/layer_activation_elu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies an Exponential Linear Unit function to an output. — layer_activation_elu","text":"","code":"layer_activation_elu(object, alpha = 1, ...)"},{"path":"https://keras.posit.co/reference/layer_activation_elu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies an Exponential Linear Unit function to an output. — layer_activation_elu","text":"object Object compose layer . tensor, array, sequential model. alpha float, slope negative section. Defaults 1.0. ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_activation_elu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Applies an Exponential Linear Unit function to an output. — layer_activation_elu","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_activation_leaky_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaky version of a Rectified Linear Unit activation layer. — layer_activation_leaky_relu","title":"Leaky version of a Rectified Linear Unit activation layer. — layer_activation_leaky_relu","text":"layer allows small gradient unit active. Formula:","code":"f <- function(x) ifelse(x >= 0, x, alpha * x)"},{"path":"https://keras.posit.co/reference/layer_activation_leaky_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leaky version of a Rectified Linear Unit activation layer. — layer_activation_leaky_relu","text":"","code":"layer_activation_leaky_relu(object, negative_slope = 0.3, ...)"},{"path":"https://keras.posit.co/reference/layer_activation_leaky_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leaky version of a Rectified Linear Unit activation layer. — layer_activation_leaky_relu","text":"object Object compose layer . tensor, array, sequential model. negative_slope Float >= 0.0. Negative slope coefficient. Defaults 0.3. ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_activation_leaky_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leaky version of a Rectified Linear Unit activation layer. — layer_activation_leaky_relu","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_activation_leaky_relu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leaky version of a Rectified Linear Unit activation layer. — layer_activation_leaky_relu","text":"","code":"leaky_relu_layer <- layer_activation_leaky_relu(negative_slope=0.5) input <- array(c(-10, -5, 0.0, 5, 10)) result <- leaky_relu_layer(input) as.array(result) ## [1] -5.0 -2.5  0.0  5.0 10.0"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_activation_parametric_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Rectified Linear Unit activation layer. — layer_activation_parametric_relu","title":"Parametric Rectified Linear Unit activation layer. — layer_activation_parametric_relu","text":"Formula:   alpha learned array shape x.","code":"f <- function(x) ifelse(x >= 0, x, alpha * x)"},{"path":"https://keras.posit.co/reference/layer_activation_parametric_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric Rectified Linear Unit activation layer. — layer_activation_parametric_relu","text":"","code":"layer_activation_parametric_relu(   object,   alpha_initializer = \"Zeros\",   alpha_regularizer = NULL,   alpha_constraint = NULL,   shared_axes = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_activation_parametric_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric Rectified Linear Unit activation layer. — layer_activation_parametric_relu","text":"object Object compose layer . tensor, array, sequential model. alpha_initializer Initializer function weights. alpha_regularizer Regularizer weights. alpha_constraint Constraint weights. shared_axes axes along share learnable parameters activation function. example, incoming feature maps 2D convolution output shape (batch, height, width, channels), wish share parameters across space filter one set parameters, set shared_axes=[1, 2]. ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_activation_parametric_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parametric Rectified Linear Unit activation layer. — layer_activation_parametric_relu","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_activation_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Rectified Linear Unit activation function layer. — layer_activation_relu","title":"Rectified Linear Unit activation function layer. — layer_activation_relu","text":"Formula:","code":"f <- function(x, max_value = Inf, negative_slope = 0, threshold = 0) {  x <- max(x,0)  if (x >= max_value)    max_value  else if (threshold <= x && x < max_value)    x  else    negative_slope * (x - threshold) }"},{"path":"https://keras.posit.co/reference/layer_activation_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rectified Linear Unit activation function layer. — layer_activation_relu","text":"","code":"layer_activation_relu(   object,   max_value = NULL,   negative_slope = 0,   threshold = 0,   ... )"},{"path":"https://keras.posit.co/reference/layer_activation_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rectified Linear Unit activation function layer. — layer_activation_relu","text":"object Object compose layer . tensor, array, sequential model. max_value Float >= 0. Maximum activation value. NULL means unlimited. Defaults NULL. negative_slope Float >= 0. Negative slope coefficient. Defaults 0.0. threshold Float >= 0. Threshold value thresholded activation. Defaults 0.0. ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_activation_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rectified Linear Unit activation function layer. — layer_activation_relu","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_activation_relu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rectified Linear Unit activation function layer. — layer_activation_relu","text":"","code":"relu_layer <- layer_activation_relu(max_value = 10,                                     negative_slope = 0.5,                                     threshold = 0) input <- array(c(-10, -5, 0.0, 5, 10)) result <- relu_layer(input) as.array(result) ## [1] -5.0 -2.5  0.0  5.0 10.0"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_activation_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax activation layer. — layer_activation_softmax","title":"Softmax activation layer. — layer_activation_softmax","text":"Formula:","code":"exp_x = exp(x - max(x)) f(x) = exp_x / sum(exp_x)"},{"path":"https://keras.posit.co/reference/layer_activation_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax activation layer. — layer_activation_softmax","text":"","code":"layer_activation_softmax(object, axis = -1L, ...)"},{"path":"https://keras.posit.co/reference/layer_activation_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax activation layer. — layer_activation_softmax","text":"object Object compose layer . tensor, array, sequential model. axis Integer, list Integers, axis along softmax normalization applied. ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_activation_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax activation layer. — layer_activation_softmax","text":"Softmaxed output shape inputs.","code":""},{"path":"https://keras.posit.co/reference/layer_activation_softmax.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax activation layer. — layer_activation_softmax","text":"","code":"softmax_layer <- layer_activation_softmax() input <- op_array(c(1, 2, 1)) softmax_layer(input) ## tf.Tensor([0.21194157 0.5761169  0.21194157], shape=(3), dtype=float32)"},{"path":"https://keras.posit.co/reference/layer_activation_softmax.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Softmax activation layer. — layer_activation_softmax","text":"inputs: inputs (logits) softmax layer. mask: boolean mask shape inputs. mask specifies 1 keep 0 mask. Defaults NULL.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_activity_regularization.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer that applies an update to the cost function based input activity. — layer_activity_regularization","title":"Layer that applies an update to the cost function based input activity. — layer_activity_regularization","text":"Layer applies update cost function based input activity.","code":""},{"path":"https://keras.posit.co/reference/layer_activity_regularization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer that applies an update to the cost function based input activity. — layer_activity_regularization","text":"","code":"layer_activity_regularization(object, l1 = 0, l2 = 0, ...)"},{"path":"https://keras.posit.co/reference/layer_activity_regularization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer that applies an update to the cost function based input activity. — layer_activity_regularization","text":"object Object compose layer . tensor, array, sequential model. l1 L1 regularization factor (positive float). l2 L2 regularization factor (positive float). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_activity_regularization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer that applies an update to the cost function based input activity. — layer_activity_regularization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_activity_regularization.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Layer that applies an update to the cost function based input activity. — layer_activity_regularization","text":"Arbitrary. Use keyword argument input_shape (tuple integers, include samples axis) using layer first layer model.","code":""},{"path":"https://keras.posit.co/reference/layer_activity_regularization.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Layer that applies an update to the cost function based input activity. — layer_activity_regularization","text":"shape input.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_add.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs elementwise addition operation. — layer_add","title":"Performs elementwise addition operation. — layer_add","text":"takes input list tensors, shape, returns single tensor (also shape).","code":""},{"path":"https://keras.posit.co/reference/layer_add.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs elementwise addition operation. — layer_add","text":"","code":"layer_add(inputs, ...)"},{"path":"https://keras.posit.co/reference/layer_add.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs elementwise addition operation. — layer_add","text":"inputs layers combine ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_add.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs elementwise addition operation. — layer_add","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_add.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs elementwise addition operation. — layer_add","text":"Usage Keras model:","code":"input_shape <- c(1, 2, 3) x1 <- op_ones(input_shape) x2 <- op_ones(input_shape) layer_add(x1, x2) ## tf.Tensor( ## [[[2. 2. 2.] ##   [2. 2. 2.]]], shape=(1, 2, 3), dtype=float32) input1 <- layer_input(shape = c(16)) x1 <- input1 |> layer_dense(8, activation = 'relu')  input2 <- layer_input(shape = c(32)) x2 <- input2 |> layer_dense(8, activation = 'relu')  # equivalent to `added = layer_add([x1, x2))` added <- layer_add(x1, x2) output <- added |> layer_dense(4)  model <- keras_model(inputs = c(input1, input2), outputs = output)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_additive_attention.html","id":null,"dir":"Reference","previous_headings":"","what":"Additive attention layer, a.k.a. Bahdanau-style attention. — layer_additive_attention","title":"Additive attention layer, a.k.a. Bahdanau-style attention. — layer_additive_attention","text":"Inputs list 2 3 elements: query tensor shape (batch_size, Tq, dim). value tensor shape (batch_size, Tv, dim). optional key tensor shape (batch_size, Tv, dim). none supplied, value used key. calculation follows steps: Calculate attention scores using query key shape (batch_size, Tq, Tv) non-linear sum scores = reduce_sum(tanh(query + key), axis=-1). Use scores calculate softmax distribution shape (batch_size, Tq, Tv). Use softmax distribution create linear combination value shape (batch_size, Tq, dim).","code":""},{"path":"https://keras.posit.co/reference/layer_additive_attention.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Additive attention layer, a.k.a. Bahdanau-style attention. — layer_additive_attention","text":"","code":"layer_additive_attention(object, use_scale = TRUE, dropout = 0, ...)"},{"path":"https://keras.posit.co/reference/layer_additive_attention.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Additive attention layer, a.k.a. Bahdanau-style attention. — layer_additive_attention","text":"object Object compose layer . tensor, array, sequential model. use_scale TRUE, create scalar variable scale attention scores. dropout Float 0 1. Fraction units drop attention scores. Defaults 0.0. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_additive_attention.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Additive attention layer, a.k.a. Bahdanau-style attention. — layer_additive_attention","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_additive_attention.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Additive attention layer, a.k.a. Bahdanau-style attention. — layer_additive_attention","text":"inputs: List following tensors: query: Query tensor shape (batch_size, Tq, dim). value: Value tensor shape (batch_size, Tv, dim). key: Optional key tensor shape (batch_size, Tv, dim). given, use value key value, common case. mask: List following tensors: query_mask: boolean mask tensor shape (batch_size, Tq). given, output zero positions mask==FALSE. value_mask: boolean mask tensor shape (batch_size, Tv). given, apply mask values positions mask==FALSE contribute result. return_attention_scores: bool, TRUE, returns attention scores (masking softmax) additional output argument. training: Python boolean indicating whether layer behave training mode (adding dropout) inference mode (dropout). use_causal_mask: Boolean. Set TRUE decoder self-attention. Adds mask position attend positions j > . prevents flow information future towards past. Defaults FALSE.","code":""},{"path":"https://keras.posit.co/reference/layer_additive_attention.html","id":"output","dir":"Reference","previous_headings":"","what":"Output","title":"Additive attention layer, a.k.a. Bahdanau-style attention. — layer_additive_attention","text":"Attention outputs shape (batch_size, Tq, dim). (Optional) Attention scores masking softmax shape (batch_size, Tq, Tv).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_alpha_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies Alpha Dropout to the input. — layer_alpha_dropout","title":"Applies Alpha Dropout to the input. — layer_alpha_dropout","text":"Alpha Dropout Dropout keeps mean variance inputs original values, order ensure self-normalizing property even dropout. Alpha Dropout fits well Scaled Exponential Linear Units (SELU) randomly setting activations negative saturation value.","code":""},{"path":"https://keras.posit.co/reference/layer_alpha_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies Alpha Dropout to the input. — layer_alpha_dropout","text":"","code":"layer_alpha_dropout(object, rate, noise_shape = NULL, seed = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_alpha_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies Alpha Dropout to the input. — layer_alpha_dropout","text":"object Object compose layer . tensor, array, sequential model. rate Float 0 1. multiplicative noise standard deviation sqrt(rate / (1 - rate)). noise_shape 1D integer tensor representing shape binary alpha dropout mask multiplied input. instance, inputs shape (batch_size, timesteps, features) want alpha dropout mask timesteps, can use noise_shape = (batch_size, 1, features). seed integer use random seed. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_alpha_dropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Applies Alpha Dropout to the input. — layer_alpha_dropout","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_alpha_dropout.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Applies Alpha Dropout to the input. — layer_alpha_dropout","text":"inputs: Input tensor (rank). training: R boolean indicating whether layer behave training mode (adding alpha dropout) inference mode (nothing).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_attention.html","id":null,"dir":"Reference","previous_headings":"","what":"Dot-product attention layer, a.k.a. Luong-style attention. — layer_attention","title":"Dot-product attention layer, a.k.a. Luong-style attention. — layer_attention","text":"Inputs list 2 3 elements: query tensor shape (batch_size, Tq, dim). value tensor shape (batch_size, Tv, dim). optional key tensor shape (batch_size, Tv, dim). none supplied, value used key. calculation follows steps: Calculate attention scores using query key shape (batch_size, Tq, Tv). Use scores calculate softmax distribution shape (batch_size, Tq, Tv). Use softmax distribution create linear combination value shape (batch_size, Tq, dim).","code":""},{"path":"https://keras.posit.co/reference/layer_attention.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dot-product attention layer, a.k.a. Luong-style attention. — layer_attention","text":"","code":"layer_attention(   object,   use_scale = FALSE,   score_mode = \"dot\",   dropout = 0,   seed = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_attention.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dot-product attention layer, a.k.a. Luong-style attention. — layer_attention","text":"object Object compose layer . tensor, array, sequential model. use_scale TRUE, create scalar variable scale attention scores. score_mode Function use compute attention scores, one {\"dot\", \"concat\"}. \"dot\" refers dot product query key vectors. \"concat\" refers hyperbolic tangent concatenation query key vectors. dropout Float 0 1. Fraction units drop attention scores. Defaults 0.0. seed integer use random seed incase dropout. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_attention.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dot-product attention layer, a.k.a. Luong-style attention. — layer_attention","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_attention.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Dot-product attention layer, a.k.a. Luong-style attention. — layer_attention","text":"inputs: List following tensors: query: Query tensor shape (batch_size, Tq, dim). value: Value tensor shape (batch_size, Tv, dim). key: Optional key tensor shape (batch_size, Tv, dim). given, use value key value, common case. mask: List following tensors: query_mask: boolean mask tensor shape (batch_size, Tq). given, output zero positions mask==FALSE. value_mask: boolean mask tensor shape (batch_size, Tv). given, apply mask values positions mask==FALSE contribute result. return_attention_scores: bool, TRUE, returns attention scores (masking softmax) additional output argument. training: Python boolean indicating whether layer behave training mode (adding dropout) inference mode (dropout). use_causal_mask: Boolean. Set TRUE decoder self-attention. Adds mask position attend positions j > . prevents flow information future towards past. Defaults FALSE.","code":""},{"path":"https://keras.posit.co/reference/layer_attention.html","id":"output","dir":"Reference","previous_headings":"","what":"Output","title":"Dot-product attention layer, a.k.a. Luong-style attention. — layer_attention","text":"Attention outputs shape (batch_size, Tq, dim). (Optional) Attention scores masking softmax shape (batch_size, Tq, Tv).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_average.html","id":null,"dir":"Reference","previous_headings":"","what":"Averages a list of inputs element-wise.. — layer_average","title":"Averages a list of inputs element-wise.. — layer_average","text":"takes input list tensors, shape, returns single tensor (also shape).","code":""},{"path":"https://keras.posit.co/reference/layer_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Averages a list of inputs element-wise.. — layer_average","text":"","code":"layer_average(inputs, ...)"},{"path":"https://keras.posit.co/reference/layer_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Averages a list of inputs element-wise.. — layer_average","text":"inputs layers combine ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_average.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Averages a list of inputs element-wise.. — layer_average","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_average.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Averages a list of inputs element-wise.. — layer_average","text":"Usage Keras model:","code":"input_shape <- c(1, 2, 3) x1 <- op_ones(input_shape) x2 <- op_zeros(input_shape) layer_average(x1, x2) ## tf.Tensor( ## [[[0.5 0.5 0.5] ##   [0.5 0.5 0.5]]], shape=(1, 2, 3), dtype=float32) input1 <- layer_input(shape = c(16)) x1 <- input1 |> layer_dense(8, activation = 'relu')  input2 <- layer_input(shape = c(32)) x2 <- input2 |> layer_dense(8, activation = 'relu')  added <- layer_average(x1, x2) output <- added |> layer_dense(4)  model <- keras_model(inputs = c(input1, input2), outputs = output)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_average_pooling_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Average pooling for temporal data. — layer_average_pooling_1d","title":"Average pooling for temporal data. — layer_average_pooling_1d","text":"Downsamples input representation taking average value window defined pool_size. window shifted strides.  resulting output using \"valid\" padding option shape : output_shape = (input_shape - pool_size + 1) / strides) resulting output shape using \"\" padding option : output_shape = input_shape / strides","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average pooling for temporal data. — layer_average_pooling_1d","text":"","code":"layer_average_pooling_1d(   object,   pool_size,   strides = NULL,   padding = \"valid\",   data_format = NULL,   name = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_average_pooling_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average pooling for temporal data. — layer_average_pooling_1d","text":"object Object compose layer . tensor, array, sequential model. pool_size int, size max pooling window. strides int NULL. Specifies much pooling window moves pooling step. NULL, default pool_size. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". name String, name object ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average pooling for temporal data. — layer_average_pooling_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Average pooling for temporal data. — layer_average_pooling_1d","text":"data_format=\"channels_last\": 3D tensor shape (batch_size, steps, features). data_format=\"channels_first\": 3D tensor shape (batch_size, features, steps).","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Average pooling for temporal data. — layer_average_pooling_1d","text":"data_format=\"channels_last\": 3D tensor shape (batch_size, downsampled_steps, features). data_format=\"channels_first\": 3D tensor shape (batch_size, features, downsampled_steps).","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average pooling for temporal data. — layer_average_pooling_1d","text":"strides=1 padding=\"valid\":     strides=2 padding=\"valid\":     strides=1 padding=\"\":","code":"x <- op_array(c(1., 2., 3., 4., 5.)) |> op_reshape(c(1, 5, 1)) output <- x |>   layer_average_pooling_1d(pool_size = 2,                            strides = 1,                            padding = \"valid\") output ## tf.Tensor( ## [[[1.5] ##   [2.5] ##   [3.5] ##   [4.5]]], shape=(1, 4, 1), dtype=float32) x <- op_array(c(1., 2., 3., 4., 5.)) |> op_reshape(c(1, 5, 1)) output <- x |>   layer_average_pooling_1d(pool_size = 2,                            strides = 2,                            padding = \"valid\") output ## tf.Tensor( ## [[[1.5] ##   [3.5]]], shape=(1, 2, 1), dtype=float32) x <- op_array(c(1., 2., 3., 4., 5.)) |> op_reshape(c(1, 5, 1)) output <- x |>   layer_average_pooling_1d(pool_size = 2,                            strides = 1,                            padding = \"same\") output ## tf.Tensor( ## [[[1.5] ##   [2.5] ##   [3.5] ##   [4.5] ##   [5. ]]], shape=(1, 5, 1), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_average_pooling_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Average pooling operation for 2D spatial data. — layer_average_pooling_2d","title":"Average pooling operation for 2D spatial data. — layer_average_pooling_2d","text":"Downsamples input along spatial dimensions (height width) taking average value input window (size defined pool_size) channel input. window shifted strides along dimension. resulting output using \"valid\" padding option spatial shape (number rows columns) : output_shape = math.floor((input_shape - pool_size) / strides) + 1 (input_shape >= pool_size) resulting output shape using \"\" padding option : output_shape = math.floor((input_shape - 1) / strides) + 1","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average pooling operation for 2D spatial data. — layer_average_pooling_2d","text":"","code":"layer_average_pooling_2d(   object,   pool_size,   strides = NULL,   padding = \"valid\",   data_format = NULL,   name = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_average_pooling_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average pooling operation for 2D spatial data. — layer_average_pooling_2d","text":"object Object compose layer . tensor, array, sequential model. pool_size int list 2 integers, factors downscale (dim1, dim2). one integer specified, window length used dimensions. strides int list 2 integers, NULL. Strides values. NULL, default pool_size. one int specified, stride size used dimensions. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". name String, name object ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average pooling operation for 2D spatial data. — layer_average_pooling_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Average pooling operation for 2D spatial data. — layer_average_pooling_2d","text":"data_format=\"channels_last\": 4D tensor shape (batch_size, height, width, channels). data_format=\"channels_first\": 4D tensor shape (batch_size, channels, height, width).","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Average pooling operation for 2D spatial data. — layer_average_pooling_2d","text":"data_format=\"channels_last\": 4D tensor shape (batch_size, pooled_height, pooled_width, channels). data_format=\"channels_first\": 4D tensor shape (batch_size, channels, pooled_height, pooled_width).","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average pooling operation for 2D spatial data. — layer_average_pooling_2d","text":"strides=(1, 1) padding=\"valid\":     strides=(2, 2) padding=\"valid\":     stride=(1, 1) padding=\"\":","code":"x <- op_array(1:9, \"float32\") |> op_reshape(c(1, 3, 3, 1)) output <- x |>   layer_average_pooling_2d(pool_size = c(2, 2),                            strides = c(1, 1),                            padding = \"valid\") output ## tf.Tensor( ## [[[[3.] ##    [4.]] ## ##   [[6.] ##    [7.]]]], shape=(1, 2, 2, 1), dtype=float32) x <- op_array(1:12, \"float32\") |> op_reshape(c(1, 3, 4, 1)) output <- x |>   layer_average_pooling_2d(pool_size = c(2, 2),                            strides = c(2, 2),                            padding = \"valid\") output ## tf.Tensor( ## [[[[3.5] ##    [5.5]]]], shape=(1, 1, 2, 1), dtype=float32) x <- op_array(1:9, \"float32\") |> op_reshape(c(1, 3, 3, 1)) output <- x |>   layer_average_pooling_2d(pool_size = c(2, 2),                            strides = c(1, 1),                            padding = \"same\") output ## tf.Tensor( ## [[[[3. ] ##    [4. ] ##    [4.5]] ## ##   [[6. ] ##    [7. ] ##    [7.5]] ## ##   [[7.5] ##    [8.5] ##    [9. ]]]], shape=(1, 3, 3, 1), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_average_pooling_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Average pooling operation for 3D data (spatial or spatio-temporal). — layer_average_pooling_3d","title":"Average pooling operation for 3D data (spatial or spatio-temporal). — layer_average_pooling_3d","text":"Downsamples input along spatial dimensions (depth, height, width) taking average value input window (size defined pool_size) channel input. window shifted strides along dimension.","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average pooling operation for 3D data (spatial or spatio-temporal). — layer_average_pooling_3d","text":"","code":"layer_average_pooling_3d(   object,   pool_size,   strides = NULL,   padding = \"valid\",   data_format = NULL,   name = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_average_pooling_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average pooling operation for 3D data (spatial or spatio-temporal). — layer_average_pooling_3d","text":"object Object compose layer . tensor, array, sequential model. pool_size int list 3 integers, factors downscale (dim1, dim2, dim3). one integer specified, window length used dimensions. strides int list 3 integers, NULL. Strides values. NULL, default pool_size. one int specified, stride size used dimensions. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". name String, name object ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average pooling operation for 3D data (spatial or spatio-temporal). — layer_average_pooling_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Average pooling operation for 3D data (spatial or spatio-temporal). — layer_average_pooling_3d","text":"data_format=\"channels_last\": 5D tensor shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) data_format=\"channels_first\": 5D tensor shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Average pooling operation for 3D data (spatial or spatio-temporal). — layer_average_pooling_3d","text":"data_format=\"channels_last\": 5D tensor shape: (batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels) data_format=\"channels_first\": 5D tensor shape: (batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_average_pooling_3d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average pooling operation for 3D data (spatial or spatio-temporal). — layer_average_pooling_3d","text":"","code":"depth <- height <- width <- 30 channels <- 3  inputs <- layer_input(shape = c(depth, height, width, channels)) outputs <- inputs |> layer_average_pooling_3d(pool_size = 3) outputs # Shape: (batch_size, 10, 10, 10, 3) ## <KerasTensor shape=(None, 10, 10, 10, 3), dtype=float32, sparse=False, name=keras_tensor_1>"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_batch_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer that normalizes its inputs. — layer_batch_normalization","title":"Layer that normalizes its inputs. — layer_batch_normalization","text":"Batch normalization applies transformation maintains mean output close 0 output standard deviation close 1. Importantly, batch normalization works differently training inference. training (.e. using fit() calling layer/model argument training = TRUE), layer normalizes output using mean standard deviation current batch inputs. say, channel normalized, layer returns gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta, : epsilon small constant (configurable part constructor arguments) gamma learned scaling factor (initialized 1), can disabled passing scale = FALSE constructor. beta learned offset factor (initialized 0), can disabled passing center = FALSE constructor. inference (.e. using evaluate() predict() calling layer/model argument training = FALSE (default), layer normalizes output using moving average mean standard deviation batches seen training. say, returns gamma * (batch - self$moving_mean) / sqrt(self$moving_var+epsilon) + beta. self$moving_mean self$moving_var non-trainable variables updated time layer called training mode, : moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum) moving_var = moving_var * momentum + var(batch) * (1 - momentum) , layer normalize inputs inference trained data similar statistics inference data. setting layer$trainable <- FALSE BatchNormalization layer: meaning setting layer$trainable <- FALSE freeze layer, .e. internal state change training: trainable weights updated fit() train_on_batch(), state updates run. Usually, necessarily mean layer run inference mode (normally controlled training argument can passed calling layer). \"Frozen state\" \"inference mode\" two separate concepts. However, case BatchNormalization layer, setting trainable <- FALSE layer means layer subsequently run inference mode (meaning use moving mean moving variance normalize current batch, rather using mean variance current batch). Note : Setting trainable model containing layers recursively set trainable value inner layers. value trainable attribute changed calling compile() model, new value take effect model compile() called .","code":""},{"path":"https://keras.posit.co/reference/layer_batch_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer that normalizes its inputs. — layer_batch_normalization","text":"","code":"layer_batch_normalization(   object,   axis = -1L,   momentum = 0.99,   epsilon = 0.001,   center = TRUE,   scale = TRUE,   beta_initializer = \"zeros\",   gamma_initializer = \"ones\",   moving_mean_initializer = \"zeros\",   moving_variance_initializer = \"ones\",   beta_regularizer = NULL,   gamma_regularizer = NULL,   beta_constraint = NULL,   gamma_constraint = NULL,   synchronized = FALSE,   ... )"},{"path":"https://keras.posit.co/reference/layer_batch_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer that normalizes its inputs. — layer_batch_normalization","text":"object Object compose layer . tensor, array, sequential model. axis Integer, axis normalized (typically features axis). instance, Conv2D layer data_format = \"channels_first\", use axis = 2. momentum Momentum moving average. epsilon Small float added variance avoid dividing zero. center TRUE, add offset beta normalized tensor. FALSE, beta ignored. scale TRUE, multiply gamma. FALSE, gamma used. next layer linear can disabled since scaling done next layer. beta_initializer Initializer beta weight. gamma_initializer Initializer gamma weight. moving_mean_initializer Initializer moving mean. moving_variance_initializer Initializer moving variance. beta_regularizer Optional regularizer beta weight. gamma_regularizer Optional regularizer gamma weight. beta_constraint Optional constraint beta weight. gamma_constraint Optional constraint gamma weight. synchronized applicable TensorFlow backend. TRUE, synchronizes global batch statistics (mean variance) layer across devices training step distributed training strategy. FALSE, replica uses local batch statistics. ... Base layer keyword arguments (e.g. name dtype).","code":""},{"path":"https://keras.posit.co/reference/layer_batch_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer that normalizes its inputs. — layer_batch_normalization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_batch_normalization.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Layer that normalizes its inputs. — layer_batch_normalization","text":"inputs: Input tensor (rank). training: R boolean indicating whether layer behave training mode inference mode. training = TRUE: layer normalize inputs using mean variance current batch inputs. training = FALSE: layer normalize inputs using mean variance moving statistics, learned training. mask: Binary tensor shape broadcastable inputs tensor, TRUE values indicating positions mean variance computed. Masked elements current inputs taken account mean variance computation training. prior unmasked element values taken account momentum expires.","code":""},{"path":"https://keras.posit.co/reference/layer_batch_normalization.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Layer that normalizes its inputs. — layer_batch_normalization","text":"Ioffe Szegedy, 2015.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_bidirectional.html","id":null,"dir":"Reference","previous_headings":"","what":"Bidirectional wrapper for RNNs. — layer_bidirectional","title":"Bidirectional wrapper for RNNs. — layer_bidirectional","text":"Bidirectional wrapper RNNs.","code":""},{"path":"https://keras.posit.co/reference/layer_bidirectional.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bidirectional wrapper for RNNs. — layer_bidirectional","text":"","code":"layer_bidirectional(   object,   layer,   merge_mode = \"concat\",   weights = NULL,   backward_layer = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_bidirectional.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bidirectional wrapper for RNNs. — layer_bidirectional","text":"object Object compose layer . tensor, array, sequential model. layer RNN instance, layer_lstm() layer_gru(). also Layer() instance meets following criteria: sequence-processing layer (accepts 3D+ inputs). go_backwards, return_sequences return_state attribute (semantics RNN class). input_spec attribute. Implement serialization via get_config() from_config(). Note recommended way create new RNN layers write custom RNN cell use layer_rnn(), instead subclassing Layer() directly. return_sequences TRUE, output masked timestep zero regardless layer's original zero_output_for_mask value. merge_mode Mode outputs forward backward RNNs combined. One {\"sum\", \"mul\", \"concat\", \"ave\", NULL}. NULL, outputs combined, returned list. Defaults \"concat\". weights see description backward_layer Optional RNN, Layer() instance used handle backwards input processing. backward_layer provided, layer instance passed layer argument used generate backward layer automatically. Note provided backward_layer layer properties matching layer argument, particular values stateful, return_states, return_sequences, etc. addition, backward_layer layer different go_backwards argument values. ValueError raised requirements met. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_bidirectional.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bidirectional wrapper for RNNs. — layer_bidirectional","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_bidirectional.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Bidirectional wrapper for RNNs. — layer_bidirectional","text":"call arguments layer wrapped RNN layer. Beware passing initial_state argument call layer, first half list elements initial_state list passed forward RNN call last half list elements passed backward RNN call.","code":""},{"path":"https://keras.posit.co/reference/layer_bidirectional.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Bidirectional wrapper for RNNs. — layer_bidirectional","text":"instantiating Bidirectional layer existing RNN layer instance reuse weights state RNN layer instance -- Bidirectional layer freshly initialized weights.","code":""},{"path":"https://keras.posit.co/reference/layer_bidirectional.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bidirectional wrapper for RNNs. — layer_bidirectional","text":"","code":"model <- keras_model_sequential(input_shape = c(5, 10)) %>%   layer_bidirectional(layer_lstm(units = 10, return_sequences = TRUE)) %>%   layer_bidirectional(layer_lstm(units = 10)) %>%   layer_dense(5, activation = \"softmax\")  model %>% compile(loss = \"categorical_crossentropy\",                   optimizer = \"rmsprop\")  # With custom backward layer forward_layer <- layer_lstm(units = 10, return_sequences = TRUE) backward_layer <- layer_lstm(units = 10, activation = \"relu\",                              return_sequences = TRUE, go_backwards = TRUE)  model <- keras_model_sequential(input_shape = c(5, 10)) %>%   bidirectional(forward_layer, backward_layer = backward_layer) %>%   layer_dense(5, activation = \"softmax\")  model %>% compile(loss = \"categorical_crossentropy\",                   optimizer = \"rmsprop\")"},{"path":"https://keras.posit.co/reference/layer_bidirectional.html","id":"states","dir":"Reference","previous_headings":"","what":"States","title":"Bidirectional wrapper for RNNs. — layer_bidirectional","text":"Bidirectional layer instance property states, can access layer$states. can also reset states using reset_state()","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_category_encoding.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which encodes integer features. — layer_category_encoding","title":"A preprocessing layer which encodes integer features. — layer_category_encoding","text":"layer provides options condensing data categorical encoding total number tokens known advance. accepts integer values inputs, outputs dense sparse representation inputs. integer inputs total number tokens known, use layer_integer_lookup() instead. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_category_encoding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which encodes integer features. — layer_category_encoding","text":"","code":"layer_category_encoding(   object,   num_tokens = NULL,   output_mode = \"multi_hot\",   ... )"},{"path":"https://keras.posit.co/reference/layer_category_encoding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which encodes integer features. — layer_category_encoding","text":"object Object compose layer . tensor, array, sequential model. num_tokens total number tokens layer support. inputs layer must integers range 0 <= value < num_tokens, error thrown. output_mode Specification output layer. Values can \"one_hot\", \"multi_hot\" \"count\", configuring layer follows: - \"one_hot\": Encodes individual element input array num_tokens size, containing 1 element index. last dimension size 1, encode dimension. last dimension size 1, append new dimension encoded output. - \"multi_hot\": Encodes sample input single array num_tokens size, containing 1 vocabulary term present sample. Treats last dimension sample dimension, input shape (..., sample_length), output shape (..., num_tokens). - \"count\": Like \"multi_hot\", int array contains count number times token index appeared sample. output modes, currently output rank 2 supported. Defaults \"multi_hot\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_category_encoding.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which encodes integer features. — layer_category_encoding","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_category_encoding.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer which encodes integer features. — layer_category_encoding","text":"One-hot encoding data     Multi-hot encoding data     Using weighted inputs \"count\" mode","code":"layer <- layer_category_encoding(num_tokens = 4, output_mode = \"one_hot\") x <- op_array(c(3, 2, 0, 1), \"int32\") layer(x) ## tf.Tensor( ## [[0. 0. 0. 1.] ##  [0. 0. 1. 0.] ##  [1. 0. 0. 0.] ##  [0. 1. 0. 0.]], shape=(4, 4), dtype=float32) layer <- layer_category_encoding(num_tokens = 4, output_mode = \"multi_hot\") x <- op_array(rbind(c(0, 1),                    c(0, 0),                    c(1, 2),                    c(3, 1)), \"int32\") layer(x) ## tf.Tensor( ## [[1. 1. 0. 0.] ##  [1. 0. 0. 0.] ##  [0. 1. 1. 0.] ##  [0. 1. 0. 1.]], shape=(4, 4), dtype=float32) layer <- layer_category_encoding(num_tokens = 4, output_mode = \"count\") count_weights <- op_array(rbind(c(.1, .2),                                c(.1, .1),                                c(.2, .3),                                c(.4, .2))) x <- op_array(rbind(c(0, 1),                    c(0, 0),                    c(1, 2),                    c(3, 1)), \"int32\") layer(x, count_weights = count_weights) #   array([[01, 02, 0. , 0. ], #          [02, 0. , 0. , 0. ], #          [0. , 02, 03, 0. ], #          [0. , 02, 0. , 04]]>"},{"path":"https://keras.posit.co/reference/layer_category_encoding.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"A preprocessing layer which encodes integer features. — layer_category_encoding","text":"inputs: 1D 2D tensor integer inputs. count_weights: tensor shape inputs indicating weight sample value summing count mode. used \"multi_hot\" \"one_hot\" modes.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_center_crop.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which crops images. — layer_center_crop","title":"A preprocessing layer which crops images. — layer_center_crop","text":"layers crops central portion images target size. image smaller target size, resized cropped return largest possible window image matches target aspect ratio. Input pixel values can range (e.g. [0., 1.) [0, 255]).","code":""},{"path":"https://keras.posit.co/reference/layer_center_crop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which crops images. — layer_center_crop","text":"","code":"layer_center_crop(object, height, width, data_format = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_center_crop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which crops images. — layer_center_crop","text":"object Object compose layer . tensor, array, sequential model. height Integer, height output shape. width Integer, width output shape. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_center_crop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which crops images. — layer_center_crop","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_center_crop.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which crops images. — layer_center_crop","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format, (..., channels, height, width), \"channels_first\" format.","code":""},{"path":"https://keras.posit.co/reference/layer_center_crop.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which crops images. — layer_center_crop","text":"3D (unbatched) 4D (batched) tensor shape: (..., target_height, target_width, channels), (..., channels, target_height, target_width), \"channels_first\" format. input height/width even target height/width odd (inversely), input image left-padded 1 pixel. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_concatenate.html","id":null,"dir":"Reference","previous_headings":"","what":"Concatenates a list of inputs. — layer_concatenate","title":"Concatenates a list of inputs. — layer_concatenate","text":"takes input list tensors, shape except concatenation axis, returns single tensor concatenation inputs.","code":""},{"path":"https://keras.posit.co/reference/layer_concatenate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Concatenates a list of inputs. — layer_concatenate","text":"","code":"layer_concatenate(inputs, ..., axis = -1L)"},{"path":"https://keras.posit.co/reference/layer_concatenate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Concatenates a list of inputs. — layer_concatenate","text":"inputs layers combine ... Standard layer keyword arguments. axis Axis along concatenate.","code":""},{"path":"https://keras.posit.co/reference/layer_concatenate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Concatenates a list of inputs. — layer_concatenate","text":"tensor, concatenation inputs alongside axis axis.","code":""},{"path":"https://keras.posit.co/reference/layer_concatenate.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Concatenates a list of inputs. — layer_concatenate","text":"Usage Keras model:","code":"x <- op_arange(20) |> op_reshape(c(2, 2, 5)) y <- op_arange(20, 40) |> op_reshape(c(2, 2, 5)) layer_concatenate(x, y, axis = 2) ## tf.Tensor( ## [[[ 0.  1.  2.  3.  4.] ##   [ 5.  6.  7.  8.  9.] ##   [20. 21. 22. 23. 24.] ##   [25. 26. 27. 28. 29.]] ## ##  [[10. 11. 12. 13. 14.] ##   [15. 16. 17. 18. 19.] ##   [30. 31. 32. 33. 34.] ##   [35. 36. 37. 38. 39.]]], shape=(2, 4, 5), dtype=float32) x1 <- op_arange(10)     |> op_reshape(c(5, 2)) |> layer_dense(8) x2 <- op_arange(10, 20) |> op_reshape(c(5, 2)) |> layer_dense(8) y <- layer_concatenate(x1, x2)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","title":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","text":"layer creates convolution kernel convolved layer input single spatial (temporal) dimension produce tensor outputs. use_bias TRUE, bias vector created added outputs. Finally, activation NULL, applied outputs well.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","text":"","code":"layer_conv_1d(   object,   filters,   kernel_size,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L,   groups = 1L,   activation = NULL,   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_conv_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters convolution). kernel_size int list 1 integer, specifying size convolution window. strides int list 1 integer, specifying stride length convolution. strides > 1 incompatible dilation_rate > 1. padding string, \"valid\", \"\" \"causal\"(case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. \"causal\" results causal (dilated) convolutions, e.g. output[t] depend ontail(input, t+1). Useful modeling temporal data model violate temporal order. See WaveNet: Generative Model Raw Audio, section2.1. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 1 integers, specifying dilation rate use dilated convolution. groups positive int specifying number groups input split along channel axis. group convolved separately filters // groups filters. output concatenation groups results along channel axis. Input channels filters must divisible groups. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. kernel_initializer Initializer convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer Initializer bias vector. NULL, default initializer (\"zeros\") used. kernel_regularizer Optional regularizer convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. kernel_constraint Optional projection function applied kernel updated Optimizer (e.g. used implement norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). Constraints safe use asynchronous distributed training. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","text":"3D tensor representing activation(conv1d(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","text":"data_format=\"channels_last\": 3D tensor shape: (batch_shape, steps, channels) data_format=\"channels_first\": 3D tensor shape: (batch_shape, channels, steps)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","text":"data_format=\"channels_last\": 3D tensor shape: (batch_shape, new_steps, filters) data_format=\"channels_first\": 3D tensor shape: (batch_shape, filters, new_steps)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","text":"ValueError: strides > 1 dilation_rate > 1.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1D convolution layer (e.g. temporal convolution). — layer_conv_1d","text":"","code":"# The inputs are 128-length vectors with 10 timesteps, and the # batch size is 4. x <- random_uniform(c(4, 10, 128)) y <- x |> layer_conv_1d(32, 3, activation='relu') shape(y) ## shape(4, 8, 32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"1D transposed convolution layer. — layer_conv_1d_transpose","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"need transposed convolutions generally arise desire use transformation going opposite direction normal convolution, .e., something shape output convolution something shape input maintaining connectivity pattern compatible said convolution.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"","code":"layer_conv_1d_transpose(   object,   filters,   kernel_size,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L,   activation = NULL,   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters transpose convolution). kernel_size int list 1 integer, specifying size transposed convolution window. strides int list 1 integer, specifying stride length transposed convolution. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 1 integers, specifying dilation rate use dilated transposed convolution. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. kernel_initializer Initializer convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer Initializer bias vector. NULL, default initializer (\"zeros\") used. kernel_regularizer Optional regularizer convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. kernel_constraint Optional projection function applied kernel updated Optimizer (e.g. used implement norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). Constraints safe use asynchronous distributed training. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"3D tensor representing activation(conv1d_transpose(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"data_format=\"channels_last\": 3D tensor shape: (batch_shape, steps, channels) data_format=\"channels_first\": 3D tensor shape: (batch_shape, channels, steps)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"data_format=\"channels_last\": 3D tensor shape: (batch_shape, new_steps, filters) data_format=\"channels_first\": 3D tensor shape: (batch_shape, filters, new_steps)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"ValueError: strides > 1 dilation_rate > 1.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"guide convolution arithmetic deep learning Deconvolutional Networks","code":""},{"path":"https://keras.posit.co/reference/layer_conv_1d_transpose.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1D transposed convolution layer. — layer_conv_1d_transpose","text":"","code":"x <- random_uniform(c(4, 10, 128)) y <- x |> layer_conv_1d_transpose(32, 3, 2, activation='relu') shape(y) ## shape(4, 21, 32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2D convolution layer. — layer_conv_2d","title":"2D convolution layer. — layer_conv_2d","text":"layer creates convolution kernel convolved layer input single spatial (temporal) dimension produce tensor outputs. use_bias TRUE, bias vector created added outputs. Finally, activation NULL, applied outputs well.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D convolution layer. — layer_conv_2d","text":"","code":"layer_conv_2d(   object,   filters,   kernel_size,   strides = list(1L, 1L),   padding = \"valid\",   data_format = NULL,   dilation_rate = list(1L, 1L),   groups = 1L,   activation = NULL,   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_conv_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D convolution layer. — layer_conv_2d","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters convolution). kernel_size int list 2 integer, specifying size convolution window. strides int list 2 integer, specifying stride length convolution. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, height, width, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 2 integers, specifying dilation rate use dilated convolution. groups positive int specifying number groups input split along channel axis. group convolved separately filters // groups filters. output concatenation groups results along channel axis. Input channels filters must divisible groups. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. kernel_initializer Initializer convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer Initializer bias vector. NULL, default initializer (\"zeros\") used. kernel_regularizer Optional regularizer convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. kernel_constraint Optional projection function applied kernel updated Optimizer (e.g. used implement norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). Constraints safe use asynchronous distributed training. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D convolution layer. — layer_conv_2d","text":"4D tensor representing activation(conv2d(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"2D convolution layer. — layer_conv_2d","text":"data_format=\"channels_last\": 4D tensor shape: (batch_size, height, width, channels) data_format=\"channels_first\": 4D tensor shape: (batch_size, channels, height, width)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"2D convolution layer. — layer_conv_2d","text":"data_format=\"channels_last\": 4D tensor shape: (batch_size, new_height, new_width, filters) data_format=\"channels_first\": 4D tensor shape: (batch_size, filters, new_height, new_width)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"2D convolution layer. — layer_conv_2d","text":"ValueError: strides > 1 dilation_rate > 1.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"2D convolution layer. — layer_conv_2d","text":"","code":"x <- random_uniform(c(4, 10, 10, 128)) y <- x |> layer_conv_2d(32, 3, activation='relu') shape(y) ## shape(4, 8, 8, 32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"2D transposed convolution layer. — layer_conv_2d_transpose","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"need transposed convolutions generally arise desire use transformation going opposite direction normal convolution, .e., something shape output convolution something shape input maintaining connectivity pattern compatible said convolution.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"","code":"layer_conv_2d_transpose(   object,   filters,   kernel_size,   strides = list(1L, 1L),   padding = \"valid\",   data_format = NULL,   dilation_rate = list(1L, 1L),   activation = NULL,   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters transposed convolution). kernel_size int list 1 integer, specifying size transposed convolution window. strides int list 1 integer, specifying stride length transposed convolution. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, height, width, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 1 integers, specifying dilation rate use dilated transposed convolution. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. kernel_initializer Initializer convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer Initializer bias vector. NULL, default initializer (\"zeros\") used. kernel_regularizer Optional regularizer convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. kernel_constraint Optional projection function applied kernel updated Optimizer (e.g. used implement norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). Constraints safe use asynchronous distributed training. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"4D tensor representing activation(conv2d_transpose(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"data_format=\"channels_last\": 4D tensor shape: (batch_size, height, width, channels) data_format=\"channels_first\": 4D tensor shape: (batch_size, channels, height, width)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"data_format=\"channels_last\": 4D tensor shape: (batch_size, new_height, new_width, filters) data_format=\"channels_first\": 4D tensor shape: (batch_size, filters, new_height, new_width)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"ValueError: strides > 1 dilation_rate > 1.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"guide convolution arithmetic deep learning Deconvolutional Networks","code":""},{"path":"https://keras.posit.co/reference/layer_conv_2d_transpose.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"2D transposed convolution layer. — layer_conv_2d_transpose","text":"","code":"x <- random_uniform(c(4, 10, 8, 128)) y <- x |> layer_conv_2d_transpose(32, 2, 2, activation='relu') shape(y) ## shape(4, 20, 16, 32) # (4, 20, 16, 32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"3D convolution layer. — layer_conv_3d","title":"3D convolution layer. — layer_conv_3d","text":"layer creates convolution kernel convolved layer input single spatial (temporal) dimension produce tensor outputs. use_bias TRUE, bias vector created added outputs. Finally, activation NULL, applied outputs well.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3D convolution layer. — layer_conv_3d","text":"","code":"layer_conv_3d(   object,   filters,   kernel_size,   strides = list(1L, 1L, 1L),   padding = \"valid\",   data_format = NULL,   dilation_rate = list(1L, 1L, 1L),   groups = 1L,   activation = NULL,   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_conv_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3D convolution layer. — layer_conv_3d","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters convolution). kernel_size int list 3 integer, specifying size convolution window. strides int list 3 integer, specifying stride length convolution. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 3 integers, specifying dilation rate use dilated convolution. groups positive int specifying number groups input split along channel axis. group convolved separately filters %/% groups filters. output concatenation groups results along channel axis. Input channels filters must divisible groups. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. kernel_initializer Initializer convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer Initializer bias vector. NULL, default initializer (\"zeros\") used. kernel_regularizer Optional regularizer convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. kernel_constraint Optional projection function applied kernel updated Optimizer (e.g. used implement norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). Constraints safe use asynchronous distributed training. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3D convolution layer. — layer_conv_3d","text":"5D tensor representing activation(conv3d(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"3D convolution layer. — layer_conv_3d","text":"data_format=\"channels_last\": 5D tensor shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) data_format=\"channels_first\": 5D tensor shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"3D convolution layer. — layer_conv_3d","text":"data_format=\"channels_last\": 5D tensor shape: (batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3, filters) data_format=\"channels_first\": 5D tensor shape: (batch_size, filters, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"3D convolution layer. — layer_conv_3d","text":"ValueError: strides > 1 dilation_rate > 1.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"3D convolution layer. — layer_conv_3d","text":"","code":"x <- random_uniform(c(4, 10, 10, 10, 128)) y <- x |> layer_conv_3d(32, 3, activation = 'relu') shape(y) ## shape(4, 8, 8, 8, 32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"3D transposed convolution layer. — layer_conv_3d_transpose","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"need transposed convolutions generally arise desire use transformation going opposite direction normal convolution, .e., something shape output convolution something shape input maintaining connectivity pattern compatible said convolution.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"","code":"layer_conv_3d_transpose(   object,   filters,   kernel_size,   strides = list(1L, 1L, 1L),   padding = \"valid\",   data_format = NULL,   dilation_rate = list(1L, 1L, 1L),   activation = NULL,   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters transposed convolution). kernel_size int list 1 integer, specifying size transposed convolution window. strides int list 1 integer, specifying stride length transposed convolution. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 1 integers, specifying dilation rate use dilated transposed convolution. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. kernel_initializer Initializer convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer Initializer bias vector. NULL, default initializer (\"zeros\") used. kernel_regularizer Optional regularizer convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. kernel_constraint Optional projection function applied kernel updated Optimizer (e.g. used implement norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). Constraints safe use asynchronous distributed training. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"5D tensor representing activation(conv3d(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"data_format=\"channels_last\": 5D tensor shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) data_format=\"channels_first\": 5D tensor shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"data_format=\"channels_last\": 5D tensor shape: (batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3, filters) data_format=\"channels_first\": 5D tensor shape: (batch_size, filters, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"ValueError: strides > 1 dilation_rate > 1.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"guide convolution arithmetic deep learning Deconvolutional Networks","code":""},{"path":"https://keras.posit.co/reference/layer_conv_3d_transpose.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"3D transposed convolution layer. — layer_conv_3d_transpose","text":"","code":"x <- random_uniform(c(4, 10, 8, 12, 128)) y <- x |> layer_conv_3d_transpose(32, 2, 2, activation = 'relu') shape(y) ## shape(4, 20, 16, 24, 32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_lstm_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"1D Convolutional LSTM. — layer_conv_lstm_1d","title":"1D Convolutional LSTM. — layer_conv_lstm_1d","text":"Similar LSTM layer, input transformations recurrent transformations convolutional.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D Convolutional LSTM. — layer_conv_lstm_1d","text":"","code":"layer_conv_lstm_1d(   object,   filters,   kernel_size,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L,   activation = \"tanh\",   recurrent_activation = \"sigmoid\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   unit_forget_bias = TRUE,   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   seed = NULL,   return_sequences = FALSE,   return_state = FALSE,   go_backwards = FALSE,   stateful = FALSE,   ...,   unroll = NULL )"},{"path":"https://keras.posit.co/reference/layer_conv_lstm_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D Convolutional LSTM. — layer_conv_lstm_1d","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters convolution). kernel_size int tuple/list 1 integer, specifying size convolution window. strides int tuple/list 1 integer, specifying stride length convolution. strides > 1 incompatible dilation_rate > 1. padding string, \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int tuple/list 1 integers, specifying dilation rate use dilated convolution. activation Activation function use. default hyperbolic tangent activation function applied (tanh(x)). recurrent_activation Activation function use recurrent step. use_bias Boolean, whether layer uses bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state. bias_initializer Initializer bias vector. unit_forget_bias Boolean. TRUE, add 1 bias forget gate initialization. Use combination bias_initializer=\"zeros\". recommended Jozefowicz et al., 2015 kernel_regularizer Regularizer function applied kernel weights matrix. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. bias_regularizer Regularizer function applied bias vector. activity_regularizer Regularizer function applied . kernel_constraint Constraint function applied kernel weights matrix. recurrent_constraint Constraint function applied recurrent_kernel weights matrix. bias_constraint Constraint function applied bias vector. dropout Float 0 1. Fraction units drop linear transformation inputs. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. seed Random seed dropout. return_sequences Boolean. Whether return last output output sequence, full sequence. Default: FALSE. return_state Boolean. Whether return last state addition output. Default: FALSE. go_backwards Boolean (default: FALSE). TRUE, process input sequence backwards return reversed sequence. stateful Boolean (default FALSE). TRUE, last state sample index batch used initial state sample index following batch. ... forward/backward compatability. unroll Boolean (default: FALSE). TRUE, network unrolled, else symbolic loop used. Unrolling can speed-RNN, although tends memory-intensive. Unrolling suitable short sequences.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D Convolutional LSTM. — layer_conv_lstm_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_1d.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"1D Convolutional LSTM. — layer_conv_lstm_1d","text":"inputs: 4D tensor. initial_state: List initial state tensors passed first call cell. mask: Binary tensor shape (samples, timesteps) indicating whether given timestep masked. training: Python boolean indicating whether layer behave training mode inference mode. relevant dropout recurrent_dropout set.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"1D Convolutional LSTM. — layer_conv_lstm_1d","text":"data_format=\"channels_first\": 4D tensor shape: (samples, time, channels, rows) data_format=\"channels_last\": 4D tensor shape: (samples, time, rows, channels)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"1D Convolutional LSTM. — layer_conv_lstm_1d","text":"return_state: list tensors. first tensor output. remaining tensors last states, 3D tensor shape: (samples, filters, new_rows) data_format='channels_first' shape: (samples, new_rows, filters) data_format='channels_last'. rows values might changed due padding. return_sequences: 4D tensor shape: (samples, timesteps, filters, new_rows) data_format='channels_first' shape: (samples, timesteps, new_rows, filters) data_format='channels_last'. Else, 3D tensor shape: (samples, filters, new_rows) data_format='channels_first' shape: (samples, new_rows, filters) data_format='channels_last'.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_1d.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"1D Convolutional LSTM. — layer_conv_lstm_1d","text":"Shi et al., 2015 (current implementation include feedback loop cells output).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_lstm_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2D Convolutional LSTM. — layer_conv_lstm_2d","title":"2D Convolutional LSTM. — layer_conv_lstm_2d","text":"Similar LSTM layer, input transformations recurrent transformations convolutional.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D Convolutional LSTM. — layer_conv_lstm_2d","text":"","code":"layer_conv_lstm_2d(   object,   filters,   kernel_size,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L,   activation = \"tanh\",   recurrent_activation = \"sigmoid\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   unit_forget_bias = TRUE,   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   seed = NULL,   return_sequences = FALSE,   return_state = FALSE,   go_backwards = FALSE,   stateful = FALSE,   ...,   unroll = NULL )"},{"path":"https://keras.posit.co/reference/layer_conv_lstm_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D Convolutional LSTM. — layer_conv_lstm_2d","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters convolution). kernel_size int tuple/list 2 integers, specifying size convolution window. strides int tuple/list 2 integers, specifying stride length convolution. strides > 1 incompatible dilation_rate > 1. padding string, \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int tuple/list 2 integers, specifying dilation rate use dilated convolution. activation Activation function use. default hyperbolic tangent activation function applied (tanh(x)). recurrent_activation Activation function use recurrent step. use_bias Boolean, whether layer uses bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state. bias_initializer Initializer bias vector. unit_forget_bias Boolean. TRUE, add 1 bias forget gate initialization. Use combination bias_initializer=\"zeros\". recommended Jozefowicz et al., 2015 kernel_regularizer Regularizer function applied kernel weights matrix. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. bias_regularizer Regularizer function applied bias vector. activity_regularizer Regularizer function applied . kernel_constraint Constraint function applied kernel weights matrix. recurrent_constraint Constraint function applied recurrent_kernel weights matrix. bias_constraint Constraint function applied bias vector. dropout Float 0 1. Fraction units drop linear transformation inputs. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. seed Random seed dropout. return_sequences Boolean. Whether return last output output sequence, full sequence. Default: FALSE. return_state Boolean. Whether return last state addition output. Default: FALSE. go_backwards Boolean (default: FALSE). TRUE, process input sequence backwards return reversed sequence. stateful Boolean (default FALSE). TRUE, last state sample index batch used initial state sample index following batch. ... forward/backward compatability. unroll Boolean (default: FALSE). TRUE, network unrolled, else symbolic loop used. Unrolling can speed-RNN, although tends memory-intensive. Unrolling suitable short sequences.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D Convolutional LSTM. — layer_conv_lstm_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_2d.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"2D Convolutional LSTM. — layer_conv_lstm_2d","text":"inputs: 5D tensor. mask: Binary tensor shape (samples, timesteps) indicating whether given timestep masked. training: Python boolean indicating whether layer behave training mode inference mode. relevant dropout recurrent_dropout set. initial_state: List initial state tensors passed first call cell.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"2D Convolutional LSTM. — layer_conv_lstm_2d","text":"data_format='channels_first': 5D tensor shape: (samples, time, channels, rows, cols) data_format='channels_last': 5D tensor shape: (samples, time, rows, cols, channels)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"2D Convolutional LSTM. — layer_conv_lstm_2d","text":"return_state: list tensors. first tensor output. remaining tensors last states, 4D tensor shape: (samples, filters, new_rows, new_cols) data_format='channels_first' shape: (samples, new_rows, new_cols, filters) data_format='channels_last'. rows cols values might changed due padding. return_sequences: 5D tensor shape: (samples, timesteps, filters, new_rows, new_cols) data_format='channels_first' shape: (samples, timesteps, new_rows, new_cols, filters) data_format='channels_last'. Else, 4D tensor shape: (samples, filters, new_rows, new_cols) data_format='channels_first' shape: (samples, new_rows, new_cols, filters) data_format='channels_last'.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_2d.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"2D Convolutional LSTM. — layer_conv_lstm_2d","text":"Shi et al., 2015 (current implementation include feedback loop cells output).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_conv_lstm_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"3D Convolutional LSTM. — layer_conv_lstm_3d","title":"3D Convolutional LSTM. — layer_conv_lstm_3d","text":"Similar LSTM layer, input transformations recurrent transformations convolutional.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3D Convolutional LSTM. — layer_conv_lstm_3d","text":"","code":"layer_conv_lstm_3d(   object,   filters,   kernel_size,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L,   activation = \"tanh\",   recurrent_activation = \"sigmoid\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   unit_forget_bias = TRUE,   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   seed = NULL,   return_sequences = FALSE,   return_state = FALSE,   go_backwards = FALSE,   stateful = FALSE,   ...,   unroll = NULL )"},{"path":"https://keras.posit.co/reference/layer_conv_lstm_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3D Convolutional LSTM. — layer_conv_lstm_3d","text":"object Object compose layer . tensor, array, sequential model. filters int, dimension output space (number filters convolution). kernel_size int tuple/list 3 integers, specifying size convolution window. strides int tuple/list 3 integers, specifying stride length convolution. strides > 1 incompatible dilation_rate > 1. padding string, \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int tuple/list 3 integers, specifying dilation rate use dilated convolution. activation Activation function use. default hyperbolic tangent activation function applied (tanh(x)). recurrent_activation Activation function use recurrent step. use_bias Boolean, whether layer uses bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state. bias_initializer Initializer bias vector. unit_forget_bias Boolean. TRUE, add 1 bias forget gate initialization. Use combination bias_initializer=\"zeros\". recommended Jozefowicz et al., 2015 kernel_regularizer Regularizer function applied kernel weights matrix. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. bias_regularizer Regularizer function applied bias vector. activity_regularizer Regularizer function applied . kernel_constraint Constraint function applied kernel weights matrix. recurrent_constraint Constraint function applied recurrent_kernel weights matrix. bias_constraint Constraint function applied bias vector. dropout Float 0 1. Fraction units drop linear transformation inputs. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. seed Random seed dropout. return_sequences Boolean. Whether return last output output sequence, full sequence. Default: FALSE. return_state Boolean. Whether return last state addition output. Default: FALSE. go_backwards Boolean (default: FALSE). TRUE, process input sequence backwards return reversed sequence. stateful Boolean (default FALSE). TRUE, last state sample index batch used initial state sample index following batch. ... forward/backward compatability. unroll Boolean (default: FALSE). TRUE, network unrolled, else symbolic loop used. Unrolling can speed-RNN, although tends memory-intensive. Unrolling suitable short sequences.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3D Convolutional LSTM. — layer_conv_lstm_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_3d.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"3D Convolutional LSTM. — layer_conv_lstm_3d","text":"inputs: 6D tensor. mask: Binary tensor shape (samples, timesteps) indicating whether given timestep masked. training: Python boolean indicating whether layer behave training mode inference mode. relevant dropout recurrent_dropout set. initial_state: List initial state tensors passed first call cell.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"3D Convolutional LSTM. — layer_conv_lstm_3d","text":"data_format='channels_first': 5D tensor shape: (samples, time, channels, *spatial_dims) data_format='channels_last': 5D tensor shape: (samples, time, *spatial_dims, channels)","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"3D Convolutional LSTM. — layer_conv_lstm_3d","text":"return_state: list tensors. first tensor output. remaining tensors last states, 4D tensor shape: (samples, filters, *spatial_dims) data_format='channels_first' shape: (samples, *spatial_dims, filters) data_format='channels_last'. return_sequences: 5D tensor shape: (samples, timesteps, filters, *spatial_dims) data_format='channels_first' shape: (samples, timesteps, *spatial_dims, filters) data_format='channels_last'. Else, 4D tensor shape: (samples, filters, *spatial_dims) data_format='channels_first' shape: (samples, *spatial_dims, filters) data_format='channels_last'.","code":""},{"path":"https://keras.posit.co/reference/layer_conv_lstm_3d.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"3D Convolutional LSTM. — layer_conv_lstm_3d","text":"Shi et al., 2015 (current implementation include feedback loop cells output).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_cropping_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Cropping layer for 1D input (e.g. temporal sequence). — layer_cropping_1d","title":"Cropping layer for 1D input (e.g. temporal sequence). — layer_cropping_1d","text":"crops along time dimension (axis 2).","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cropping layer for 1D input (e.g. temporal sequence). — layer_cropping_1d","text":"","code":"layer_cropping_1d(object, cropping = list(1L, 1L), ...)"},{"path":"https://keras.posit.co/reference/layer_cropping_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cropping layer for 1D input (e.g. temporal sequence). — layer_cropping_1d","text":"object Object compose layer . tensor, array, sequential model. cropping Int, list int (length 2). int: many units trimmed beginning end cropping dimension (axis 1). list 2 ints: many units trimmed beginning end cropping dimension ((left_crop, right_crop)). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cropping layer for 1D input (e.g. temporal sequence). — layer_cropping_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cropping layer for 1D input (e.g. temporal sequence). — layer_cropping_1d","text":"","code":"input_shape <- c(2, 3, 2) x <- op_arange(prod(input_shape)) |> op_reshape(input_shape) x ## tf.Tensor( ## [[[ 0.  1.] ##   [ 2.  3.] ##   [ 4.  5.]] ## ##  [[ 6.  7.] ##   [ 8.  9.] ##   [10. 11.]]], shape=(2, 3, 2), dtype=float64) y <- x |> layer_cropping_1d(cropping = 1) y ## tf.Tensor( ## [[[2. 3.]] ## ##  [[8. 9.]]], shape=(2, 1, 2), dtype=float32)"},{"path":"https://keras.posit.co/reference/layer_cropping_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Cropping layer for 1D input (e.g. temporal sequence). — layer_cropping_1d","text":"3D tensor shape (batch_size, axis_to_crop, features)","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Cropping layer for 1D input (e.g. temporal sequence). — layer_cropping_1d","text":"3D tensor shape (batch_size, cropped_axis, features)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_cropping_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Cropping layer for 2D input (e.g. picture). — layer_cropping_2d","title":"Cropping layer for 2D input (e.g. picture). — layer_cropping_2d","text":"crops along spatial dimensions, .e. height width.","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cropping layer for 2D input (e.g. picture). — layer_cropping_2d","text":"","code":"layer_cropping_2d(   object,   cropping = list(list(0L, 0L), list(0L, 0L)),   data_format = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_cropping_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cropping layer for 2D input (e.g. picture). — layer_cropping_2d","text":"object Object compose layer . tensor, array, sequential model. cropping Int, list 2 ints, list 2 lists 2 ints. int: symmetric cropping applied height width. list 2 ints: interpreted two different symmetric cropping values height width: (symmetric_height_crop, symmetric_width_crop). list 2 lists 2 ints: interpreted ((top_crop, bottom_crop), (left_crop, right_crop)). data_format string, one \"channels_last\" (default) \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, height, width, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, height, width). unspecified, uses image_data_format value found Keras config file ~/.keras/keras.json (exists). Defaults \"channels_last\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cropping layer for 2D input (e.g. picture). — layer_cropping_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cropping layer for 2D input (e.g. picture). — layer_cropping_2d","text":"","code":"input_shape <- c(2, 28, 28, 3) x <- op_arange(prod(input_shape), dtype ='int32') |> op_reshape(input_shape) y <- x |> layer_cropping_2d(cropping=list(c(2, 2), c(4, 4))) shape(y) ## shape(2, 24, 20, 3)"},{"path":"https://keras.posit.co/reference/layer_cropping_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Cropping layer for 2D input (e.g. picture). — layer_cropping_2d","text":"4D tensor shape: data_format \"channels_last\": (batch_size, height, width, channels) data_format \"channels_first\": (batch_size, channels, height, width)","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Cropping layer for 2D input (e.g. picture). — layer_cropping_2d","text":"4D tensor shape: data_format \"channels_last\": (batch_size, cropped_height, cropped_width, channels) data_format \"channels_first\": (batch_size, channels, cropped_height, cropped_width)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_cropping_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). — layer_cropping_3d","title":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). — layer_cropping_3d","text":"Cropping layer 3D data (e.g. spatial spatio-temporal).","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). — layer_cropping_3d","text":"","code":"layer_cropping_3d(   object,   cropping = list(list(1L, 1L), list(1L, 1L), list(1L, 1L)),   data_format = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_cropping_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). — layer_cropping_3d","text":"object Object compose layer . tensor, array, sequential model. cropping Int, list 3 ints, list 3 lists 2 ints. int: symmetric cropping applied depth, height, width. list 3 ints: interpreted three different symmetric cropping values depth, height, width: (symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop). list 3 lists 2 ints: interpreted ((left_dim1_crop, right_dim1_crop), (left_dim2_crop, right_dim2_crop), (left_dim3_crop, right_dim3_crop)). data_format string, one \"channels_last\" (default) \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3). unspecified, uses image_data_format value found Keras config file ~/.keras/keras.json (exists). Defaults \"channels_last\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). — layer_cropping_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_3d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). — layer_cropping_3d","text":"","code":"input_shape <- c(2, 28, 28, 10, 3) x <- input_shape %>% { op_reshape(seq(prod(.)), .) } y <- x |> layer_cropping_3d(cropping = c(2, 4, 2)) shape(y) ## shape(2, 24, 20, 6, 3)"},{"path":"https://keras.posit.co/reference/layer_cropping_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). — layer_cropping_3d","text":"5D tensor shape: data_format \"channels_last\": (batch_size, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop, channels) data_format \"channels_first\": (batch_size, channels, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)","code":""},{"path":"https://keras.posit.co/reference/layer_cropping_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Cropping layer for 3D data (e.g. spatial or spatio-temporal). — layer_cropping_3d","text":"5D tensor shape: data_format \"channels_last\": (batch_size, first_cropped_axis, second_cropped_axis, third_cropped_axis, channels) data_format \"channels_first\": (batch_size, channels, first_cropped_axis, second_cropped_axis, third_cropped_axis)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_dense.html","id":null,"dir":"Reference","previous_headings":"","what":"Just your regular densely-connected NN layer. — layer_dense","title":"Just your regular densely-connected NN layer. — layer_dense","text":"Dense implements operation: output = activation(dot(input, kernel) + bias) activation element-wise activation function passed activation argument, kernel weights matrix created layer, bias bias vector created layer (applicable use_bias TRUE).","code":""},{"path":"https://keras.posit.co/reference/layer_dense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Just your regular densely-connected NN layer. — layer_dense","text":"","code":"layer_dense(   object,   units,   activation = NULL,   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   lora_rank = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_dense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Just your regular densely-connected NN layer. — layer_dense","text":"object Object compose layer . tensor, array, sequential model. units Positive integer, dimensionality output space. activation Activation function use. specify anything, activation applied (ie. \"linear\" activation: (x) = x). use_bias Boolean, whether layer uses bias vector. kernel_initializer Initializer kernel weights matrix. bias_initializer Initializer bias vector. kernel_regularizer Regularizer function applied kernel weights matrix. bias_regularizer Regularizer function applied bias vector. activity_regularizer Regularizer function applied output layer (\"activation\"). kernel_constraint Constraint function applied kernel weights matrix. bias_constraint Constraint function applied bias vector. lora_rank Optional integer. set, layer's forward pass implement LoRA (Low-Rank Adaptation) provided rank. LoRA sets layer's kernel non-trainable replaces delta original kernel, obtained via multiplying two lower-rank trainable matrices. can useful reduce computation cost fine-tuning large dense layers. can also enable LoRA existing Dense layer calling layer$enable_lora(rank). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_dense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Just your regular densely-connected NN layer. — layer_dense","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_dense.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Just your regular densely-connected NN layer. — layer_dense","text":"input layer rank greater 2, Dense computes dot product inputs kernel along last axis inputs axis 0 kernel (using tf.tensordot). example, input dimensions (batch_size, d0, d1), create kernel shape (d1, units), kernel operates along axis 2 input, every sub-tensor shape (1, 1, d1) (batch_size * d0 sub-tensors). output case shape (batch_size, d0, units).","code":""},{"path":"https://keras.posit.co/reference/layer_dense.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Just your regular densely-connected NN layer. — layer_dense","text":"N-D tensor shape: (batch_size, ..., input_dim). common situation 2D input shape (batch_size, input_dim).","code":""},{"path":"https://keras.posit.co/reference/layer_dense.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Just your regular densely-connected NN layer. — layer_dense","text":"N-D tensor shape: (batch_size, ..., units). instance, 2D input shape (batch_size, input_dim), output shape (batch_size, units).","code":""},{"path":"https://keras.posit.co/reference/layer_dense.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Just your regular densely-connected NN layer. — layer_dense","text":"","code":"enable_lora(   rank,   a_initializer = 'he_uniform',   b_initializer = 'zeros' )"},{"path":"https://keras.posit.co/reference/layer_dense.html","id":"readonly-properties-","dir":"Reference","previous_headings":"","what":"Readonly properties:","title":"Just your regular densely-connected NN layer. — layer_dense","text":"kernel","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"1D depthwise convolution layer. — layer_depthwise_conv_1d","title":"1D depthwise convolution layer. — layer_depthwise_conv_1d","text":"Depthwise convolution type convolution input channel convolved different kernel (called depthwise kernel). can understand depthwise convolution first step depthwise separable convolution. implemented via following steps: Split input individual channels. Convolve channel individual depthwise kernel depth_multiplier output channels. Concatenate convolved outputs along channels axis. Unlike regular 1D convolution, depthwise convolution mix information across different input channels. depth_multiplier argument determines many filters applied one input channel. , controls amount output channels generated per input channel depthwise step.","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D depthwise convolution layer. — layer_depthwise_conv_1d","text":"","code":"layer_depthwise_conv_1d(   object,   kernel_size,   strides = 1L,   padding = \"valid\",   depth_multiplier = 1L,   data_format = NULL,   dilation_rate = 1L,   activation = NULL,   use_bias = TRUE,   depthwise_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   depthwise_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   depthwise_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D depthwise convolution layer. — layer_depthwise_conv_1d","text":"object Object compose layer . tensor, array, sequential model. kernel_size int list 1 integer, specifying size depthwise convolution window. strides int list 1 integer, specifying stride length convolution. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. depth_multiplier number depthwise convolution output channels input channel. total number depthwise convolution output channels equal input_channel * depth_multiplier. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 1 integers, specifying dilation rate use dilated convolution. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. depthwise_initializer Initializer convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer Initializer bias vector. NULL, default initializer (\"zeros\") used. depthwise_regularizer Optional regularizer convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. depthwise_constraint Optional projection function applied kernel updated Optimizer (e.g. used implement norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). Constraints safe use asynchronous distributed training. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D depthwise convolution layer. — layer_depthwise_conv_1d","text":"3D tensor representing activation(depthwise_conv1d(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"1D depthwise convolution layer. — layer_depthwise_conv_1d","text":"data_format=\"channels_last\": 3D tensor shape: (batch_shape, steps, channels) data_format=\"channels_first\": 3D tensor shape: (batch_shape, channels, steps)","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"1D depthwise convolution layer. — layer_depthwise_conv_1d","text":"data_format=\"channels_last\": 3D tensor shape: (batch_shape, new_steps, channels * depth_multiplier) data_format=\"channels_first\": 3D tensor shape: (batch_shape, channels * depth_multiplier, new_steps)","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_1d.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"1D depthwise convolution layer. — layer_depthwise_conv_1d","text":"ValueError: strides > 1 dilation_rate > 1.","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1D depthwise convolution layer. — layer_depthwise_conv_1d","text":"","code":"x <- random_uniform(c(4, 10, 12)) y <- x |> layer_depthwise_conv_1d(   kernel_size = 3,   depth_multiplier = 3,   activation = 'relu' ) shape(y) ## shape(4, 8, 36)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2D depthwise convolution layer. — layer_depthwise_conv_2d","title":"2D depthwise convolution layer. — layer_depthwise_conv_2d","text":"Depthwise convolution type convolution input channel convolved different kernel (called depthwise kernel). can understand depthwise convolution first step depthwise separable convolution. implemented via following steps: Split input individual channels. Convolve channel individual depthwise kernel depth_multiplier output channels. Concatenate convolved outputs along channels axis. Unlike regular 2D convolution, depthwise convolution mix information across different input channels. depth_multiplier argument determines many filters applied one input channel. , controls amount output channels generated per input channel depthwise step.","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D depthwise convolution layer. — layer_depthwise_conv_2d","text":"","code":"layer_depthwise_conv_2d(   object,   kernel_size,   strides = list(1L, 1L),   padding = \"valid\",   depth_multiplier = 1L,   data_format = NULL,   dilation_rate = list(1L, 1L),   activation = NULL,   use_bias = TRUE,   depthwise_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   depthwise_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   depthwise_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D depthwise convolution layer. — layer_depthwise_conv_2d","text":"object Object compose layer . tensor, array, sequential model. kernel_size int list 2 integer, specifying size depthwise convolution window. strides int list 2 integer, specifying stride length depthwise convolution. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. depth_multiplier number depthwise convolution output channels input channel. total number depthwise convolution output channels equal input_channel * depth_multiplier. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 2 integers, specifying dilation rate use dilated convolution. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. depthwise_initializer Initializer convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer Initializer bias vector. NULL, default initializer (\"zeros\") used. depthwise_regularizer Optional regularizer convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. depthwise_constraint Optional projection function applied kernel updated Optimizer (e.g. used implement norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). Constraints safe use asynchronous distributed training. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D depthwise convolution layer. — layer_depthwise_conv_2d","text":"4D tensor representing activation(depthwise_conv2d(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"2D depthwise convolution layer. — layer_depthwise_conv_2d","text":"data_format=\"channels_last\": 4D tensor shape: (batch_size, height, width, channels) data_format=\"channels_first\": 4D tensor shape: (batch_size, channels, height, width)","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"2D depthwise convolution layer. — layer_depthwise_conv_2d","text":"data_format=\"channels_last\": 4D tensor shape: (batch_size, new_height, new_width, channels * depth_multiplier) data_format=\"channels_first\": 4D tensor shape: (batch_size, channels * depth_multiplier, new_height, new_width)","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_2d.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"2D depthwise convolution layer. — layer_depthwise_conv_2d","text":"ValueError: strides > 1 dilation_rate > 1.","code":""},{"path":"https://keras.posit.co/reference/layer_depthwise_conv_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"2D depthwise convolution layer. — layer_depthwise_conv_2d","text":"","code":"x <- random_uniform(c(4, 10, 10, 12)) y <- x |> layer_depthwise_conv_2d(3, 3, activation = 'relu') shape(y) ## shape(4, 3, 3, 12)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_discretization.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which buckets continuous features by ranges. — layer_discretization","title":"A preprocessing layer which buckets continuous features by ranges. — layer_discretization","text":"layer place element input data one several contiguous ranges output integer index indicating range element placed . Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_discretization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which buckets continuous features by ranges. — layer_discretization","text":"","code":"layer_discretization(   object,   bin_boundaries = NULL,   num_bins = NULL,   epsilon = 0.01,   output_mode = \"int\",   sparse = FALSE,   dtype = NULL,   name = NULL )"},{"path":"https://keras.posit.co/reference/layer_discretization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which buckets continuous features by ranges. — layer_discretization","text":"object Object compose layer . tensor, array, sequential model. bin_boundaries list bin boundaries. leftmost rightmost bins always extend -Inf Inf, bin_boundaries = c(0, 1, 2) generates bins (-Inf, 0), [0, 1), [1, 2), [2, +Inf). option set, adapt() called. num_bins integer number bins compute. option set, adapt() called learn bin boundaries. epsilon Error tolerance, typically small fraction close zero (e.g. 0.01). Higher values epsilon increase quantile approximation, hence result unequal buckets, improve performance resource consumption. output_mode Specification output layer. Values can \"int\", \"one_hot\", \"multi_hot\", \"count\" configuring layer follows: \"int\": Return discretized bin indices directly. \"one_hot\": Encodes individual element input array size num_bins, containing 1 input's bin index. last dimension size 1, encode dimension.  last dimension size 1, append new dimension encoded output. \"multi_hot\": Encodes sample input single array size num_bins, containing 1 bin index index present sample. Treats last dimension sample dimension, input shape (..., sample_length), output shape (..., num_tokens). \"count\": \"multi_hot\", int array contains count number times bin index appeared sample. Defaults \"int\". sparse Boolean. applicable \"one_hot\", \"multi_hot\", \"count\" output modes. supported TensorFlow backend. TRUE, returns SparseTensor instead dense Tensor. Defaults FALSE. dtype datatype (e.g., \"float32\"). name String, name object","code":""},{"path":"https://keras.posit.co/reference/layer_discretization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which buckets continuous features by ranges. — layer_discretization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_discretization.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which buckets continuous features by ranges. — layer_discretization","text":"array dimension 2 higher.","code":""},{"path":"https://keras.posit.co/reference/layer_discretization.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which buckets continuous features by ranges. — layer_discretization","text":"input shape.","code":""},{"path":"https://keras.posit.co/reference/layer_discretization.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer which buckets continuous features by ranges. — layer_discretization","text":"Discretize float values based provided buckets.     Discretize float values based number buckets compute.","code":"input <- op_array(rbind(c(-1.5, 1, 3.4, 0.5),                        c(0, 3, 1.3, 0),                        c(-.5, 0, .5, 1),                        c(1.5, 2, 2.5, 3))) output <- input |> layer_discretization(bin_boundaries = c(0, 1, 2)) output ## tf.Tensor( ## [[0 2 3 1] ##  [1 3 2 1] ##  [0 1 1 2] ##  [2 3 3 3]], shape=(4, 4), dtype=int64) layer <- layer_discretization(num_bins = 4, epsilon = 0.01) layer |> adapt(input) layer(input) ## tf.Tensor( ## [[0 2 3 1] ##  [1 3 2 1] ##  [0 1 1 2] ##  [2 3 3 3]], shape=(4, 4), dtype=int64)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_dot.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes element-wise dot product of two tensors. — layer_dot","title":"Computes element-wise dot product of two tensors. — layer_dot","text":"takes list inputs size 2, axes corresponding input along dot product performed. say x y two input tensors shapes (2, 3, 5) (2, 10, 3). batch dimension size inputs, axes correspond dimensions size corresponding inputs. e.g. axes = c(1, 2), dot product x, y result tensor shape (2, 5, 10)","code":""},{"path":"https://keras.posit.co/reference/layer_dot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes element-wise dot product of two tensors. — layer_dot","text":"","code":"layer_dot(inputs, ..., axes, normalize = FALSE)"},{"path":"https://keras.posit.co/reference/layer_dot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes element-wise dot product of two tensors. — layer_dot","text":"inputs layers combine ... Standard layer keyword arguments. axes Integer list integers, axis axes along take dot product. list, two integers corresponding desired axis first input desired axis second input, respectively. Note size two selected axes must match. normalize Whether L2-normalize samples along dot product axis taking dot product. set TRUE, output dot product cosine proximity two samples.","code":""},{"path":"https://keras.posit.co/reference/layer_dot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes element-wise dot product of two tensors. — layer_dot","text":"tensor, dot product samples inputs.","code":""},{"path":"https://keras.posit.co/reference/layer_dot.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes element-wise dot product of two tensors. — layer_dot","text":"Usage Keras model:","code":"x <- op_reshape(0:9,   c(1, 5, 2)) y <- op_reshape(10:19, c(1, 2, 5)) layer_dot(x, y, axes=c(2, 3)) ## tf.Tensor( ## [[[260 360] ##   [320 445]]], shape=(1, 2, 2), dtype=int32) x1 <- op_reshape(0:9, c(5, 2)) |> layer_dense(8) x2 <- op_reshape(10:19, c(5, 2)) |> layer_dense(8) shape(x1) ## shape(5, 8) shape(x2) ## shape(5, 8) y <- layer_dot(x1, x2, axes=2) shape(y) ## shape(5, 1)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies dropout to the input. — layer_dropout","title":"Applies dropout to the input. — layer_dropout","text":"Dropout layer randomly sets input units 0 frequency rate step training time, helps prevent overfitting. Inputs set 0 scaled 1 / (1 - rate) sum inputs unchanged. Note Dropout layer applies training set TRUE call(), values dropped inference. using model.fit, training appropriately set TRUE automatically. contexts, can set argument explicitly TRUE calling layer. (contrast setting trainable=FALSE Dropout layer. trainable affect layer's behavior, Dropout variables/weights can frozen training.)","code":""},{"path":"https://keras.posit.co/reference/layer_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies dropout to the input. — layer_dropout","text":"","code":"layer_dropout(object, rate, noise_shape = NULL, seed = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies dropout to the input. — layer_dropout","text":"object Object compose layer . tensor, array, sequential model. rate Float 0 1. Fraction input units drop. noise_shape 1D integer tensor representing shape binary dropout mask multiplied input. instance, inputs shape (batch_size, timesteps, features) want dropout mask timesteps, can use noise_shape=(batch_size, 1, features). seed R integer use random seed. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_dropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Applies dropout to the input. — layer_dropout","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_dropout.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Applies dropout to the input. — layer_dropout","text":"inputs: Input tensor (rank). training: Python boolean indicating whether layer behave training mode (adding dropout) inference mode (nothing).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_einsum_dense.html","id":null,"dir":"Reference","previous_headings":"","what":"A layer that uses einsum as the backing computation. — layer_einsum_dense","title":"A layer that uses einsum as the backing computation. — layer_einsum_dense","text":"layer can perform einsum calculations arbitrary dimensionality.","code":""},{"path":"https://keras.posit.co/reference/layer_einsum_dense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A layer that uses einsum as the backing computation. — layer_einsum_dense","text":"","code":"layer_einsum_dense(   object,   equation,   output_shape,   activation = NULL,   bias_axes = NULL,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   lora_rank = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_einsum_dense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A layer that uses einsum as the backing computation. — layer_einsum_dense","text":"object Object compose layer . tensor, array, sequential model. equation equation describing einsum perform. equation must valid einsum string form ab,bc->ac, ...ab,bc->...ac, ab...,bc->ac... 'ab', 'bc', 'ac' can valid einsum axis expression sequence. output_shape expected shape output tensor (excluding batch dimension dimensions represented ellipses). can specify NA NULL dimension unknown can inferred input shape. activation Activation function use. specify anything, activation applied (, \"linear\" activation: (x) = x). bias_axes string containing output dimension(s) apply bias . character bias_axes string correspond character output portion equation string. kernel_initializer Initializer kernel weights matrix. bias_initializer Initializer bias vector. kernel_regularizer Regularizer function applied kernel weights matrix. bias_regularizer Regularizer function applied bias vector. kernel_constraint Constraint function applied kernel weights matrix. bias_constraint Constraint function applied bias vector. lora_rank Optional integer. set, layer's forward pass implement LoRA (Low-Rank Adaptation) provided rank. LoRA sets layer's kernel non-trainable replaces delta original kernel, obtained via multiplying two lower-rank trainable matrices (factorization happens last dimension). can useful reduce computation cost fine-tuning large dense layers. can also enable LoRA existing EinsumDense layer calling layer$enable_lora(rank). ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_einsum_dense.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A layer that uses einsum as the backing computation. — layer_einsum_dense","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_einsum_dense.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A layer that uses einsum as the backing computation. — layer_einsum_dense","text":"Biased dense layer einsums example shows instantiate standard Keras dense layer using einsum operations. example equivalent layer_Dense(64, use_bias=TRUE).     Applying dense layer sequence example shows instantiate layer applies dense operation every element sequence. , output_shape two values (since two non-batch dimensions output); first dimension output_shape NA, sequence dimension b unknown shape.     Applying dense layer sequence using ellipses example shows instantiate layer applies dense operation every element sequence, uses ellipsis notation instead specifying batch sequence dimensions. using ellipsis notation specified one axis, output_shape arg single value. instantiated way, layer can handle number sequence dimensions - including case sequence dimension exists.","code":"input <- layer_input(shape = c(32)) output <- input |>   layer_einsum_dense(\"ab,bc->ac\",                      output_shape = 64,                      bias_axes = \"c\") output # shape(NA, 64) ## <KerasTensor shape=(None, 64), dtype=float32, sparse=False, name=keras_tensor_1> input <- layer_input(shape = c(32, 128)) output <- input |>   layer_einsum_dense(\"abc,cd->abd\",                      output_shape = c(NA, 64),                      bias_axes = \"d\") output  # shape(NA, 32, 64) ## <KerasTensor shape=(None, None, 64), dtype=float32, sparse=False, name=keras_tensor_3> input <- layer_input(shape = c(32, 128)) output <- input |>   layer_einsum_dense(\"...x,xy->...y\",                      output_shape = 64,                      bias_axes = \"y\")  output  # shape(NA, 32, 64) ## <KerasTensor shape=(None, 32, 64), dtype=float32, sparse=False, name=keras_tensor_5>"},{"path":"https://keras.posit.co/reference/layer_einsum_dense.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"A layer that uses einsum as the backing computation. — layer_einsum_dense","text":"","code":"enable_lora(   rank,   a_initializer = 'he_uniform',   b_initializer = 'zeros' )"},{"path":"https://keras.posit.co/reference/layer_einsum_dense.html","id":"readonly-properties-","dir":"Reference","previous_headings":"","what":"Readonly properties:","title":"A layer that uses einsum as the backing computation. — layer_einsum_dense","text":"kernel","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"e.g. rbind(4L, 20L) \\(\\rightarrow\\) rbind(c(0.25, 0.1), c(0.6, -0.2)) layer can used positive integer inputs fixed range.","code":""},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"","code":"layer_embedding(   object,   input_dim,   output_dim,   embeddings_initializer = \"uniform\",   embeddings_regularizer = NULL,   embeddings_constraint = NULL,   mask_zero = FALSE,   lora_rank = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"object Object compose layer . tensor, array, sequential model. input_dim Integer. Size vocabulary, .e. maximum integer index + 1. output_dim Integer. Dimension dense embedding. embeddings_initializer Initializer embeddings matrix (see keras3::initializer_*). embeddings_regularizer Regularizer function applied embeddings matrix (see keras3::regularizer_*). embeddings_constraint Constraint function applied embeddings matrix (see keras3::constraint_*). mask_zero Boolean, whether input value 0 special \"padding\" value masked . useful using recurrent layers may take variable length input. TRUE, subsequent layers model need support masking exception raised. mask_zero set TRUE, consequence, index 0 used vocabulary (input_dim equal size vocabulary + 1). lora_rank Optional integer. set, layer's forward pass implement LoRA (Low-Rank Adaptation) provided rank. LoRA sets layer's embeddings matrix non-trainable replaces delta original matrix, obtained via multiplying two lower-rank trainable matrices. can useful reduce computation cost fine-tuning large embedding layers. can also enable LoRA existing Embedding layer instance calling layer$enable_lora(rank). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"","code":"model <- keras_model_sequential() |>   layer_embedding(1000, 64)  # The model will take as input an integer matrix of size (batch,input_length), # and the largest integer (i.e. word index) in the input # should be no larger than 999 (vocabulary size). # Now model$output_shape is (NA, 10, 64), where `NA` is the batch # dimension.  input_array <- random_integer(shape = c(32, 10), minval = 0, maxval = 1000) model |> compile('rmsprop', 'mse') output_array <- model |> predict(input_array, verbose = 0) dim(output_array)    # (32, 10, 64) ## [1] 32 10 64"},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"2D tensor shape: (batch_size, input_length).","code":""},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"3D tensor shape: (batch_size, input_length, output_dim).","code":""},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"","code":"enable_lora(   rank,   a_initializer = 'he_uniform',   b_initializer = 'zeros' )"},{"path":"https://keras.posit.co/reference/layer_embedding.html","id":"readonly-properties-","dir":"Reference","previous_headings":"","what":"Readonly properties:","title":"Turns positive integers (indexes) into dense vectors of fixed size. — layer_embedding","text":"embeddings","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_feature_space.html","id":null,"dir":"Reference","previous_headings":"","what":"One-stop utility for preprocessing and encoding structured data. — layer_feature_space","title":"One-stop utility for preprocessing and encoding structured data. — layer_feature_space","text":"Available feature types: Note features can referred string name, e.g. \"integer_categorical\". using string name, default argument values used.","code":"# Plain float values. feature_float(name = NULL)  # Float values to be preprocessed via featurewise standardization # (i.e. via a `layer_normalization()` layer). feature_float_normalized(name = NULL)  # Float values to be preprocessed via linear rescaling # (i.e. via a `layer_rescaling` layer). feature_float_rescaled(scale = 1., offset = 0., name = NULL)  # Float values to be discretized. By default, the discrete # representation will then be one-hot encoded. feature_float_discretized(   num_bins,   bin_boundaries = NULL,   output_mode = \"one_hot\",   name = NULL )  # Integer values to be indexed. By default, the discrete # representation will then be one-hot encoded. feature_integer_categorical(   max_tokens = NULL,   num_oov_indices = 1,   output_mode = \"one_hot\",   name = NULL )  # String values to be indexed. By default, the discrete # representation will then be one-hot encoded. feature_string_categorical(   max_tokens = NULL,   num_oov_indices = 1,   output_mode = \"one_hot\",   name = NULL )  # Integer values to be hashed into a fixed number of bins. # By default, the discrete representation will then be one-hot encoded. feature_integer_hashed(num_bins, output_mode = \"one_hot\", name = NULL)  # String values to be hashed into a fixed number of bins. # By default, the discrete representation will then be one-hot encoded. feature_string_hashed(num_bins, output_mode = \"one_hot\", name = NULL)"},{"path":"https://keras.posit.co/reference/layer_feature_space.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One-stop utility for preprocessing and encoding structured data. — layer_feature_space","text":"","code":"layer_feature_space(   object,   features,   output_mode = \"concat\",   crosses = NULL,   crossing_dim = 32L,   hashing_dim = 32L,   num_discretization_bins = 32L,   name = NULL,   feature_names = NULL )  feature_cross(feature_names, crossing_dim, output_mode = \"one_hot\")  feature_custom(dtype, preprocessor, output_mode)  feature_float(name = NULL)  feature_float_rescaled(scale = 1, offset = 0, name = NULL)  feature_float_normalized(name = NULL)  feature_float_discretized(   num_bins,   bin_boundaries = NULL,   output_mode = \"one_hot\",   name = NULL )  feature_integer_categorical(   max_tokens = NULL,   num_oov_indices = 1,   output_mode = \"one_hot\",   name = NULL )  feature_string_categorical(   max_tokens = NULL,   num_oov_indices = 1,   output_mode = \"one_hot\",   name = NULL )  feature_string_hashed(num_bins, output_mode = \"one_hot\", name = NULL)  feature_integer_hashed(num_bins, output_mode = \"one_hot\", name = NULL)"},{"path":"https://keras.posit.co/reference/layer_feature_space.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One-stop utility for preprocessing and encoding structured data. — layer_feature_space","text":"object see description features see description output_mode string. layer_feature_space(), one \"concat\" \"dict\". concat mode, features get concatenated together single vector. dict mode, FeatureSpace returns named list individually encoded features (names input list names). feature_* functions, one : \"int\" \"one_hot\" \"float\". crosses List features crossed together, e.g. crosses=list(c(\"feature_1\", \"feature_2\")). features \"crossed\" hashing combined value fixed-length vector. crossing_dim Default vector size hashing crossed features. Defaults 32. hashing_dim Default vector size hashing features type \"integer_hashed\" \"string_hashed\". Defaults 32. num_discretization_bins Default number bins used discretizing features type \"float_discretized\". Defaults 32. name String, name object feature_names Named list mapping names features type specification, e.g. list(my_feature = \"integer_categorical\") list(my_feature = feature_integer_categorical()). complete list supported types, see \"Available feature types\" paragraph . dtype string, output dtype feature. E.g., \"float32\". preprocessor callable. scale, offset Passed layer_rescaling() num_bins, bin_boundaries Passed layer_discretization() max_tokens, num_oov_indices Passed layer_integer_lookup() feature_integer_categorical() layer_string_lookup() feature_string_categorical().","code":""},{"path":"https://keras.posit.co/reference/layer_feature_space.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"One-stop utility for preprocessing and encoding structured data. — layer_feature_space","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_feature_space.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"One-stop utility for preprocessing and encoding structured data. — layer_feature_space","text":"Basic usage named list input data:   Basic usage tf.data:   Basic usage Keras Functional API:           Customizing feature feature cross:   Returning dict (named list) integer-encoded features:   Specifying Keras preprocessing layer:   Retrieving underlying Keras preprocessing layers:   Saving reloading FeatureSpace:","code":"raw_data <- list(   float_values = c(0.0, 0.1, 0.2, 0.3),   string_values = c(\"zero\", \"one\", \"two\", \"three\"),   int_values = as.integer(c(0, 1, 2, 3)) )  dataset <- tfdatasets::tensor_slices_dataset(raw_data)  feature_space <- layer_feature_space(   features = list(     float_values = \"float_normalized\",     string_values = \"string_categorical\",     int_values = \"integer_categorical\"   ),   crosses = list(c(\"string_values\", \"int_values\")),   output_mode = \"concat\" )  # Before you start using the feature_space(), # you must `adapt()` it on some data. feature_space |> adapt(dataset)  # You can call the feature_space() on a named list of # data (batched or unbatched). output_vector <- feature_space(raw_data) library(tfdatasets) # Unlabeled data preprocessed_ds <- unlabeled_dataset |>   dataset_map(feature_space)  # Labeled data preprocessed_ds <- labeled_dataset |>   dataset_map(function(x, y) tuple(feature_space(x), y)) # Retrieve a named list of Keras layer_input() objects (inputs <- feature_space$get_inputs()) ## $float_values ## <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=float_values> ## ## $string_values ## <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=string_values> ## ## $int_values ## <KerasTensor shape=(None, 1), dtype=int32, sparse=None, name=int_values> # Retrieve the corresponding encoded Keras tensors (encoded_features <- feature_space$get_encoded_features()) ## <KerasTensor shape=(None, 43), dtype=float32, sparse=False, name=keras_tensor_7> # Build a Functional model outputs <- encoded_features |> layer_dense(1, activation = \"sigmoid\") model <- keras_model(inputs, outputs) feature_space <- layer_feature_space(   features = list(     float_values = feature_float_normalized(),     string_values = feature_string_categorical(max_tokens = 10),     int_values = feature_integer_categorical(max_tokens = 10)   ),   crosses = list(     feature_cross(c(\"string_values\", \"int_values\"), crossing_dim = 32)   ),   output_mode = \"concat\" ) feature_space <- layer_feature_space(   features = list(     \"string_values\" = feature_string_categorical(output_mode = \"int\"),     \"int_values\" = feature_integer_categorical(output_mode = \"int\")   ),   crosses = list(     feature_cross(       feature_names = c(\"string_values\", \"int_values\"),       crossing_dim = 32,       output_mode = \"int\"     )   ),   output_mode = \"dict\" ) # Let's say that one of the features is a short text paragraph that # we want to encode as a vector (one vector per paragraph) via TF-IDF. data <- list(text = c(\"1st string\", \"2nd string\", \"3rd string\"))  # There's a Keras layer for this: layer_text_vectorization() custom_layer <- layer_text_vectorization(output_mode = \"tf_idf\")  # We can use feature_custom() to create a custom feature # that will use our preprocessing layer. feature_space <- layer_feature_space(   features = list(     text = feature_custom(preprocessor = custom_layer,                           dtype = \"string\",                           output_mode = \"float\"     )   ),   output_mode = \"concat\" ) feature_space |> adapt(tfdatasets::tensor_slices_dataset(data)) output_vector <- feature_space(data) # The preprocessing layer of each feature is available in `$preprocessors`. preprocessing_layer <- feature_space$preprocessors$feature1  # The crossing layer of each feature cross is available in `$crossers`. # It's an instance of layer_hashed_crossing() crossing_layer <- feature_space$crossers[[\"feature1_X_feature2\"]] feature_space$save(\"featurespace.keras\") reloaded_feature_space <- keras$models$load_model(\"featurespace.keras\")"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_flatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Flattens the input. Does not affect the batch size. — layer_flatten","title":"Flattens the input. Does not affect the batch size. — layer_flatten","text":"Flattens input. affect batch size.","code":""},{"path":"https://keras.posit.co/reference/layer_flatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flattens the input. Does not affect the batch size. — layer_flatten","text":"","code":"layer_flatten(object, data_format = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_flatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flattens the input. Does not affect the batch size. — layer_flatten","text":"object Object compose layer . tensor, array, sequential model. data_format string, one \"channels_last\" (default) \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, ..., channels) \"channels_first\" corresponds inputs shape (batch, channels, ...). unspecified, uses image_data_format value found Keras config file ~/.keras/keras.json (exists). Defaults \"channels_last\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_flatten.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flattens the input. Does not affect the batch size. — layer_flatten","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_flatten.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Flattens the input. Does not affect the batch size. — layer_flatten","text":"inputs shaped (batch) without feature axis, flattening adds extra channel dimension output shape (batch, 1).","code":""},{"path":"https://keras.posit.co/reference/layer_flatten.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flattens the input. Does not affect the batch size. — layer_flatten","text":"","code":"x <- layer_input(shape=c(10, 64)) y <- x |> layer_flatten() shape(y) ## shape(NA, 640)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_gaussian_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply multiplicative 1-centered Gaussian noise. — layer_gaussian_dropout","title":"Apply multiplicative 1-centered Gaussian noise. — layer_gaussian_dropout","text":"regularization layer, active training time.","code":""},{"path":"https://keras.posit.co/reference/layer_gaussian_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply multiplicative 1-centered Gaussian noise. — layer_gaussian_dropout","text":"","code":"layer_gaussian_dropout(object, rate, seed = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_gaussian_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply multiplicative 1-centered Gaussian noise. — layer_gaussian_dropout","text":"object Object compose layer . tensor, array, sequential model. rate Float, drop probability (Dropout). multiplicative noise standard deviation sqrt(rate / (1 - rate)). seed Integer, optional random seed enable deterministic behavior. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_gaussian_dropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply multiplicative 1-centered Gaussian noise. — layer_gaussian_dropout","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_gaussian_dropout.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Apply multiplicative 1-centered Gaussian noise. — layer_gaussian_dropout","text":"inputs: Input tensor (rank). training: Python boolean indicating whether layer behave training mode (adding dropout) inference mode (nothing).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_gaussian_noise.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply additive zero-centered Gaussian noise. — layer_gaussian_noise","title":"Apply additive zero-centered Gaussian noise. — layer_gaussian_noise","text":"useful mitigate overfitting (see form random data augmentation). Gaussian Noise (GS) natural choice corruption process real valued inputs. regularization layer, active training time.","code":""},{"path":"https://keras.posit.co/reference/layer_gaussian_noise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply additive zero-centered Gaussian noise. — layer_gaussian_noise","text":"","code":"layer_gaussian_noise(object, stddev, seed = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_gaussian_noise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply additive zero-centered Gaussian noise. — layer_gaussian_noise","text":"object Object compose layer . tensor, array, sequential model. stddev Float, standard deviation noise distribution. seed Integer, optional random seed enable deterministic behavior. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_gaussian_noise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply additive zero-centered Gaussian noise. — layer_gaussian_noise","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_gaussian_noise.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Apply additive zero-centered Gaussian noise. — layer_gaussian_noise","text":"inputs: Input tensor (rank). training: Python boolean indicating whether layer behave training mode (adding noise) inference mode (nothing).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","title":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","text":"Global average pooling operation temporal data.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","text":"","code":"layer_global_average_pooling_1d(   object,   data_format = NULL,   keepdims = FALSE,   ... )"},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","text":"object Object compose layer . tensor, array, sequential model. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". keepdims boolean, whether keep temporal dimension . keepdims FALSE (default), rank tensor reduced spatial dimensions. keepdims TRUE, temporal dimension retained length 1. behavior tf$reduce_mean() op_mean(). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_1d.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","text":"inputs: 3D tensor. mask: Binary tensor shape (batch_size, steps) indicating whether given step masked (excluded average).","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","text":"data_format='channels_last': 3D tensor shape: (batch_size, steps, features) data_format='channels_first': 3D tensor shape: (batch_size, features, steps)","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","text":"keepdims=FALSE: 2D tensor shape (batch_size, features). keepdims=TRUE: data_format=\"channels_last\": 3D tensor shape (batch_size, 1, features) data_format=\"channels_first\": 3D tensor shape (batch_size, features, 1)","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global average pooling operation for temporal data. — layer_global_average_pooling_1d","text":"","code":"x <- random_uniform(c(2, 3, 4)) y <- x |> layer_global_average_pooling_1d() shape(y) ## shape(2, 4)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Global average pooling operation for 2D data. — layer_global_average_pooling_2d","title":"Global average pooling operation for 2D data. — layer_global_average_pooling_2d","text":"Global average pooling operation 2D data.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global average pooling operation for 2D data. — layer_global_average_pooling_2d","text":"","code":"layer_global_average_pooling_2d(   object,   data_format = NULL,   keepdims = FALSE,   ... )"},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global average pooling operation for 2D data. — layer_global_average_pooling_2d","text":"object Object compose layer . tensor, array, sequential model. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, features, height, weight). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". keepdims boolean, whether keep temporal dimension . keepdims FALSE (default), rank tensor reduced spatial dimensions. keepdims TRUE, spatial dimension retained length 1. behavior tf$reduce_mean() op_mean(). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global average pooling operation for 2D data. — layer_global_average_pooling_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Global average pooling operation for 2D data. — layer_global_average_pooling_2d","text":"data_format='channels_last': 4D tensor shape: (batch_size, height, width, channels) data_format='channels_first': 4D tensor shape: (batch_size, channels, height, width)","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Global average pooling operation for 2D data. — layer_global_average_pooling_2d","text":"keepdims=FALSE: 2D tensor shape (batch_size, channels). keepdims=TRUE: data_format=\"channels_last\": 4D tensor shape (batch_size, 1, 1, channels) data_format=\"channels_first\": 4D tensor shape (batch_size, channels, 1, 1)","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global average pooling operation for 2D data. — layer_global_average_pooling_2d","text":"","code":"x <- random_uniform(c(2, 4, 5, 3)) y <- x |> layer_global_average_pooling_2d() shape(y) ## shape(2, 3)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Global average pooling operation for 3D data. — layer_global_average_pooling_3d","title":"Global average pooling operation for 3D data. — layer_global_average_pooling_3d","text":"Global average pooling operation 3D data.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global average pooling operation for 3D data. — layer_global_average_pooling_3d","text":"","code":"layer_global_average_pooling_3d(   object,   data_format = NULL,   keepdims = FALSE,   ... )"},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global average pooling operation for 3D data. — layer_global_average_pooling_3d","text":"object Object compose layer . tensor, array, sequential model. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". keepdims boolean, whether keep temporal dimension . keepdims FALSE (default), rank tensor reduced spatial dimensions. keepdims TRUE, spatial dimension retained length 1. behavior tf$reduce_mean() op_mean(). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global average pooling operation for 3D data. — layer_global_average_pooling_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Global average pooling operation for 3D data. — layer_global_average_pooling_3d","text":"data_format='channels_last': 5D tensor shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) data_format='channels_first': 5D tensor shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Global average pooling operation for 3D data. — layer_global_average_pooling_3d","text":"keepdims=FALSE: 2D tensor shape (batch_size, channels). keepdims=TRUE: data_format=\"channels_last\": 5D tensor shape (batch_size, 1, 1, 1, channels) data_format=\"channels_first\": 5D tensor shape (batch_size, channels, 1, 1, 1)","code":""},{"path":"https://keras.posit.co/reference/layer_global_average_pooling_3d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global average pooling operation for 3D data. — layer_global_average_pooling_3d","text":"","code":"x <- random_uniform(c(2, 4, 5, 4, 3)) y <- x |> layer_global_average_pooling_3d() shape(y) ## shape(2, 3)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Global max pooling operation for temporal data. — layer_global_max_pooling_1d","title":"Global max pooling operation for temporal data. — layer_global_max_pooling_1d","text":"Global max pooling operation temporal data.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global max pooling operation for temporal data. — layer_global_max_pooling_1d","text":"","code":"layer_global_max_pooling_1d(object, data_format = NULL, keepdims = FALSE, ...)"},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global max pooling operation for temporal data. — layer_global_max_pooling_1d","text":"object Object compose layer . tensor, array, sequential model. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". keepdims boolean, whether keep temporal dimension . keepdims FALSE (default), rank tensor reduced spatial dimensions. keepdims TRUE, temporal dimension retained length 1. behavior tf$reduce_mean() op_mean(). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global max pooling operation for temporal data. — layer_global_max_pooling_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Global max pooling operation for temporal data. — layer_global_max_pooling_1d","text":"data_format='channels_last': 3D tensor shape: (batch_size, steps, features) data_format='channels_first': 3D tensor shape: (batch_size, features, steps)","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Global max pooling operation for temporal data. — layer_global_max_pooling_1d","text":"keepdims=FALSE: 2D tensor shape (batch_size, features). keepdims=TRUE: data_format=\"channels_last\": 3D tensor shape (batch_size, 1, features) data_format=\"channels_first\": 3D tensor shape (batch_size, features, 1)","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global max pooling operation for temporal data. — layer_global_max_pooling_1d","text":"","code":"x <- random_uniform(c(2, 3, 4)) y <- x |> layer_global_max_pooling_1d() shape(y) ## shape(2, 4)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Global max pooling operation for 2D data. — layer_global_max_pooling_2d","title":"Global max pooling operation for 2D data. — layer_global_max_pooling_2d","text":"Global max pooling operation 2D data.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global max pooling operation for 2D data. — layer_global_max_pooling_2d","text":"","code":"layer_global_max_pooling_2d(object, data_format = NULL, keepdims = FALSE, ...)"},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global max pooling operation for 2D data. — layer_global_max_pooling_2d","text":"object Object compose layer . tensor, array, sequential model. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, features, height, weight). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". keepdims boolean, whether keep temporal dimension . keepdims FALSE (default), rank tensor reduced spatial dimensions. keepdims TRUE, spatial dimension retained length 1. behavior tf$reduce_mean() op_mean(). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global max pooling operation for 2D data. — layer_global_max_pooling_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Global max pooling operation for 2D data. — layer_global_max_pooling_2d","text":"data_format='channels_last': 4D tensor shape: (batch_size, height, width, channels) data_format='channels_first': 4D tensor shape: (batch_size, channels, height, width)","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Global max pooling operation for 2D data. — layer_global_max_pooling_2d","text":"keepdims=FALSE: 2D tensor shape (batch_size, channels). keepdims=TRUE: data_format=\"channels_last\": 4D tensor shape (batch_size, 1, 1, channels) data_format=\"channels_first\": 4D tensor shape (batch_size, channels, 1, 1)","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global max pooling operation for 2D data. — layer_global_max_pooling_2d","text":"","code":"x <- random_uniform(c(2, 4, 5, 3)) y <- x |> layer_global_max_pooling_2d() shape(y) ## shape(2, 3)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Global max pooling operation for 3D data. — layer_global_max_pooling_3d","title":"Global max pooling operation for 3D data. — layer_global_max_pooling_3d","text":"Global max pooling operation 3D data.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global max pooling operation for 3D data. — layer_global_max_pooling_3d","text":"","code":"layer_global_max_pooling_3d(object, data_format = NULL, keepdims = FALSE, ...)"},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global max pooling operation for 3D data. — layer_global_max_pooling_3d","text":"object Object compose layer . tensor, array, sequential model. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". keepdims boolean, whether keep temporal dimension . keepdims FALSE (default), rank tensor reduced spatial dimensions. keepdims TRUE, spatial dimension retained length 1. behavior tf$reduce_mean() op_mean(). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global max pooling operation for 3D data. — layer_global_max_pooling_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Global max pooling operation for 3D data. — layer_global_max_pooling_3d","text":"data_format='channels_last': 5D tensor shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) data_format='channels_first': 5D tensor shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Global max pooling operation for 3D data. — layer_global_max_pooling_3d","text":"keepdims=FALSE: 2D tensor shape (batch_size, channels). keepdims=TRUE: data_format=\"channels_last\": 5D tensor shape (batch_size, 1, 1, 1, channels) data_format=\"channels_first\": 5D tensor shape (batch_size, channels, 1, 1, 1)","code":""},{"path":"https://keras.posit.co/reference/layer_global_max_pooling_3d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global max pooling operation for 3D data. — layer_global_max_pooling_3d","text":"","code":"x <- random_uniform(c(2, 4, 5, 4, 3)) y <- x |> layer_global_max_pooling_3d() shape(y) ## shape(2, 3)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_group_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"Group normalization layer. — layer_group_normalization","title":"Group normalization layer. — layer_group_normalization","text":"Group Normalization divides channels groups computes within group mean variance normalization. Empirically, accuracy stable batch norm wide range small batch sizes, learning rate adjusted linearly batch sizes. Relation Layer Normalization: number groups set 1, operation becomes nearly identical Layer Normalization (see Layer Normalization docs details). Relation Instance Normalization: number groups set input dimension (number groups equal number channels), operation becomes identical Instance Normalization. can achieve via groups=-1.","code":""},{"path":"https://keras.posit.co/reference/layer_group_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group normalization layer. — layer_group_normalization","text":"","code":"layer_group_normalization(   object,   groups = 32L,   axis = -1L,   epsilon = 0.001,   center = TRUE,   scale = TRUE,   beta_initializer = \"zeros\",   gamma_initializer = \"ones\",   beta_regularizer = NULL,   gamma_regularizer = NULL,   beta_constraint = NULL,   gamma_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_group_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group normalization layer. — layer_group_normalization","text":"object Object compose layer . tensor, array, sequential model. groups Integer, number groups Group Normalization. Can range [1, N] N input dimension. input dimension must divisible number groups. Defaults 32. axis Integer List/Tuple. axis axes normalize across. Typically, features axis/axes. left-axes typically batch axis/axes. -1 last dimension input. Defaults -1. epsilon Small float added variance avoid dividing zero. Defaults 1e-3. center TRUE, add offset beta normalized tensor. FALSE, beta ignored. Defaults TRUE. scale TRUE, multiply gamma. FALSE, gamma used. next layer linear (also e.g. relu), can disabled since scaling done next layer. Defaults TRUE. beta_initializer Initializer beta weight. Defaults zeros. gamma_initializer Initializer gamma weight. Defaults ones. beta_regularizer Optional regularizer beta weight. NULL default. gamma_regularizer Optional regularizer gamma weight. NULL default. beta_constraint Optional constraint beta weight. NULL default. gamma_constraint Optional constraint gamma weight. NULL default. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_group_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group normalization layer. — layer_group_normalization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_group_normalization.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Group normalization layer. — layer_group_normalization","text":"Arbitrary. Use keyword argument input_shape (tuple integers, include samples axis) using layer first layer model.","code":""},{"path":"https://keras.posit.co/reference/layer_group_normalization.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Group normalization layer. — layer_group_normalization","text":"shape input. **kwargs: Base layer keyword arguments (e.g. name dtype).","code":""},{"path":"https://keras.posit.co/reference/layer_group_normalization.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Group normalization layer. — layer_group_normalization","text":"Yuxin Wu & Kaiming , 2018","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_group_query_attention.html","id":null,"dir":"Reference","previous_headings":"","what":"Grouped Query Attention layer. — layer_group_query_attention","title":"Grouped Query Attention layer. — layer_group_query_attention","text":"implementation grouped-query attention introduced Ainslie et al., 2023. num_key_value_heads denotes number groups, setting num_key_value_heads 1 equivalent multi-query attention, num_key_value_heads equal num_query_heads equivalent multi-head attention. layer first projects query, key, value tensors. , key value repeated match number heads query. , query scaled dot-producted key tensors. softmaxed obtain attention probabilities. value tensors interpolated probabilities concatenated back single tensor.","code":""},{"path":"https://keras.posit.co/reference/layer_group_query_attention.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grouped Query Attention layer. — layer_group_query_attention","text":"","code":"layer_group_query_attention(   object,   head_dim,   num_query_heads,   num_key_value_heads,   dropout = 0,   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_group_query_attention.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grouped Query Attention layer. — layer_group_query_attention","text":"object Object compose layer . tensor, array, sequential model. head_dim Size attention head. num_query_heads Number query attention heads. num_key_value_heads Number key value attention heads. dropout Dropout probability. use_bias Boolean, whether dense layers use bias vectors/matrices. kernel_initializer Initializer dense layer kernels. bias_initializer Initializer dense layer biases. kernel_regularizer Regularizer dense layer kernels. bias_regularizer Regularizer dense layer biases. activity_regularizer Regularizer dense layer activity. kernel_constraint Constraint dense layer kernels. bias_constraint Constraint dense layer kernels. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_group_query_attention.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grouped Query Attention layer. — layer_group_query_attention","text":"attention_output: Result computation, shape (batch_dim, target_seq_len, feature_dim), target_seq_len target sequence length feature_dim query input last dim. attention_scores: (Optional) attention coefficients shape (batch_dim, num_query_heads, target_seq_len, source_seq_len).","code":""},{"path":"https://keras.posit.co/reference/layer_group_query_attention.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Grouped Query Attention layer. — layer_group_query_attention","text":"query: Query tensor shape (batch_dim, target_seq_len, feature_dim), batch_dim batch size, target_seq_len length target sequence, feature_dim dimension feature. value: Value tensor shape (batch_dim, source_seq_len, feature_dim), batch_dim batch size, source_seq_len length source sequence, feature_dim dimension feature. key: Optional key tensor shape (batch_dim, source_seq_len, feature_dim). given, use value key value, common case. attention_mask: boolean mask shape (batch_dim, target_seq_len, source_seq_len), prevents attention certain positions. boolean mask specifies query elements can attend key elements, 1 indicates attention 0 indicates attention. Broadcasting can happen missing batch dimensions head dimension. return_attention_scores: boolean indicate whether output (attention_output, attention_scores) TRUE, attention_output FALSE. Defaults FALSE. training: Python boolean indicating whether layer behave training mode (adding dropout) inference mode (dropout). go either using training mode parent layer/model FALSE (inference) parent layer. use_causal_mask: boolean indicate whether apply causal mask prevent tokens attending future tokens (e.g., used decoder Transformer).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_gru.html","id":null,"dir":"Reference","previous_headings":"","what":"Gated Recurrent Unit - Cho et al. 2014. — layer_gru","title":"Gated Recurrent Unit - Cho et al. 2014. — layer_gru","text":"Based available runtime hardware constraints, layer choose different implementations (cuDNN-based backend-native) maximize performance. GPU available arguments layer meet requirement cuDNN kernel (see details), layer use fast cuDNN implementation using TensorFlow backend. requirements use cuDNN implementation : activation == tanh recurrent_activation == sigmoid dropout == 0 recurrent_dropout == 0 unroll FALSE use_bias TRUE reset_after TRUE Inputs, use masking, strictly right-padded. Eager execution enabled outermost context. two variants GRU implementation. default one based v3 reset gate applied hidden state matrix multiplication. one based original order reversed. second variant compatible CuDNNGRU (GPU-) allows inference CPU. Thus separate biases kernel recurrent_kernel. use variant, set reset_after=TRUE recurrent_activation='sigmoid'. example:","code":"inputs <- random_uniform(c(32, 10, 8)) outputs <- inputs |> layer_gru(4) shape(outputs) ## shape(32, 4) # (32, 4) gru <- layer_gru(, 4, return_sequences = TRUE, return_state = TRUE) c(whole_sequence_output, final_state) %<-% gru(inputs) shape(whole_sequence_output) ## shape(32, 10, 4) shape(final_state) ## shape(32, 4)"},{"path":"https://keras.posit.co/reference/layer_gru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gated Recurrent Unit - Cho et al. 2014. — layer_gru","text":"","code":"layer_gru(   object,   units,   activation = \"tanh\",   recurrent_activation = \"sigmoid\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   seed = NULL,   return_sequences = FALSE,   return_state = FALSE,   go_backwards = FALSE,   stateful = FALSE,   unroll = FALSE,   reset_after = TRUE,   ... )"},{"path":"https://keras.posit.co/reference/layer_gru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gated Recurrent Unit - Cho et al. 2014. — layer_gru","text":"object Object compose layer . tensor, array, sequential model. units Positive integer, dimensionality output space. activation Activation function use. Default: hyperbolic tangent (tanh). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). recurrent_activation Activation function use recurrent step. Default: sigmoid (sigmoid). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). use_bias Boolean, (default TRUE), whether layer use bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. Default: \"glorot_uniform\". recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state. Default: \"orthogonal\". bias_initializer Initializer bias vector. Default: \"zeros\". kernel_regularizer Regularizer function applied kernel weights matrix. Default: NULL. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. Default: NULL. bias_regularizer Regularizer function applied bias vector. Default: NULL. activity_regularizer Regularizer function applied output layer (\"activation\"). Default: NULL. kernel_constraint Constraint function applied kernel weights matrix. Default: NULL. recurrent_constraint Constraint function applied recurrent_kernel weights matrix. Default: NULL. bias_constraint Constraint function applied bias vector. Default: NULL. dropout Float 0 1. Fraction units drop linear transformation inputs. Default: 0. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. Default: 0. seed Random seed dropout. return_sequences Boolean. Whether return last output output sequence, full sequence. Default: FALSE. return_state Boolean. Whether return last state addition output. Default: FALSE. go_backwards Boolean (default FALSE). TRUE, process input sequence backwards return reversed sequence. stateful Boolean (default: FALSE). TRUE, last state sample index batch used initial state sample index following batch. unroll Boolean (default: FALSE). TRUE, network unrolled, else symbolic loop used. Unrolling can speed-RNN, although tends memory-intensive. Unrolling suitable short sequences. reset_after GRU convention (whether apply reset gate matrix multiplication). FALSE \"\", TRUE \"\" (default cuDNN compatible). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_gru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gated Recurrent Unit - Cho et al. 2014. — layer_gru","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_gru.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Gated Recurrent Unit - Cho et al. 2014. — layer_gru","text":"inputs: 3D tensor, shape (batch, timesteps, feature). mask: Binary tensor shape (samples, timesteps) indicating whether given timestep masked  (optional). individual TRUE entry indicates corresponding timestep utilized, FALSE entry indicates corresponding timestep ignored. Defaults NULL. training: Python boolean indicating whether layer behave training mode inference mode. argument passed cell calling . relevant dropout recurrent_dropout used  (optional). Defaults NULL. initial_state: List initial state tensors passed first call cell (optional, NULL causes creation zero-filled initial state tensors). Defaults NULL.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_hashed_crossing.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which crosses features using the ","title":"A preprocessing layer which crosses features using the ","text":"layer performs crosses categorical features using \"hashing trick\". Conceptually, transformation can thought : hash(concatenate(features)) %% num_bins. layer currently performs crosses scalar inputs batches scalar inputs. Valid input shapes (batch_size, 1), (batch_size) (). Note: layer wraps tf.keras.layers.HashedCrossing. used part compiled computation graph model backend TensorFlow. can however used backend running eagerly. can also always used part input preprocessing pipeline backend (outside model ), recommend use layer. Note: layer safe use inside tfdatasets pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_hashed_crossing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which crosses features using the ","text":"","code":"layer_hashed_crossing(   object,   num_bins,   output_mode = \"int\",   sparse = FALSE,   name = NULL,   dtype = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_hashed_crossing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which crosses features using the ","text":"object Object compose layer . tensor, array, sequential model. num_bins Number hash bins. output_mode Specification output layer. Values can \"int\", \"one_hot\" configuring layer follows: \"int\": Return integer bin indices directly. \"one_hot\": Encodes individual element input array size num_bins, containing 1 input's bin index. Defaults \"int\". sparse Boolean. applicable \"one_hot\" mode valid using TensorFlow backend. TRUE, returns SparseTensor instead dense Tensor. Defaults FALSE. name String, name object dtype datatype (e.g., \"float32\"). ... Keyword arguments construct layer.","code":""},{"path":"https://keras.posit.co/reference/layer_hashed_crossing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which crosses features using the ","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_hashed_crossing.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer which crosses features using the ","text":"Crossing two scalar features.     Crossing one-hotting two scalar features.","code":"feat1 <- c('A', 'B', 'A', 'B', 'A') |> as.array() feat2 <- c(101, 101, 101, 102, 102) |> as.integer() |> as.array() layer <- layer_hashed_crossing(num_bins = 5) layer(list(feat1, feat2)) ## tf.Tensor([1 4 1 1 3], shape=(5), dtype=int64) layer <- layer_hashed_crossing(num_bins = 5, output_mode = 'one_hot') layer(list(feat1, feat2)) ## tf.Tensor( ## [[0. 1. 0. 0. 0.] ##  [0. 0. 0. 0. 1.] ##  [0. 1. 0. 0. 0.] ##  [0. 1. 0. 0. 0.] ##  [0. 0. 0. 1. 0.]], shape=(5, 5), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_hashing.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which hashes and bins categorical features. — layer_hashing","title":"A preprocessing layer which hashes and bins categorical features. — layer_hashing","text":"layer transforms categorical inputs hashed output. element-wise converts ints strings ints fixed range. stable hash function uses tensorflow::ops::Fingerprint produce output consistently across platforms. layer uses FarmHash64 default, provides consistent hashed output across different platforms stable across invocations, regardless device context, mixing input bits thoroughly. want obfuscate hashed output, can also pass random salt argument constructor. case, layer use SipHash64 hash function, salt value serving additional input hash function. Note: layer internally uses TensorFlow. used part compiled computation graph model backend TensorFlow. can however used backend running eagerly. can also always used part input preprocessing pipeline backend (outside model ), recommend use layer. Note: layer safe use inside tf.data pipeline (independently backend using). Example (FarmHash64)     Example (FarmHash64) mask value     Example (SipHash64)     Example (Siphash64 single integer, salt=[133, 133])","code":"layer <- layer_hashing(num_bins = 3) inp <- c('A', 'B', 'C', 'D', 'E') |> array(dim = c(5, 1)) layer(inp) ## tf.Tensor( ## [[1] ##  [0] ##  [1] ##  [1] ##  [2]], shape=(5, 1), dtype=int64) layer <- layer_hashing(num_bins=3, mask_value='') inp <- c('A', 'B', '', 'C', 'D') |> array(dim = c(5, 1)) layer(inp) ## tf.Tensor( ## [[1] ##  [1] ##  [0] ##  [2] ##  [2]], shape=(5, 1), dtype=int64) layer <- layer_hashing(num_bins=3, salt=c(133, 137)) inp <- c('A', 'B', 'C', 'D', 'E') |> array(dim = c(5, 1)) layer(inp) ## tf.Tensor( ## [[1] ##  [2] ##  [1] ##  [0] ##  [2]], shape=(5, 1), dtype=int64) layer <- layer_hashing(num_bins=3, salt=133) inp <- c('A', 'B', 'C', 'D', 'E') |> array(dim = c(5, 1)) layer(inp) ## tf.Tensor( ## [[0] ##  [0] ##  [2] ##  [1] ##  [0]], shape=(5, 1), dtype=int64)"},{"path":"https://keras.posit.co/reference/layer_hashing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which hashes and bins categorical features. — layer_hashing","text":"","code":"layer_hashing(   object,   num_bins,   mask_value = NULL,   salt = NULL,   output_mode = \"int\",   sparse = FALSE,   ... )"},{"path":"https://keras.posit.co/reference/layer_hashing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which hashes and bins categorical features. — layer_hashing","text":"object Object compose layer . tensor, array, sequential model. num_bins Number hash bins. Note includes mask_value bin, effective number bins (num_bins - 1) mask_value set. mask_value value represents masked inputs, mapped index 0. NULL means mask term added hashing start index 0. Defaults NULL. salt single unsigned integer NULL. passed, hash function used SipHash64, values used additional input (known \"salt\" cryptography). non-zero. NULL, uses FarmHash64 hash function. also supports list 2 unsigned integer numbers, see reference paper details. Defaults NULL. output_mode Specification output layer. Values can \"int\", \"one_hot\", \"multi_hot\", \"count\" configuring layer follows: \"int\": Return integer bin indices directly. \"one_hot\": Encodes individual element input array size num_bins, containing 1 input's bin index. last dimension size 1, encode dimension. last dimension size 1, append new dimension encoded output. \"multi_hot\": Encodes sample input single array size num_bins, containing 1 bin index index present sample. Treats last dimension sample dimension, input shape (..., sample_length), output shape (..., num_tokens). \"count\": \"multi_hot\", int array contains count number times bin index appeared sample. Defaults \"int\". sparse Boolean. applicable \"one_hot\", \"multi_hot\", \"count\" output modes. supported TensorFlow backend. TRUE, returns SparseTensor instead dense Tensor. Defaults FALSE. ... Keyword arguments construct layer.","code":""},{"path":"https://keras.posit.co/reference/layer_hashing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which hashes and bins categorical features. — layer_hashing","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_hashing.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which hashes and bins categorical features. — layer_hashing","text":"single string, list strings, int32 int64 tensor shape (batch_size, ...,).","code":""},{"path":"https://keras.posit.co/reference/layer_hashing.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which hashes and bins categorical features. — layer_hashing","text":"int32 tensor shape (batch_size, ...).","code":""},{"path":"https://keras.posit.co/reference/layer_hashing.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"A preprocessing layer which hashes and bins categorical features. — layer_hashing","text":"SipHash salt","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Identity layer. — layer_identity","title":"Identity layer. — layer_identity","text":"layer used placeholder operation performed. layer just returns inputs argument output.","code":""},{"path":"https://keras.posit.co/reference/layer_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identity layer. — layer_identity","text":"","code":"layer_identity(object, ...)"},{"path":"https://keras.posit.co/reference/layer_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identity layer. — layer_identity","text":"object Object compose layer . tensor, array, sequential model. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identity layer. — layer_identity","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_input.html","id":null,"dir":"Reference","previous_headings":"","what":"keras_input — layer_input","title":"keras_input — layer_input","text":"layer_input() alias keras_input(). See ?keras_input() full documentation.","code":""},{"path":"https://keras.posit.co/reference/layer_input.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"keras_input — layer_input","text":"","code":"layer_input(   shape = NULL,   batch_size = NULL,   dtype = NULL,   sparse = NULL,   batch_shape = NULL,   name = NULL,   tensor = NULL )"},{"path":"https://keras.posit.co/reference/layer_input.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"keras_input — layer_input","text":"shape shape list (list integers NULL objects), including batch size. instance, shape = c(32) indicates expected input batches 32-dimensional vectors. Elements list can NULL NA; NULL/NA elements represent dimensions shape known may vary (e.g. sequence length). batch_size Optional static batch size (integer). dtype data type expected input, string (e.g. \"float32\", \"int32\"...) sparse boolean specifying whether expected input sparse tensors. Note , sparse FALSE, sparse tensors can still passed input - densified default value 0. feature supported TensorFlow backend. Defaults FALSE. batch_shape Shape, including batch dim. name Optional name string layer. unique model (reuse name twice). autogenerated provided. tensor Optional existing tensor wrap Input layer. set, layer use tensor rather creating new placeholder tensor.","code":""},{"path":"https://keras.posit.co/reference/layer_input.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"keras_input — layer_input","text":"Keras tensor, can passed inputs argument (keras_model()).","code":""},{"path":"https://keras.posit.co/reference/layer_integer_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer that maps integers to (possibly encoded) indices. — layer_integer_lookup","title":"A preprocessing layer that maps integers to (possibly encoded) indices. — layer_integer_lookup","text":"layer maps set arbitrary integer input tokens indexed integer output via table-based vocabulary lookup. layer's output indices contiguously arranged maximum vocab size, even input tokens non-continguous unbounded. layer supports multiple options encoding output via output_mode, optional support --vocabulary (OOV) tokens masking. vocabulary layer must either supplied construction learned via adapt(). adapt(), layer analyze data set, determine frequency individual integer tokens, create vocabulary . vocabulary capped size, frequent tokens used create vocabulary others treated OOV. two possible output modes layer.  output_mode \"int\", input integers converted index vocabulary (integer).  output_mode \"multi_hot\", \"count\", \"tf_idf\", input integers encoded array dimension corresponds element vocabulary. vocabulary can optionally contain mask token well OOV token (can optionally occupy multiple indices vocabulary, set num_oov_indices). position tokens vocabulary fixed. output_mode \"int\", vocabulary begin mask token index 0, followed OOV indices, followed rest vocabulary. output_mode \"multi_hot\", \"count\", \"tf_idf\" vocabulary begin OOV indices instances mask token dropped. Note: layer uses TensorFlow internally. used part compiled computation graph model backend TensorFlow. can however used backend running eagerly. can also always used part input preprocessing pipeline backend (outside model ), recommend use layer. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_integer_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer that maps integers to (possibly encoded) indices. — layer_integer_lookup","text":"","code":"layer_integer_lookup(   object,   max_tokens = NULL,   num_oov_indices = 1L,   mask_token = NULL,   oov_token = -1L,   vocabulary = NULL,   vocabulary_dtype = \"int64\",   idf_weights = NULL,   invert = FALSE,   output_mode = \"int\",   sparse = FALSE,   pad_to_max_tokens = FALSE,   name = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_integer_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer that maps integers to (possibly encoded) indices. — layer_integer_lookup","text":"object Object compose layer . tensor, array, sequential model. max_tokens Maximum size vocabulary layer. specified adapting vocabulary setting pad_to_max_tokens=TRUE. NULL, cap size vocabulary. Note size includes OOV mask tokens. Defaults NULL. num_oov_indices number --vocabulary tokens use. value 1, OOV inputs modulated determine OOV value. value 0, OOV inputs cause error calling layer. Defaults 1. mask_token integer token represents masked inputs. output_mode \"int\", token included vocabulary mapped index 0. output modes, token appear vocabulary instances mask token input dropped. set NULL, mask term added. Defaults NULL. oov_token used invert TRUE. token return OOV indices. Defaults -1. vocabulary Optional. Either array integers string path text file. passing array, can pass list, list, 1D NumPy array, 1D tensor containing integer vocbulary terms. passing file path, file contain one line per term vocabulary. argument set, need adapt() layer. vocabulary_dtype dtype vocabulary terms, example \"int64\" \"int32\". Defaults \"int64\". idf_weights valid output_mode \"tf_idf\". list, list, 1D NumPy array, 1D tensor length vocabulary, containing floating point inverse document frequency weights, multiplied per sample term counts final TF-IDF weight. vocabulary argument set, output_mode \"tf_idf\", argument must supplied. invert valid output_mode \"int\". TRUE, layer map indices vocabulary items instead mapping vocabulary items indices. Defaults FALSE. output_mode Specification output layer. Values can \"int\", \"one_hot\", \"multi_hot\", \"count\", \"tf_idf\" configuring layer follows: \"int\": Return vocabulary indices input tokens. \"one_hot\": Encodes individual element input array size vocabulary, containing 1 element index. last dimension size 1, encode dimension. last dimension size 1, append new dimension encoded output. \"multi_hot\": Encodes sample input single array size vocabulary, containing 1 vocabulary term present sample. Treats last dimension sample dimension, input shape (..., sample_length), output shape (..., num_tokens). \"count\": \"multi_hot\", int array contains count number times token index appeared sample. \"tf_idf\": \"multi_hot\", TF-IDF algorithm applied find value token slot. \"int\" output, shape input output supported. output modes, currently output rank 2 supported. Defaults \"int\". sparse Boolean. applicable \"multi_hot\", \"count\", \"tf_idf\" output modes. supported TensorFlow backend. TRUE, returns SparseTensor instead dense Tensor. Defaults FALSE. pad_to_max_tokens applicable output_mode \"multi_hot\", \"count\", \"tf_idf\". TRUE, output feature axis padded max_tokens even number unique tokens vocabulary less max_tokens, resulting tensor shape (batch_size, max_tokens) regardless vocabulary size. Defaults FALSE. name String, name object ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_integer_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer that maps integers to (possibly encoded) indices. — layer_integer_lookup","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_integer_lookup.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer that maps integers to (possibly encoded) indices. — layer_integer_lookup","text":"Creating lookup layer known vocabulary example creates lookup layer pre-existing vocabulary.     Creating lookup layer adapted vocabulary example creates lookup layer generates vocabulary analyzing dataset.     Note OOV token -1 added vocabulary. remaining tokens sorted frequency (42, 2 occurrences, first) inverse sort order.     Lookups multiple OOV indices example demonstrates use lookup layer multiple OOV indices.  layer created one OOV index, OOV tokens hashed number OOV buckets, distributing OOV tokens deterministic fashion across set.     Note output OOV token 37 1, output OOV token 1000 0. -vocab terms output index increased 1 earlier examples (12 maps 2, etc) order make space extra OOV token. One-hot output Configure layer output_mode='one_hot'. Note first num_oov_indices dimensions ont_hot encoding represent OOV values.     Multi-hot output Configure layer output_mode = 'multi_hot'. Note first num_oov_indices dimensions multi_hot encoding represent OOV tokens     Token count output Configure layer output_mode='count'. multi_hot output, first num_oov_indices dimensions output represent OOV tokens.     TF-IDF output Configure layer output_mode='tf_idf'. multi_hot output, first num_oov_indices dimensions output represent OOV tokens. token bin output token_count * idf_weight, idf weights inverse document frequency weights per token. provided along vocabulary. Note idf_weight OOV tokens default average idf weights passed .     specify idf weights oov tokens, need pass entire vocabulary including leading oov token.     adapting layer \"tf_idf\" mode, input sample considered document, IDF weight per token calculated : log(1 + num_documents / (1 + token_document_count)). Inverse lookup example demonstrates map indices tokens using layer. (can also use adapt() inverse = TRUE, simplicity pass vocab example.)     Note first index correspond oov token default. Forward inverse lookup pairs example demonstrates use vocabulary standard lookup layer create inverse lookup layer.     example, input token 1000 resulted output -1, since 1000 vocabulary - got represented OOV, OOV tokens returned -1 inverse layer. Also, note inverse work, must already set forward layer vocabulary either directly via adapt() calling get_vocabulary().","code":"vocab <- c(12, 36, 1138, 42) |> as.integer() data <- op_array(rbind(c(12, 1138, 42),                       c(42, 1000, 36)))  # Note OOV tokens out <- data |> layer_integer_lookup(vocabulary = vocab) out ## tf.Tensor( ## [[1 3 4] ##  [4 0 2]], shape=(2, 3), dtype=int64) data <- op_array(rbind(c(12, 1138, 42),                       c(42, 1000, 36)))  # Note OOV tokens layer <- layer_integer_lookup() layer |> adapt(data) layer |> get_vocabulary() |> str() ## List of 6 ##  $ : int -1 ##  $ : num 42 ##  $ : num 1138 ##  $ : num 1000 ##  $ : num 36 ##  $ : num 12 layer(data) ## tf.Tensor( ## [[5 2 1] ##  [1 3 4]], shape=(2, 3), dtype=int64) vocab <- c(12, 36, 1138, 42) |> as.integer() data <- op_array(rbind(c(12, 1138, 42),                       c(37, 1000, 36)))  # Note OOV tokens out <- data |>   layer_integer_lookup(vocabulary = vocab,                        num_oov_indices = 2) out ## tf.Tensor( ## [[2 4 5] ##  [1 0 3]], shape=(2, 3), dtype=int64) vocab <- c(12, 36, 1138, 42) |> as.integer() data <- op_array(c(12, 36, 1138, 42, 7), 'int32')  # Note OOV tokens layer <- layer_integer_lookup(vocabulary = vocab,                               output_mode = 'one_hot') layer(data) ## tf.Tensor( ## [[0 1 0 0 0] ##  [0 0 1 0 0] ##  [0 0 0 1 0] ##  [0 0 0 0 1] ##  [1 0 0 0 0]], shape=(5, 5), dtype=int64) vocab <- c(12, 36, 1138, 42) |> as.integer() data <- op_array(rbind(c(12, 1138, 42, 42),                       c(42,    7, 36,  7)), \"int64\")  # Note OOV tokens layer <- layer_integer_lookup(vocabulary = vocab,                               output_mode = 'multi_hot') layer(data) ## tf.Tensor( ## [[0 1 0 1 1] ##  [1 0 1 0 1]], shape=(2, 5), dtype=int64) vocab <- c(12, 36, 1138, 42) |> as.integer() data <- rbind(c(12, 1138, 42, 42),               c(42,    7, 36,  7)) |> op_array(\"int64\") layer <- layer_integer_lookup(vocabulary = vocab,                               output_mode = 'count') layer(data) ## tf.Tensor( ## [[0 1 0 1 2] ##  [2 0 1 0 1]], shape=(2, 5), dtype=int64) vocab <- c(12, 36, 1138, 42) |> as.integer() idf_weights <- c(0.25, 0.75, 0.6, 0.4) data <- rbind(c(12, 1138, 42, 42),               c(42,    7, 36,  7)) |> op_array(\"int64\") layer <- layer_integer_lookup(output_mode = 'tf_idf',                               vocabulary = vocab,                               idf_weights = idf_weights) layer(data) ## tf.Tensor( ## [[0.   0.25 0.   0.6  0.8 ] ##  [1.   0.   0.75 0.   0.4 ]], shape=(2, 5), dtype=float32) vocab <- c(-1, 12, 36, 1138, 42) |> as.integer() idf_weights <- c(0.9, 0.25, 0.75, 0.6, 0.4) data <- rbind(c(12, 1138, 42, 42),               c(42,    7, 36,  7)) |> op_array(\"int64\") layer <- layer_integer_lookup(output_mode = 'tf_idf',                               vocabulary = vocab,                               idf_weights = idf_weights) layer(data) ## tf.Tensor( ## [[0.   0.25 0.   0.6  0.8 ] ##  [1.8  0.   0.75 0.   0.4 ]], shape=(2, 5), dtype=float32) vocab <- c(12, 36, 1138, 42) |> as.integer() data <- op_array(c(1, 3, 4,                   4, 0, 2)) |> op_reshape(c(2,-1)) |> op_cast(\"int32\") layer <- layer_integer_lookup(vocabulary = vocab, invert = TRUE) layer(data) ## tf.Tensor( ## [[  12 1138   42] ##  [  42   -1   36]], shape=(2, 3), dtype=int64) vocab <- c(12, 36, 1138, 42) |> as.integer() data <- op_array(rbind(c(12, 1138, 42), c(42, 1000, 36)), \"int32\") layer <- layer_integer_lookup(vocabulary = vocab) i_layer <- layer_integer_lookup(vocabulary = get_vocabulary(layer),                                 invert = TRUE) int_data <- layer(data) i_layer(int_data) ## tf.Tensor( ## [[  12 1138   42] ##  [  42   -1   36]], shape=(2, 3), dtype=int64)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Wraps arbitrary expressions as a Layer object. — layer_lambda","title":"Wraps arbitrary expressions as a Layer object. — layer_lambda","text":"layer_lambda() layer exists arbitrary expressions can used Layer constructing Sequential Functional API models. Lambda layers best suited simple operations quick experimentation. advanced use cases, prefer writing new subclasses Layer using new_layer_class().","code":""},{"path":"https://keras.posit.co/reference/layer_lambda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wraps arbitrary expressions as a Layer object. — layer_lambda","text":"","code":"layer_lambda(   object,   f,   output_shape = NULL,   mask = NULL,   arguments = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wraps arbitrary expressions as a Layer object. — layer_lambda","text":"object Object compose layer . tensor, array, sequential model. f function evaluated. Takes input tensor first argument. output_shape Expected output shape function. argument can usually inferred explicitly provided. Can list function. list, specifies first dimension onward; sample dimension assumed either input: output_shape = c(input_shape[1], output_shape) , input NULL sample dimension also NULL: output_shape = c(NA, output_shape). function, specifies entire shape function input shape: output_shape = f(input_shape). mask Either NULL (indicating masking) callable signature compute_mask layer method, tensor returned output mask regardless input . arguments Optional named list arguments passed function. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_lambda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wraps arbitrary expressions as a Layer object. — layer_lambda","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_lambda.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wraps arbitrary expressions as a Layer object. — layer_lambda","text":"","code":"# add a x -> x^2 layer model <- keras_model_sequential() model |> layer_lambda(\\(x) x^2)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_layer_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer normalization layer (Ba et al., 2016). — layer_layer_normalization","title":"Layer normalization layer (Ba et al., 2016). — layer_layer_normalization","text":"Normalize activations previous layer given example batch independently, rather across batch like Batch Normalization. .e. applies transformation maintains mean activation within example close 0 activation standard deviation close 1. scale center enabled, layer scale normalized outputs broadcasting trainable variable gamma, center outputs broadcasting trainable variable beta. gamma default ones tensor beta default zeros tensor, centering scaling -ops training begun. , scaling centering enabled normalization equations follows: Let intermediate activations mini-batch inputs. sample x batch inputs, compute mean variance sample, normalize value sample (including small factor epsilon numerical stability), finally, transform normalized output gamma beta, learned parameters:   gamma beta span axes inputs specified axis, part inputs' shape must fully defined. example:         Note implementations layer normalization may choose define gamma beta separate set axes axes normalized across. example, Group Normalization (Wu et al. 2018) group size 1 corresponds layer_layer_normalization() normalizes across height, width, channel gamma beta span channel dimension. , layer_layer_normalization() implementation match layer_group_normalization() layer group size set 1.","code":"outputs <- inputs |> apply(1, function(x) {   x_normalized <- (x - mean(x)) /                   sqrt(var(x) + epsilon)   x_normalized * gamma + beta }) layer <- layer_layer_normalization(axis = c(2, 3, 4))  layer(op_ones(c(5, 20, 30, 40))) |> invisible() # build() shape(layer$beta) ## shape(20, 30, 40) shape(layer$gamma) ## shape(20, 30, 40)"},{"path":"https://keras.posit.co/reference/layer_layer_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer normalization layer (Ba et al., 2016). — layer_layer_normalization","text":"","code":"layer_layer_normalization(   object,   axis = -1L,   epsilon = 0.001,   center = TRUE,   scale = TRUE,   rms_scaling = FALSE,   beta_initializer = \"zeros\",   gamma_initializer = \"ones\",   beta_regularizer = NULL,   gamma_regularizer = NULL,   beta_constraint = NULL,   gamma_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_layer_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer normalization layer (Ba et al., 2016). — layer_layer_normalization","text":"object Object compose layer . tensor, array, sequential model. axis Integer list. axis axes normalize across. Typically, features axis/axes. left-axes typically batch axis/axes. -1 last dimension input. Defaults -1. epsilon Small float added variance avoid dividing zero. Defaults 1e-3. center TRUE, add offset beta normalized tensor. FALSE, beta ignored. Defaults TRUE. scale TRUE, multiply gamma. FALSE, gamma used. next layer linear (also e.g. layer_activation_relu()), can disabled since scaling done next layer. Defaults TRUE. rms_scaling TRUE, center scale ignored, inputs scaled gamma inverse square root square inputs. approximate faster approach avoids ever computing mean input. beta_initializer Initializer beta weight. Defaults zeros. gamma_initializer Initializer gamma weight. Defaults ones. beta_regularizer Optional regularizer beta weight. NULL default. gamma_regularizer Optional regularizer gamma weight. NULL default. beta_constraint Optional constraint beta weight. NULL default. gamma_constraint Optional constraint gamma weight. NULL default. ... Base layer keyword arguments (e.g. name dtype).","code":""},{"path":"https://keras.posit.co/reference/layer_layer_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer normalization layer (Ba et al., 2016). — layer_layer_normalization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_layer_normalization.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Layer normalization layer (Ba et al., 2016). — layer_layer_normalization","text":"Lei Ba et al., 2016.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_lstm.html","id":null,"dir":"Reference","previous_headings":"","what":"Long Short-Term Memory layer - Hochreiter 1997. — layer_lstm","title":"Long Short-Term Memory layer - Hochreiter 1997. — layer_lstm","text":"Based available runtime hardware constraints, layer choose different implementations (cuDNN-based backend-native) maximize performance. GPU available arguments layer meet requirement cuDNN kernel (see details), layer use fast cuDNN implementation using TensorFlow backend. requirements use cuDNN implementation : activation == tanh recurrent_activation == sigmoid dropout == 0 recurrent_dropout == 0 unroll FALSE use_bias TRUE Inputs, use masking, strictly right-padded. Eager execution enabled outermost context. example:","code":"input <- random_uniform(c(32, 10, 8)) output <- input |> layer_lstm(4) shape(output) ## shape(32, 4) lstm <- layer_lstm(units = 4, return_sequences = TRUE, return_state = TRUE) c(whole_seq_output, final_memory_state, final_carry_state) %<-% lstm(input) shape(whole_seq_output) ## shape(32, 10, 4) shape(final_memory_state) ## shape(32, 4) shape(final_carry_state) ## shape(32, 4)"},{"path":"https://keras.posit.co/reference/layer_lstm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Long Short-Term Memory layer - Hochreiter 1997. — layer_lstm","text":"","code":"layer_lstm(   object,   units,   activation = \"tanh\",   recurrent_activation = \"sigmoid\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   unit_forget_bias = TRUE,   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   seed = NULL,   return_sequences = FALSE,   return_state = FALSE,   go_backwards = FALSE,   stateful = FALSE,   unroll = FALSE,   ... )"},{"path":"https://keras.posit.co/reference/layer_lstm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Long Short-Term Memory layer - Hochreiter 1997. — layer_lstm","text":"object Object compose layer . tensor, array, sequential model. units Positive integer, dimensionality output space. activation Activation function use. Default: hyperbolic tangent (tanh). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). recurrent_activation Activation function use recurrent step. Default: sigmoid (sigmoid). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). use_bias Boolean, (default TRUE), whether layer use bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. Default: \"glorot_uniform\". recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state. Default: \"orthogonal\". bias_initializer Initializer bias vector. Default: \"zeros\". unit_forget_bias Boolean (default TRUE). TRUE, add 1 bias forget gate initialization. Setting TRUE also force bias_initializer=\"zeros\". recommended Jozefowicz et al. kernel_regularizer Regularizer function applied kernel weights matrix. Default: NULL. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. Default: NULL. bias_regularizer Regularizer function applied bias vector. Default: NULL. activity_regularizer Regularizer function applied output layer (\"activation\"). Default: NULL. kernel_constraint Constraint function applied kernel weights matrix. Default: NULL. recurrent_constraint Constraint function applied recurrent_kernel weights matrix. Default: NULL. bias_constraint Constraint function applied bias vector. Default: NULL. dropout Float 0 1. Fraction units drop linear transformation inputs. Default: 0. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. Default: 0. seed Random seed dropout. return_sequences Boolean. Whether return last output output sequence, full sequence. Default: FALSE. return_state Boolean. Whether return last state addition output. Default: FALSE. go_backwards Boolean (default: FALSE). TRUE, process input sequence backwards return reversed sequence. stateful Boolean (default: FALSE). TRUE, last state sample index batch used initial state sample index following batch. unroll Boolean (default FALSE). TRUE, network unrolled, else symbolic loop used. Unrolling can speed-RNN, although tends memory-intensive. Unrolling suitable short sequences. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_lstm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Long Short-Term Memory layer - Hochreiter 1997. — layer_lstm","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_lstm.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Long Short-Term Memory layer - Hochreiter 1997. — layer_lstm","text":"inputs: 3D tensor, shape (batch, timesteps, feature). mask: Binary tensor shape (samples, timesteps) indicating whether given timestep masked  (optional). individual TRUE entry indicates corresponding timestep utilized, FALSE entry indicates corresponding timestep ignored. Defaults NULL. training: Boolean indicating whether layer behave training mode inference mode. argument passed cell calling . relevant dropout recurrent_dropout used  (optional). Defaults NULL. initial_state: List initial state tensors passed first call cell (optional, NULL causes creation zero-filled initial state tensors). Defaults NULL.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_masking.html","id":null,"dir":"Reference","previous_headings":"","what":"Masks a sequence by using a mask value to skip timesteps. — layer_masking","title":"Masks a sequence by using a mask value to skip timesteps. — layer_masking","text":"timestep input tensor (dimension #1 tensor), values input tensor timestep equal mask_value, timestep masked (skipped) downstream layers (long support masking). downstream layer support masking yet receives input mask, exception raised.","code":""},{"path":"https://keras.posit.co/reference/layer_masking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Masks a sequence by using a mask value to skip timesteps. — layer_masking","text":"","code":"layer_masking(object, mask_value = 0, ...)"},{"path":"https://keras.posit.co/reference/layer_masking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Masks a sequence by using a mask value to skip timesteps. — layer_masking","text":"object Object compose layer . tensor, array, sequential model. mask_value see description ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_masking.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Masks a sequence by using a mask value to skip timesteps. — layer_masking","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_masking.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Masks a sequence by using a mask value to skip timesteps. — layer_masking","text":"Consider array x shape c(samples, timesteps, features), fed LSTM layer. want mask timestep #3 #5 lack data timesteps. can: Set x[, 3, ] <- 0. x[, 5, ] <- 0. Insert layer_masking() layer mask_value = 0. LSTM layer:","code":"c(samples, timesteps, features) %<-% c(32, 10, 8) inputs <- c(samples, timesteps, features) %>% { array(runif(prod(.)), dim = .) } inputs[, 3, ] <- 0 inputs[, 5, ] <- 0  model <- keras_model_sequential() %>%   layer_masking(mask_value = 0) %>%   layer_lstm(32)  output <- model(inputs) # The time step 3 and 5 will be skipped from LSTM calculation."},{"path":"https://keras.posit.co/reference/layer_masking.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Masks a sequence by using a mask value to skip timesteps. — layer_masking","text":"Keras masking convention, masked timestep denoted mask value FALSE, non-masked (.e. usable) timestep denoted mask value TRUE.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_max_pooling_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max pooling operation for 1D temporal data. — layer_max_pooling_1d","title":"Max pooling operation for 1D temporal data. — layer_max_pooling_1d","text":"Downsamples input representation taking maximum value spatial window size pool_size. window shifted strides. resulting output using \"valid\" padding option shape : output_shape = (input_shape - pool_size + 1) / strides). resulting output shape using \"\" padding option : output_shape = input_shape / strides","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max pooling operation for 1D temporal data. — layer_max_pooling_1d","text":"","code":"layer_max_pooling_1d(   object,   pool_size = 2L,   strides = NULL,   padding = \"valid\",   data_format = NULL,   name = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_max_pooling_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max pooling operation for 1D temporal data. — layer_max_pooling_1d","text":"object Object compose layer . tensor, array, sequential model. pool_size int, size max pooling window. strides int NULL. Specifies much pooling window moves pooling step. NULL, default pool_size. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". name String, name object ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Max pooling operation for 1D temporal data. — layer_max_pooling_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Max pooling operation for 1D temporal data. — layer_max_pooling_1d","text":"data_format=\"channels_last\": 3D tensor shape (batch_size, steps, features). data_format=\"channels_first\": 3D tensor shape (batch_size, features, steps).","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Max pooling operation for 1D temporal data. — layer_max_pooling_1d","text":"data_format=\"channels_last\": 3D tensor shape (batch_size, downsampled_steps, features). data_format=\"channels_first\": 3D tensor shape (batch_size, features, downsampled_steps).","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Max pooling operation for 1D temporal data. — layer_max_pooling_1d","text":"strides=1 padding=\"valid\":     strides=2 padding=\"valid\":     strides=1 padding=\"\":","code":"x <- op_reshape(c(1, 2, 3, 4, 5),                c(1, 5, 1)) max_pool_1d <- layer_max_pooling_1d(pool_size = 2,                                     strides = 1,                                     padding = \"valid\") max_pool_1d(x) ## tf.Tensor( ## [[[2.] ##   [3.] ##   [4.] ##   [5.]]], shape=(1, 4, 1), dtype=float32) x <- op_reshape(c(1, 2, 3, 4, 5),                c(1, 5, 1)) max_pool_1d <- layer_max_pooling_1d(pool_size = 2,                                     strides = 2,                                     padding = \"valid\") max_pool_1d(x) ## tf.Tensor( ## [[[2.] ##   [4.]]], shape=(1, 2, 1), dtype=float32) x <- op_reshape(c(1, 2, 3, 4, 5),                c(1, 5, 1)) max_pool_1d <- layer_max_pooling_1d(pool_size = 2,                                     strides = 1,                                     padding = \"same\") max_pool_1d(x) ## tf.Tensor( ## [[[2.] ##   [3.] ##   [4.] ##   [5.] ##   [5.]]], shape=(1, 5, 1), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_max_pooling_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max pooling operation for 2D spatial data. — layer_max_pooling_2d","title":"Max pooling operation for 2D spatial data. — layer_max_pooling_2d","text":"Downsamples input along spatial dimensions (height width) taking maximum value input window (size defined pool_size) channel input. window shifted strides along dimension. resulting output using \"valid\" padding option spatial shape (number rows columns) : output_shape = floor((input_shape - pool_size) / strides) + 1 (input_shape >= pool_size) resulting output shape using \"\" padding option : output_shape = floor((input_shape - 1) / strides) + 1","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max pooling operation for 2D spatial data. — layer_max_pooling_2d","text":"","code":"layer_max_pooling_2d(   object,   pool_size = list(2L, 2L),   strides = NULL,   padding = \"valid\",   data_format = NULL,   name = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_max_pooling_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max pooling operation for 2D spatial data. — layer_max_pooling_2d","text":"object Object compose layer . tensor, array, sequential model. pool_size int list 2 integers, factors downscale (dim1, dim2). one integer specified, window length used dimensions. strides int list 2 integers, NULL. Strides values. NULL, default pool_size. one int specified, stride size used dimensions. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". name String, name object ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Max pooling operation for 2D spatial data. — layer_max_pooling_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Max pooling operation for 2D spatial data. — layer_max_pooling_2d","text":"data_format=\"channels_last\": 4D tensor shape (batch_size, height, width, channels). data_format=\"channels_first\": 4D tensor shape (batch_size, channels, height, width).","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Max pooling operation for 2D spatial data. — layer_max_pooling_2d","text":"data_format=\"channels_last\": 4D tensor shape (batch_size, pooled_height, pooled_width, channels). data_format=\"channels_first\": 4D tensor shape (batch_size, channels, pooled_height, pooled_width).","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Max pooling operation for 2D spatial data. — layer_max_pooling_2d","text":"strides = (1, 1) padding = \"valid\":     strides = c(2, 2) padding = \"valid\":     stride = (1, 1) padding = \"\":","code":"x <- rbind(c(1., 2., 3.),            c(4., 5., 6.),            c(7., 8., 9.)) |> op_reshape(c(1, 3, 3, 1)) max_pool_2d <- layer_max_pooling_2d(pool_size = c(2, 2),                                     strides = c(1, 1),                                     padding = \"valid\") max_pool_2d(x) ## tf.Tensor( ## [[[[5.] ##    [6.]] ## ##   [[8.] ##    [9.]]]], shape=(1, 2, 2, 1), dtype=float32) x <- rbind(c(1., 2., 3., 4.),            c(5., 6., 7., 8.),            c(9., 10., 11., 12.)) |> op_reshape(c(1, 3, 4, 1)) max_pool_2d <- layer_max_pooling_2d(pool_size = c(2, 2),                                     strides = c(2, 2),                                     padding = \"valid\") max_pool_2d(x) ## tf.Tensor( ## [[[[6.] ##    [8.]]]], shape=(1, 1, 2, 1), dtype=float32) x <- rbind(c(1., 2., 3.),            c(4., 5., 6.),            c(7., 8., 9.)) |> op_reshape(c(1, 3, 3, 1)) max_pool_2d <- layer_max_pooling_2d(pool_size = c(2, 2),                                     strides = c(1, 1),                                     padding = \"same\") max_pool_2d(x) ## tf.Tensor( ## [[[[5.] ##    [6.] ##    [6.]] ## ##   [[8.] ##    [9.] ##    [9.]] ## ##   [[8.] ##    [9.] ##    [9.]]]], shape=(1, 3, 3, 1), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_max_pooling_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max pooling operation for 3D data (spatial or spatio-temporal). — layer_max_pooling_3d","title":"Max pooling operation for 3D data (spatial or spatio-temporal). — layer_max_pooling_3d","text":"Downsamples input along spatial dimensions (depth, height, width) taking maximum value input window (size defined pool_size) channel input. window shifted strides along dimension.","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max pooling operation for 3D data (spatial or spatio-temporal). — layer_max_pooling_3d","text":"","code":"layer_max_pooling_3d(   object,   pool_size = list(2L, 2L, 2L),   strides = NULL,   padding = \"valid\",   data_format = NULL,   name = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_max_pooling_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max pooling operation for 3D data (spatial or spatio-temporal). — layer_max_pooling_3d","text":"object Object compose layer . tensor, array, sequential model. pool_size int list 3 integers, factors downscale (dim1, dim2, dim3). one integer specified, window length used dimensions. strides int list 3 integers, NULL. Strides values. NULL, default pool_size. one int specified, stride size used dimensions. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input output height/width dimension input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". name String, name object ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Max pooling operation for 3D data (spatial or spatio-temporal). — layer_max_pooling_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Max pooling operation for 3D data (spatial or spatio-temporal). — layer_max_pooling_3d","text":"data_format=\"channels_last\": 5D tensor shape: (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) data_format=\"channels_first\": 5D tensor shape: (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Max pooling operation for 3D data (spatial or spatio-temporal). — layer_max_pooling_3d","text":"data_format=\"channels_last\": 5D tensor shape: (batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels) data_format=\"channels_first\": 5D tensor shape: (batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_max_pooling_3d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Max pooling operation for 3D data (spatial or spatio-temporal). — layer_max_pooling_3d","text":"","code":"depth <- 30 height <- 30 width <- 30 channels <- 3  inputs <- layer_input(shape=c(depth, height, width, channels)) layer <- layer_max_pooling_3d(pool_size=3) outputs <- inputs |> layer() outputs ## <KerasTensor shape=(None, 10, 10, 10, 3), dtype=float32, sparse=False, name=keras_tensor_1>"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_maximum.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes element-wise maximum on a list of inputs. — layer_maximum","title":"Computes element-wise maximum on a list of inputs. — layer_maximum","text":"takes input list tensors, shape, returns single tensor (also shape).","code":""},{"path":"https://keras.posit.co/reference/layer_maximum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes element-wise maximum on a list of inputs. — layer_maximum","text":"","code":"layer_maximum(inputs, ...)"},{"path":"https://keras.posit.co/reference/layer_maximum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes element-wise maximum on a list of inputs. — layer_maximum","text":"inputs layers combine ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_maximum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes element-wise maximum on a list of inputs. — layer_maximum","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_maximum.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes element-wise maximum on a list of inputs. — layer_maximum","text":"Usage Keras model:","code":"input_shape <- c(2, 3, 4) x1 <- random_uniform(input_shape) x2 <- random_uniform(input_shape) y <- layer_maximum(x1, x2) input1 <- layer_input(shape = c(16)) x1 <- input1 |> layer_dense(8, activation = 'relu') input2 <- layer_input(shape = c(32)) x2 <- input2 |> layer_dense(8, activation = 'relu') # equivalent to `y <- layer_maximum(x1, x2)` y <- layer_maximum(x1, x2) out <- y |> layer_dense(4) model <- keras_model(inputs = c(input1, input2), outputs = out)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_mel_spectrogram.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","title":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","text":"layer takes float32/float64 single batched audio signal inputs computes Mel spectrogram using Short-Time Fourier Transform Mel scaling. input 1D (unbatched) 2D (batched) tensor representing audio signals. output 2D 3D tensor representing Mel spectrograms. spectrogram image-like representation shows frequency spectrum signal time. uses x-axis represent time, y-axis represent frequency, pixel represent intensity. Mel spectrograms special type spectrogram use mel scale, approximates humans perceive sound. commonly used speech music processing tasks like speech recognition, speaker identification, music genre classification.","code":""},{"path":"https://keras.posit.co/reference/layer_mel_spectrogram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","text":"","code":"layer_mel_spectrogram(   object,   fft_length = 2048L,   sequence_stride = 512L,   sequence_length = NULL,   window = \"hann\",   sampling_rate = 16000L,   num_mel_bins = 128L,   min_freq = 20,   max_freq = NULL,   power_to_db = TRUE,   top_db = 80,   mag_exp = 2,   min_power = 1e-10,   ref_power = 1,   ... )"},{"path":"https://keras.posit.co/reference/layer_mel_spectrogram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","text":"object Object compose layer . tensor, array, sequential model. fft_length Integer, size FFT window. sequence_stride Integer, number samples successive STFT columns. sequence_length Integer, size window used applying window audio frame. NULL, defaults fft_length. window String, name window function use. Available values \"hann\" \"hamming\". window tensor, used directly window length must sequence_length. window NULL, windowing used. Defaults \"hann\". sampling_rate Integer, sample rate input signal. num_mel_bins Integer, number mel bins generate. min_freq Float, minimum frequency mel bins. max_freq Float, maximum frequency mel bins. NULL, defaults sampling_rate / 2. power_to_db TRUE, convert power spectrogram decibels. top_db Float, minimum negative cut-max(10 * log10(S)) - top_db. mag_exp Float, exponent magnitude spectrogram. 1 magnitude, 2 power, etc. Default 2. min_power Float, minimum value power ref_power. ref_power Float, power scaled relative 10 * log10(S / ref_power). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_mel_spectrogram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_mel_spectrogram.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","text":"Spectrogram, Mel scale.","code":""},{"path":"https://keras.posit.co/reference/layer_mel_spectrogram.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","text":"Unbatched audio signal   Batched audio signal","code":"layer <- layer_mel_spectrogram(   num_mel_bins = 64,   sampling_rate = 8000,   sequence_stride = 256,   fft_length = 2048 ) layer(random_uniform(shape = c(16000))) |> shape() layer <- layer_mel_spectrogram(   num_mel_bins = 80,   sampling_rate = 8000,   sequence_stride = 128,   fft_length = 2048 ) layer(random_uniform(shape = c(2, 16000))) |> shape()"},{"path":"https://keras.posit.co/reference/layer_mel_spectrogram.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","text":"1D (unbatched) 2D (batched) tensor shape:(..., samples).","code":""},{"path":"https://keras.posit.co/reference/layer_mel_spectrogram.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer to convert raw audio signals to Mel spectrograms. — layer_mel_spectrogram","text":"2D (unbatched) 3D (batched) tensor shape:(..., num_mel_bins, time).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_minimum.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes elementwise minimum on a list of inputs. — layer_minimum","title":"Computes elementwise minimum on a list of inputs. — layer_minimum","text":"takes input list tensors, shape, returns single tensor (also shape).","code":""},{"path":"https://keras.posit.co/reference/layer_minimum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes elementwise minimum on a list of inputs. — layer_minimum","text":"","code":"layer_minimum(inputs, ...)"},{"path":"https://keras.posit.co/reference/layer_minimum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes elementwise minimum on a list of inputs. — layer_minimum","text":"inputs layers combine ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_minimum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes elementwise minimum on a list of inputs. — layer_minimum","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_minimum.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes elementwise minimum on a list of inputs. — layer_minimum","text":"Usage Keras model:","code":"input_shape <- c(2, 3, 4) x1 <- random_uniform(input_shape) x2 <- random_uniform(input_shape) y <- layer_minimum(x1, x2) input1 <- layer_input(shape = c(16)) x1 <- input1 |> layer_dense(8, activation = 'relu') input2 <- layer_input(shape = c(32)) x2 <- input2 |> layer_dense(8, activation = 'relu') # equivalent to `y <- layer_minimum(x1, x2)` y <- layer_minimum(x1, x2) out <- y |> layer_dense(4) model <- keras_model(inputs = c(input1, input2), outputs = out)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_multi_head_attention.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi Head Attention layer. — layer_multi_head_attention","title":"Multi Head Attention layer. — layer_multi_head_attention","text":"implementation multi-headed attention described paper \"Attention Need\" Vaswani et al., 2017. query, key, value , self-attention. timestep query attends corresponding sequence key, returns fixed-width vector. layer first projects query, key value. (effectively) list tensors length num_attention_heads, corresponding shapes (batch_size, <query dimensions>, key_dim), (batch_size, <key/value dimensions>, key_dim), (batch_size, <key/value dimensions>, value_dim). , query key tensors dot-producted scaled. softmaxed obtain attention probabilities. value tensors interpolated probabilities, concatenated back single tensor. Finally, result tensor last dimension value_dim can take linear projection return.","code":""},{"path":"https://keras.posit.co/reference/layer_multi_head_attention.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi Head Attention layer. — layer_multi_head_attention","text":"","code":"layer_multi_head_attention(   inputs,   num_heads,   key_dim,   value_dim = NULL,   dropout = 0,   use_bias = TRUE,   output_shape = NULL,   attention_axes = NULL,   kernel_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_multi_head_attention.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi Head Attention layer. — layer_multi_head_attention","text":"inputs see description num_heads Number attention heads. key_dim Size attention head query key. value_dim Size attention head value. dropout Dropout probability. use_bias Boolean, whether dense layers use bias vectors/matrices. output_shape expected shape output tensor, besides batch sequence dims. specified, projects back query feature dim (query input's last dimension). attention_axes axes attention applied. NULL means attention axes, batch, heads, features. kernel_initializer Initializer dense layer kernels. bias_initializer Initializer dense layer biases. kernel_regularizer Regularizer dense layer kernels. bias_regularizer Regularizer dense layer biases. activity_regularizer Regularizer dense layer activity. kernel_constraint Constraint dense layer kernels. bias_constraint Constraint dense layer kernels. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_multi_head_attention.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi Head Attention layer. — layer_multi_head_attention","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_multi_head_attention.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Multi Head Attention layer. — layer_multi_head_attention","text":"query: Query tensor shape (B, T, dim), B batch size, T target sequence length, dim feature dimension. value: Value tensor shape (B, S, dim), B batch size, S source sequence length, dim feature dimension. key: Optional key tensor shape (B, S, dim). given, use value key value, common case. attention_mask: boolean mask shape (B, T, S), prevents attention certain positions. boolean mask specifies query elements can attend key elements, 1 indicates attention 0 indicates attention. Broadcasting can happen missing batch dimensions head dimension. return_attention_scores: boolean indicate whether output (attention_output, attention_scores) TRUE, attention_output FALSE. Defaults FALSE. training: Python boolean indicating whether layer behave training mode (adding dropout) inference mode (dropout). go either using training mode parent layer/model, FALSE (inference) parent layer. use_causal_mask: boolean indicate whether apply causal mask prevent tokens attending future tokens (e.g., used decoder Transformer).","code":""},{"path":"https://keras.posit.co/reference/layer_multi_head_attention.html","id":"call-return","dir":"Reference","previous_headings":"","what":"Call return","title":"Multi Head Attention layer. — layer_multi_head_attention","text":"attention_output: result computation, shape (B, T, E), T target sequence shapes E query input last dimension output_shape NULL. Otherwise, multi-head outputs projected shape specified output_shape. attention_scores: (Optional) multi-head attention coefficients attention axes.","code":""},{"path":"https://keras.posit.co/reference/layer_multi_head_attention.html","id":"properties","dir":"Reference","previous_headings":"","what":"Properties","title":"Multi Head Attention layer. — layer_multi_head_attention","text":"MultiHeadAttention Layer instance following additional read-properties: attention_axes dropout key_dense key_dim num_heads output_dense output_shape query_dense use_bias value_dense value_dim","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_multiply.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs elementwise multiplication. — layer_multiply","title":"Performs elementwise multiplication. — layer_multiply","text":"takes input list tensors, shape, returns single tensor (also shape).","code":""},{"path":"https://keras.posit.co/reference/layer_multiply.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs elementwise multiplication. — layer_multiply","text":"","code":"layer_multiply(inputs, ...)"},{"path":"https://keras.posit.co/reference/layer_multiply.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs elementwise multiplication. — layer_multiply","text":"inputs layers combine ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_multiply.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs elementwise multiplication. — layer_multiply","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_multiply.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs elementwise multiplication. — layer_multiply","text":"Usage Keras model:","code":"input_shape <- c(2, 3, 4) x1 <- random_uniform(input_shape) x2 <- random_uniform(input_shape) y <- layer_multiply(x1, x2) input1 <- layer_input(shape = c(16)) x1 <- input1 |> layer_dense(8, activation = 'relu') input2 <- layer_input(shape = c(32)) x2 <- input2 |> layer_dense(8, activation = 'relu') # equivalent to `y <- layer_multiply(x1, x2)` y <- layer_multiply(x1, x2) out <- y |> layer_dense(4) model <- keras_model(inputs = c(input1, input2), outputs = out)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer that normalizes continuous features. — layer_normalization","title":"A preprocessing layer that normalizes continuous features. — layer_normalization","text":"layer shift scale inputs distribution centered around 0 standard deviation 1. accomplishes precomputing mean variance data, calling (input - mean) / sqrt(var) runtime. mean variance values layer must either supplied construction learned via adapt(). adapt() compute mean variance data store layer's weights. adapt() called fit(), evaluate(), predict().","code":""},{"path":"https://keras.posit.co/reference/layer_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer that normalizes continuous features. — layer_normalization","text":"","code":"layer_normalization(   object,   axis = -1L,   mean = NULL,   variance = NULL,   invert = FALSE,   ... )"},{"path":"https://keras.posit.co/reference/layer_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer that normalizes continuous features. — layer_normalization","text":"object Object compose layer . tensor, array, sequential model. axis Integer, list integers, NULL. axis axes separate mean variance index shape. example, shape (NULL, 5) axis=1, layer track 5 separate mean variance values last axis. axis set NULL, layer normalize elements input scalar mean variance. -1, last axis input assumed feature dimension normalized per index. Note specific case batched scalar inputs axis batch axis, default normalize index batch separately. case, consider passing axis=NULL. Defaults -1. mean mean value(s) use normalization. passed value(s) broadcast shape kept axes ; value(s) broadcast, error raised layer's build() method called. variance variance value(s) use normalization. passed value(s) broadcast shape kept axes ; value(s) broadcast, error raised layer's build() method called. invert TRUE, layer apply inverse transformation inputs: turn normalized input back original form. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer that normalizes continuous features. — layer_normalization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_normalization.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer that normalizes continuous features. — layer_normalization","text":"Calculate global mean variance analyzing dataset adapt().     Calculate mean variance index last axis.     Pass mean variance directly.     Use layer de-normalize inputs (adapting layer).","code":"adapt_data <- op_array(c(1., 2., 3., 4., 5.), dtype='float32') input_data <- op_array(c(1., 2., 3.), dtype='float32') layer <- layer_normalization(axis = NULL) layer %>% adapt(adapt_data) layer(input_data) ## tf.Tensor([-1.4142135  -0.70710677  0.        ], shape=(3), dtype=float32) adapt_data <- op_array(rbind(c(0., 7., 4.),                        c(2., 9., 6.),                        c(0., 7., 4.),                        c(2., 9., 6.)), dtype='float32') input_data <- op_array(matrix(c(0., 7., 4.), nrow = 1), dtype='float32') layer <- layer_normalization(axis=-1) layer %>% adapt(adapt_data) layer(input_data) ## tf.Tensor([[-1. -1. -1.]], shape=(1, 3), dtype=float32) input_data <- op_array(rbind(1, 2, 3), dtype='float32') layer <- layer_normalization(mean=3., variance=2.) layer(input_data) ## tf.Tensor( ## [[-1.4142135 ] ##  [-0.70710677] ##  [ 0.        ]], shape=(3, 1), dtype=float32) adapt_data <- op_array(rbind(c(0., 7., 4.),                        c(2., 9., 6.),                        c(0., 7., 4.),                        c(2., 9., 6.)), dtype='float32') input_data <- op_array(c(1., 2., 3.), dtype='float32') layer <- layer_normalization(axis=-1, invert=TRUE) layer %>% adapt(adapt_data) layer(input_data) ## tf.Tensor([[ 2. 10.  8.]], shape=(1, 3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_permute.html","id":null,"dir":"Reference","previous_headings":"","what":"Permutes the dimensions of the input according to a given pattern. — layer_permute","title":"Permutes the dimensions of the input according to a given pattern. — layer_permute","text":"Useful e.g. connecting RNNs convnets.","code":""},{"path":"https://keras.posit.co/reference/layer_permute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Permutes the dimensions of the input according to a given pattern. — layer_permute","text":"","code":"layer_permute(object, dims, ...)"},{"path":"https://keras.posit.co/reference/layer_permute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Permutes the dimensions of the input according to a given pattern. — layer_permute","text":"object Object compose layer . tensor, array, sequential model. dims List integers. Permutation pattern include batch dimension. Indexing starts 1. instance, c(2, 1) permutes first second dimensions input. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_permute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Permutes the dimensions of the input according to a given pattern. — layer_permute","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_permute.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Permutes the dimensions of the input according to a given pattern. — layer_permute","text":"Arbitrary.","code":""},{"path":"https://keras.posit.co/reference/layer_permute.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Permutes the dimensions of the input according to a given pattern. — layer_permute","text":"input shape, dimensions re-ordered according specified pattern.","code":""},{"path":"https://keras.posit.co/reference/layer_permute.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Permutes the dimensions of the input according to a given pattern. — layer_permute","text":"","code":"x <- layer_input(shape=c(10, 64)) y <- layer_permute(x, c(2, 1)) shape(y) ## shape(NA, 64, 10)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_random_brightness.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which randomly adjusts brightness during training. — layer_random_brightness","title":"A preprocessing layer which randomly adjusts brightness during training. — layer_random_brightness","text":"layer randomly increase/reduce brightness input RGB images. inference time, output identical input. Call layer training=TRUE adjust brightness input. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_random_brightness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which randomly adjusts brightness during training. — layer_random_brightness","text":"","code":"layer_random_brightness(   object,   factor,   value_range = list(0L, 255L),   seed = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_random_brightness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which randomly adjusts brightness during training. — layer_random_brightness","text":"object Object compose layer . tensor, array, sequential model. factor Float list 2 floats -1.0 1.0. factor used determine lower bound upper bound brightness adjustment. float value chosen randomly limits. -1.0 chosen, output image black, 1.0 chosen, image fully white. one float provided, eg, 0.2, -0.2 used lower bound 0.2 used upper bound. value_range Optional list 2 floats lower upper limit values input data. make change, use c(0.0, 1.0), e.g., image input scaled layer. Defaults c(0.0, 255.0). brightness adjustment scaled range, output values clipped range. seed optional integer, fixed RNG behavior. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_random_brightness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which randomly adjusts brightness during training. — layer_random_brightness","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_random_brightness.html","id":"inputs","dir":"Reference","previous_headings":"","what":"Inputs","title":"A preprocessing layer which randomly adjusts brightness during training. — layer_random_brightness","text":"3D (HWC) 4D (NHWC) tensor, float int dtype. Input pixel values can range (e.g. [0., 1.) [0, 255])","code":""},{"path":"https://keras.posit.co/reference/layer_random_brightness.html","id":"output","dir":"Reference","previous_headings":"","what":"Output","title":"A preprocessing layer which randomly adjusts brightness during training. — layer_random_brightness","text":"3D (HWC) 4D (NHWC) tensor brightness adjusted based factor. default, layer output floats. output value clipped range [0, 255], valid range RGB colors, rescaled based value_range needed. Sample usage:","code":"random_bright <- layer_random_brightness(factor=0.2, seed = 1)  # An image with shape [2, 2, 3] image <- array(1:12, dim=c(2, 2, 3))  # Assume we randomly select the factor to be 0.1, then it will apply # 0.1 * 255 to all the channel output <- random_bright(image, training=TRUE) output ## tf.Tensor( ## [[[39.605797 43.605797 47.605797] ##   [41.605797 45.605797 49.605797]] ## ##  [[40.605797 44.605797 48.605797] ##   [42.605797 46.605797 50.605797]]], shape=(2, 2, 3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_random_contrast.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which randomly adjusts contrast during training. — layer_random_contrast","title":"A preprocessing layer which randomly adjusts contrast during training. — layer_random_contrast","text":"layer randomly adjust contrast image images random factor. Contrast adjusted independently channel image training. channel, layer computes mean image pixels channel adjusts component x pixel (x - mean) * contrast_factor + mean. Input pixel values can range (e.g. [0., 1.) [0, 255]) integer floating point dtype. default, layer output floats. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_random_contrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which randomly adjusts contrast during training. — layer_random_contrast","text":"","code":"layer_random_contrast(object, factor, seed = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_random_contrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which randomly adjusts contrast during training. — layer_random_contrast","text":"object Object compose layer . tensor, array, sequential model. factor positive float represented fraction value, tuple size 2 representing lower upper bound. represented single float, lower = upper. contrast factor randomly picked [1.0 - lower, 1.0 + upper]. pixel x channel, output (x - mean) * factor + mean mean mean value channel. seed Integer. Used create random seed. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_random_contrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which randomly adjusts contrast during training. — layer_random_contrast","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_random_contrast.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which randomly adjusts contrast during training. — layer_random_contrast","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format.","code":""},{"path":"https://keras.posit.co/reference/layer_random_contrast.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which randomly adjusts contrast during training. — layer_random_contrast","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_random_crop.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which randomly crops images during training. — layer_random_crop","title":"A preprocessing layer which randomly crops images during training. — layer_random_crop","text":"training, layer randomly choose location crop images target size. layer crop images batch cropping location. inference time, training input image smaller target size, input resized cropped return largest possible window image matches target aspect ratio. need apply random cropping inference time, set training TRUE calling layer. Input pixel values can range (e.g. [0., 1.) [0, 255]) integer floating point dtype. default, layer output floats. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_random_crop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which randomly crops images during training. — layer_random_crop","text":"","code":"layer_random_crop(   object,   height,   width,   seed = NULL,   data_format = NULL,   name = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_random_crop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which randomly crops images during training. — layer_random_crop","text":"object Object compose layer . tensor, array, sequential model. height Integer, height output shape. width Integer, width output shape. seed Integer. Used create random seed. data_format see description name String, name object ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_random_crop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which randomly crops images during training. — layer_random_crop","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_random_crop.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which randomly crops images during training. — layer_random_crop","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format.","code":""},{"path":"https://keras.posit.co/reference/layer_random_crop.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which randomly crops images during training. — layer_random_crop","text":"3D (unbatched) 4D (batched) tensor shape: (..., target_height, target_width, channels).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_random_flip.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which randomly flips images during training. — layer_random_flip","title":"A preprocessing layer which randomly flips images during training. — layer_random_flip","text":"layer flip images horizontally vertically based mode attribute. inference time, output identical input. Call layer training=TRUE flip input. Input pixel values can range (e.g. [0., 1.) [0, 255]) integer floating point dtype. default, layer output floats. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_random_flip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which randomly flips images during training. — layer_random_flip","text":"","code":"layer_random_flip(object, mode = \"horizontal_and_vertical\", seed = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_random_flip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which randomly flips images during training. — layer_random_flip","text":"object Object compose layer . tensor, array, sequential model. mode String indicating flip mode use. Can \"horizontal\", \"vertical\", \"horizontal_and_vertical\". \"horizontal\" left-right flip \"vertical\" top-bottom flip. Defaults \"horizontal_and_vertical\" seed Integer. Used create random seed. ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_random_flip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which randomly flips images during training. — layer_random_flip","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_random_flip.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which randomly flips images during training. — layer_random_flip","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format.","code":""},{"path":"https://keras.posit.co/reference/layer_random_flip.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which randomly flips images during training. — layer_random_flip","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_random_rotation.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which randomly rotates images during training. — layer_random_rotation","title":"A preprocessing layer which randomly rotates images during training. — layer_random_rotation","text":"layer apply random rotations image, filling empty space according fill_mode. default, random rotations applied training. inference time, layer nothing. need apply random rotations inference time, set training TRUE calling layer. Input pixel values can range (e.g. [0., 1.) [0, 255]) integer floating point dtype. default, layer output floats. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_random_rotation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which randomly rotates images during training. — layer_random_rotation","text":"","code":"layer_random_rotation(   object,   factor,   fill_mode = \"reflect\",   interpolation = \"bilinear\",   seed = NULL,   fill_value = 0,   value_range = list(0L, 255L),   data_format = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_random_rotation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which randomly rotates images during training. — layer_random_rotation","text":"object Object compose layer . tensor, array, sequential model. factor float represented fraction 2 Pi, tuple size 2 representing lower upper bound rotating clockwise counter-clockwise. positive values means rotating counter clock-wise, negative value means clock-wise. represented single float, value used upper lower bound. instance, factor=(-0.2, 0.3) results output rotation random amount range [-20% * 2pi, 30% * 2pi]. factor=0.2 results output rotating random amount range [-20% * 2pi, 20% * 2pi]. fill_mode Points outside boundaries input filled according given mode (one {\"constant\", \"reflect\", \"wrap\", \"nearest\"}). reflect: (d c b | b c d | d c b ) input extended reflecting edge last pixel. constant: (k k k k | b c d | k k k k) input extended filling values beyond edge constant value k = 0. wrap: (b c d | b c d | b c d) input extended wrapping around opposite edge. nearest: (| b c d | d d d d) input extended nearest pixel. interpolation Interpolation mode. Supported values: \"nearest\", \"bilinear\". seed Integer. Used create random seed. fill_value float represents value filled outside boundaries fill_mode=\"constant\". value_range see description data_format see description ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_random_rotation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which randomly rotates images during training. — layer_random_rotation","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_random_rotation.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which randomly rotates images during training. — layer_random_rotation","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format","code":""},{"path":"https://keras.posit.co/reference/layer_random_rotation.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which randomly rotates images during training. — layer_random_rotation","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_random_translation.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which randomly translates images during training. — layer_random_translation","title":"A preprocessing layer which randomly translates images during training. — layer_random_translation","text":"layer apply random translations image training, filling empty space according fill_mode. Input pixel values can range (e.g. [0., 1.) [0, 255]) integer floating point dtype. default, layer output floats.","code":""},{"path":"https://keras.posit.co/reference/layer_random_translation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which randomly translates images during training. — layer_random_translation","text":"","code":"layer_random_translation(   object,   height_factor,   width_factor,   fill_mode = \"reflect\",   interpolation = \"bilinear\",   seed = NULL,   fill_value = 0,   data_format = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_random_translation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which randomly translates images during training. — layer_random_translation","text":"object Object compose layer . tensor, array, sequential model. height_factor float represented fraction value, tuple size 2 representing lower upper bound shifting vertically. negative value means shifting image , positive value means shifting image . represented single positive float, value used upper lower bound. instance, height_factor=(-0.2, 0.3) results output shifted random amount range [-20%, +30%]. height_factor=0.2 results output height shifted random amount range [-20%, +20%]. width_factor float represented fraction value, tuple size 2 representing lower upper bound shifting horizontally. negative value means shifting image left, positive value means shifting image right. represented single positive float, value used upper lower bound. instance, width_factor=(-0.2, 0.3) results output shifted left 20%, shifted right 30%. width_factor=0.2 results output height shifted left right 20%. fill_mode Points outside boundaries input filled according given mode. Available methods \"constant\", \"nearest\", \"wrap\" \"reflect\". Defaults \"constant\". \"reflect\": (d c b | b c d | d c b ) input extended reflecting edge last pixel. \"constant\": (k k k k | b c d | k k k k) input extended filling values beyond edge constant value k specified fill_value. \"wrap\": (b c d | b c d | b c d) input extended wrapping around opposite edge. \"nearest\": (| b c d | d d d d) input extended nearest pixel. Note using torch backend, \"reflect\" redirected \"mirror\" (c d c b | b c d | c b b) torch support \"reflect\". Note torch backend support \"wrap\". interpolation Interpolation mode. Supported values: \"nearest\", \"bilinear\". seed Integer. Used create random seed. fill_value float represents value filled outside boundaries fill_mode=\"constant\". data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_random_translation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which randomly translates images during training. — layer_random_translation","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_random_translation.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which randomly translates images during training. — layer_random_translation","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format, (..., channels, height, width), \"channels_first\" format.","code":""},{"path":"https://keras.posit.co/reference/layer_random_translation.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which randomly translates images during training. — layer_random_translation","text":"3D (unbatched) 4D (batched) tensor shape: (..., target_height, target_width, channels), (..., channels, target_height, target_width), \"channels_first\" format. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_random_zoom.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which randomly zooms images during training. — layer_random_zoom","title":"A preprocessing layer which randomly zooms images during training. — layer_random_zoom","text":"layer randomly zoom axis image independently, filling empty space according fill_mode. Input pixel values can range (e.g. [0., 1.) [0, 255]) integer floating point dtype. default, layer output floats.","code":""},{"path":"https://keras.posit.co/reference/layer_random_zoom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which randomly zooms images during training. — layer_random_zoom","text":"","code":"layer_random_zoom(   object,   height_factor,   width_factor = NULL,   fill_mode = \"reflect\",   interpolation = \"bilinear\",   seed = NULL,   fill_value = 0,   data_format = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_random_zoom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which randomly zooms images during training. — layer_random_zoom","text":"object Object compose layer . tensor, array, sequential model. height_factor float represented fraction value, list size 2 representing lower upper bound zooming vertically. represented single float, value used upper lower bound. positive value means zooming , negative value means zooming . instance, height_factor=c(0.2, 0.3) result output zoomed random amount range [+20%, +30%]. height_factor=c(-0.3, -0.2) result output zoomed random amount range [+20%, +30%]. width_factor float represented fraction value, list size 2 representing lower upper bound zooming horizontally. represented single float, value used upper lower bound. instance, width_factor=c(0.2, 0.3) result output zooming 20% 30%. width_factor=c(-0.3, -0.2) result output zooming 20% 30%. NULL means .e., zooming vertical horizontal directions preserving aspect ratio. Defaults NULL. fill_mode Points outside boundaries input filled according given mode. Available methods \"constant\", \"nearest\", \"wrap\" \"reflect\". Defaults \"constant\". \"reflect\": (d c b | b c d | d c b ) input extended reflecting edge last pixel. \"constant\": (k k k k | b c d | k k k k) input extended filling values beyond edge constant value k specified fill_value. \"wrap\": (b c d | b c d | b c d) input extended wrapping around opposite edge. \"nearest\": (| b c d | d d d d) input extended nearest pixel. Note using torch backend, \"reflect\" redirected \"mirror\" (c d c b | b c d | c b b) torch support \"reflect\". Note torch backend support \"wrap\". interpolation Interpolation mode. Supported values: \"nearest\", \"bilinear\". seed Integer. Used create random seed. fill_value float represents value filled outside boundaries fill_mode=\"constant\". data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_random_zoom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which randomly zooms images during training. — layer_random_zoom","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_random_zoom.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which randomly zooms images during training. — layer_random_zoom","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format, (..., channels, height, width), \"channels_first\" format.","code":""},{"path":"https://keras.posit.co/reference/layer_random_zoom.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which randomly zooms images during training. — layer_random_zoom","text":"3D (unbatched) 4D (batched) tensor shape: (..., target_height, target_width, channels), (..., channels, target_height, target_width), \"channels_first\" format. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_random_zoom.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer which randomly zooms images during training. — layer_random_zoom","text":"","code":"input_img <- random_uniform(c(32, 224, 224, 3)) layer <- layer_random_zoom(height_factor = .5, width_factor = .2) out_img <- layer(input_img)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_repeat_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeats the input n times. — layer_repeat_vector","title":"Repeats the input n times. — layer_repeat_vector","text":"Repeats input n times.","code":""},{"path":"https://keras.posit.co/reference/layer_repeat_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeats the input n times. — layer_repeat_vector","text":"","code":"layer_repeat_vector(object, n, ...)"},{"path":"https://keras.posit.co/reference/layer_repeat_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeats the input n times. — layer_repeat_vector","text":"object Object compose layer . tensor, array, sequential model. n Integer, repetition factor. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_repeat_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repeats the input n times. — layer_repeat_vector","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_repeat_vector.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repeats the input n times. — layer_repeat_vector","text":"","code":"x <- layer_input(shape = 32) y <- layer_repeat_vector(x, n = 3) shape(y) ## shape(NA, 3, 32)"},{"path":"https://keras.posit.co/reference/layer_repeat_vector.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Repeats the input n times. — layer_repeat_vector","text":"2D tensor shape (batch_size, features).","code":""},{"path":"https://keras.posit.co/reference/layer_repeat_vector.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Repeats the input n times. — layer_repeat_vector","text":"3D tensor shape (batch_size, n, features).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_rescaling.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which rescales input values to a new range. — layer_rescaling","title":"A preprocessing layer which rescales input values to a new range. — layer_rescaling","text":"layer rescales every value input (often image) multiplying scale adding offset. instance: rescale input [0, 255] range [0, 1] range, pass scale=1./255. rescale input [0, 255] range [-1, 1] range, pass scale=1./127.5, offset=-1. rescaling applied training inference. Inputs can integer floating point dtype, default layer output floats. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_rescaling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which rescales input values to a new range. — layer_rescaling","text":"","code":"layer_rescaling(object, scale, offset = 0, ...)"},{"path":"https://keras.posit.co/reference/layer_rescaling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which rescales input values to a new range. — layer_rescaling","text":"object Object compose layer . tensor, array, sequential model. scale Float, scale apply inputs. offset Float, offset apply inputs. ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_rescaling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which rescales input values to a new range. — layer_rescaling","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_reshape.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer that reshapes inputs into the given shape. — layer_reshape","title":"Layer that reshapes inputs into the given shape. — layer_reshape","text":"Layer reshapes inputs given shape.","code":""},{"path":"https://keras.posit.co/reference/layer_reshape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer that reshapes inputs into the given shape. — layer_reshape","text":"","code":"layer_reshape(object, target_shape, ...)"},{"path":"https://keras.posit.co/reference/layer_reshape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer that reshapes inputs into the given shape. — layer_reshape","text":"object Object compose layer . tensor, array, sequential model. target_shape Target shape. List integers, include samples dimension (batch size). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_reshape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer that reshapes inputs into the given shape. — layer_reshape","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_reshape.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Layer that reshapes inputs into the given shape. — layer_reshape","text":"Arbitrary, although dimensions input shape must known/fixed. Use keyword argument input_shape (list integers, include samples/batch size axis) using layer first layer model.","code":""},{"path":"https://keras.posit.co/reference/layer_reshape.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Layer that reshapes inputs into the given shape. — layer_reshape","text":"(batch_size, *target_shape)","code":""},{"path":"https://keras.posit.co/reference/layer_reshape.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Layer that reshapes inputs into the given shape. — layer_reshape","text":"","code":"x <- layer_input(shape = 12) y <- layer_reshape(x, c(3, 4)) shape(y) ## shape(NA, 3, 4) # also supports shape inference using `-1` as dimension y <- layer_reshape(x, c(-1, 2, 2)) shape(y) ## shape(NA, 3, 2, 2)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_resizing.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which resizes images. — layer_resizing","title":"A preprocessing layer which resizes images. — layer_resizing","text":"layer resizes image input target height width. input 4D (batched) 3D (unbatched) tensor \"channels_last\" format. Input pixel values can range (e.g. [0., 1.) [0, 255]).","code":""},{"path":"https://keras.posit.co/reference/layer_resizing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which resizes images. — layer_resizing","text":"","code":"layer_resizing(   object,   height,   width,   interpolation = \"bilinear\",   crop_to_aspect_ratio = FALSE,   data_format = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_resizing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which resizes images. — layer_resizing","text":"object Object compose layer . tensor, array, sequential model. height Integer, height output shape. width Integer, width output shape. interpolation String, interpolation method. Supports \"bilinear\", \"nearest\", \"bicubic\", \"lanczos3\", \"lanczos5\". Defaults \"bilinear\". crop_to_aspect_ratio TRUE, resize images without aspect ratio distortion. original aspect ratio differs target aspect ratio, output image cropped return largest possible window image (size (height, width)) matches target aspect ratio. default (crop_to_aspect_ratio=FALSE), aspect ratio may preserved. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". ... Base layer keyword arguments, name dtype.","code":""},{"path":"https://keras.posit.co/reference/layer_resizing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which resizes images. — layer_resizing","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_resizing.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"A preprocessing layer which resizes images. — layer_resizing","text":"3D (unbatched) 4D (batched) tensor shape: (..., height, width, channels), \"channels_last\" format, (..., channels, height, width), \"channels_first\" format.","code":""},{"path":"https://keras.posit.co/reference/layer_resizing.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"A preprocessing layer which resizes images. — layer_resizing","text":"3D (unbatched) 4D (batched) tensor shape: (..., target_height, target_width, channels), (..., channels, target_height, target_width), \"channels_first\" format. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Base class for recurrent layers — layer_rnn","title":"Base class for recurrent layers — layer_rnn","text":"Base class recurrent layers","code":""},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base class for recurrent layers — layer_rnn","text":"","code":"layer_rnn(   object,   cell,   return_sequences = FALSE,   return_state = FALSE,   go_backwards = FALSE,   stateful = FALSE,   unroll = FALSE,   zero_output_for_mask = FALSE,   ... )"},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Base class for recurrent layers — layer_rnn","text":"object Object compose layer . tensor, array, sequential model. cell RNN cell instance list RNN cell instances. RNN cell class : call(input_at_t, states_at_t) method, returning (output_at_t, states_at_t_plus_1). call method cell can also take optional argument constants, see section \"Note passing external constants\" . state_size attribute. can single integer (single state) case size recurrent state. can also list integers (one size per state). output_size attribute, single integer. get_initial_state(batch_size=NULL) method creates tensor meant fed call() initial state, user specify initial state via means. returned initial state shape (batch_size, cell.state_size). cell might choose create tensor full zeros, values based cell's implementation. inputs input tensor RNN layer, shape (batch_size, timesteps, features). method implemented cell, RNN layer create zero filled tensor shape (batch_size, cell$state_size). case cell list RNN cell instances, cells stacked top RNN, resulting efficient stacked RNN. return_sequences Boolean (default FALSE). Whether return last output output sequence, full sequence. return_state Boolean (default FALSE). Whether return last state addition output. go_backwards Boolean (default FALSE). TRUE, process input sequence backwards return reversed sequence. stateful Boolean (default FALSE). TRUE, last state sample index batch used initial state sample index following batch. unroll Boolean (default FALSE). TRUE, network unrolled, else symbolic loop used. Unrolling can speed-RNN, although tends memory-intensive. Unrolling suitable short sequences. zero_output_for_mask Boolean (default FALSE). Whether output use zeros masked timesteps. Note field used return_sequences TRUE mask provided. can useful want reuse raw output sequence RNN without interference masked timesteps, e.g., merging bidirectional RNNs. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Base class for recurrent layers — layer_rnn","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Base class for recurrent layers — layer_rnn","text":"inputs: Input tensor. initial_state: List initial state tensors passed first call cell. mask: Binary tensor shape [batch_size, timesteps] indicating whether given timestep masked. individual TRUE entry indicates corresponding timestep utilized, FALSE entry indicates corresponding timestep ignored. training: Python boolean indicating whether layer behave training mode inference mode. argument passed cell calling . use cells use dropout.","code":""},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Base class for recurrent layers — layer_rnn","text":"3-D tensor shape (batch_size, timesteps, features).","code":""},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Base class for recurrent layers — layer_rnn","text":"return_state: list tensors. first tensor output. remaining tensors last states, shape (batch_size, state_size), state_size high dimension tensor shape. return_sequences: 3D tensor shape (batch_size, timesteps, output_size).","code":""},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":"masking-","dir":"Reference","previous_headings":"","what":"Masking:","title":"Base class for recurrent layers — layer_rnn","text":"layer supports masking input data variable number timesteps. introduce masks data, use layer_embedding() layer mask_zero parameter set TRUE. Note using statefulness RNNs: can set RNN layers 'stateful', means states computed samples one batch reused initial states samples next batch. assumes one--one mapping samples different successive batches. enable statefulness: Specify stateful = TRUE layer constructor. Specify fixed batch size model, passing sequential model: input_batch_shape = c(...) keras_model_sequential() call. Else functional model 1 input layers: batch_shape = c(...) layer_input() call(s). expected shape inputs including batch size. list integers, e.g. c(32, 10, 100). Specify shuffle = FALSE calling fit(). reset states model, call reset_state() either specific layer, entire model. Note specifying initial state RNNs: can specify initial state RNN layers symbolically calling keyword argument initial_state. value initial_state tensor list tensors representing initial state RNN layer.","code":""},{"path":"https://keras.posit.co/reference/layer_rnn.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Base class for recurrent layers — layer_rnn","text":"First, define RNN Cell, layer subclass.   use cell RNN layer:","code":"rnn_cell_minimal <- Layer(   \"MinimalRNNCell\",    initialize = function(units, ...) {     super$initialize(...)     self$units <- as.integer(units)     self$state_size <- as.integer(units)   },    build = function(input_shape) {     self$kernel <- self$add_weight(       shape = shape(tail(input_shape, 1), self$units),       initializer = 'uniform',       name = 'kernel'     )     self$recurrent_kernel <- self$add_weight(       shape = shape(self$units, self$units),       initializer = 'uniform',       name = 'recurrent_kernel'     )     self$built <- TRUE   },    call = function(inputs, states) {     prev_output <- states[[1]]     h <- op_matmul(inputs, self$kernel)     output <- h + op_matmul(prev_output, self$recurrent_kernel)     list(output, list(output))   } ) cell <- rnn_cell_minimal(units = 32) x <- layer_input(shape = shape(NULL, 5)) layer <- layer_rnn(cell = cell) y <- layer(x) cells <- list(rnn_cell_minimal(units = 32), rnn_cell_minimal(units = 4)) x <- layer_input(shape = shape(NULL, 5)) layer <- layer_rnn(cell = cells) y <- layer(x)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_separable_conv_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"1D separable convolution layer. — layer_separable_conv_1d","title":"1D separable convolution layer. — layer_separable_conv_1d","text":"layer performs depthwise convolution acts separately channels, followed pointwise convolution mixes channels. use_bias TRUE bias initializer provided, adds bias vector output. optionally applies activation function produce final output.","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D separable convolution layer. — layer_separable_conv_1d","text":"","code":"layer_separable_conv_1d(   object,   filters,   kernel_size,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L,   depth_multiplier = 1L,   activation = NULL,   use_bias = TRUE,   depthwise_initializer = \"glorot_uniform\",   pointwise_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   depthwise_regularizer = NULL,   pointwise_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   depthwise_constraint = NULL,   pointwise_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_separable_conv_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D separable convolution layer. — layer_separable_conv_1d","text":"object Object compose layer . tensor, array, sequential model. filters int, dimensionality output space (.e. number filters pointwise convolution). kernel_size int list 1 integers, specifying size depthwise convolution window. strides int list 1 integers, specifying stride length depthwise convolution. one int specified, stride size used dimensions. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, steps, features) \"channels_first\" corresponds inputs shape (batch, features, steps). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 1 integers, specifying dilation rate use dilated convolution. one int specified, dilation rate used dimensions. depth_multiplier number depthwise convolution output channels input channel. total number depthwise convolution output channels equal input_channel * depth_multiplier. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. depthwise_initializer initializer depthwise convolution kernel. NULL, default initializer (\"glorot_uniform\") used. pointwise_initializer initializer pointwise convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer initializer bias vector. NULL, default initializer ('\"zeros\"') used. depthwise_regularizer Optional regularizer depthwise convolution kernel. pointwise_regularizer Optional regularizer pointwise convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. depthwise_constraint Optional projection function applied depthwise kernel updated Optimizer (e.g. used norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). pointwise_constraint Optional projection function applied pointwise kernel updated Optimizer. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D separable convolution layer. — layer_separable_conv_1d","text":"3D tensor representing activation(separable_conv1d(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"1D separable convolution layer. — layer_separable_conv_1d","text":"data_format=\"channels_last\": 3D tensor shape: (batch_shape, steps, channels) data_format=\"channels_first\": 3D tensor shape: (batch_shape, channels, steps)","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"1D separable convolution layer. — layer_separable_conv_1d","text":"data_format=\"channels_last\": 3D tensor shape: (batch_shape, new_steps, filters) data_format=\"channels_first\": 3D tensor shape: (batch_shape, filters, new_steps)","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"1D separable convolution layer. — layer_separable_conv_1d","text":"","code":"x <- random_uniform(c(4, 10, 12)) y <- layer_separable_conv_1d(x, 3, 2, 2, activation='relu') shape(y) ## shape(4, 5, 3)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_separable_conv_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2D separable convolution layer. — layer_separable_conv_2d","title":"2D separable convolution layer. — layer_separable_conv_2d","text":"layer performs depthwise convolution acts separately channels, followed pointwise convolution mixes channels. use_bias TRUE bias initializer provided, adds bias vector output. optionally applies activation function produce final output.","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D separable convolution layer. — layer_separable_conv_2d","text":"","code":"layer_separable_conv_2d(   object,   filters,   kernel_size,   strides = list(1L, 1L),   padding = \"valid\",   data_format = NULL,   dilation_rate = list(1L, 1L),   depth_multiplier = 1L,   activation = NULL,   use_bias = TRUE,   depthwise_initializer = \"glorot_uniform\",   pointwise_initializer = \"glorot_uniform\",   bias_initializer = \"zeros\",   depthwise_regularizer = NULL,   pointwise_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   depthwise_constraint = NULL,   pointwise_constraint = NULL,   bias_constraint = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_separable_conv_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D separable convolution layer. — layer_separable_conv_2d","text":"object Object compose layer . tensor, array, sequential model. filters int, dimensionality output space (.e. number filters pointwise convolution). kernel_size int list 2 integers, specifying size depthwise convolution window. strides int list 2 integers, specifying stride length depthwise convolution. one int specified, stride size used dimensions. strides > 1 incompatible dilation_rate > 1. padding string, either \"valid\" \"\" (case-insensitive). \"valid\" means padding. \"\" results padding evenly left/right /input. padding=\"\" strides=1, output size input. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, width). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". dilation_rate int list 2 integers, specifying dilation rate use dilated convolution. one int specified, dilation rate used dimensions. depth_multiplier number depthwise convolution output channels input channel. total number depthwise convolution output channels equal input_channel * depth_multiplier. activation Activation function. NULL, activation applied. use_bias bool, TRUE, bias added output. depthwise_initializer initializer depthwise convolution kernel. NULL, default initializer (\"glorot_uniform\") used. pointwise_initializer initializer pointwise convolution kernel. NULL, default initializer (\"glorot_uniform\") used. bias_initializer initializer bias vector. NULL, default initializer ('\"zeros\"') used. depthwise_regularizer Optional regularizer depthwise convolution kernel. pointwise_regularizer Optional regularizer pointwise convolution kernel. bias_regularizer Optional regularizer bias vector. activity_regularizer Optional regularizer function output. depthwise_constraint Optional projection function applied depthwise kernel updated Optimizer (e.g. used norm constraints value constraints layer weights). function must take input unprojected variable must return projected variable (must shape). pointwise_constraint Optional projection function applied pointwise kernel updated Optimizer. bias_constraint Optional projection function applied bias updated Optimizer. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D separable convolution layer. — layer_separable_conv_2d","text":"4D tensor representing activation(separable_conv2d(inputs, kernel) + bias).","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"2D separable convolution layer. — layer_separable_conv_2d","text":"data_format=\"channels_last\": 4D tensor shape: (batch_size, height, width, channels) data_format=\"channels_first\": 4D tensor shape: (batch_size, channels, height, width)","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"2D separable convolution layer. — layer_separable_conv_2d","text":"data_format=\"channels_last\": 4D tensor shape: (batch_size, new_height, new_width, filters) data_format=\"channels_first\": 4D tensor shape: (batch_size, filters, new_height, new_width)","code":""},{"path":"https://keras.posit.co/reference/layer_separable_conv_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"2D separable convolution layer. — layer_separable_conv_2d","text":"","code":"x <- random_uniform(c(4, 10, 10, 12)) y <- layer_separable_conv_2d(x, 3, c(4, 3), 2, activation='relu') shape(y) ## shape(4, 4, 4, 3)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_simple_rnn.html","id":null,"dir":"Reference","previous_headings":"","what":"Fully-connected RNN where the output is to be fed back as the new input. — layer_simple_rnn","title":"Fully-connected RNN where the output is to be fed back as the new input. — layer_simple_rnn","text":"Fully-connected RNN output fed back new input.","code":""},{"path":"https://keras.posit.co/reference/layer_simple_rnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fully-connected RNN where the output is to be fed back as the new input. — layer_simple_rnn","text":"","code":"layer_simple_rnn(   object,   units,   activation = \"tanh\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   activity_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   return_sequences = FALSE,   return_state = FALSE,   go_backwards = FALSE,   stateful = FALSE,   unroll = FALSE,   seed = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_simple_rnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fully-connected RNN where the output is to be fed back as the new input. — layer_simple_rnn","text":"object Object compose layer . tensor, array, sequential model. units Positive integer, dimensionality output space. activation Activation function use. Default: hyperbolic tangent (tanh). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). use_bias Boolean, (default TRUE), whether layer uses bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. Default: \"glorot_uniform\". recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state.  Default: \"orthogonal\". bias_initializer Initializer bias vector. Default: \"zeros\". kernel_regularizer Regularizer function applied kernel weights matrix. Default: NULL. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. Default: NULL. bias_regularizer Regularizer function applied bias vector. Default: NULL. activity_regularizer Regularizer function applied output layer (\"activation\"). Default: NULL. kernel_constraint Constraint function applied kernel weights matrix. Default: NULL. recurrent_constraint Constraint function applied recurrent_kernel weights matrix.  Default: NULL. bias_constraint Constraint function applied bias vector. Default: NULL. dropout Float 0 1. Fraction units drop linear transformation inputs. Default: 0. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. Default: 0. return_sequences Boolean. Whether return last output output sequence, full sequence. Default: FALSE. return_state Boolean. Whether return last state addition output. Default: FALSE. go_backwards Boolean (default: FALSE). TRUE, process input sequence backwards return reversed sequence. stateful Boolean (default: FALSE). TRUE, last state sample index batch used initial state sample index following batch. unroll Boolean (default: FALSE). TRUE, network unrolled, else symbolic loop used. Unrolling can speed-RNN, although tends memory-intensive. Unrolling suitable short sequences. seed Initial seed random number generator ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_simple_rnn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fully-connected RNN where the output is to be fed back as the new input. — layer_simple_rnn","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_simple_rnn.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Fully-connected RNN where the output is to be fed back as the new input. — layer_simple_rnn","text":"sequence: 3D tensor, shape [batch, timesteps, feature]. mask: Binary tensor shape [batch, timesteps] indicating whether given timestep masked. individual TRUE entry indicates corresponding timestep utilized, FALSE entry indicates corresponding timestep ignored. training: Python boolean indicating whether layer behave training mode inference mode. argument passed cell calling . relevant dropout recurrent_dropout used. initial_state: List initial state tensors passed first call cell.","code":""},{"path":"https://keras.posit.co/reference/layer_simple_rnn.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fully-connected RNN where the output is to be fed back as the new input. — layer_simple_rnn","text":"","code":"inputs <- random_uniform(c(32, 10, 8)) simple_rnn <- layer_simple_rnn(units = 4) output <- simple_rnn(inputs)  # The output has shape `(32, 4)`. simple_rnn <- layer_simple_rnn(     units = 4, return_sequences=TRUE, return_state=TRUE ) # whole_sequence_output has shape `(32, 10, 4)`. # final_state has shape `(32, 4)`. c(whole_sequence_output, final_state) %<-% simple_rnn(inputs)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","title":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","text":"layer performs function Dropout, however, drops entire 1D feature maps instead individual elements. adjacent frames within feature maps strongly correlated (normally case early convolution layers) regular dropout regularize activations otherwise just result effective learning rate decrease. case, SpatialDropout1D help promote independence feature maps used instead.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","text":"","code":"layer_spatial_dropout_1d(object, rate, seed = NULL, name = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","text":"object Object compose layer . tensor, array, sequential model. rate Float 0 1. Fraction input units drop. seed Initial seed random number generator name String, name object dtype datatype (e.g., \"float32\").","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_1d.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","text":"inputs: 3D tensor. training: Python boolean indicating whether layer behave training mode (applying dropout) inference mode (pass-).","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","text":"3D tensor shape: (samples, timesteps, channels)","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","text":"input.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_1d.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Spatial 1D version of Dropout. — layer_spatial_dropout_1d","text":"Tompson et al., 2014","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","title":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","text":"version performs function Dropout, however, drops entire 2D feature maps instead individual elements. adjacent pixels within feature maps strongly correlated (normally case early convolution layers) regular dropout regularize activations otherwise just result effective learning rate decrease. case, SpatialDropout2D help promote independence feature maps used instead.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","text":"","code":"layer_spatial_dropout_2d(   object,   rate,   data_format = NULL,   seed = NULL,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","text":"object Object compose layer . tensor, array, sequential model. rate Float 0 1. Fraction input units drop. data_format \"channels_first\" \"channels_last\". \"channels_first\" mode, channels dimension (depth) index 1, \"channels_last\" mode index 3. defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". seed Initial seed random number generator name String, name object dtype datatype (e.g., \"float32\").","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_2d.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","text":"inputs: 4D tensor. training: Python boolean indicating whether layer behave training mode (applying dropout) inference mode (pass-).","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","text":"4D tensor shape: (samples, channels, rows, cols) data_format='channels_first' 4D tensor shape: (samples, rows, cols, channels) data_format='channels_last'.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","text":"input.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_2d.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Spatial 2D version of Dropout. — layer_spatial_dropout_2d","text":"Tompson et al., 2014","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","title":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","text":"version performs function Dropout, however, drops entire 3D feature maps instead individual elements. adjacent voxels within feature maps strongly correlated (normally case early convolution layers) regular dropout regularize activations otherwise just result effective learning rate decrease. case, SpatialDropout3D help promote independence feature maps used instead.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","text":"","code":"layer_spatial_dropout_3d(   object,   rate,   data_format = NULL,   seed = NULL,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","text":"object Object compose layer . tensor, array, sequential model. rate Float 0 1. Fraction input units drop. data_format \"channels_first\" \"channels_last\". \"channels_first\" mode, channels dimension (depth) index 1, \"channels_last\" mode index 4. defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\". seed Initial seed random number generator name String, name object dtype datatype (e.g., \"float32\").","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_3d.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","text":"inputs: 5D tensor. training: Python boolean indicating whether layer behave training mode (applying dropout) inference mode (pass-).","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","text":"5D tensor shape: (samples, channels, dim1, dim2, dim3) data_format='channels_first' 5D tensor shape: (samples, dim1, dim2, dim3, channels) data_format='channels_last'.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","text":"input.","code":""},{"path":"https://keras.posit.co/reference/layer_spatial_dropout_3d.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Spatial 3D version of Dropout. — layer_spatial_dropout_3d","text":"Tompson et al., 2014","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_spectral_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs spectral normalization on the weights of a target layer. — layer_spectral_normalization","title":"Performs spectral normalization on the weights of a target layer. — layer_spectral_normalization","text":"wrapper controls Lipschitz constant weights layer constraining spectral norm, can stabilize training GANs.","code":""},{"path":"https://keras.posit.co/reference/layer_spectral_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs spectral normalization on the weights of a target layer. — layer_spectral_normalization","text":"","code":"layer_spectral_normalization(object, layer, power_iterations = 1L, ...)"},{"path":"https://keras.posit.co/reference/layer_spectral_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs spectral normalization on the weights of a target layer. — layer_spectral_normalization","text":"object Object compose layer . tensor, array, sequential model. layer Layer instance either kernel (e.g. layer_conv_2d, layer_dense...) embeddings attribute (layer_embedding layer). power_iterations int, number iterations normalization. ... Base wrapper keyword arguments.","code":""},{"path":"https://keras.posit.co/reference/layer_spectral_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs spectral normalization on the weights of a target layer. — layer_spectral_normalization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_spectral_normalization.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs spectral normalization on the weights of a target layer. — layer_spectral_normalization","text":"Wrap layer_conv_2d:     Wrap layer_dense:","code":"x <- random_uniform(c(1, 10, 10, 1)) conv2d <- layer_spectral_normalization(   layer = layer_conv_2d(filters = 2, kernel_size = 2) ) y <- conv2d(x) shape(y) ## shape(1, 9, 9, 2) x <- random_uniform(c(1, 10, 10, 1)) dense <- layer_spectral_normalization(layer = layer_dense(units = 10)) y <- dense(x) shape(y) ## shape(1, 10, 10, 10)"},{"path":"https://keras.posit.co/reference/layer_spectral_normalization.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Performs spectral normalization on the weights of a target layer. — layer_spectral_normalization","text":"Spectral Normalization GAN.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_string_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer that maps strings to (possibly encoded) indices. — layer_string_lookup","title":"A preprocessing layer that maps strings to (possibly encoded) indices. — layer_string_lookup","text":"layer translates set arbitrary strings integer output via table-based vocabulary lookup. layer perform splitting transformation input strings. layer can split tokenize natural language, see layer_text_vectorization layer. vocabulary layer must either supplied construction learned via adapt(). adapt(), layer analyze data set, determine frequency individual strings tokens, create vocabulary . vocabulary capped size, frequent tokens used create vocabulary others treated --vocabulary (OOV). two possible output modes layer. output_mode \"int\", input strings converted index vocabulary (integer). output_mode \"multi_hot\", \"count\", \"tf_idf\", input strings encoded array dimension corresponds element vocabulary. vocabulary can optionally contain mask token well OOV token (can optionally occupy multiple indices vocabulary, set num_oov_indices). position tokens vocabulary fixed. output_mode \"int\", vocabulary begin mask token (set), followed OOV indices, followed rest vocabulary. output_mode \"multi_hot\", \"count\", \"tf_idf\" vocabulary begin OOV indices instances mask token dropped. Note: layer uses TensorFlow internally. used part compiled computation graph model backend TensorFlow. can however used backend running eagerly. can also always used part input preprocessing pipeline backend (outside model ), recommend use layer. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_string_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer that maps strings to (possibly encoded) indices. — layer_string_lookup","text":"","code":"layer_string_lookup(   object,   max_tokens = NULL,   num_oov_indices = 1L,   mask_token = NULL,   oov_token = \"[UNK]\",   vocabulary = NULL,   idf_weights = NULL,   invert = FALSE,   output_mode = \"int\",   pad_to_max_tokens = FALSE,   sparse = FALSE,   encoding = \"utf-8\",   name = NULL,   ...,   vocabulary_dtype = NULL )"},{"path":"https://keras.posit.co/reference/layer_string_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer that maps strings to (possibly encoded) indices. — layer_string_lookup","text":"object Object compose layer . tensor, array, sequential model. max_tokens Maximum size vocabulary layer. specified adapting vocabulary setting pad_to_max_tokens=TRUE. NULL, cap size vocabulary. Note size includes OOV mask tokens. Defaults NULL. num_oov_indices number --vocabulary tokens use. value 1, OOV inputs modulated determine OOV value. value 0, OOV inputs cause error calling layer. Defaults 1. mask_token token represents masked inputs. output_mode \"int\", token included vocabulary mapped index 0. output modes, token appear vocabulary instances mask token input dropped. set NULL, mask term added. Defaults NULL. oov_token used invert TRUE. token return OOV indices. Defaults \"[UNK]\". vocabulary Optional. Either array integers string path text file. passing array, can pass list, list, 1D NumPy array, 1D tensor containing integer vocbulary terms. passing file path, file contain one line per term vocabulary. argument set, need adapt() layer. idf_weights valid output_mode \"tf_idf\". list, list, 1D NumPy array, 1D tensor length vocabulary, containing floating point inverse document frequency weights, multiplied per sample term counts final TF-IDF weight. vocabulary argument set, output_mode \"tf_idf\", argument must supplied. invert valid output_mode \"int\". TRUE, layer map indices vocabulary items instead mapping vocabulary items indices. Defaults FALSE. output_mode Specification output layer. Values can \"int\", \"one_hot\", \"multi_hot\", \"count\", \"tf_idf\" configuring layer follows: \"int\": Return vocabulary indices input tokens. \"one_hot\": Encodes individual element input array size vocabulary, containing 1 element index. last dimension size 1, encode dimension. last dimension size 1, append new dimension encoded output. \"multi_hot\": Encodes sample input single array size vocabulary, containing 1 vocabulary term present sample. Treats last dimension sample dimension, input shape (..., sample_length), output shape (..., num_tokens). \"count\": \"multi_hot\", int array contains count number times token index appeared sample. \"tf_idf\": \"multi_hot\", TF-IDF algorithm applied find value token slot. \"int\" output, shape input output supported. output modes, currently output rank 2 supported. Defaults \"int\". pad_to_max_tokens applicable output_mode \"multi_hot\", \"count\", \"tf_idf\". TRUE, output feature axis padded max_tokens even number unique tokens vocabulary less max_tokens, resulting tensor shape (batch_size, max_tokens) regardless vocabulary size. Defaults FALSE. sparse Boolean. applicable \"multi_hot\", \"count\", \"tf_idf\" output modes. supported TensorFlow backend. TRUE, returns SparseTensor instead dense Tensor. Defaults FALSE. encoding Optional. text encoding use interpret input strings. Defaults \"utf-8\". name String, name object ... forward/backward compatability. vocabulary_dtype dtype vocabulary terms, example \"int64\" \"int32\". Defaults \"int64\".","code":""},{"path":"https://keras.posit.co/reference/layer_string_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer that maps strings to (possibly encoded) indices. — layer_string_lookup","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_string_lookup.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer that maps strings to (possibly encoded) indices. — layer_string_lookup","text":"Creating lookup layer known vocabulary example creates lookup layer pre-existing vocabulary.     Creating lookup layer adapted vocabulary example creates lookup layer generates vocabulary analyzing dataset.     Note OOV token \"[UNK]\" added vocabulary. remaining tokens sorted frequency (\"d\", 2 occurrences, first) inverse sort order.     Lookups multiple OOV indices example demonstrates use lookup layer multiple OOV indices.  layer created one OOV index, OOV values hashed number OOV buckets, distributing OOV values deterministic fashion across set.     Note output OOV value 'm' 0, output OOV value \"z\" 1. -vocab terms output index increased 1 earlier examples (maps 2, etc) order make space extra OOV value. One-hot output Configure layer output_mode='one_hot'. Note first num_oov_indices dimensions ont_hot encoding represent OOV values.     Multi-hot output Configure layer output_mode='multi_hot'. Note first num_oov_indices dimensions multi_hot encoding represent OOV values.     Token count output Configure layer output_mode='count'. multi_hot output, first num_oov_indices dimensions output represent OOV values.     TF-IDF output Configure layer output_mode=\"tf_idf\". multi_hot output, first num_oov_indices dimensions output represent OOV values. token bin output token_count * idf_weight, idf weights inverse document frequency weights per token. provided along vocabulary. Note idf_weight OOV values default average idf weights passed .     specify idf weights oov values, need pass entire vocabulary including leading oov token.     adapting layer \"tf_idf\" mode, input sample considered document, IDF weight per token calculated log(1 + num_documents / (1 + token_document_count)). Inverse lookup example demonstrates map indices strings using layer. (can also use adapt() inverse=TRUE, simplicity pass vocab example.)     Note first index correspond oov token default. Forward inverse lookup pairs example demonstrates use vocabulary standard lookup layer create inverse lookup layer.     example, input value \"z\" resulted output \"[UNK]\", since 1000 vocabulary - got represented OOV, OOV values returned \"[UNK]\" inverse layer. Also, note inverse work, must already set forward layer vocabulary either directly via adapt() calling get_vocabulary().","code":"vocab <- c(\"a\", \"b\", \"c\", \"d\") data <- rbind(c(\"a\", \"c\", \"d\"), c(\"d\", \"z\", \"b\")) layer <- layer_string_lookup(vocabulary=vocab) layer(data) ## tf.Tensor( ## [[1 3 4] ##  [4 0 2]], shape=(2, 3), dtype=int64) data <- rbind(c(\"a\", \"c\", \"d\"), c(\"d\", \"z\", \"b\")) layer <- layer_string_lookup() layer %>% adapt(data) get_vocabulary(layer) ## [1] \"[UNK]\" \"d\"     \"z\"     \"c\"     \"b\"     \"a\" data <- rbind(c(\"a\", \"c\", \"d\"), c(\"d\", \"z\", \"b\")) layer <- layer_string_lookup() layer %>% adapt(data) layer(data) ## tf.Tensor( ## [[5 3 1] ##  [1 2 4]], shape=(2, 3), dtype=int64) vocab <- c(\"a\", \"b\", \"c\", \"d\") data <- rbind(c(\"a\", \"c\", \"d\"), c(\"m\", \"z\", \"b\")) layer <- layer_string_lookup(vocabulary = vocab, num_oov_indices = 2) layer(data) ## tf.Tensor( ## [[2 4 5] ##  [0 1 3]], shape=(2, 3), dtype=int64) vocab <- c(\"a\", \"b\", \"c\", \"d\") data <- c(\"a\", \"b\", \"c\", \"d\", \"z\") layer <- layer_string_lookup(vocabulary = vocab, output_mode = 'one_hot') layer(data) ## tf.Tensor( ## [[0 1 0 0 0] ##  [0 0 1 0 0] ##  [0 0 0 1 0] ##  [0 0 0 0 1] ##  [1 0 0 0 0]], shape=(5, 5), dtype=int64) vocab <- c(\"a\", \"b\", \"c\", \"d\") data <- rbind(c(\"a\", \"c\", \"d\", \"d\"), c(\"d\", \"z\", \"b\", \"z\")) layer <- layer_string_lookup(vocabulary = vocab, output_mode = 'multi_hot') layer(data) ## tf.Tensor( ## [[0 1 0 1 1] ##  [1 0 1 0 1]], shape=(2, 5), dtype=int64) vocab <- c(\"a\", \"b\", \"c\", \"d\") data <- rbind(c(\"a\", \"c\", \"d\", \"d\"), c(\"d\", \"z\", \"b\", \"z\")) layer <- layer_string_lookup(vocabulary = vocab, output_mode = 'count') layer(data) ## tf.Tensor( ## [[0 1 0 1 2] ##  [2 0 1 0 1]], shape=(2, 5), dtype=int64) vocab <- c(\"a\", \"b\", \"c\", \"d\") idf_weights <- c(0.25, 0.75, 0.6, 0.4) data <- rbind(c(\"a\", \"c\", \"d\", \"d\"), c(\"d\", \"z\", \"b\", \"z\")) layer <- layer_string_lookup(output_mode = \"tf_idf\") layer %>% set_vocabulary(vocab, idf_weights=idf_weights) layer(data) ## tf.Tensor( ## [[0.   0.25 0.   0.6  0.8 ] ##  [1.   0.   0.75 0.   0.4 ]], shape=(2, 5), dtype=float32) vocab <- c(\"[UNK]\", \"a\", \"b\", \"c\", \"d\") idf_weights <- c(0.9, 0.25, 0.75, 0.6, 0.4) data <- rbind(c(\"a\", \"c\", \"d\", \"d\"), c(\"d\", \"z\", \"b\", \"z\")) layer <- layer_string_lookup(output_mode = \"tf_idf\") layer %>% set_vocabulary(vocab, idf_weights=idf_weights) layer(data) ## tf.Tensor( ## [[0.   0.25 0.   0.6  0.8 ] ##  [1.8  0.   0.75 0.   0.4 ]], shape=(2, 5), dtype=float32) vocab <- c(\"a\", \"b\", \"c\", \"d\") data <- rbind(c(1, 3, 4), c(4, 0, 2)) layer <- layer_string_lookup(vocabulary = vocab, invert = TRUE) layer(data) ## tf.Tensor( ## [[b'a' b'c' b'd'] ##  [b'd' b'[UNK]' b'b']], shape=(2, 3), dtype=string) vocab <- c(\"a\", \"b\", \"c\", \"d\") data <- rbind(c(\"a\", \"c\", \"d\"), c(\"d\", \"z\", \"b\")) layer <- layer_string_lookup(vocabulary = vocab) i_layer <- layer_string_lookup(vocabulary = vocab, invert = TRUE) int_data <- layer(data) i_layer(int_data) ## tf.Tensor( ## [[b'a' b'c' b'd'] ##  [b'd' b'[UNK]' b'b']], shape=(2, 3), dtype=string)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_subtract.html","id":null,"dir":"Reference","previous_headings":"","what":"Performs elementwise subtraction. — layer_subtract","title":"Performs elementwise subtraction. — layer_subtract","text":"takes input list tensors size 2 shape, returns single tensor (inputs[0] - inputs[1)) shape.","code":""},{"path":"https://keras.posit.co/reference/layer_subtract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performs elementwise subtraction. — layer_subtract","text":"","code":"layer_subtract(inputs, ...)"},{"path":"https://keras.posit.co/reference/layer_subtract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performs elementwise subtraction. — layer_subtract","text":"inputs layers combine ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_subtract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performs elementwise subtraction. — layer_subtract","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_subtract.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performs elementwise subtraction. — layer_subtract","text":"Usage Keras model:","code":"input_shape <- c(2, 3, 4) x1 <- random_uniform(input_shape) x2 <- random_uniform(input_shape) y <- layer_subtract(list(x1, x2)) input1 <- layer_input(shape = 16) x1 <- layer_dense(input1, units = 8, activation = 'relu') input2 <- layer_input(shape = 32) x2 <- layer_dense(input2, units = 8, activation = 'relu') subtracted <- layer_subtract(list(x1, x2)) out <- layer_dense(subtracted, units = 4) model <- keras_model(inputs = list(input1, input2), outputs = out)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_text_vectorization.html","id":null,"dir":"Reference","previous_headings":"","what":"A preprocessing layer which maps text features to integer sequences. — layer_text_vectorization","title":"A preprocessing layer which maps text features to integer sequences. — layer_text_vectorization","text":"layer basic options managing text Keras model. transforms batch strings (one example = one string) either list token indices (one example = 1D tensor integer token indices) dense representation (one example = 1D tensor float values representing data example's tokens). layer meant handle natural language inputs. handle simple string inputs (categorical strings pre-tokenized strings) see layer_string_lookup(). vocabulary layer must either supplied construction learned via adapt(). layer adapted, analyze dataset, determine frequency individual string values, create vocabulary . vocabulary can unlimited size capped, depending configuration options layer; unique values input maximum vocabulary size, frequent terms used create vocabulary. processing example contains following steps: Standardize example (usually lowercasing + punctuation stripping) Split example substrings (usually words) Recombine substrings tokens (usually ngrams) Index tokens (associate unique int value token) Transform example using index, either vector ints dense float vector. notes passing callables customize splitting normalization layer: callable can passed Layer, want serialize object pass functions registered Keras serializables (see register_keras_serializable() details). using custom callable standardize, data received callable exactly passed layer. callable return tensor shape input. using custom callable split, data received callable 1st dimension squeezed - instead list(\"string split\", \"another string split\"), Callable see c(\"string split\", \"another string split\"). callable return tf.Tensor dtype string first dimension containing split tokens - example, see something like list(c(\"string\", \"\", \"split\"), c(\"another\", \"string\", \"\", \"split\")). Note: layer uses TensorFlow internally. used part compiled computation graph model backend TensorFlow. can however used backend running eagerly. can also always used part input preprocessing pipeline backend (outside model ), recommend use layer. Note: layer safe use inside tf.data pipeline (independently backend using).","code":""},{"path":"https://keras.posit.co/reference/layer_text_vectorization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A preprocessing layer which maps text features to integer sequences. — layer_text_vectorization","text":"","code":"layer_text_vectorization(   object,   max_tokens = NULL,   standardize = \"lower_and_strip_punctuation\",   split = \"whitespace\",   ngrams = NULL,   output_mode = \"int\",   output_sequence_length = NULL,   pad_to_max_tokens = FALSE,   vocabulary = NULL,   idf_weights = NULL,   sparse = FALSE,   ragged = FALSE,   encoding = \"utf-8\",   name = NULL,   ... )  get_vocabulary(object, include_special_tokens = TRUE)  set_vocabulary(object, vocabulary, idf_weights = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_text_vectorization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A preprocessing layer which maps text features to integer sequences. — layer_text_vectorization","text":"object Object compose layer . tensor, array, sequential model. max_tokens Maximum size vocabulary layer. specified adapting vocabulary setting pad_to_max_tokens=TRUE. Note vocabulary contains 1 OOV token, effective number tokens (max_tokens - 1 - (1 output_mode == \"int\" else 0)). standardize Optional specification standardization apply input text. Values can : NULL: standardization. \"lower_and_strip_punctuation\": Text lowercased punctuation removed. \"lower\": Text lowercased. \"strip_punctuation\": punctuation removed. Callable: Inputs passed callable function, standardized returned. split Optional specification splitting input text. Values can : NULL: splitting. \"whitespace\": Split whitespace. \"character\": Split unicode character. Callable: Standardized inputs passed callable function, split returned. ngrams Optional specification ngrams create possibly-split input text. Values can NULL, integer list integers; passing integer create ngrams integer, passing list integers create ngrams specified values list. Passing NULL means ngrams created. output_mode Optional specification output layer. Values can \"int\", \"multi_hot\", \"count\" \"tf_idf\", configuring layer follows: \"int\": Outputs integer indices, one integer index per split string token. output_mode == \"int\", 0 reserved masked locations; reduces vocab size max_tokens - 2 instead max_tokens - 1. \"multi_hot\": Outputs single int array per batch, either vocab_size max_tokens size, containing 1s elements token mapped index exists least batch item. \"count\": Like \"multi_hot\", int array contains count number times token index appeared batch item. \"tf_idf\": Like \"multi_hot\", TF-IDF algorithm applied find value token slot. \"int\" output, shape input output supported. output modes, currently rank 1 inputs (rank 2 outputs splitting) supported. output_sequence_length valid INT mode. set, output time dimension padded truncated exactly output_sequence_length values, resulting tensor shape (batch_size, output_sequence_length) regardless many tokens resulted splitting step. Defaults NULL. ragged TRUE output_sequence_length may still truncate output. pad_to_max_tokens valid  \"multi_hot\", \"count\", \"tf_idf\" modes. TRUE, output feature axis padded max_tokens even number unique tokens vocabulary less max_tokens, resulting tensor shape (batch_size, max_tokens) regardless vocabulary size. Defaults FALSE. vocabulary Optional. Either array strings string path text file. passing array, can pass list, list, 1D NumPy array, 1D tensor containing string vocabulary terms. passing file path, file contain one line per term vocabulary. argument set, need adapt() layer. idf_weights R vector, 1D numpy array, 1D tensor inverse document frequency weights equal length vocabulary. Must set output_mode \"tf_idf\". set otherwise. sparse Boolean. applicable \"multi_hot\", \"count\", \"tf_idf\" output modes. supported TensorFlow backend. TRUE, returns SparseTensor instead dense Tensor. Defaults FALSE. ragged Boolean. applicable \"int\" output mode. supported TensorFlow backend. TRUE, returns RaggedTensor instead dense Tensor, sequence may different length string splitting. Defaults FALSE. encoding Optional. text encoding use interpret input strings. Defaults \"utf-8\". name String, name object ... forward/backward compatability. include_special_tokens TRUE, returned vocabulary include padding OOV tokens, term's index vocabulary equal term's index calling layer. FALSE, returned vocabulary include padding OOV tokens.","code":""},{"path":"https://keras.posit.co/reference/layer_text_vectorization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A preprocessing layer which maps text features to integer sequences. — layer_text_vectorization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_text_vectorization.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A preprocessing layer which maps text features to integer sequences. — layer_text_vectorization","text":"example instantiates TextVectorization layer lowercases text, splits whitespace, strips punctuation, outputs integer vocab indices.         example instantiates TextVectorization layer passing list vocabulary terms layer's initialize() method.","code":"max_tokens <- 5000  # Maximum vocab size. max_len <- 4  # Sequence length to pad the outputs to. # Create the layer. vectorize_layer <- layer_text_vectorization(     max_tokens = max_tokens,     output_mode = 'int',     output_sequence_length = max_len) # Now that the vocab layer has been created, call `adapt` on the # list of strings to create the vocabulary. vectorize_layer %>% adapt(c(\"foo bar\", \"bar baz\", \"baz bada boom\")) # Now, the layer can map strings to integers -- you can use an # embedding layer to map these integers to learned embeddings. input_data <- rbind(\"foo qux bar\", \"qux baz\") vectorize_layer(input_data) ## tf.Tensor( ## [[4 1 3 0] ##  [1 2 0 0]], shape=(2, 4), dtype=int64) vocab_data <- c(\"earth\", \"wind\", \"and\", \"fire\") max_len <- 4  # Sequence length to pad the outputs to. # Create the layer, passing the vocab directly. You can also pass the # vocabulary arg a path to a file containing one vocabulary word per # line. vectorize_layer <- layer_text_vectorization(     max_tokens = max_tokens,     output_mode = 'int',     output_sequence_length = max_len,     vocabulary = vocab_data) # Because we've passed the vocabulary directly, we don't need to adapt # the layer - the vocabulary is already set. The vocabulary contains the # padding token ('') and OOV token ('[UNK]') # as well as the passed tokens. vectorize_layer %>% get_vocabulary() ## [1] \"\"      \"[UNK]\" \"earth\" \"wind\"  \"and\"   \"fire\" # ['', '[UNK]', 'earth', 'wind', 'and', 'fire']"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_tfsm.html","id":null,"dir":"Reference","previous_headings":"","what":"Reload a Keras model/layer that was saved via export_savedmodel(). — layer_tfsm","title":"Reload a Keras model/layer that was saved via export_savedmodel(). — layer_tfsm","text":"Reload Keras model/layer saved via export_savedmodel().","code":""},{"path":"https://keras.posit.co/reference/layer_tfsm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reload a Keras model/layer that was saved via export_savedmodel(). — layer_tfsm","text":"","code":"layer_tfsm(   object,   filepath,   call_endpoint = \"serve\",   call_training_endpoint = NULL,   trainable = TRUE,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/layer_tfsm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reload a Keras model/layer that was saved via export_savedmodel(). — layer_tfsm","text":"object Object compose layer . tensor, array, sequential model. filepath string, path SavedModel. call_endpoint Name endpoint use call() method reloaded layer. SavedModel created via export_savedmodel(), default endpoint name 'serve'. cases may named 'serving_default'. call_training_endpoint see description trainable see description name String, name object dtype datatype (e.g., \"float32\").","code":""},{"path":"https://keras.posit.co/reference/layer_tfsm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reload a Keras model/layer that was saved via export_savedmodel(). — layer_tfsm","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_tfsm.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reload a Keras model/layer that was saved via export_savedmodel(). — layer_tfsm","text":"reloaded object can used like regular Keras layer, supports training/fine-tuning trainable weights. Note reloaded object retains none internal structure custom methods original object -- brand new layer created around saved function. Limitations: call endpoints single inputs tensor argument (may optionally named list/list tensors) supported. endpoints multiple separate input tensor arguments, consider subclassing layer_tfsm implementing call() method custom signature. need training-time behavior differ inference-time behavior (.e. need reloaded object support training=TRUE argument __call__()), make sure training-time call function saved standalone endpoint artifact, provide name layer_tfsm via call_training_endpoint argument.","code":"model <- keras_model_sequential(input_shape = c(784)) |> layer_dense(10) model |> export_savedmodel(\"path/to/artifact\") ## Saved artifact at 'path/to/artifact'. The following endpoints are available: ## ## * Endpoint 'serve' ##   args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor') ## Output Type: ##   TensorSpec(shape=(None, 10), dtype=tf.float32, name=None) ## Captures: ##   129193089033744: TensorSpec(shape=(), dtype=tf.resource, name=None) ##   129193089037264: TensorSpec(shape=(), dtype=tf.resource, name=None) reloaded_layer <- layer_tfsm(filepath = \"path/to/artifact\") input <- random_normal(c(2, 784)) output <- reloaded_layer(input) stopifnot(all.equal(as.array(output), as.array(model(input))))"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_time_distributed.html","id":null,"dir":"Reference","previous_headings":"","what":"This wrapper allows to apply a layer to every temporal slice of an input. — layer_time_distributed","title":"This wrapper allows to apply a layer to every temporal slice of an input. — layer_time_distributed","text":"Every input least 3D, dimension index one first input considered temporal dimension. Consider batch 32 video samples, sample 128x128 RGB image channels_last data format, across 10 timesteps. batch input shape (32, 10, 128, 128, 3). can use TimeDistributed apply Conv2D layer 10 timesteps, independently:     layer_time_distributed applies instance layer_conv2d timestamps, set weights used timestamp.","code":"inputs <- keras_input(shape = c(10, 128, 128, 3), batch_size = 32) conv_2d_layer <- layer_conv_2d(filters = 64, kernel_size = c(3, 3)) outputs <- layer_time_distributed(inputs, layer = conv_2d_layer) shape(outputs) ## shape(32, 10, 126, 126, 64)"},{"path":"https://keras.posit.co/reference/layer_time_distributed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This wrapper allows to apply a layer to every temporal slice of an input. — layer_time_distributed","text":"","code":"layer_time_distributed(object, layer, ...)"},{"path":"https://keras.posit.co/reference/layer_time_distributed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This wrapper allows to apply a layer to every temporal slice of an input. — layer_time_distributed","text":"object Object compose layer . tensor, array, sequential model. layer Layer instance. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_time_distributed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This wrapper allows to apply a layer to every temporal slice of an input. — layer_time_distributed","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_time_distributed.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"This wrapper allows to apply a layer to every temporal slice of an input. — layer_time_distributed","text":"inputs: Input tensor shape (batch, time, ...) nested tensors, shape (batch, time, ...). training: Boolean indicating whether layer behave training mode inference mode. argument passed wrapped layer (layer supports argument). mask: Binary tensor shape (samples, timesteps) indicating whether given timestep masked. argument passed wrapped layer (layer supports argument).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_torch_module_wrapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Torch module wrapper layer. — layer_torch_module_wrapper","title":"Torch module wrapper layer. — layer_torch_module_wrapper","text":"layer_torch_module_wrapper wrapper class can turn torch.nn.Module Keras layer, particular making parameters trackable Keras.","code":""},{"path":"https://keras.posit.co/reference/layer_torch_module_wrapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Torch module wrapper layer. — layer_torch_module_wrapper","text":"","code":"layer_torch_module_wrapper(object, module, name = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_torch_module_wrapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Torch module wrapper layer. — layer_torch_module_wrapper","text":"object Object compose layer . tensor, array, sequential model. module torch.nn.Module instance. LazyModule instance, parameters must initialized passing instance layer_torch_module_wrapper (e.g. calling ). name name layer (string). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_torch_module_wrapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Torch module wrapper layer. — layer_torch_module_wrapper","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_torch_module_wrapper.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Torch module wrapper layer. — layer_torch_module_wrapper","text":"example layer_torch_module_wrapper() can used vanilla PyTorch modules.","code":"# reticulate::py_install( #   packages = c(\"torch\", \"torchvision\", \"torchaudio\"), #   envname = \"r-keras\", #   pip_options = c(\"--index-url https://download.pytorch.org/whl/cpu\") # ) library(keras3) use_backend(\"torch\") torch <- reticulate::import(\"torch\") nn <- reticulate::import(\"torch.nn\") nnf <- reticulate::import(\"torch.nn.functional\")  Classifier(keras$Model) \\%py_class\\% {   initialize <- function(...) {     super$initialize(...)      self$conv1 <- layer_torch_module_wrapper(module = nn$Conv2d(       in_channels = 1L,       out_channels = 32L,       kernel_size = tuple(3L, 3L)     ))     self$conv2 <- layer_torch_module_wrapper(module = nn$Conv2d(       in_channels = 32L,       out_channels = 64L,       kernel_size = tuple(3L, 3L)     ))     self$pool <- nn$MaxPool2d(kernel_size = tuple(2L, 2L))     self$flatten <- nn$Flatten()     self$dropout <- nn$Dropout(p = 0.5)     self$fc <-       layer_torch_module_wrapper(module = nn$Linear(1600L, 10L))   }    call <- function(inputs) {     x <- nnf$relu(self$conv1(inputs))     x <- self$pool(x)     x <- nnf$relu(self$conv2(x))     x <- self$pool(x)     x <- self$flatten(x)     x <- self$dropout(x)     x <- self$fc(x)     nnf$softmax(x, dim = 1L)   } } model <- Classifier() model$build(shape(1, 28, 28)) cat(\"Output shape:\", format(shape(model(torch$ones(1L, 1L, 28L, 28L)))))  model |> compile(loss = \"sparse_categorical_crossentropy\",                  optimizer = \"adam\",                  metrics = \"accuracy\") model |> fit(train_loader, epochs = 5)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_unit_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"Unit normalization layer. — layer_unit_normalization","title":"Unit normalization layer. — layer_unit_normalization","text":"Normalize batch inputs input batch L2 norm equal 1 (across axes specified axis).","code":""},{"path":"https://keras.posit.co/reference/layer_unit_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unit normalization layer. — layer_unit_normalization","text":"","code":"layer_unit_normalization(object, axis = -1L, ...)"},{"path":"https://keras.posit.co/reference/layer_unit_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unit normalization layer. — layer_unit_normalization","text":"object Object compose layer . tensor, array, sequential model. axis Integer list. axis axes normalize across. Typically, features axis axes. left-axes typically batch axis axes. -1 last dimension input. Defaults -1. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_unit_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unit normalization layer. — layer_unit_normalization","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_unit_normalization.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unit normalization layer. — layer_unit_normalization","text":"","code":"data <- op_reshape(1:6, newshape = c(2, 3)) normalized_data <- layer_unit_normalization(data) op_sum(normalized_data[1,]^2) ## tf.Tensor(0.9999999, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/layer_upsampling_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Upsampling layer for 1D inputs. — layer_upsampling_1d","title":"Upsampling layer for 1D inputs. — layer_upsampling_1d","text":"Repeats temporal step size times along time axis.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upsampling layer for 1D inputs. — layer_upsampling_1d","text":"","code":"layer_upsampling_1d(object, size = 2L, ...)"},{"path":"https://keras.posit.co/reference/layer_upsampling_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upsampling layer for 1D inputs. — layer_upsampling_1d","text":"object Object compose layer . tensor, array, sequential model. size Integer. Upsampling factor. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upsampling layer for 1D inputs. — layer_upsampling_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upsampling layer for 1D inputs. — layer_upsampling_1d","text":"[[ 6.  7.  8.] [ 6.  7.  8.] [ 9. 10. 11.] [ 9. 10. 11.]]]","code":"input_shape <- c(2, 2, 3) x <- seq_len(prod(input_shape)) %>% op_reshape(input_shape) x ## tf.Tensor( ## [[[ 1  2  3] ##   [ 4  5  6]] ## ##  [[ 7  8  9] ##   [10 11 12]]], shape=(2, 2, 3), dtype=int32) y <- layer_upsampling_1d(x, size = 2) y ## tf.Tensor( ## [[[ 1  2  3] ##   [ 1  2  3] ##   [ 4  5  6] ##   [ 4  5  6]] ## ##  [[ 7  8  9] ##   [ 7  8  9] ##   [10 11 12] ##   [10 11 12]]], shape=(2, 4, 3), dtype=int32)"},{"path":"https://keras.posit.co/reference/layer_upsampling_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Upsampling layer for 1D inputs. — layer_upsampling_1d","text":"3D tensor shape: (batch_size, steps, features).","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Upsampling layer for 1D inputs. — layer_upsampling_1d","text":"3D tensor shape: (batch_size, upsampled_steps, features).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_upsampling_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Upsampling layer for 2D inputs. — layer_upsampling_2d","title":"Upsampling layer for 2D inputs. — layer_upsampling_2d","text":"implementation uses interpolative resizing, given resize method (specified interpolation argument). Use interpolation=nearest repeat rows columns data.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upsampling layer for 2D inputs. — layer_upsampling_2d","text":"","code":"layer_upsampling_2d(   object,   size = list(2L, 2L),   data_format = NULL,   interpolation = \"nearest\",   ... )"},{"path":"https://keras.posit.co/reference/layer_upsampling_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upsampling layer for 2D inputs. — layer_upsampling_2d","text":"object Object compose layer . tensor, array, sequential model. size Int, list 2 integers. upsampling factors rows columns. data_format string, one \"channels_last\" (default) \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, height, width, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, height, width). unspecified, uses image_data_format value found Keras config file ~/.keras/keras.json (exists) else \"channels_last\". Defaults \"channels_last\". interpolation string, one \"bicubic\", \"bilinear\", \"lanczos3\", \"lanczos5\", \"nearest\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upsampling layer for 2D inputs. — layer_upsampling_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upsampling layer for 2D inputs. — layer_upsampling_2d","text":"","code":"input_shape <- c(2, 2, 1, 3) x <- op_reshape(seq_len(prod(input_shape)), input_shape) print(x) ## tf.Tensor( ## [[[[ 1  2  3]] ## ##   [[ 4  5  6]]] ## ## ##  [[[ 7  8  9]] ## ##   [[10 11 12]]]], shape=(2, 2, 1, 3), dtype=int32) y <- layer_upsampling_2d(x, size = c(1, 2)) print(y) ## tf.Tensor( ## [[[[ 1  2  3] ##    [ 1  2  3]] ## ##   [[ 4  5  6] ##    [ 4  5  6]]] ## ## ##  [[[ 7  8  9] ##    [ 7  8  9]] ## ##   [[10 11 12] ##    [10 11 12]]]], shape=(2, 2, 2, 3), dtype=int32)"},{"path":"https://keras.posit.co/reference/layer_upsampling_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Upsampling layer for 2D inputs. — layer_upsampling_2d","text":"4D tensor shape: data_format \"channels_last\": (batch_size, rows, cols, channels) data_format \"channels_first\": (batch_size, channels, rows, cols)","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Upsampling layer for 2D inputs. — layer_upsampling_2d","text":"4D tensor shape: data_format \"channels_last\": (batch_size, upsampled_rows, upsampled_cols, channels) data_format \"channels_first\": (batch_size, channels, upsampled_rows, upsampled_cols)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_upsampling_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Upsampling layer for 3D inputs. — layer_upsampling_3d","title":"Upsampling layer for 3D inputs. — layer_upsampling_3d","text":"Repeats 1st, 2nd 3rd dimensions data size[0], size[1] size[2] respectively.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upsampling layer for 3D inputs. — layer_upsampling_3d","text":"","code":"layer_upsampling_3d(object, size = list(2L, 2L, 2L), data_format = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_upsampling_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upsampling layer for 3D inputs. — layer_upsampling_3d","text":"object Object compose layer . tensor, array, sequential model. size Int, list 3 integers. upsampling factors dim1, dim2 dim3. data_format string, one \"channels_last\" (default) \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3). unspecified, uses image_data_format value found Keras config file ~/.keras/keras.json (exists) else \"channels_last\". Defaults \"channels_last\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upsampling layer for 3D inputs. — layer_upsampling_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_3d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upsampling layer for 3D inputs. — layer_upsampling_3d","text":"","code":"input_shape <- c(2, 1, 2, 1, 3) x <- array(1, dim = input_shape) y <- layer_upsampling_3d(x, size = c(2, 2, 2)) shape(y) ## shape(2, 2, 4, 2, 3)"},{"path":"https://keras.posit.co/reference/layer_upsampling_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Upsampling layer for 3D inputs. — layer_upsampling_3d","text":"5D tensor shape: data_format \"channels_last\": (batch_size, dim1, dim2, dim3, channels) data_format \"channels_first\": (batch_size, channels, dim1, dim2, dim3)","code":""},{"path":"https://keras.posit.co/reference/layer_upsampling_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Upsampling layer for 3D inputs. — layer_upsampling_3d","text":"5D tensor shape: data_format \"channels_last\": (batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels) data_format \"channels_first\": (batch_size, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_zero_padding_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Zero-padding layer for 1D input (e.g. temporal sequence). — layer_zero_padding_1d","title":"Zero-padding layer for 1D input (e.g. temporal sequence). — layer_zero_padding_1d","text":"Zero-padding layer 1D input (e.g. temporal sequence).","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zero-padding layer for 1D input (e.g. temporal sequence). — layer_zero_padding_1d","text":"","code":"layer_zero_padding_1d(object, padding = 1L, ...)"},{"path":"https://keras.posit.co/reference/layer_zero_padding_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zero-padding layer for 1D input (e.g. temporal sequence). — layer_zero_padding_1d","text":"object Object compose layer . tensor, array, sequential model. padding Int, list int (length 2), named listionary. int: many zeros add beginning end padding dimension (axis 1). list 2 ints: many zeros add beginning end padding dimension ((left_pad, right_pad)). ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zero-padding layer for 1D input (e.g. temporal sequence). — layer_zero_padding_1d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_1d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zero-padding layer for 1D input (e.g. temporal sequence). — layer_zero_padding_1d","text":"","code":"input_shape <- c(2, 2, 3) x <- op_reshape(seq_len(prod(input_shape)), input_shape) x ## tf.Tensor( ## [[[ 1  2  3] ##   [ 4  5  6]] ## ##  [[ 7  8  9] ##   [10 11 12]]], shape=(2, 2, 3), dtype=int32) y <- layer_zero_padding_1d(x, padding = 2) y ## tf.Tensor( ## [[[ 0  0  0] ##   [ 0  0  0] ##   [ 1  2  3] ##   [ 4  5  6] ##   [ 0  0  0] ##   [ 0  0  0]] ## ##  [[ 0  0  0] ##   [ 0  0  0] ##   [ 7  8  9] ##   [10 11 12] ##   [ 0  0  0] ##   [ 0  0  0]]], shape=(2, 6, 3), dtype=int32)"},{"path":"https://keras.posit.co/reference/layer_zero_padding_1d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Zero-padding layer for 1D input (e.g. temporal sequence). — layer_zero_padding_1d","text":"3D tensor shape (batch_size, axis_to_pad, features)","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_1d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Zero-padding layer for 1D input (e.g. temporal sequence). — layer_zero_padding_1d","text":"3D tensor shape (batch_size, padded_axis, features)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_zero_padding_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Zero-padding layer for 2D input (e.g. picture). — layer_zero_padding_2d","title":"Zero-padding layer for 2D input (e.g. picture). — layer_zero_padding_2d","text":"layer can add rows columns zeros top, bottom, left right side image tensor.","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zero-padding layer for 2D input (e.g. picture). — layer_zero_padding_2d","text":"","code":"layer_zero_padding_2d(object, padding = list(1L, 1L), data_format = NULL, ...)"},{"path":"https://keras.posit.co/reference/layer_zero_padding_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zero-padding layer for 2D input (e.g. picture). — layer_zero_padding_2d","text":"object Object compose layer . tensor, array, sequential model. padding Int, list 2 ints, list 2 lists 2 ints. int: symmetric padding applied height width. list 2 ints: interpreted two different symmetric padding values height width: (symmetric_height_pad, symmetric_width_pad). list 2 lists 2 ints: interpreted ((top_pad, bottom_pad), (left_pad, right_pad)). data_format string, one \"channels_last\" (default) \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, height, width, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, height, width). unspecified, uses image_data_format value found Keras config file ~/.keras/keras.json (exists). Defaults \"channels_last\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zero-padding layer for 2D input (e.g. picture). — layer_zero_padding_2d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_2d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zero-padding layer for 2D input (e.g. picture). — layer_zero_padding_2d","text":"","code":"input_shape <- c(1, 1, 2, 2) x <- op_reshape(seq_len(prod(input_shape)), input_shape) x ## tf.Tensor( ## [[[[1 2] ##    [3 4]]]], shape=(1, 1, 2, 2), dtype=int32) y <- layer_zero_padding_2d(x, padding = 1) y ## tf.Tensor( ## [[[[0 0] ##    [0 0] ##    [0 0] ##    [0 0]] ## ##   [[0 0] ##    [1 2] ##    [3 4] ##    [0 0]] ## ##   [[0 0] ##    [0 0] ##    [0 0] ##    [0 0]]]], shape=(1, 3, 4, 2), dtype=int32)"},{"path":"https://keras.posit.co/reference/layer_zero_padding_2d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Zero-padding layer for 2D input (e.g. picture). — layer_zero_padding_2d","text":"4D tensor shape: data_format \"channels_last\": (batch_size, height, width, channels) data_format \"channels_first\": (batch_size, channels, height, width)","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_2d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Zero-padding layer for 2D input (e.g. picture). — layer_zero_padding_2d","text":"4D tensor shape: data_format \"channels_last\": (batch_size, padded_height, padded_width, channels) data_format \"channels_first\": (batch_size, channels, padded_height, padded_width)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/layer_zero_padding_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Zero-padding layer for 3D data (spatial or spatio-temporal). — layer_zero_padding_3d","title":"Zero-padding layer for 3D data (spatial or spatio-temporal). — layer_zero_padding_3d","text":"Zero-padding layer 3D data (spatial spatio-temporal).","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zero-padding layer for 3D data (spatial or spatio-temporal). — layer_zero_padding_3d","text":"","code":"layer_zero_padding_3d(   object,   padding = list(list(1L, 1L), list(1L, 1L), list(1L, 1L)),   data_format = NULL,   ... )"},{"path":"https://keras.posit.co/reference/layer_zero_padding_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zero-padding layer for 3D data (spatial or spatio-temporal). — layer_zero_padding_3d","text":"object Object compose layer . tensor, array, sequential model. padding Int, list 3 ints, list 3 lists 2 ints. int: symmetric padding applied depth, height, width. list 3 ints: interpreted three different symmetric padding values depth, height, width: (symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad). list 3 lists 2 ints: interpreted ((left_dim1_pad, right_dim1_pad), (left_dim2_pad, right_dim2_pad), (left_dim3_pad, right_dim3_pad)). data_format string, one \"channels_last\" (default) \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels) \"channels_first\" corresponds inputs shape (batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3). unspecified, uses image_data_format value found Keras config file ~/.keras/keras.json (exists). Defaults \"channels_last\". ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zero-padding layer for 3D data (spatial or spatio-temporal). — layer_zero_padding_3d","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_3d.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zero-padding layer for 3D data (spatial or spatio-temporal). — layer_zero_padding_3d","text":"","code":"input_shape <- c(1, 1, 2, 2, 3) x <- op_reshape(seq_len(prod(input_shape)), input_shape) x ## tf.Tensor( ## [[[[[ 1  2  3] ##     [ 4  5  6]] ## ##    [[ 7  8  9] ##     [10 11 12]]]]], shape=(1, 1, 2, 2, 3), dtype=int32) y <- layer_zero_padding_3d(x, padding = 2) shape(y) ## shape(1, 5, 6, 6, 3)"},{"path":"https://keras.posit.co/reference/layer_zero_padding_3d.html","id":"input-shape","dir":"Reference","previous_headings":"","what":"Input Shape","title":"Zero-padding layer for 3D data (spatial or spatio-temporal). — layer_zero_padding_3d","text":"5D tensor shape: data_format \"channels_last\": (batch_size, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad, depth) data_format \"channels_first\": (batch_size, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)","code":""},{"path":"https://keras.posit.co/reference/layer_zero_padding_3d.html","id":"output-shape","dir":"Reference","previous_headings":"","what":"Output Shape","title":"Zero-padding layer for 3D data (spatial or spatio-temporal). — layer_zero_padding_3d","text":"5D tensor shape: data_format \"channels_last\": (batch_size, first_padded_axis, second_padded_axis, third_axis_to_pad, depth) data_format \"channels_first\": (batch_size, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/learning_rate_schedule_cosine_decay.html","id":null,"dir":"Reference","previous_headings":"","what":"A LearningRateSchedule that uses a cosine decay with optional warmup. — learning_rate_schedule_cosine_decay","title":"A LearningRateSchedule that uses a cosine decay with optional warmup. — learning_rate_schedule_cosine_decay","text":"See Loshchilov & Hutter, ICLR2016, SGDR: Stochastic Gradient Descent Warm Restarts. idea linear warmup learning rate, see Goyal et al.. begin training model, often want initial increase learning rate followed decay. warmup_target int, schedule applies linear increase per optimizer step learning rate initial_learning_rate warmup_target duration warmup_steps. Afterwards, applies cosine decay function taking learning rate warmup_target alpha duration decay_steps. warmup_target NULL skip warmup decay take learning rate initial_learning_rate alpha. requires step value  compute learning rate. can just pass backend variable increment training step. schedule 1-arg callable produces warmup followed decayed learning rate passed current optimizer step. can useful changing learning rate value across different invocations optimizer functions. warmup computed :   decay computed :   Example usage without warmup:   Example usage warmup:   can pass schedule directly optimizer learning rate. learning rate schedule also serializable deserializable using keras$optimizers$schedules$serialize keras$optimizers$schedules$deserialize.","code":"warmup_learning_rate <- function(step) {   completed_fraction <- step / warmup_steps   total_delta <- target_warmup - initial_learning_rate   completed_fraction * total_delta } if (is.null(warmup_target)) {   initial_decay_lr <- initial_learning_rate } else {   initial_decay_lr <- warmup_target }  decayed_learning_rate <- function(step) {   step <- min(step, decay_steps)   cosine_decay <- 0.5 * (1 + cos(pi * step / decay_steps))   decayed <- (1 - alpha) * cosine_decay + alpha   initial_decay_lr * decayed } decay_steps <- 1000 initial_learning_rate <- 0.1 lr_decayed_fn <- learning_rate_schedule_cosine_decay(     initial_learning_rate, decay_steps) decay_steps <- 1000 initial_learning_rate <- 0 warmup_steps <- 1000 target_learning_rate <- 0.1 lr_warmup_decayed_fn <- learning_rate_schedule_cosine_decay(     initial_learning_rate, decay_steps, warmup_target = target_learning_rate,     warmup_steps = warmup_steps )"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_cosine_decay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A LearningRateSchedule that uses a cosine decay with optional warmup. — learning_rate_schedule_cosine_decay","text":"","code":"learning_rate_schedule_cosine_decay(   initial_learning_rate,   decay_steps,   alpha = 0,   name = \"CosineDecay\",   warmup_target = NULL,   warmup_steps = 0L )"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_cosine_decay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A LearningRateSchedule that uses a cosine decay with optional warmup. — learning_rate_schedule_cosine_decay","text":"initial_learning_rate float. initial learning rate. decay_steps int. Number steps decay . alpha float. Minimum learning rate value decay fraction initial_learning_rate. name String. Optional name operation.  Defaults \"CosineDecay\". warmup_target float. target learning rate warmup phase. cast initial_learning_rate datatype. Setting NULL skip warmup begins decay phase initial_learning_rate. Otherwise scheduler warmup initial_learning_rate warmup_target. warmup_steps int. Number steps warmup .","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_cosine_decay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A LearningRateSchedule that uses a cosine decay with optional warmup. — learning_rate_schedule_cosine_decay","text":"1-arg callable learning rate schedule takes current optimizer step outputs decayed learning rate, scalar tensor type initial_learning_rate.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/learning_rate_schedule_cosine_decay_restarts.html","id":null,"dir":"Reference","previous_headings":"","what":"A LearningRateSchedule that uses a cosine decay schedule with restarts. — learning_rate_schedule_cosine_decay_restarts","title":"A LearningRateSchedule that uses a cosine decay schedule with restarts. — learning_rate_schedule_cosine_decay_restarts","text":"See Loshchilov & Hutter, ICLR2016, SGDR: Stochastic Gradient Descent Warm Restarts. training model, often useful lower learning rate training progresses. schedule applies cosine decay function restarts optimizer step, given provided initial learning rate. requires step value compute decayed learning rate. can just pass backend variable increment training step. schedule 1-arg callable produces decayed learning rate passed current optimizer step. can useful changing learning rate value across different invocations optimizer functions. learning rate multiplier first decays 1 alpha first_decay_steps steps. , warm restart performed. new warm restart runs t_mul times steps m_mul times initial learning rate new learning rate. Example usage:   can pass schedule directly optimizer learning rate. learning rate schedule also serializable deserializable using keras$optimizers$schedules$serialize keras$optimizers$schedules$deserialize.","code":"first_decay_steps <- 1000 lr_decayed_fn <- learning_rate_schedule_cosine_decay_restarts(         0.001,         first_decay_steps)"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_cosine_decay_restarts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A LearningRateSchedule that uses a cosine decay schedule with restarts. — learning_rate_schedule_cosine_decay_restarts","text":"","code":"learning_rate_schedule_cosine_decay_restarts(   initial_learning_rate,   first_decay_steps,   t_mul = 2,   m_mul = 1,   alpha = 0,   name = \"SGDRDecay\" )"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_cosine_decay_restarts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A LearningRateSchedule that uses a cosine decay schedule with restarts. — learning_rate_schedule_cosine_decay_restarts","text":"initial_learning_rate float. initial learning rate. first_decay_steps integer. Number steps decay . t_mul float. Used derive number iterations -th period. m_mul float. Used derive initial learning rate -th period. alpha float. Minimum learning rate value fraction initial_learning_rate. name String. Optional name operation. Defaults \"SGDRDecay\".","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_cosine_decay_restarts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A LearningRateSchedule that uses a cosine decay schedule with restarts. — learning_rate_schedule_cosine_decay_restarts","text":"1-arg callable learning rate schedule takes current optimizer step outputs decayed learning rate, scalar tensor type initial_learning_rate.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/learning_rate_schedule_exponential_decay.html","id":null,"dir":"Reference","previous_headings":"","what":"A LearningRateSchedule that uses an exponential decay schedule. — learning_rate_schedule_exponential_decay","title":"A LearningRateSchedule that uses an exponential decay schedule. — learning_rate_schedule_exponential_decay","text":"training model, often useful lower learning rate training progresses. schedule applies exponential decay function optimizer step, given provided initial learning rate. schedule 1-arg callable produces decayed learning rate passed current optimizer step. can useful changing learning rate value across different invocations optimizer functions. computed :   argument staircase TRUE, step / decay_steps integer division decayed learning rate follows staircase function. can pass schedule directly optimizer learning rate.","code":"decayed_learning_rate <- function(step) {   initial_learning_rate * decay_rate ^ (step / decay_steps) }"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_exponential_decay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A LearningRateSchedule that uses an exponential decay schedule. — learning_rate_schedule_exponential_decay","text":"","code":"learning_rate_schedule_exponential_decay(   initial_learning_rate,   decay_steps,   decay_rate,   staircase = FALSE,   name = \"ExponentialDecay\" )"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_exponential_decay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A LearningRateSchedule that uses an exponential decay schedule. — learning_rate_schedule_exponential_decay","text":"initial_learning_rate float. initial learning rate. decay_steps integer. Must positive. See decay computation . decay_rate float. decay rate. staircase Boolean.  TRUE decay learning rate discrete intervals. name String.  Optional name operation.  Defaults \"ExponentialDecay\".","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_exponential_decay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A LearningRateSchedule that uses an exponential decay schedule. — learning_rate_schedule_exponential_decay","text":"1-arg callable learning rate schedule takes current optimizer step outputs decayed learning rate, scalar tensor type initial_learning_rate.","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_exponential_decay.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A LearningRateSchedule that uses an exponential decay schedule. — learning_rate_schedule_exponential_decay","text":"fitting Keras model, decay every 100000 steps base 0.96:   learning rate schedule also serializable deserializable using keras$optimizers$schedules$serialize keras$optimizers$schedules$deserialize.","code":"initial_learning_rate <- 0.1 lr_schedule <- learning_rate_schedule_exponential_decay(     initial_learning_rate,     decay_steps=100000,     decay_rate=0.96,     staircase=TRUE)  model %>% compile(   optimizer = optimizer_sgd(learning_rate = lr_schedule),   loss = 'sparse_categorical_crossentropy',   metrics = c('accuracy'))  model %>% fit(data, labels, epochs=5)"},{"path":[]},{"path":"https://keras.posit.co/reference/learning_rate_schedule_inverse_time_decay.html","id":null,"dir":"Reference","previous_headings":"","what":"A LearningRateSchedule that uses an inverse time decay schedule. — learning_rate_schedule_inverse_time_decay","title":"A LearningRateSchedule that uses an inverse time decay schedule. — learning_rate_schedule_inverse_time_decay","text":"training model, often useful lower learning rate training progresses. schedule applies inverse decay function optimizer step, given provided initial learning rate. requires step value compute decayed learning rate. can just pass backend variable increment training step. schedule 1-arg callable produces decayed learning rate passed current optimizer step. can useful changing learning rate value across different invocations optimizer functions. computed :   , staircase TRUE, :   can pass schedule directly optimizer_* learning rate.","code":"decayed_learning_rate <- function(step) {   initial_learning_rate / (1 + decay_rate * step / decay_step) } decayed_learning_rate <- function(step) {   initial_learning_rate /            (1 + decay_rate * floor(step / decay_step)) }"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_inverse_time_decay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A LearningRateSchedule that uses an inverse time decay schedule. — learning_rate_schedule_inverse_time_decay","text":"","code":"learning_rate_schedule_inverse_time_decay(   initial_learning_rate,   decay_steps,   decay_rate,   staircase = FALSE,   name = \"InverseTimeDecay\" )"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_inverse_time_decay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A LearningRateSchedule that uses an inverse time decay schedule. — learning_rate_schedule_inverse_time_decay","text":"initial_learning_rate float. initial learning rate. decay_steps often apply decay. decay_rate number.  decay rate. staircase Whether apply decay discrete staircase, o pposed continuous, fashion. name String.  Optional name operation.  Defaults \"InverseTimeDecay\".","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_inverse_time_decay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A LearningRateSchedule that uses an inverse time decay schedule. — learning_rate_schedule_inverse_time_decay","text":"1-arg callable learning rate schedule takes current optimizer step outputs decayed learning rate, scalar tensor type initial_learning_rate.","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_inverse_time_decay.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A LearningRateSchedule that uses an inverse time decay schedule. — learning_rate_schedule_inverse_time_decay","text":"Fit Keras model decaying 1/t rate 0.5:","code":"... initial_learning_rate <- 0.1 decay_steps <- 1.0 decay_rate <- 0.5 learning_rate_fn <- learning_rate_schedule_inverse_time_decay(     initial_learning_rate, decay_steps, decay_rate)  model %>% compile(   optimizer = optimizer_sgd(learning_rate=learning_rate_fn),   loss = 'sparse_categorical_crossentropy',   metrics = 'accuracy') )  model %>% fit(data, labels, epochs=5)"},{"path":[]},{"path":"https://keras.posit.co/reference/learning_rate_schedule_piecewise_constant_decay.html","id":null,"dir":"Reference","previous_headings":"","what":"A LearningRateSchedule that uses a piecewise constant decay schedule. — learning_rate_schedule_piecewise_constant_decay","title":"A LearningRateSchedule that uses a piecewise constant decay schedule. — learning_rate_schedule_piecewise_constant_decay","text":"function returns 1-arg callable compute piecewise constant passed current optimizer step. can useful changing learning rate value across different invocations optimizer functions.","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_piecewise_constant_decay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A LearningRateSchedule that uses a piecewise constant decay schedule. — learning_rate_schedule_piecewise_constant_decay","text":"","code":"learning_rate_schedule_piecewise_constant_decay(   boundaries,   values,   name = \"PiecewiseConstant\" )"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_piecewise_constant_decay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A LearningRateSchedule that uses a piecewise constant decay schedule. — learning_rate_schedule_piecewise_constant_decay","text":"boundaries list Python numbers strictly increasing entries, elements type optimizer step. values list Python numbers specifies values intervals defined boundaries. one element boundaries, elements type. name string. Optional name operation. Defaults \"PiecewiseConstant\".","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_piecewise_constant_decay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A LearningRateSchedule that uses a piecewise constant decay schedule. — learning_rate_schedule_piecewise_constant_decay","text":"1-arg callable learning rate schedule takes current optimizer step outputs decayed learning rate, scalar tensor type boundary tensors. output 1-arg function takes step values[0] step <= boundaries[0], values[1] step > boundaries[0] step <= boundaries[1], ..., values[-1] step > boundaries[-1].","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_piecewise_constant_decay.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A LearningRateSchedule that uses a piecewise constant decay schedule. — learning_rate_schedule_piecewise_constant_decay","text":"use learning rate 1.0 first 100001 steps, 0.5 next 10000 steps, 0.1 additional steps.   can pass schedule directly optimizer learning rate. learning rate schedule also serializable deserializable using keras$optimizers$schedules$serialize keras$optimizers$schedules$deserialize.","code":"step <- 0 boundaries <- c(100000, 110000) values <- c(1.0, 0.5, 0.1) learning_rate_fn <- learning_rate_schedule_piecewise_constant_decay(   boundaries, values)  # Later, whenever we perform an optimization step, we pass in the step. learning_rate <- learning_rate_fn(step)"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_piecewise_constant_decay.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"A LearningRateSchedule that uses a piecewise constant decay schedule. — learning_rate_schedule_piecewise_constant_decay","text":"ValueError: number elements boundaries values lists match.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/learning_rate_schedule_polynomial_decay.html","id":null,"dir":"Reference","previous_headings":"","what":"A LearningRateSchedule that uses a polynomial decay schedule. — learning_rate_schedule_polynomial_decay","title":"A LearningRateSchedule that uses a polynomial decay schedule. — learning_rate_schedule_polynomial_decay","text":"commonly observed monotonically decreasing learning rate, whose degree change carefully chosen, results better performing model. schedule applies polynomial decay function optimizer step, given provided initial_learning_rate, reach end_learning_rate given decay_steps. requires step value compute decayed learning rate. can just pass backend variable increment training step. schedule 1-arg callable produces decayed learning rate passed current optimizer step. can useful changing learning rate value across different invocations optimizer functions. computed :   cycle TRUE multiple decay_steps used, first one bigger step.   can pass schedule directly Optimizer learning rate.","code":"decayed_learning_rate <- function(step) {   step = min(step, decay_steps)   ((initial_learning_rate - end_learning_rate) *     (1 - step / decay_steps) ^ (power)) +     end_learning_rate } decayed_learning_rate <- function(step) {   decay_steps = decay_steps * ceil(step / decay_steps)   ((initial_learning_rate - end_learning_rate) *       (1 - step / decay_steps) ^ (power)) +     end_learning_rate }"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_polynomial_decay.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A LearningRateSchedule that uses a polynomial decay schedule. — learning_rate_schedule_polynomial_decay","text":"","code":"learning_rate_schedule_polynomial_decay(   initial_learning_rate,   decay_steps,   end_learning_rate = 1e-04,   power = 1,   cycle = FALSE,   name = \"PolynomialDecay\" )"},{"path":"https://keras.posit.co/reference/learning_rate_schedule_polynomial_decay.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A LearningRateSchedule that uses a polynomial decay schedule. — learning_rate_schedule_polynomial_decay","text":"initial_learning_rate float. initial learning rate. decay_steps integer. Must positive. See decay computation . end_learning_rate float. minimal end learning rate. power float. power polynomial. Defaults 1.0. cycle boolean, whether cycle beyond decay_steps. name String.  Optional name operation. Defaults \"PolynomialDecay\".","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_polynomial_decay.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A LearningRateSchedule that uses a polynomial decay schedule. — learning_rate_schedule_polynomial_decay","text":"1-arg callable learning rate schedule takes current optimizer step outputs decayed learning rate, scalar tensor type initial_learning_rate.","code":""},{"path":"https://keras.posit.co/reference/learning_rate_schedule_polynomial_decay.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A LearningRateSchedule that uses a polynomial decay schedule. — learning_rate_schedule_polynomial_decay","text":"Fit model decaying 0.1 0.01 10000 steps using sqrt (.e. power=0.5):   learning rate schedule also serializable deserializable using keras$optimizers$schedules$serialize keras$optimizers$schedules$deserialize.","code":"... starter_learning_rate <- 0.1 end_learning_rate <- 0.01 decay_steps <- 10000 learning_rate_fn <- learning_rate_schedule_polynomial_decay(     starter_learning_rate,     decay_steps,     end_learning_rate,     power=0.5)  model %>% compile(   optimizer = optimizer_sgd(learning_rate=learning_rate_fn),   loss = 'sparse_categorical_crossentropy',   metrics = 'accuracy' )  model %>% fit(data, labels, epochs=5)"},{"path":[]},{"path":"https://keras.posit.co/reference/load_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads a model saved via save_model(). — load_model","title":"Loads a model saved via save_model(). — load_model","text":"Loads model saved via save_model().","code":""},{"path":"https://keras.posit.co/reference/load_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loads a model saved via save_model(). — load_model","text":"","code":"load_model(model, custom_objects = NULL, compile = TRUE, safe_mode = TRUE)"},{"path":"https://keras.posit.co/reference/load_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loads a model saved via save_model(). — load_model","text":"model string, path saved model file, raw vector, returned save_model(filepath = NULL) custom_objects Optional named list mapping names custom classes functions considered deserialization. compile Boolean, whether compile model loading. safe_mode Boolean, whether disallow unsafe lambda deserialization. safe_mode=FALSE, loading object potential trigger arbitrary code execution. argument applicable Keras v3 model format. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/load_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loads a model saved via save_model(). — load_model","text":"Keras model instance. original model compiled, argument compile = TRUE set, returned model compiled. Otherwise, model left uncompiled.","code":""},{"path":"https://keras.posit.co/reference/load_model.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Loads a model saved via save_model(). — load_model","text":"Note model variables may different name values (var$name property, e.g. \"dense_1/kernel:0\") reloaded. recommended use layer attributes access specific variables, e.g. model |> get_layer(\"dense_1\") |> _$kernel.","code":"model <- keras_model_sequential(input_shape = c(3)) |>   layer_dense(5) |>   layer_activation_softmax()  model |> save_model(\"model.keras\") loaded_model <- load_model(\"model.keras\") x <- random_uniform(c(10, 3)) stopifnot(all.equal(   model |> predict(x),   loaded_model |> predict(x) ))"},{"path":[]},{"path":"https://keras.posit.co/reference/load_model_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Load weights from a file saved via save_model_weights(). — load_model_weights","title":"Load weights from a file saved via save_model_weights(). — load_model_weights","text":"Weights loaded based network's topology. means architecture weights saved. Note layers weights taken account topological ordering, adding removing layers fine long weights. Partial weight loading modified model, instance adding new layer (weights) changing shape weights layer, can choose ignore errors continue loading setting skip_mismatch=TRUE. case layer mismatching weights skipped. warning displayed skipped layer.","code":""},{"path":"https://keras.posit.co/reference/load_model_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load weights from a file saved via save_model_weights(). — load_model_weights","text":"","code":"load_model_weights(model, filepath, skip_mismatch = FALSE, ...)"},{"path":"https://keras.posit.co/reference/load_model_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load weights from a file saved via save_model_weights(). — load_model_weights","text":"model keras model. filepath String, path weights file load. can either .weights.h5 file legacy .h5 weights file. skip_mismatch Boolean, whether skip loading layers mismatch number weights, mismatch shape weights. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/load_model_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load weights from a file saved via save_model_weights(). — load_model_weights","text":"called primarily side effects. model returned, invisibly, enable usage pipe.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/loss_binary_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the cross-entropy loss between true labels and predicted labels. — loss_binary_crossentropy","title":"Computes the cross-entropy loss between true labels and predicted labels. — loss_binary_crossentropy","text":"Use cross-entropy loss binary (0 1) classification applications. loss function requires following inputs: y_true (true label): either 0 1. y_pred (predicted value): model's prediction, .e, single floating-point value either represents logit, (.e, value [-inf, inf] from_logits=TRUE) probability (.e, value [0., 1.] from_logits=FALSE).","code":""},{"path":"https://keras.posit.co/reference/loss_binary_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the cross-entropy loss between true labels and predicted labels. — loss_binary_crossentropy","text":"","code":"loss_binary_crossentropy(   y_true,   y_pred,   from_logits = FALSE,   label_smoothing = 0,   axis = -1L,   ...,   reduction = \"sum_over_batch_size\",   name = \"binary_crossentropy\" )"},{"path":"https://keras.posit.co/reference/loss_binary_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the cross-entropy loss between true labels and predicted labels. — loss_binary_crossentropy","text":"y_true Ground truth values. shape = [batch_size, d0, .. dN]. y_pred predicted values. shape = [batch_size, d0, .. dN]. from_logits Whether interpret y_pred tensor logit values. default, assume y_pred probabilities (.e., values [0, 1)). label_smoothing Float range [0, 1]. 0, smoothing occurs. > 0, compute loss predicted labels smoothed version true labels, smoothing squeezes labels towards 0.5. Larger values label_smoothing correspond heavier smoothing. axis axis along compute crossentropy (features axis). Defaults -1. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_binary_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the cross-entropy loss between true labels and predicted labels. — loss_binary_crossentropy","text":"Binary crossentropy loss value. shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_binary_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the cross-entropy loss between true labels and predicted labels. — loss_binary_crossentropy","text":"Recommended Usage: (set from_logits=TRUE) compile() API:   standalone function:                     Default Usage: (set from_logits=FALSE)","code":"y_true <- rbind(c(0, 1), c(0, 0)) y_pred <- rbind(c(0.6, 0.4), c(0.4, 0.6)) loss <- loss_binary_crossentropy(y_true, y_pred) loss ## tf.Tensor([0.91629073 0.71355818], shape=(2), dtype=float64) model %>% compile(     loss = loss_binary_crossentropy(from_logits=TRUE),     ... ) # Example 1: (batch_size = 1, number of samples = 4) y_true <- op_array(c(0, 1, 0, 0)) y_pred <- op_array(c(-18.6, 0.51, 2.94, -12.8)) bce <- loss_binary_crossentropy(from_logits = TRUE) bce(y_true, y_pred) ## tf.Tensor(0.865458, shape=(), dtype=float32) # Example 2: (batch_size = 2, number of samples = 4) y_true <- rbind(c(0, 1), c(0, 0)) y_pred <- rbind(c(-18.6, 0.51), c(2.94, -12.8)) # Using default 'auto'/'sum_over_batch_size' reduction type. bce <- loss_binary_crossentropy(from_logits = TRUE) bce(y_true, y_pred) ## tf.Tensor(0.865458, shape=(), dtype=float32) # Using 'sample_weight' attribute bce(y_true, y_pred, sample_weight = c(0.8, 0.2)) ## tf.Tensor(0.2436386, shape=(), dtype=float32) # 0.243 # Using 'sum' reduction` type. bce <- loss_binary_crossentropy(from_logits = TRUE, reduction = \"sum\") bce(y_true, y_pred) ## tf.Tensor(1.730916, shape=(), dtype=float32) # Using 'none' reduction type. bce <- loss_binary_crossentropy(from_logits = TRUE, reduction = NULL) bce(y_true, y_pred) ## tf.Tensor([0.23515666 1.4957594 ], shape=(2), dtype=float32) # Make the following updates to the above \"Recommended Usage\" section # 1. Set `from_logits=FALSE` loss_binary_crossentropy() # OR ...('from_logits=FALSE') ## <keras.src.losses.losses.BinaryCrossentropy object> # 2. Update `y_pred` to use probabilities instead of logits y_pred <- c(0.6, 0.3, 0.2, 0.8) # OR [[0.6, 0.3], [0.2, 0.8]]"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_binary_focal_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes focal cross-entropy loss between true labels and predictions. — loss_binary_focal_crossentropy","title":"Computes focal cross-entropy loss between true labels and predictions. — loss_binary_focal_crossentropy","text":"According Lin et al., 2018, helps apply focal factor -weight easy examples focus hard examples. default, focal tensor computed follows: focal_factor = (1 - output)^gamma class 1 focal_factor = output^gamma class 0 gamma focusing parameter. gamma = 0, focal effect binary crossentropy loss. apply_class_balancing == TRUE, function also takes account weight balancing factor binary classes 0 1 follows: weight = alpha class 1 (target == 1) weight = 1 - alpha class 0 alpha float range [0, 1]. Binary cross-entropy loss often used binary (0 1) classification tasks. loss function requires following inputs: y_true (true label): either 0 1. y_pred (predicted value): model's prediction, .e, single floating-point value either represents logit, (.e, value [-inf, inf] from_logits=TRUE) probability (.e, value [0., 1.] from_logits=FALSE). According Lin et al., 2018, helps apply \"focal factor\" -weight easy examples focus hard examples. default, focal tensor computed follows: focal_factor = (1 - output) ** gamma class 1 focal_factor = output ** gamma class 0 gamma focusing parameter. gamma=0, function equivalent binary crossentropy loss.","code":""},{"path":"https://keras.posit.co/reference/loss_binary_focal_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes focal cross-entropy loss between true labels and predictions. — loss_binary_focal_crossentropy","text":"","code":"loss_binary_focal_crossentropy(   y_true,   y_pred,   apply_class_balancing = FALSE,   alpha = 0.25,   gamma = 2,   from_logits = FALSE,   label_smoothing = 0,   axis = -1L,   ...,   reduction = \"sum_over_batch_size\",   name = \"binary_focal_crossentropy\" )"},{"path":"https://keras.posit.co/reference/loss_binary_focal_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes focal cross-entropy loss between true labels and predictions. — loss_binary_focal_crossentropy","text":"y_true Ground truth values, shape (batch_size, d0, .. dN). y_pred predicted values, shape (batch_size, d0, .. dN). apply_class_balancing bool, whether apply weight balancing binary classes 0 1. alpha weight balancing factor class 1, default 0.25 mentioned reference Lin et al., 2018.  weight class 0 1.0 - alpha. gamma focusing parameter used compute focal factor, default 2.0 mentioned reference Lin et al., 2018. from_logits Whether interpret y_pred tensor logit values. default, assume y_pred probabilities (.e., values [0, 1]). label_smoothing Float [0, 1]. 0, smoothing occurs. > 0, compute loss predicted labels smoothed version true labels, smoothing squeezes labels towards 0.5. Larger values label_smoothing correspond heavier smoothing. axis axis along compute crossentropy (features axis). Defaults -1. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_binary_focal_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes focal cross-entropy loss between true labels and predictions. — loss_binary_focal_crossentropy","text":"Binary focal crossentropy loss value shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_binary_focal_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes focal cross-entropy loss between true labels and predictions. — loss_binary_focal_crossentropy","text":"compile() API:   standalone function:","code":"y_true <- rbind(c(0, 1), c(0, 0)) y_pred <- rbind(c(0.6, 0.4), c(0.4, 0.6)) loss <- loss_binary_focal_crossentropy(y_true, y_pred, gamma = 2) loss ## tf.Tensor([0.32986466 0.20579838], shape=(2), dtype=float64) model %>% compile(     loss = loss_binary_focal_crossentropy(         gamma = 2.0, from_logits = TRUE),     ... ) # Example 1: (batch_size = 1, number of samples = 4) y_true <- op_array(c(0, 1, 0, 0)) y_pred <- op_array(c(-18.6, 0.51, 2.94, -12.8)) loss <- loss_binary_focal_crossentropy(gamma = 2, from_logits = TRUE) loss(y_true, y_pred) ## tf.Tensor(0.6912122, shape=(), dtype=float32) # Apply class weight loss <- loss_binary_focal_crossentropy(   apply_class_balancing = TRUE, gamma = 2, from_logits = TRUE) loss(y_true, y_pred) ## tf.Tensor(0.5101333, shape=(), dtype=float32) # Example 2: (batch_size = 2, number of samples = 4) y_true <- rbind(c(0, 1), c(0, 0)) y_pred <- rbind(c(-18.6, 0.51), c(2.94, -12.8)) # Using default 'auto'/'sum_over_batch_size' reduction type. loss <- loss_binary_focal_crossentropy(     gamma = 3, from_logits = TRUE) loss(y_true, y_pred) ## tf.Tensor(0.6469951, shape=(), dtype=float32) # Apply class weight loss <- loss_binary_focal_crossentropy(      apply_class_balancing = TRUE, gamma = 3, from_logits = TRUE) loss(y_true, y_pred) ## tf.Tensor(0.48214132, shape=(), dtype=float32) # Using 'sample_weight' attribute with focal effect loss <- loss_binary_focal_crossentropy(     gamma = 3, from_logits = TRUE) loss(y_true, y_pred, sample_weight = c(0.8, 0.2)) ## tf.Tensor(0.13312504, shape=(), dtype=float32) # Apply class weight loss <- loss_binary_focal_crossentropy(      apply_class_balancing = TRUE, gamma = 3, from_logits = TRUE) loss(y_true, y_pred, sample_weight = c(0.8, 0.2)) ## tf.Tensor(0.09735977, shape=(), dtype=float32) # Using 'sum' reduction` type. loss <- loss_binary_focal_crossentropy(     gamma = 4, from_logits = TRUE,     reduction = \"sum\") loss(y_true, y_pred) ## tf.Tensor(1.2218808, shape=(), dtype=float32) # Apply class weight loss <- loss_binary_focal_crossentropy(     apply_class_balancing = TRUE, gamma = 4, from_logits = TRUE,     reduction = \"sum\") loss(y_true, y_pred) ## tf.Tensor(0.9140807, shape=(), dtype=float32) # Using 'none' reduction type. loss <- loss_binary_focal_crossentropy(     gamma = 5, from_logits = TRUE,     reduction = NULL) loss(y_true, y_pred) ## tf.Tensor([0.00174837 1.1561027 ], shape=(2), dtype=float32) # Apply class weight loss <- loss_binary_focal_crossentropy(     apply_class_balancing = TRUE, gamma = 5, from_logits = TRUE,     reduction = NULL) loss(y_true, y_pred) ## tf.Tensor([4.3709317e-04 8.6707699e-01], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_categorical_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the crossentropy loss between the labels and predictions. — loss_categorical_crossentropy","title":"Computes the crossentropy loss between the labels and predictions. — loss_categorical_crossentropy","text":"Use crossentropy loss function two label classes. expect labels provided one_hot representation. want provide labels integers, please use SparseCategoricalCrossentropy loss. num_classes floating point values per feature, .e., shape y_pred y_true [batch_size, num_classes].","code":""},{"path":"https://keras.posit.co/reference/loss_categorical_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the crossentropy loss between the labels and predictions. — loss_categorical_crossentropy","text":"","code":"loss_categorical_crossentropy(   y_true,   y_pred,   from_logits = FALSE,   label_smoothing = 0,   axis = -1L,   ...,   reduction = \"sum_over_batch_size\",   name = \"categorical_crossentropy\" )"},{"path":"https://keras.posit.co/reference/loss_categorical_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the crossentropy loss between the labels and predictions. — loss_categorical_crossentropy","text":"y_true Tensor one-hot true targets. y_pred Tensor predicted targets. from_logits Whether y_pred expected logits tensor. default, assume y_pred encodes probability distribution. label_smoothing Float [0, 1]. > 0, label values smoothed, meaning confidence label values relaxed. example, 0.1, use 0.1 / num_classes non-target labels 0.9 + 0.1 / num_classes target labels. axis axis along compute crossentropy (features axis). Defaults -1. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_categorical_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the crossentropy loss between the labels and predictions. — loss_categorical_crossentropy","text":"Categorical crossentropy loss value.","code":""},{"path":"https://keras.posit.co/reference/loss_categorical_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the crossentropy loss between the labels and predictions. — loss_categorical_crossentropy","text":"Standalone usage:                 Usage compile() API:","code":"y_true <- rbind(c(0, 1, 0), c(0, 0, 1)) y_pred <- rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1)) loss <- loss_categorical_crossentropy(y_true, y_pred) loss ## tf.Tensor([0.05129329 2.30258509], shape=(2), dtype=float64) y_true <- rbind(c(0, 1, 0), c(0, 0, 1)) y_pred <- rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1)) # Using 'auto'/'sum_over_batch_size' reduction type. cce <- loss_categorical_crossentropy() cce(y_true, y_pred) ## tf.Tensor(1.1769392, shape=(), dtype=float32) # Calling with 'sample_weight'. cce(y_true, y_pred, sample_weight = op_array(c(0.3, 0.7))) ## tf.Tensor(0.8135988, shape=(), dtype=float32) # Using 'sum' reduction type. cce <- loss_categorical_crossentropy(reduction = \"sum\") cce(y_true, y_pred) ## tf.Tensor(2.3538785, shape=(), dtype=float32) # Using 'none' reduction type. cce <- loss_categorical_crossentropy(reduction = NULL) cce(y_true, y_pred) ## tf.Tensor([0.05129331 2.3025851 ], shape=(2), dtype=float32) model %>% compile(optimizer = 'sgd',               loss=loss_categorical_crossentropy())"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_categorical_focal_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the alpha balanced focal crossentropy loss. — loss_categorical_focal_crossentropy","title":"Computes the alpha balanced focal crossentropy loss. — loss_categorical_focal_crossentropy","text":"Use crossentropy loss function two label classes want handle class imbalance without using class_weights. expect labels provided one_hot representation. According Lin et al., 2018, helps apply focal factor -weight easy examples focus hard examples. general formula focal loss (FL) follows: FL(p_t) = (1 - p_t)^gamma * log(p_t) p_t defined follows: p_t = output y_true == 1, else 1 - output (1 - p_t)^gamma modulating_factor, gamma focusing parameter. gamma = 0, focal effect cross entropy. gamma reduces importance given simple examples smooth manner. authors use alpha-balanced variant focal loss (FL) paper: FL(p_t) = -alpha * (1 - p_t)^gamma * log(p_t) alpha weight factor classes. alpha = 1, loss able handle class imbalance properly classes weight. can constant list constants. alpha list, must length number classes. formula can generalized : FL(p_t) = alpha * (1 - p_t)^gamma * CrossEntropy(y_true, y_pred) minus comes CrossEntropy(y_true, y_pred) (CE). Extending multi-class case straightforward: FL(p_t) = alpha * (1 - p_t) ** gamma * CategoricalCE(y_true, y_pred) snippet , num_classes floating pointing values per example. shape y_pred y_true (batch_size, num_classes).","code":""},{"path":"https://keras.posit.co/reference/loss_categorical_focal_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the alpha balanced focal crossentropy loss. — loss_categorical_focal_crossentropy","text":"","code":"loss_categorical_focal_crossentropy(   y_true,   y_pred,   alpha = 0.25,   gamma = 2,   from_logits = FALSE,   label_smoothing = 0,   axis = -1L,   ...,   reduction = \"sum_over_batch_size\",   name = \"categorical_focal_crossentropy\" )"},{"path":"https://keras.posit.co/reference/loss_categorical_focal_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the alpha balanced focal crossentropy loss. — loss_categorical_focal_crossentropy","text":"y_true Tensor one-hot true targets. y_pred Tensor predicted targets. alpha weight balancing factor classes, default 0.25 mentioned reference. can list floats scalar. multi-class case, alpha may set inverse class frequency using compute_class_weight sklearn.utils. gamma focusing parameter, default 2.0 mentioned reference. helps gradually reduce importance given simple examples smooth manner. gamma = 0, focal effect categorical crossentropy. from_logits Whether output expected logits tensor. default, consider output encodes probability distribution. label_smoothing Float [0, 1]. > 0, label values smoothed, meaning confidence label values relaxed. example, 0.1, use 0.1 / num_classes non-target labels 0.9 + 0.1 / num_classes target labels. axis axis along compute crossentropy (features axis). Defaults -1. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_categorical_focal_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the alpha balanced focal crossentropy loss. — loss_categorical_focal_crossentropy","text":"Categorical focal crossentropy loss value.","code":""},{"path":"https://keras.posit.co/reference/loss_categorical_focal_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the alpha balanced focal crossentropy loss. — loss_categorical_focal_crossentropy","text":"Standalone usage:                 Usage compile() API:","code":"y_true <- rbind(c(0, 1, 0), c(0, 0, 1)) y_pred <- rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1)) loss <- loss_categorical_focal_crossentropy(y_true, y_pred) loss ## tf.Tensor([3.20583090e-05 4.66273481e-01], shape=(2), dtype=float64) y_true <- rbind(c(0, 1, 0), c(0, 0, 1)) y_pred <- rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1)) # Using 'auto'/'sum_over_batch_size' reduction type. cce <- loss_categorical_focal_crossentropy() cce(y_true, y_pred) ## tf.Tensor(0.23315276, shape=(), dtype=float32) # Calling with 'sample_weight'. cce(y_true, y_pred, sample_weight = op_array(c(0.3, 0.7))) ## tf.Tensor(0.16320053, shape=(), dtype=float32) # Using 'sum' reduction type. cce <- loss_categorical_focal_crossentropy(reduction = \"sum\") cce(y_true, y_pred) ## tf.Tensor(0.46630552, shape=(), dtype=float32) # Using 'none' reduction type. cce <- loss_categorical_focal_crossentropy(reduction = NULL) cce(y_true, y_pred) ## tf.Tensor([3.2058331e-05 4.6627346e-01], shape=(2), dtype=float32) model %>% compile(   optimizer = 'adam',   loss = loss_categorical_focal_crossentropy())"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_categorical_hinge.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the categorical hinge loss between y_true & y_pred. — loss_categorical_hinge","title":"Computes the categorical hinge loss between y_true & y_pred. — loss_categorical_hinge","text":"Formula:   neg=maximum((1-y_true)*y_pred) pos=sum(y_true*y_pred)","code":"loss <- maximum(neg - pos + 1, 0)"},{"path":"https://keras.posit.co/reference/loss_categorical_hinge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the categorical hinge loss between y_true & y_pred. — loss_categorical_hinge","text":"","code":"loss_categorical_hinge(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"categorical_hinge\" )"},{"path":"https://keras.posit.co/reference/loss_categorical_hinge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the categorical hinge loss between y_true & y_pred. — loss_categorical_hinge","text":"y_true ground truth values. y_true values expected either {-1, +1} {0, 1} (.e. one-hot-encoded tensor) shape <- [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_categorical_hinge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the categorical hinge loss between y_true & y_pred. — loss_categorical_hinge","text":"Categorical hinge loss values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_categorical_hinge.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the categorical hinge loss between y_true & y_pred. — loss_categorical_hinge","text":"","code":"y_true <- rbind(c(0, 1), c(0, 0)) y_pred <- rbind(c(0.6, 0.4), c(0.4, 0.6)) loss <- loss_categorical_hinge(y_true, y_pred)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_cosine_similarity.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the cosine similarity between y_true & y_pred. — loss_cosine_similarity","title":"Computes the cosine similarity between y_true & y_pred. — loss_cosine_similarity","text":"Formula:   Note number -1 1. negative number -1 0, 0 indicates orthogonality values closer -1 indicate greater similarity. makes usable loss function setting try maximize proximity predictions targets. either y_true y_pred zero vector, cosine similarity 0 regardless proximity predictions targets.","code":"loss <- -sum(l2_norm(y_true) * l2_norm(y_pred))"},{"path":"https://keras.posit.co/reference/loss_cosine_similarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the cosine similarity between y_true & y_pred. — loss_cosine_similarity","text":"","code":"loss_cosine_similarity(   y_true,   y_pred,   axis = -1L,   ...,   reduction = \"sum_over_batch_size\",   name = \"cosine_similarity\" )"},{"path":"https://keras.posit.co/reference/loss_cosine_similarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the cosine similarity between y_true & y_pred. — loss_cosine_similarity","text":"y_true Tensor true targets. y_pred Tensor predicted targets. axis axis along cosine similarity computed (features axis). Defaults -1. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_cosine_similarity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the cosine similarity between y_true & y_pred. — loss_cosine_similarity","text":"Cosine similarity tensor.","code":""},{"path":"https://keras.posit.co/reference/loss_cosine_similarity.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the cosine similarity between y_true & y_pred. — loss_cosine_similarity","text":"","code":"y_true <- rbind(c(0., 1.), c(1., 1.), c(1., 1.)) y_pred <- rbind(c(1., 0.), c(1., 1.), c(-1., -1.)) loss <- loss_cosine_similarity(y_true, y_pred, axis=-1) loss ## tf.Tensor([-0. -1.  1.], shape=(3), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_ctc.html","id":null,"dir":"Reference","previous_headings":"","what":"CTC (Connectionist Temporal Classification) loss. — loss_ctc","title":"CTC (Connectionist Temporal Classification) loss. — loss_ctc","text":"CTC (Connectionist Temporal Classification) loss.","code":""},{"path":"https://keras.posit.co/reference/loss_ctc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CTC (Connectionist Temporal Classification) loss. — loss_ctc","text":"","code":"loss_ctc(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"sparse_categorical_crossentropy\" )"},{"path":"https://keras.posit.co/reference/loss_ctc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CTC (Connectionist Temporal Classification) loss. — loss_ctc","text":"y_true tensor shape (batch_size, target_max_length) containing true labels integer format. 0 always represents blank/mask index used classes. y_pred tensor shape (batch_size, output_max_length, num_classes) containing logits (output model). normalized via softmax. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name String, name object","code":""},{"path":"https://keras.posit.co/reference/loss_ctc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CTC (Connectionist Temporal Classification) loss. — loss_ctc","text":"CTC loss value.","code":""},{"path":"https://keras.posit.co/reference/loss_hinge.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the hinge loss between y_true & y_pred. — loss_hinge","title":"Computes the hinge loss between y_true & y_pred. — loss_hinge","text":"Formula:   y_true values expected -1 1. binary (0 1) labels provided convert -1 1.","code":"loss <- mean(maximum(1 - y_true * y_pred, 0), axis=-1)"},{"path":"https://keras.posit.co/reference/loss_hinge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the hinge loss between y_true & y_pred. — loss_hinge","text":"","code":"loss_hinge(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"hinge\" )"},{"path":"https://keras.posit.co/reference/loss_hinge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the hinge loss between y_true & y_pred. — loss_hinge","text":"y_true ground truth values. y_true values expected -1 1. binary (0 1) labels provided converted -1 1 shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_hinge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the hinge loss between y_true & y_pred. — loss_hinge","text":"Hinge loss values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_hinge.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the hinge loss between y_true & y_pred. — loss_hinge","text":"","code":"y_true <- array(sample(c(-1,1), 6, replace = TRUE), dim = c(2, 3)) y_pred <- random_uniform(c(2, 3)) loss <- loss_hinge(y_true, y_pred) loss ## tf.Tensor([1.0610152  0.93285507], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_huber.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Huber loss between y_true & y_pred. — loss_huber","title":"Computes the Huber loss between y_true & y_pred. — loss_huber","text":"Formula:   See: Huber loss.","code":"for (x in error) {   if (abs(x) <= delta){     loss <- c(loss, (0.5 * x^2))   } else if (abs(x) > delta) {     loss <- c(loss, (delta * abs(x) - 0.5 * delta^2))   } } loss <- mean(loss)"},{"path":"https://keras.posit.co/reference/loss_huber.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Huber loss between y_true & y_pred. — loss_huber","text":"","code":"loss_huber(   y_true,   y_pred,   delta = 1,   ...,   reduction = \"sum_over_batch_size\",   name = \"huber_loss\" )"},{"path":"https://keras.posit.co/reference/loss_huber.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Huber loss between y_true & y_pred. — loss_huber","text":"y_true tensor true targets. y_pred tensor predicted targets. delta float, point Huber loss function changes quadratic linear. Defaults 1.0. ... forward/backward compatability. reduction Type reduction apply loss. Options \"sum\", \"sum_over_batch_size\" NULL. Defaults \"sum_over_batch_size\". name Optional name instance.","code":""},{"path":"https://keras.posit.co/reference/loss_huber.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the Huber loss between y_true & y_pred. — loss_huber","text":"Tensor one scalar loss entry per sample.","code":""},{"path":"https://keras.posit.co/reference/loss_huber.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Huber loss between y_true & y_pred. — loss_huber","text":"","code":"y_true <- rbind(c(0, 1), c(0, 0)) y_pred <- rbind(c(0.6, 0.4), c(0.4, 0.6)) loss <- loss_huber(y_true, y_pred)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_kl_divergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes Kullback-Leibler divergence loss between y_true & y_pred. — loss_kl_divergence","title":"Computes Kullback-Leibler divergence loss between y_true & y_pred. — loss_kl_divergence","text":"Formula:","code":"loss <- y_true * log(y_true / y_pred)"},{"path":"https://keras.posit.co/reference/loss_kl_divergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes Kullback-Leibler divergence loss between y_true & y_pred. — loss_kl_divergence","text":"","code":"loss_kl_divergence(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"kl_divergence\" )"},{"path":"https://keras.posit.co/reference/loss_kl_divergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes Kullback-Leibler divergence loss between y_true & y_pred. — loss_kl_divergence","text":"y_true Tensor true targets. y_pred Tensor predicted targets. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_kl_divergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes Kullback-Leibler divergence loss between y_true & y_pred. — loss_kl_divergence","text":"KL Divergence loss values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_kl_divergence.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes Kullback-Leibler divergence loss between y_true & y_pred. — loss_kl_divergence","text":"","code":"y_true <- random_uniform(c(2, 3), 0, 2) y_pred <- random_uniform(c(2,3)) loss <- loss_kl_divergence(y_true, y_pred) loss ## tf.Tensor([3.5312676 0.2128672], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_log_cosh.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the logarithm of the hyperbolic cosine of the prediction error. — loss_log_cosh","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — loss_log_cosh","text":"Formula:   Note log(cosh(x)) approximately equal (x ** 2) / 2 small x abs(x) - log(2) large x. means 'logcosh' works mostly like mean squared error, strongly affected occasional wildly incorrect prediction.","code":"loss <- mean(log(cosh(y_pred - y_true)), axis=-1)"},{"path":"https://keras.posit.co/reference/loss_log_cosh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — loss_log_cosh","text":"","code":"loss_log_cosh(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"log_cosh\" )"},{"path":"https://keras.posit.co/reference/loss_log_cosh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — loss_log_cosh","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. Options \"sum\", \"sum_over_batch_size\" NULL. Defaults \"sum_over_batch_size\". name Optional name instance.","code":""},{"path":"https://keras.posit.co/reference/loss_log_cosh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — loss_log_cosh","text":"Logcosh error values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_log_cosh.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — loss_log_cosh","text":"","code":"y_true <- rbind(c(0., 1.), c(0., 0.)) y_pred <- rbind(c(1., 1.), c(0., 0.)) loss <- loss_log_cosh(y_true, y_pred) # 0.108"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_mean_absolute_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the mean of absolute difference between labels and predictions. — loss_mean_absolute_error","title":"Computes the mean of absolute difference between labels and predictions. — loss_mean_absolute_error","text":"Formula:","code":"loss <- mean(abs(y_true - y_pred))"},{"path":"https://keras.posit.co/reference/loss_mean_absolute_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the mean of absolute difference between labels and predictions. — loss_mean_absolute_error","text":"","code":"loss_mean_absolute_error(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"mean_absolute_error\" )"},{"path":"https://keras.posit.co/reference/loss_mean_absolute_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the mean of absolute difference between labels and predictions. — loss_mean_absolute_error","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_mean_absolute_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the mean of absolute difference between labels and predictions. — loss_mean_absolute_error","text":"Mean absolute error values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_mean_absolute_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the mean of absolute difference between labels and predictions. — loss_mean_absolute_error","text":"","code":"y_true <- random_uniform(c(2, 3), 0, 2) y_pred <- random_uniform(c(2, 3)) loss <- loss_mean_absolute_error(y_true, y_pred)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_mean_absolute_percentage_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the mean absolute percentage error between y_true and y_pred. — loss_mean_absolute_percentage_error","title":"Computes the mean absolute percentage error between y_true and y_pred. — loss_mean_absolute_percentage_error","text":"Formula:   Division zero prevented dividing max(y_true, epsilon) epsilon = config_epsilon() (default 1e-7).","code":"loss <- 100 * op_mean(op_abs((y_true - y_pred) / y_true),                       axis=-1)"},{"path":"https://keras.posit.co/reference/loss_mean_absolute_percentage_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the mean absolute percentage error between y_true and y_pred. — loss_mean_absolute_percentage_error","text":"","code":"loss_mean_absolute_percentage_error(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"mean_absolute_percentage_error\" )"},{"path":"https://keras.posit.co/reference/loss_mean_absolute_percentage_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the mean absolute percentage error between y_true and y_pred. — loss_mean_absolute_percentage_error","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_mean_absolute_percentage_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the mean absolute percentage error between y_true and y_pred. — loss_mean_absolute_percentage_error","text":"Mean absolute percentage error values shape = [batch_size, d0, ..dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_mean_absolute_percentage_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the mean absolute percentage error between y_true and y_pred. — loss_mean_absolute_percentage_error","text":"","code":"y_true <- random_uniform(c(2, 3)) y_pred <- random_uniform(c(2, 3)) loss <- loss_mean_absolute_percentage_error(y_true, y_pred)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_mean_squared_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the mean of squares of errors between labels and predictions. — loss_mean_squared_error","title":"Computes the mean of squares of errors between labels and predictions. — loss_mean_squared_error","text":"Formula:","code":"loss <- mean(square(y_true - y_pred))"},{"path":"https://keras.posit.co/reference/loss_mean_squared_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the mean of squares of errors between labels and predictions. — loss_mean_squared_error","text":"","code":"loss_mean_squared_error(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"mean_squared_error\" )"},{"path":"https://keras.posit.co/reference/loss_mean_squared_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the mean of squares of errors between labels and predictions. — loss_mean_squared_error","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_mean_squared_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the mean of squares of errors between labels and predictions. — loss_mean_squared_error","text":"Mean squared error values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_mean_squared_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the mean of squares of errors between labels and predictions. — loss_mean_squared_error","text":"","code":"y_true <- random_uniform(c(2, 3), 0, 2) y_pred <- random_uniform(c(2, 3)) loss <- loss_mean_squared_error(y_true, y_pred)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_mean_squared_logarithmic_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the mean squared logarithmic error between y_true and y_pred. — loss_mean_squared_logarithmic_error","title":"Computes the mean squared logarithmic error between y_true and y_pred. — loss_mean_squared_logarithmic_error","text":"Note y_pred y_true less equal 0. Negative values 0 values replaced config_epsilon() (default 1e-7). Formula:","code":"loss <- mean(square(log(y_true + 1) - log(y_pred + 1)))"},{"path":"https://keras.posit.co/reference/loss_mean_squared_logarithmic_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the mean squared logarithmic error between y_true and y_pred. — loss_mean_squared_logarithmic_error","text":"","code":"loss_mean_squared_logarithmic_error(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"mean_squared_logarithmic_error\" )"},{"path":"https://keras.posit.co/reference/loss_mean_squared_logarithmic_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the mean squared logarithmic error between y_true and y_pred. — loss_mean_squared_logarithmic_error","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_mean_squared_logarithmic_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the mean squared logarithmic error between y_true and y_pred. — loss_mean_squared_logarithmic_error","text":"Mean squared logarithmic error values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_mean_squared_logarithmic_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the mean squared logarithmic error between y_true and y_pred. — loss_mean_squared_logarithmic_error","text":"","code":"y_true <- random_uniform(c(2, 3), 0, 2) y_pred <- random_uniform(c(2, 3)) loss <- loss_mean_squared_logarithmic_error(y_true, y_pred)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Poisson loss between y_true & y_pred. — loss_poisson","title":"Computes the Poisson loss between y_true & y_pred. — loss_poisson","text":"Formula:","code":"loss <- y_pred - y_true * log(y_pred)"},{"path":"https://keras.posit.co/reference/loss_poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Poisson loss between y_true & y_pred. — loss_poisson","text":"","code":"loss_poisson(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"poisson\" )"},{"path":"https://keras.posit.co/reference/loss_poisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Poisson loss between y_true & y_pred. — loss_poisson","text":"y_true Ground truth values. shape = [batch_size, d0, .. dN]. y_pred predicted values. shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_poisson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the Poisson loss between y_true & y_pred. — loss_poisson","text":"Poisson loss values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_poisson.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Poisson loss between y_true & y_pred. — loss_poisson","text":"","code":"y_true <- random_uniform(c(2, 3), 0, 2) y_pred <- random_uniform(c(2, 3)) loss <- loss_poisson(y_true, y_pred) loss ## tf.Tensor([2.5907533  0.66836613], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_sparse_categorical_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the crossentropy loss between the labels and predictions. — loss_sparse_categorical_crossentropy","title":"Computes the crossentropy loss between the labels and predictions. — loss_sparse_categorical_crossentropy","text":"Use crossentropy loss function two label classes.  expect labels provided integers. want provide labels using one-hot representation, please use CategoricalCrossentropy loss.  # classes floating point values per feature y_pred single floating point value per feature y_true. snippet , single floating point value per example y_true num_classes floating pointing values per example y_pred. shape y_true [batch_size] shape y_pred [batch_size, num_classes].","code":""},{"path":"https://keras.posit.co/reference/loss_sparse_categorical_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the crossentropy loss between the labels and predictions. — loss_sparse_categorical_crossentropy","text":"","code":"loss_sparse_categorical_crossentropy(   y_true,   y_pred,   from_logits = FALSE,   ignore_class = NULL,   axis = -1L,   ...,   reduction = \"sum_over_batch_size\",   name = \"sparse_categorical_crossentropy\" )"},{"path":"https://keras.posit.co/reference/loss_sparse_categorical_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the crossentropy loss between the labels and predictions. — loss_sparse_categorical_crossentropy","text":"y_true Ground truth values. y_pred predicted values. from_logits Whether y_pred expected logits tensor. default, assume y_pred encodes probability distribution. ignore_class Optional integer. ID class ignored loss computation. useful, example, segmentation problems featuring \"void\" class (commonly -1 255) segmentation maps. default (ignore_class=NULL), classes considered. axis Defaults -1. dimension along entropy computed. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_sparse_categorical_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the crossentropy loss between the labels and predictions. — loss_sparse_categorical_crossentropy","text":"Sparse categorical crossentropy loss value.","code":""},{"path":"https://keras.posit.co/reference/loss_sparse_categorical_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the crossentropy loss between the labels and predictions. — loss_sparse_categorical_crossentropy","text":"Usage compile() API:","code":"y_true <- c(1, 2) y_pred <- rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1)) loss <- loss_sparse_categorical_crossentropy(y_true, y_pred) loss ## tf.Tensor([0.05129339 2.30258509], shape=(2), dtype=float64) y_true <- c(1, 2) y_pred <- rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1)) # Using 'auto'/'sum_over_batch_size' reduction type. scce <- loss_sparse_categorical_crossentropy() scce(op_array(y_true), op_array(y_pred)) ## tf.Tensor(1.1769392, shape=(), dtype=float32) # 1.177 # Calling with 'sample_weight'. scce(op_array(y_true), op_array(y_pred), sample_weight = op_array(c(0.3, 0.7))) ## tf.Tensor(0.8135988, shape=(), dtype=float32) # Using 'sum' reduction type. scce <- loss_sparse_categorical_crossentropy(reduction=\"sum\") scce(op_array(y_true), op_array(y_pred)) ## tf.Tensor(2.3538785, shape=(), dtype=float32) # 2.354 # Using 'none' reduction type. scce <- loss_sparse_categorical_crossentropy(reduction=NULL) scce(op_array(y_true), op_array(y_pred)) ## tf.Tensor([0.05129344 2.3025851 ], shape=(2), dtype=float32) # array([0.0513, 2.303], dtype=float32) model %>% compile(optimizer = 'sgd',                   loss = loss_sparse_categorical_crossentropy())"},{"path":[]},{"path":"https://keras.posit.co/reference/loss_squared_hinge.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the squared hinge loss between y_true & y_pred. — loss_squared_hinge","title":"Computes the squared hinge loss between y_true & y_pred. — loss_squared_hinge","text":"Formula:   y_true values expected -1 1. binary (0 1) labels provided convert -1 1.","code":"loss <- square(maximum(1 - y_true * y_pred, 0))"},{"path":"https://keras.posit.co/reference/loss_squared_hinge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the squared hinge loss between y_true & y_pred. — loss_squared_hinge","text":"","code":"loss_squared_hinge(   y_true,   y_pred,   ...,   reduction = \"sum_over_batch_size\",   name = \"squared_hinge\" )"},{"path":"https://keras.posit.co/reference/loss_squared_hinge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the squared hinge loss between y_true & y_pred. — loss_squared_hinge","text":"y_true ground truth values. y_true values expected -1 1. binary (0 1) labels provided convert -1 1 shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. reduction Type reduction apply loss. almost cases \"sum_over_batch_size\". Supported options \"sum\", \"sum_over_batch_size\" NULL. name Optional name loss instance.","code":""},{"path":"https://keras.posit.co/reference/loss_squared_hinge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the squared hinge loss between y_true & y_pred. — loss_squared_hinge","text":"Squared hinge loss values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/loss_squared_hinge.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the squared hinge loss between y_true & y_pred. — loss_squared_hinge","text":"","code":"y_true <- array(sample(c(-1,1), 6, replace = TRUE), dim = c(2, 3)) y_pred <- random_uniform(c(2, 3)) loss <- loss_squared_hinge(y_true, y_pred)"},{"path":[]},{"path":"https://keras.posit.co/reference/mark_active.html","id":null,"dir":"Reference","previous_headings":"","what":"active_property — mark_active","title":"active_property — mark_active","text":"mark_active() alias active_property(). See ?active_property() full documentation.","code":""},{"path":"https://keras.posit.co/reference/mark_active.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"active_property — mark_active","text":"","code":"mark_active(fn)"},{"path":"https://keras.posit.co/reference/mark_active.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"active_property — mark_active","text":"fn R function","code":""},{"path":"https://keras.posit.co/reference/mark_active.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"active_property — mark_active","text":"fn, additional R attribute cause fn converted active property converted method custom subclass.","code":""},{"path":"https://keras.posit.co/reference/metric_auc.html","id":null,"dir":"Reference","previous_headings":"","what":"Approximates the AUC (Area under the curve) of the ROC or PR curves. — metric_auc","title":"Approximates the AUC (Area under the curve) of the ROC or PR curves. — metric_auc","text":"AUC (Area curve) ROC (Receiver operating characteristic; default) PR (Precision Recall) curves quality measures binary classifiers. Unlike accuracy, like cross-entropy losses, ROC-AUC PR-AUC evaluate operational points model. class approximates AUCs using Riemann sum. metric accumulation phrase, predictions accumulated within predefined buckets value. AUC computed interpolating per-bucket averages. buckets define evaluated operational points. metric creates four local variables, true_positives, true_negatives, false_positives false_negatives used compute AUC.  discretize AUC curve, linearly spaced set thresholds used compute pairs recall precision values. area ROC-curve therefore computed using height recall values false positive rate, area PR-curve computed using height precision values recall. value ultimately returned auc, idempotent operation computes area discretized curve precision versus recall values (computed using aforementioned variables). num_thresholds variable controls degree discretization larger numbers thresholds closely approximating true AUC. quality approximation may vary dramatically depending num_thresholds. thresholds parameter can used manually specify thresholds split predictions evenly. best approximation real AUC, predictions distributed approximately uniformly range [0, 1] (from_logits=FALSE). quality AUC approximation may poor case. Setting summation_method 'minoring' 'majoring' can help quantify error approximation providing lower upper bound estimate AUC. sample_weight NULL, weights default 1. Use sample_weight 0 mask values.","code":""},{"path":"https://keras.posit.co/reference/metric_auc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Approximates the AUC (Area under the curve) of the ROC or PR curves. — metric_auc","text":"","code":"metric_auc(   ...,   num_thresholds = 200L,   curve = \"ROC\",   summation_method = \"interpolation\",   name = NULL,   dtype = NULL,   thresholds = NULL,   multi_label = FALSE,   num_labels = NULL,   label_weights = NULL,   from_logits = FALSE )"},{"path":"https://keras.posit.co/reference/metric_auc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Approximates the AUC (Area under the curve) of the ROC or PR curves. — metric_auc","text":"... forward/backward compatability. num_thresholds (Optional) number thresholds use discretizing roc curve. Values must > 1. Defaults 200. curve (Optional) Specifies name curve computed, 'ROC' (default) 'PR' Precision-Recall-curve. summation_method (Optional) Specifies Riemann summation method used. 'interpolation' (default) applies mid-point summation scheme ROC.  PR-AUC, interpolates (true/false) positives ratio precision (see Davis & Goadrich 2006 details); 'minoring' applies left summation increasing intervals right summation decreasing intervals; 'majoring' opposite. name (Optional) string name metric instance. dtype (Optional) data type metric result. thresholds (Optional) list floating point values use thresholds discretizing curve. set, num_thresholds parameter ignored. Values [0, 1]. Endpoint thresholds equal {-epsilon, 1+epsilon} small positive epsilon value automatically included correctly handle predictions equal exactly 0 1. multi_label boolean indicating whether multilabel data treated , wherein AUC computed separately label averaged across labels, (FALSE) data flattened single label AUC computation. latter case, multilabel data passed AUC, label-prediction pair treated individual data point. set FALSE multi-class data. num_labels (Optional) number labels, used multi_label TRUE. num_labels specified, state variables get created first call update_state. label_weights (Optional) list, array, tensor non-negative weights used compute AUCs multilabel data. multi_label TRUE, weights applied individual label AUCs averaged produce multi-label AUC. FALSE, used weight individual label predictions computing confusion matrix flattened data. Note unlike class_weights class_weights weights example depending value label, whereas label_weights depends index label flattening; therefore label_weights used multi-class data. from_logits boolean indicating whether predictions (y_pred update_state) probabilities sigmoid logits. rule thumb, using keras loss, from_logits constructor argument loss match AUC from_logits constructor argument.","code":""},{"path":"https://keras.posit.co/reference/metric_auc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Approximates the AUC (Area under the curve) of the ROC or PR curves. — metric_auc","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_auc.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Approximates the AUC (Area under the curve) of the ROC or PR curves. — metric_auc","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_auc(num_thresholds = 3) m$update_state(c(0,   0,   1,   1),                c(0, 0.5, 0.3, 0.9)) # threshold values are [0 - 1e-7, 0.5, 1 + 1e-7] # tp = [2, 1, 0], fp = [2, 0, 0], fn = [0, 1, 2], tn = [0, 2, 2] # tp_rate = recall = [1, 0.5, 0], fp_rate = [1, 0, 0] # auc = ((((1 + 0.5) / 2) * (1 - 0)) + (((0.5 + 0) / 2) * (0 - 0))) #     = 0.75 m$result() ## tf.Tensor(0.75, shape=(), dtype=float32) m$reset_state() m$update_state(c(0,   0,   1,   1),                c(0, 0.5, 0.3, 0.9),                sample_weight=c(1, 0, 0, 1)) m$result() ## tf.Tensor(1.0, shape=(), dtype=float32) # Reports the AUC of a model outputting a probability. model |> compile(   optimizer = 'sgd',   loss = loss_binary_crossentropy(),   metrics = list(metric_auc()) )  # Reports the AUC of a model outputting a logit. model |> compile(   optimizer = 'sgd',   loss = loss_binary_crossentropy(from_logits = TRUE),   metrics = list(metric_auc(from_logits = TRUE)) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_binary_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates how often predictions match binary labels. — metric_binary_accuracy","title":"Calculates how often predictions match binary labels. — metric_binary_accuracy","text":"metric creates two local variables, total count used compute frequency y_pred matches y_true. frequency ultimately returned binary accuracy: idempotent operation simply divides total count. sample_weight NULL, weights default 1. Use sample_weight 0 mask values.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates how often predictions match binary labels. — metric_binary_accuracy","text":"","code":"metric_binary_accuracy(   y_true,   y_pred,   threshold = 0.5,   ...,   name = \"binary_accuracy\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_binary_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates how often predictions match binary labels. — metric_binary_accuracy","text":"y_true Tensor true targets. y_pred Tensor predicted targets. threshold (Optional) Float representing threshold deciding whether prediction values 1 0. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates how often predictions match binary labels. — metric_binary_accuracy","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_accuracy.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates how often predictions match binary labels. — metric_binary_accuracy","text":"Standalone usage:             Usage compile() API:","code":"m <- metric_binary_accuracy() m$update_state(rbind(1, 1, 0, 0), rbind(0.98, 1, 0, 0.6)) m$result() ## tf.Tensor(0.75, shape=(), dtype=float32) # 0.75 m$reset_state() m$update_state(rbind(1, 1, 0, 0), rbind(0.98, 1, 0, 0.6),                sample_weight = c(1, 0, 0, 1)) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) # 0.5 model %>% compile(optimizer='sgd',                   loss='binary_crossentropy',                   metrics=list(metric_binary_accuracy()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_binary_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the crossentropy metric between the labels and predictions. — metric_binary_crossentropy","title":"Computes the crossentropy metric between the labels and predictions. — metric_binary_crossentropy","text":"crossentropy metric class used two label classes (0 1).","code":""},{"path":"https://keras.posit.co/reference/metric_binary_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the crossentropy metric between the labels and predictions. — metric_binary_crossentropy","text":"","code":"metric_binary_crossentropy(   y_true,   y_pred,   from_logits = FALSE,   label_smoothing = 0,   axis = -1L,   ...,   name = \"binary_crossentropy\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_binary_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the crossentropy metric between the labels and predictions. — metric_binary_crossentropy","text":"y_true Ground truth values. shape = [batch_size, d0, .. dN]. y_pred predicted values. shape = [batch_size, d0, .. dN]. from_logits (Optional) Whether output expected logits tensor. default, consider output encodes probability distribution. label_smoothing (Optional) Float [0, 1]. > 0, label values smoothed, meaning confidence label values relaxed. e.g. label_smoothing=0.2 means use value 0.1 label \"0\" 0.9 label \"1\". axis axis along mean computed. Defaults -1. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the crossentropy metric between the labels and predictions. — metric_binary_crossentropy","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the crossentropy metric between the labels and predictions. — metric_binary_crossentropy","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_binary_crossentropy() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6))) m$result() ## tf.Tensor(0.8149245, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6)),                sample_weight=c(1, 0)) m$result() ## tf.Tensor(0.91629076, shape=(), dtype=float32) model %>% compile(     optimizer = 'sgd',     loss = 'mse',     metrics = list(metric_binary_crossentropy()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_binary_focal_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the binary focal crossentropy loss. — metric_binary_focal_crossentropy","title":"Computes the binary focal crossentropy loss. — metric_binary_focal_crossentropy","text":"According Lin et al., 2018, helps apply focal factor -weight easy examples focus hard examples. default, focal tensor computed follows: focal_factor = (1 - output)^gamma class 1 focal_factor = output^gamma class 0 gamma focusing parameter. gamma = 0, focal effect binary crossentropy loss. apply_class_balancing == TRUE, function also takes account weight balancing factor binary classes 0 1 follows: weight = alpha class 1 (target == 1) weight = 1 - alpha class 0 alpha float range [0, 1].","code":""},{"path":"https://keras.posit.co/reference/metric_binary_focal_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the binary focal crossentropy loss. — metric_binary_focal_crossentropy","text":"","code":"metric_binary_focal_crossentropy(   y_true,   y_pred,   apply_class_balancing = FALSE,   alpha = 0.25,   gamma = 2,   from_logits = FALSE,   label_smoothing = 0,   axis = -1L )"},{"path":"https://keras.posit.co/reference/metric_binary_focal_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the binary focal crossentropy loss. — metric_binary_focal_crossentropy","text":"y_true Ground truth values, shape (batch_size, d0, .. dN). y_pred predicted values, shape (batch_size, d0, .. dN). apply_class_balancing bool, whether apply weight balancing binary classes 0 1. alpha weight balancing factor class 1, default 0.25 mentioned reference. weight class 0 1.0 - alpha. gamma focusing parameter, default 2.0 mentioned reference. from_logits Whether y_pred expected logits tensor. default, assume y_pred encodes probability distribution. label_smoothing Float [0, 1]. > 0 smooth labels squeezing towards 0.5, , using 1. - 0.5 * label_smoothing target class 0.5 * label_smoothing non-target class. axis axis along mean computed. Defaults -1.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_focal_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the binary focal crossentropy loss. — metric_binary_focal_crossentropy","text":"Binary focal crossentropy loss value shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/metric_binary_focal_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the binary focal crossentropy loss. — metric_binary_focal_crossentropy","text":"","code":"y_true <- rbind(c(0, 1), c(0, 0)) y_pred <- rbind(c(0.6, 0.4), c(0.4, 0.6)) loss <- loss_binary_focal_crossentropy(y_true, y_pred, gamma=2) loss ## tf.Tensor([0.32986466 0.20579838], shape=(2), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_binary_iou.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Intersection-Over-Union metric for class 0 and/or 1. — metric_binary_iou","title":"Computes the Intersection-Over-Union metric for class 0 and/or 1. — metric_binary_iou","text":"Formula:   Intersection--Union common evaluation metric semantic image segmentation. compute IoUs, predictions accumulated confusion matrix, weighted sample_weight metric calculated . sample_weight NULL, weights default 1. Use sample_weight 0 mask values. class can used compute IoUs binary classification task predictions provided logits. First threshold applied predicted values threshold converted class 0 threshold converted class 1. IoUs classes 0 1 computed, mean IoUs classes specified target_class_ids returned.","code":"iou <- true_positives / (true_positives + false_positives + false_negatives)"},{"path":"https://keras.posit.co/reference/metric_binary_iou.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Intersection-Over-Union metric for class 0 and/or 1. — metric_binary_iou","text":"","code":"metric_binary_iou(   ...,   target_class_ids = list(0L, 1L),   threshold = 0.5,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_binary_iou.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Intersection-Over-Union metric for class 0 and/or 1. — metric_binary_iou","text":"... forward/backward compatability. target_class_ids list list target class ids metric returned. Options 0, 1, c(0, 1). 0 (1), IoU metric class 0 (class 1, respectively) returned. c(0, 1), mean IoUs two classes returned. threshold threshold applies prediction logits convert either predicted class 0 logit threshold predicted class 1 logit threshold. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_iou.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the Intersection-Over-Union metric for class 0 and/or 1. — metric_binary_iou","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_iou.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the Intersection-Over-Union metric for class 0 and/or 1. — metric_binary_iou","text":"threshold=0, metric behavior IoU.","code":""},{"path":"https://keras.posit.co/reference/metric_binary_iou.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Intersection-Over-Union metric for class 0 and/or 1. — metric_binary_iou","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_binary_iou(target_class_ids=c(0L, 1L), threshold = 0.3) m$update_state(c(0, 1, 0, 1), c(0.1, 0.2, 0.4, 0.7)) m$result() ## tf.Tensor(0.33333334, shape=(), dtype=float32) m$reset_state() m$update_state(c(0, 1, 0, 1), c(0.1, 0.2, 0.4, 0.7),                sample_weight = c(0.2, 0.3, 0.4, 0.1)) m$result() ## tf.Tensor(0.17361109, shape=(), dtype=float32) model %>% compile(     optimizer = 'sgd',     loss = 'mse',     metrics = list(metric_binary_iou(         target_class_ids = 0L,         threshold = 0.5     )) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_categorical_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates how often predictions match one-hot labels. — metric_categorical_accuracy","title":"Calculates how often predictions match one-hot labels. — metric_categorical_accuracy","text":"can provide logits classes y_pred, since argmax logits probabilities . metric creates two local variables, total count used compute frequency y_pred matches y_true. frequency ultimately returned categorical accuracy: idempotent operation simply divides total count. y_pred y_true passed vectors probabilities, rather labels. necessary, use op_one_hot expand y_true vector. sample_weight NULL, weights default 1. Use sample_weight 0 mask values.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates how often predictions match one-hot labels. — metric_categorical_accuracy","text":"","code":"metric_categorical_accuracy(   y_true,   y_pred,   ...,   name = \"categorical_accuracy\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_categorical_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates how often predictions match one-hot labels. — metric_categorical_accuracy","text":"y_true Tensor true targets. y_pred Tensor predicted targets. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates how often predictions match one-hot labels. — metric_categorical_accuracy","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_accuracy.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates how often predictions match one-hot labels. — metric_categorical_accuracy","text":"Standalone usage:           Usage compile() API:","code":"m <- metric_categorical_accuracy() m$update_state(rbind(c(0, 0, 1), c(0, 1, 0)), rbind(c(0.1, 0.9, 0.8),                 c(0.05, 0.95, 0))) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 0, 1), c(0, 1, 0)), rbind(c(0.1, 0.9, 0.8),                c(0.05, 0.95, 0)),                sample_weight = c(0.7, 0.3)) m$result() ## tf.Tensor(0.3, shape=(), dtype=float32) # 0.3 model %>% compile(optimizer = 'sgd',                   loss = 'categorical_crossentropy',                   metrics = list(metric_categorical_accuracy()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_categorical_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the crossentropy metric between the labels and predictions. — metric_categorical_crossentropy","title":"Computes the crossentropy metric between the labels and predictions. — metric_categorical_crossentropy","text":"crossentropy metric class used multiple label classes (2 ). assumes labels one-hot encoded, e.g., labels values c(2, 0, 1), y_true rbind(c([0, 0, 1), c(1, 0, 0), c(0, 1, 0)).","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the crossentropy metric between the labels and predictions. — metric_categorical_crossentropy","text":"","code":"metric_categorical_crossentropy(   y_true,   y_pred,   from_logits = FALSE,   label_smoothing = 0,   axis = -1L,   ...,   name = \"categorical_crossentropy\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_categorical_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the crossentropy metric between the labels and predictions. — metric_categorical_crossentropy","text":"y_true Tensor one-hot true targets. y_pred Tensor predicted targets. from_logits (Optional) Whether output expected logits tensor. default, consider output encodes probability distribution. label_smoothing (Optional) Float [0, 1]. > 0, label values smoothed, meaning confidence label values relaxed. e.g. label_smoothing=0.2 means use value 0.1 label \"0\" 0.9 label \"1\". axis (Optional) Defaults -1. dimension along entropy computed. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the crossentropy metric between the labels and predictions. — metric_categorical_crossentropy","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the crossentropy metric between the labels and predictions. — metric_categorical_crossentropy","text":"Standalone usage:           Usage compile() API:","code":"# EPSILON = 1e-7, y = y_true, y` = y_pred # y` = clip_op_clip_by_value(output, EPSILON, 1. - EPSILON) # y` = rbind(c(0.05, 0.95, EPSILON), c(0.1, 0.8, 0.1)) # xent = -sum(y * log(y'), axis = -1) #      = -((log 0.95), (log 0.1)) #      = [0.051, 2.302] # Reduced xent = (0.051 + 2.302) / 2 m <- metric_categorical_crossentropy() m$update_state(rbind(c(0, 1, 0), c(0, 0, 1)),                rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1))) m$result() ## tf.Tensor(1.1769392, shape=(), dtype=float32) # 1.1769392 m$reset_state() m$update_state(rbind(c(0, 1, 0), c(0, 0, 1)),                rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1)),                sample_weight = c(0.3, 0.7)) m$result() ## tf.Tensor(1.6271976, shape=(), dtype=float32) model %>% compile(   optimizer = 'sgd',   loss = 'mse',   metrics = list(metric_categorical_crossentropy()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_categorical_focal_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the categorical focal crossentropy loss. — metric_categorical_focal_crossentropy","title":"Computes the categorical focal crossentropy loss. — metric_categorical_focal_crossentropy","text":"Computes categorical focal crossentropy loss.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_focal_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the categorical focal crossentropy loss. — metric_categorical_focal_crossentropy","text":"","code":"metric_categorical_focal_crossentropy(   y_true,   y_pred,   alpha = 0.25,   gamma = 2,   from_logits = FALSE,   label_smoothing = 0,   axis = -1L )"},{"path":"https://keras.posit.co/reference/metric_categorical_focal_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the categorical focal crossentropy loss. — metric_categorical_focal_crossentropy","text":"y_true Tensor one-hot true targets. y_pred Tensor predicted targets. alpha weight balancing factor classes, default 0.25 mentioned reference. can list floats scalar. multi-class case, alpha may set inverse class frequency using compute_class_weight sklearn.utils. gamma focusing parameter, default 2.0 mentioned reference. helps gradually reduce importance given simple examples smooth manner. gamma = 0, focal effect categorical crossentropy. from_logits Whether y_pred expected logits tensor. default, assume y_pred encodes probability distribution. label_smoothing Float [0, 1]. > 0 smooth labels. example, 0.1, use 0.1 / num_classes non-target labels 0.9 + 0.1 / num_classes target labels. axis Defaults -1. dimension along entropy computed.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_focal_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the categorical focal crossentropy loss. — metric_categorical_focal_crossentropy","text":"Categorical focal crossentropy loss value.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_focal_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the categorical focal crossentropy loss. — metric_categorical_focal_crossentropy","text":"","code":"y_true <- rbind(c(0, 1, 0), c(0, 0, 1)) y_pred <- rbind(c(0.05, 0.9, 0.05), c(0.1, 0.85, 0.05)) loss <- loss_categorical_focal_crossentropy(y_true, y_pred) loss ## tf.Tensor([2.63401289e-04 6.75912094e-01], shape=(2), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_categorical_hinge.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the categorical hinge metric between y_true and y_pred. — metric_categorical_hinge","title":"Computes the categorical hinge metric between y_true and y_pred. — metric_categorical_hinge","text":"Formula:   neg=maximum((1-y_true)*y_pred) pos=sum(y_true*y_pred)","code":"loss <- maximum(neg - pos + 1, 0)"},{"path":"https://keras.posit.co/reference/metric_categorical_hinge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the categorical hinge metric between y_true and y_pred. — metric_categorical_hinge","text":"","code":"metric_categorical_hinge(   y_true,   y_pred,   ...,   name = \"categorical_hinge\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_categorical_hinge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the categorical hinge metric between y_true and y_pred. — metric_categorical_hinge","text":"y_true ground truth values. y_true values expected either {-1, +1} {0, 1} (.e. one-hot-encoded tensor) shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_hinge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the categorical hinge metric between y_true and y_pred. — metric_categorical_hinge","text":"Categorical hinge loss values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/metric_categorical_hinge.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the categorical hinge metric between y_true and y_pred. — metric_categorical_hinge","text":"Standalone usage:","code":"m <- metric_categorical_hinge() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6))) m$result() ## tf.Tensor(1.4000001, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(1.2, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_cosine_similarity.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the cosine similarity between the labels and predictions. — metric_cosine_similarity","title":"Computes the cosine similarity between the labels and predictions. — metric_cosine_similarity","text":"Formula:   See: Cosine Similarity. metric keeps average cosine similarity predictions labels stream data.","code":"loss <- sum(l2_norm(y_true) * l2_norm(y_pred))"},{"path":"https://keras.posit.co/reference/metric_cosine_similarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the cosine similarity between the labels and predictions. — metric_cosine_similarity","text":"","code":"metric_cosine_similarity(   ...,   name = \"cosine_similarity\",   dtype = NULL,   axis = -1L )"},{"path":"https://keras.posit.co/reference/metric_cosine_similarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the cosine similarity between the labels and predictions. — metric_cosine_similarity","text":"... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result. axis (Optional) Defaults -1. dimension along cosine similarity computed.","code":""},{"path":"https://keras.posit.co/reference/metric_cosine_similarity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the cosine similarity between the labels and predictions. — metric_cosine_similarity","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_cosine_similarity.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the cosine similarity between the labels and predictions. — metric_cosine_similarity","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_cosine_similarity(axis=2) m$update_state(rbind(c(0., 1.), c(1., 1.)), rbind(c(1., 0.), c(1., 1.))) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0., 1.), c(1., 1.)), rbind(c(1., 0.), c(1., 1.)),                sample_weight = c(0.3, 0.7)) m$result() ## tf.Tensor(0.7, shape=(), dtype=float32) model %>% compile(   optimizer = 'sgd',   loss = 'mse',   metrics = list(metric_cosine_similarity(axis=2)))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_f1_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes F-1 Score. — metric_f1_score","title":"Computes F-1 Score. — metric_f1_score","text":"Formula:   harmonic mean precision recall. output range [0, 1]. works multi-class multi-label classification.","code":"f1_score <- 2 * (precision * recall) / (precision + recall)"},{"path":"https://keras.posit.co/reference/metric_f1_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes F-1 Score. — metric_f1_score","text":"","code":"metric_f1_score(   ...,   average = NULL,   threshold = NULL,   name = \"f1_score\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_f1_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes F-1 Score. — metric_f1_score","text":"... forward/backward compatability. average Type averaging performed data. Acceptable values NULL, \"micro\", \"macro\" \"weighted\". Defaults NULL. NULL, averaging performed result() return score class. \"micro\", compute metrics globally counting total true positives, false negatives false positives. \"macro\", compute metrics label, return unweighted mean. take label imbalance account. \"weighted\", compute metrics label, return average weighted support (number true instances label). alters \"macro\" account label imbalance. can result score precision recall. threshold Elements y_pred greater threshold converted 1, rest 0. threshold NULL, argmax y_pred converted 1, rest 0. name Optional. String name metric instance. dtype Optional. Data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_f1_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes F-1 Score. — metric_f1_score","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_f1_score.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes F-1 Score. — metric_f1_score","text":"","code":"metric <- metric_f1_score(threshold = 0.5) y_true <- rbind(c(1, 1, 1),                 c(1, 0, 0),                 c(1, 1, 0)) y_pred <- rbind(c(0.2, 0.6, 0.7),                 c(0.2, 0.6, 0.6),                 c(0.6, 0.8, 0.0)) metric$update_state(y_true, y_pred) result <- metric$result() result ## tf.Tensor([0.49999997 0.79999995 0.66666657], shape=(3), dtype=float32)"},{"path":"https://keras.posit.co/reference/metric_f1_score.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Computes F-1 Score. — metric_f1_score","text":"F-1 Score: float.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/metric_false_negatives.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the number of false negatives. — metric_false_negatives","title":"Calculates the number of false negatives. — metric_false_negatives","text":"sample_weight given, calculates sum weights false negatives. metric creates one local variable, accumulator used keep track number false negatives. sample_weight NULL, weights default 1. Use sample_weight 0 mask values.","code":""},{"path":"https://keras.posit.co/reference/metric_false_negatives.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the number of false negatives. — metric_false_negatives","text":"","code":"metric_false_negatives(..., thresholds = NULL, name = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_false_negatives.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the number of false negatives. — metric_false_negatives","text":"... forward/backward compatability. thresholds (Optional) Defaults 0.5. float value, Python list float threshold values [0, 1]. threshold compared prediction values determine truth value predictions (.e., threshold TRUE, FALSE). used loss function sets from_logits=TRUE (.e. sigmoid applied predictions), thresholds set 0. One metric value generated threshold value. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_false_negatives.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the number of false negatives. — metric_false_negatives","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_false_negatives.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the number of false negatives. — metric_false_negatives","text":"Standalone usage:","code":"m <- metric_false_negatives() m$update_state(c(0, 1, 1, 1), c(0, 1, 0, 0)) m$result() ## tf.Tensor(2.0, shape=(), dtype=float32) m$reset_state() m$update_state(c(0, 1, 1, 1), c(0, 1, 0, 0), sample_weight=c(0, 0, 1, 0)) m$result() ## tf.Tensor(1.0, shape=(), dtype=float32) # 1.0"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_false_positives.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the number of false positives. — metric_false_positives","title":"Calculates the number of false positives. — metric_false_positives","text":"sample_weight given, calculates sum weights false positives. metric creates one local variable, accumulator used keep track number false positives. sample_weight NULL, weights default 1. Use sample_weight 0 mask values.","code":""},{"path":"https://keras.posit.co/reference/metric_false_positives.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the number of false positives. — metric_false_positives","text":"","code":"metric_false_positives(..., thresholds = NULL, name = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_false_positives.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the number of false positives. — metric_false_positives","text":"... forward/backward compatability. thresholds (Optional) Defaults 0.5. float value, Python list float threshold values [0, 1]. threshold compared prediction values determine truth value predictions (.e., threshold TRUE, FALSE). used loss function sets from_logits=TRUE (.e. sigmoid applied predictions), thresholds set 0. One metric value generated threshold value. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_false_positives.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the number of false positives. — metric_false_positives","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_false_positives.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the number of false positives. — metric_false_positives","text":"Standalone usage:","code":"m <- metric_false_positives() m$update_state(c(0, 1, 0, 0), c(0, 0, 1, 1)) m$result() ## tf.Tensor(2.0, shape=(), dtype=float32) m$reset_state() m$update_state(c(0, 1, 0, 0), c(0, 0, 1, 1), sample_weight = c(0, 0, 1, 0)) m$result() ## tf.Tensor(1.0, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_fbeta_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes F-Beta score. — metric_fbeta_score","title":"Computes F-Beta score. — metric_fbeta_score","text":"Formula:   weighted harmonic mean precision recall. output range [0, 1]. works multi-class multi-label classification.","code":"b2 <- beta^2 f_beta_score <- (1 + b2) * (precision * recall) / (precision * b2 + recall)"},{"path":"https://keras.posit.co/reference/metric_fbeta_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes F-Beta score. — metric_fbeta_score","text":"","code":"metric_fbeta_score(   ...,   average = NULL,   beta = 1,   threshold = NULL,   name = \"fbeta_score\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_fbeta_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes F-Beta score. — metric_fbeta_score","text":"... forward/backward compatability. average Type averaging performed across per-class results multi-class case. Acceptable values NULL, \"micro\", \"macro\" \"weighted\". Defaults NULL. NULL, averaging performed result() return score class. \"micro\", compute metrics globally counting total true positives, false negatives false positives. \"macro\", compute metrics label, return unweighted mean. take label imbalance account. \"weighted\", compute metrics label, return average weighted support (number true instances label). alters \"macro\" account label imbalance. can result score precision recall. beta Determines weight given recall harmonic mean precision recall (see pseudocode equation ). Defaults 1. threshold Elements y_pred greater threshold converted 1, rest 0. threshold NULL, argmax y_pred converted 1, rest 0. name Optional. String name metric instance. dtype Optional. Data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_fbeta_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes F-Beta score. — metric_fbeta_score","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_fbeta_score.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes F-Beta score. — metric_fbeta_score","text":"","code":"metric <- metric_fbeta_score(beta = 2.0, threshold = 0.5) y_true <- rbind(c(1, 1, 1),                 c(1, 0, 0),                 c(1, 1, 0)) y_pred <- rbind(c(0.2, 0.6, 0.7),                 c(0.2, 0.6, 0.6),                 c(0.6, 0.8, 0.0)) metric$update_state(y_true, y_pred) metric$result() ## tf.Tensor([0.3846154  0.90909094 0.8333332 ], shape=(3), dtype=float32)"},{"path":"https://keras.posit.co/reference/metric_fbeta_score.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Computes F-Beta score. — metric_fbeta_score","text":"F-Beta Score: float.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/metric_hinge.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the hinge metric between y_true and y_pred. — metric_hinge","title":"Computes the hinge metric between y_true and y_pred. — metric_hinge","text":"Formula:   y_true values expected -1 1. binary (0 1) labels provided convert -1 1.","code":"loss <- mean(maximum(1 - y_true * y_pred, 0), axis=-1)"},{"path":"https://keras.posit.co/reference/metric_hinge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the hinge metric between y_true and y_pred. — metric_hinge","text":"","code":"metric_hinge(y_true, y_pred, ..., name = \"hinge\", dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_hinge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the hinge metric between y_true and y_pred. — metric_hinge","text":"y_true ground truth values. y_true values expected -1 1. binary (0 1) labels provided converted -1 1 shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_hinge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the hinge metric between y_true and y_pred. — metric_hinge","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_hinge.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the hinge metric between y_true and y_pred. — metric_hinge","text":"Standalone usage:","code":"m <- metric_hinge() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6))) m$result() ## tf.Tensor(1.3, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(1.1, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_huber.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes Huber loss value. — metric_huber","title":"Computes Huber loss value. — metric_huber","text":"Formula:   See: Huber loss.","code":"for (x in error) {   if (abs(x) <= delta){     loss <- c(loss, (0.5 * x^2))   } else if (abs(x) > delta) {     loss <- c(loss, (delta * abs(x) - 0.5 * delta^2))   } } loss <- mean(loss)"},{"path":"https://keras.posit.co/reference/metric_huber.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes Huber loss value. — metric_huber","text":"","code":"metric_huber(y_true, y_pred, delta = 1)"},{"path":"https://keras.posit.co/reference/metric_huber.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes Huber loss value. — metric_huber","text":"y_true tensor true targets. y_pred tensor predicted targets. delta float, point Huber loss function changes quadratic linear. Defaults 1.0.","code":""},{"path":"https://keras.posit.co/reference/metric_huber.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes Huber loss value. — metric_huber","text":"Tensor one scalar loss entry per sample.","code":""},{"path":"https://keras.posit.co/reference/metric_huber.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes Huber loss value. — metric_huber","text":"","code":"y_true <- rbind(c(0, 1), c(0, 0)) y_pred <- rbind(c(0.6, 0.4), c(0.4, 0.6)) loss <- loss_huber(y_true, y_pred)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_iou.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Intersection-Over-Union metric for specific target classes. — metric_iou","title":"Computes the Intersection-Over-Union metric for specific target classes. — metric_iou","text":"Formula:   Intersection--Union common evaluation metric semantic image segmentation. compute IoUs, predictions accumulated confusion matrix, weighted sample_weight metric calculated . sample_weight NULL, weights default 1. Use sample_weight 0 mask values. Note, class first computes IoUs individual classes, returns mean IoUs classes specified target_class_ids. target_class_ids one id value, IoU specific class returned.","code":"iou <- true_positives / (true_positives + false_positives + false_negatives)"},{"path":"https://keras.posit.co/reference/metric_iou.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Intersection-Over-Union metric for specific target classes. — metric_iou","text":"","code":"metric_iou(   ...,   num_classes,   target_class_ids,   name = NULL,   dtype = NULL,   ignore_class = NULL,   sparse_y_true = TRUE,   sparse_y_pred = TRUE,   axis = -1L )"},{"path":"https://keras.posit.co/reference/metric_iou.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Intersection-Over-Union metric for specific target classes. — metric_iou","text":"... forward/backward compatability. num_classes possible number labels prediction task can . target_class_ids list target class ids metric returned. compute IoU specific class, list single id value provided. name (Optional) string name metric instance. dtype (Optional) data type metric result. ignore_class Optional integer. ID class ignored metric computation. useful, example, segmentation problems featuring \"void\" class (commonly -1 255) segmentation maps. default (ignore_class=NULL), classes considered. sparse_y_true Whether labels encoded using integers dense floating point vectors. FALSE, argmax function used determine sample's likely associated label. sparse_y_pred Whether predictions encoded using integers dense floating point vectors. FALSE, argmax function used determine sample's likely associated label. axis (Optional) -1 dimension containing logits. Defaults -1.","code":""},{"path":"https://keras.posit.co/reference/metric_iou.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the Intersection-Over-Union metric for specific target classes. — metric_iou","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_iou.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Intersection-Over-Union metric for specific target classes. — metric_iou","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_iou(num_classes = 2L, target_class_ids = list(0L)) m$update_state(c(0, 0, 1, 1), c(0, 1, 0, 1)) m$result() ## tf.Tensor(0.3333333, shape=(), dtype=float32) m$reset_state() m$update_state(c(0, 0, 1, 1), c(0, 1, 0, 1),                sample_weight = c(0.3, 0.3, 0.3, 0.1)) m$result() ## tf.Tensor(0.33333325, shape=(), dtype=float32) model %>% compile(   optimizer = 'sgd',   loss = 'mse',   metrics = list(metric_iou(num_classes = 2L, target_class_ids = list(0L))))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_kl_divergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes Kullback-Leibler divergence metric between y_true and — metric_kl_divergence","title":"Computes Kullback-Leibler divergence metric between y_true and — metric_kl_divergence","text":"Formula:","code":"loss <- y_true * log(y_true / y_pred)"},{"path":"https://keras.posit.co/reference/metric_kl_divergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes Kullback-Leibler divergence metric between y_true and — metric_kl_divergence","text":"","code":"metric_kl_divergence(y_true, y_pred, ..., name = \"kl_divergence\", dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_kl_divergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes Kullback-Leibler divergence metric between y_true and — metric_kl_divergence","text":"y_true Tensor true targets. y_pred Tensor predicted targets. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_kl_divergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes Kullback-Leibler divergence metric between y_true and — metric_kl_divergence","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_kl_divergence.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes Kullback-Leibler divergence metric between y_true and — metric_kl_divergence","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_kl_divergence() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6))) m$result() ## tf.Tensor(0.45814303, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(0.91628915, shape=(), dtype=float32) model %>% compile(optimizer = 'sgd',                   loss = 'mse',                   metrics = list(metric_kl_divergence()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_log_cosh.html","id":null,"dir":"Reference","previous_headings":"","what":"Logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh","title":"Logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh","text":"Formula:   Note log(cosh(x)) approximately equal (x ** 2) / 2 small x abs(x) - log(2) large x. means 'logcosh' works mostly like mean squared error, strongly affected occasional wildly incorrect prediction.","code":"loss <- mean(log(cosh(y_pred - y_true)), axis=-1)"},{"path":"https://keras.posit.co/reference/metric_log_cosh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh","text":"","code":"metric_log_cosh(y_true, y_pred)"},{"path":"https://keras.posit.co/reference/metric_log_cosh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN].","code":""},{"path":"https://keras.posit.co/reference/metric_log_cosh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh","text":"Logcosh error values shape = [batch_size, d0, .. dN-1].","code":""},{"path":"https://keras.posit.co/reference/metric_log_cosh.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh","text":"","code":"y_true <- rbind(c(0., 1.), c(0., 0.)) y_pred <- rbind(c(1., 1.), c(0., 0.)) loss <- metric_log_cosh(y_true, y_pred) loss ## tf.Tensor([ 2.16890413e-01 -1.90465432e-09], shape=(2), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_log_cosh_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh_error","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh_error","text":"Formula:","code":"error <- y_pred - y_true logcosh <- mean(log((exp(error) + exp(-error))/2), axis=-1)"},{"path":"https://keras.posit.co/reference/metric_log_cosh_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh_error","text":"","code":"metric_log_cosh_error(..., name = \"logcosh\", dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_log_cosh_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh_error","text":"... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_log_cosh_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh_error","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_log_cosh_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the logarithm of the hyperbolic cosine of the prediction error. — metric_log_cosh_error","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_log_cosh_error() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0))) m$result() ## tf.Tensor(0.108445205, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(0.21689041, shape=(), dtype=float32) model %>% compile(optimizer = 'sgd',                   loss = 'mse',                   metrics = list(metric_log_cosh_error()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the (weighted) mean of the given values. — metric_mean","title":"Compute the (weighted) mean of the given values. — metric_mean","text":"example, values c(1, 3, 5, 7) mean 4. sample_weight specified c(1, 1, 0, 0) mean 2. metric creates two variables, total count. mean value returned simply total divided count.","code":""},{"path":"https://keras.posit.co/reference/metric_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the (weighted) mean of the given values. — metric_mean","text":"","code":"metric_mean(..., name = \"mean\", dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the (weighted) mean of the given values. — metric_mean","text":"... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the (weighted) mean of the given values. — metric_mean","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_mean.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the (weighted) mean of the given values. — metric_mean","text":"","code":"m <- metric_mean() m$update_state(c(1, 3, 5, 7)) m$result() ## tf.Tensor(4.0, shape=(), dtype=float32) m$reset_state() m$update_state(c(1, 3, 5, 7), sample_weight = c(1, 1, 0, 0)) m$result() ## tf.Tensor(2.0, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_mean_absolute_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the mean absolute error between the labels and predictions. — metric_mean_absolute_error","title":"Computes the mean absolute error between the labels and predictions. — metric_mean_absolute_error","text":"Formula:","code":"loss <- mean(abs(y_true - y_pred))"},{"path":"https://keras.posit.co/reference/metric_mean_absolute_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the mean absolute error between the labels and predictions. — metric_mean_absolute_error","text":"","code":"metric_mean_absolute_error(   y_true,   y_pred,   ...,   name = \"mean_absolute_error\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_mean_absolute_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the mean absolute error between the labels and predictions. — metric_mean_absolute_error","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_absolute_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the mean absolute error between the labels and predictions. — metric_mean_absolute_error","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_absolute_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the mean absolute error between the labels and predictions. — metric_mean_absolute_error","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_mean_absolute_error() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0))) m$result() ## tf.Tensor(0.25, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) model %>% compile(     optimizer = 'sgd',     loss = 'mse',     metrics = list(metric_mean_absolute_error()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_mean_absolute_percentage_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes mean absolute percentage error between y_true and y_pred. — metric_mean_absolute_percentage_error","title":"Computes mean absolute percentage error between y_true and y_pred. — metric_mean_absolute_percentage_error","text":"Formula:   Division zero prevented dividing maximum(y_true, epsilon) epsilon = keras$backend$epsilon() (default 1e-7).","code":"loss <- 100 * mean(abs((y_true - y_pred) / y_true), axis=-1)"},{"path":"https://keras.posit.co/reference/metric_mean_absolute_percentage_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes mean absolute percentage error between y_true and y_pred. — metric_mean_absolute_percentage_error","text":"","code":"metric_mean_absolute_percentage_error(   y_true,   y_pred,   ...,   name = \"mean_absolute_percentage_error\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_mean_absolute_percentage_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes mean absolute percentage error between y_true and y_pred. — metric_mean_absolute_percentage_error","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_absolute_percentage_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes mean absolute percentage error between y_true and y_pred. — metric_mean_absolute_percentage_error","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_absolute_percentage_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes mean absolute percentage error between y_true and y_pred. — metric_mean_absolute_percentage_error","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_mean_absolute_percentage_error() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0))) m$result() ## tf.Tensor(250000000.0, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(500000000.0, shape=(), dtype=float32) model %>% compile(     optimizer = 'sgd',     loss = 'mse',     metrics = list(metric_mean_absolute_percentage_error()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_mean_iou.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the mean Intersection-Over-Union metric. — metric_mean_iou","title":"Computes the mean Intersection-Over-Union metric. — metric_mean_iou","text":"Formula:   Intersection--Union common evaluation metric semantic image segmentation. compute IoUs, predictions accumulated confusion matrix, weighted sample_weight metric calculated . sample_weight NULL, weights default 1. Use sample_weight 0 mask values. Note class first computes IoUs individual classes, returns mean values.","code":"iou <- true_positives / (true_positives + false_positives + false_negatives)"},{"path":"https://keras.posit.co/reference/metric_mean_iou.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the mean Intersection-Over-Union metric. — metric_mean_iou","text":"","code":"metric_mean_iou(   ...,   num_classes,   name = NULL,   dtype = NULL,   ignore_class = NULL,   sparse_y_true = TRUE,   sparse_y_pred = TRUE,   axis = -1L )"},{"path":"https://keras.posit.co/reference/metric_mean_iou.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the mean Intersection-Over-Union metric. — metric_mean_iou","text":"... forward/backward compatability. num_classes possible number labels prediction task can . value must provided, since confusion matrix dimension = [num_classes, num_classes] allocated. name (Optional) string name metric instance. dtype (Optional) data type metric result. ignore_class Optional integer. ID class ignored metric computation. useful, example, segmentation problems featuring \"void\" class (commonly -1 255) segmentation maps. default (ignore_class=NULL), classes considered. sparse_y_true Whether labels encoded using integers dense floating point vectors. FALSE, argmax function used determine sample's likely associated label. sparse_y_pred Whether predictions encoded using integers dense floating point vectors. FALSE, argmax function used determine sample's likely associated label. axis (Optional) dimension containing logits. Defaults -1.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_iou.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the mean Intersection-Over-Union metric. — metric_mean_iou","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_iou.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the mean Intersection-Over-Union metric. — metric_mean_iou","text":"Standalone usage:         Usage compile() API:","code":"# cm = [[1, 1], #        [1, 1]] # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1] # iou = true_positives / (sum_row + sum_col - true_positives)) # result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2 = 0.33 m <- metric_mean_iou(num_classes = 2) m$update_state(c(0, 0, 1, 1), c(0, 1, 0, 1)) m$result() ## tf.Tensor(0.33333334, shape=(), dtype=float32) m$reset_state() m$update_state(c(0, 0, 1, 1), c(0, 1, 0, 1),                sample_weight=c(0.3, 0.3, 0.3, 0.1)) m$result() ## tf.Tensor(0.2380952, shape=(), dtype=float32) model %>% compile(   optimizer = 'sgd',   loss = 'mse',   metrics = list(metric_mean_iou(num_classes=2)))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_mean_squared_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the mean squared error between y_true and y_pred. — metric_mean_squared_error","title":"Computes the mean squared error between y_true and y_pred. — metric_mean_squared_error","text":"Formula:","code":"loss <- mean(square(y_true - y_pred))"},{"path":"https://keras.posit.co/reference/metric_mean_squared_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the mean squared error between y_true and y_pred. — metric_mean_squared_error","text":"","code":"metric_mean_squared_error(   y_true,   y_pred,   ...,   name = \"mean_squared_error\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_mean_squared_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the mean squared error between y_true and y_pred. — metric_mean_squared_error","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_squared_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the mean squared error between y_true and y_pred. — metric_mean_squared_error","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_squared_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the mean squared error between y_true and y_pred. — metric_mean_squared_error","text":"","code":"m <- metric_mean_squared_error() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0))) m$result() ## tf.Tensor(0.25, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_mean_squared_logarithmic_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes mean squared logarithmic error between y_true and y_pred. — metric_mean_squared_logarithmic_error","title":"Computes mean squared logarithmic error between y_true and y_pred. — metric_mean_squared_logarithmic_error","text":"Formula:   Note y_pred y_true less equal 0. Negative values 0 values replaced keras$backend$epsilon() (default 1e-7).","code":"loss <- mean(square(log(y_true + 1) - log(y_pred + 1)), axis=-1)"},{"path":"https://keras.posit.co/reference/metric_mean_squared_logarithmic_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes mean squared logarithmic error between y_true and y_pred. — metric_mean_squared_logarithmic_error","text":"","code":"metric_mean_squared_logarithmic_error(   y_true,   y_pred,   ...,   name = \"mean_squared_logarithmic_error\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_mean_squared_logarithmic_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes mean squared logarithmic error between y_true and y_pred. — metric_mean_squared_logarithmic_error","text":"y_true Ground truth values shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_squared_logarithmic_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes mean squared logarithmic error between y_true and y_pred. — metric_mean_squared_logarithmic_error","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_squared_logarithmic_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes mean squared logarithmic error between y_true and y_pred. — metric_mean_squared_logarithmic_error","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_mean_squared_logarithmic_error() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0))) m$result() ## tf.Tensor(0.12011322, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(0.24022643, shape=(), dtype=float32) model %>% compile(   optimizer = 'sgd',   loss = 'mse',   metrics = list(metric_mean_squared_logarithmic_error()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_mean_wrapper.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrap a stateless metric function with the Mean metric. — metric_mean_wrapper","title":"Wrap a stateless metric function with the Mean metric. — metric_mean_wrapper","text":"use class quickly build mean metric function. function needs signature fn(y_true, y_pred) return per-sample loss array. metric_mean_wrapper$result() return average metric value across samples seen far. example:","code":"mse <- function(y_true, y_pred) {   (y_true - y_pred)^2 }  mse_metric <- metric_mean_wrapper(fn = mse) mse_metric$update_state(c(0, 1), c(1, 1)) mse_metric$result() ## tf.Tensor(0.5, shape=(), dtype=float32)"},{"path":"https://keras.posit.co/reference/metric_mean_wrapper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrap a stateless metric function with the Mean metric. — metric_mean_wrapper","text":"","code":"metric_mean_wrapper(..., fn, name = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_mean_wrapper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrap a stateless metric function with the Mean metric. — metric_mean_wrapper","text":"... Keyword arguments pass fn. fn metric function wrap, signature fn(y_true, y_pred). name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_mean_wrapper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrap a stateless metric function with the Mean metric. — metric_mean_wrapper","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/metric_one_hot_iou.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_iou","title":"Computes the Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_iou","text":"Formula:   Intersection--Union common evaluation metric semantic image segmentation. compute IoUs, predictions accumulated confusion matrix, weighted sample_weight metric calculated . sample_weight NULL, weights default 1. Use sample_weight 0 mask values. class can used compute IoU multi-class classification tasks labels one-hot encoded (last axis one dimension per class). Note predictions also shape. compute IoU, first labels predictions converted back integer format taking argmax class axis. computation steps base IoU class apply. Note, one channel labels predictions, class class IoU. case, use IoU instead. Also, make sure num_classes equal number classes data, avoid \"labels bound\" error confusion matrix computed.","code":"iou <- true_positives / (true_positives + false_positives + false_negatives)"},{"path":"https://keras.posit.co/reference/metric_one_hot_iou.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_iou","text":"","code":"metric_one_hot_iou(   ...,   num_classes,   target_class_ids,   name = NULL,   dtype = NULL,   ignore_class = NULL,   sparse_y_pred = FALSE,   axis = -1L )"},{"path":"https://keras.posit.co/reference/metric_one_hot_iou.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_iou","text":"... forward/backward compatability. num_classes possible number labels prediction task can . target_class_ids list list target class ids metric returned. compute IoU specific class, list (list) single id value provided. name (Optional) string name metric instance. dtype (Optional) data type metric result. ignore_class Optional integer. ID class ignored metric computation. useful, example, segmentation problems featuring \"void\" class (commonly -1 255) segmentation maps. default (ignore_class=NULL), classes considered. sparse_y_pred Whether predictions encoded using integers dense floating point vectors. FALSE, argmax function used determine sample's likely associated label. axis (Optional) dimension containing logits. Defaults -1.","code":""},{"path":"https://keras.posit.co/reference/metric_one_hot_iou.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_iou","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_one_hot_iou.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_iou","text":"Standalone usage:     Usage compile() API:","code":"y_true <- rbind(c(0, 0, 1), c(1, 0, 0), c(0, 1, 0), c(1, 0, 0)) y_pred <- rbind(c(0.2, 0.3, 0.5), c(0.1, 0.2, 0.7), c(0.5, 0.3, 0.1),                 c(0.1, 0.4, 0.5)) sample_weight <- c(0.1, 0.2, 0.3, 0.4) m <- metric_one_hot_iou(num_classes = 3, target_class_ids = c(0, 2)) m$update_state(     y_true = y_true, y_pred = y_pred, sample_weight = sample_weight) m$result() ## tf.Tensor(0.07142855, shape=(), dtype=float32) model %>% compile(   optimizer = 'sgd',   loss = 'mse',   metrics = list(metric_one_hot_iou(     num_classes = 3L,     target_class_id = list(1L)   )) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_one_hot_mean_iou.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes mean Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_mean_iou","title":"Computes mean Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_mean_iou","text":"Formula:   Intersection--Union common evaluation metric semantic image segmentation. compute IoUs, predictions accumulated confusion matrix, weighted sample_weight metric calculated . sample_weight NULL, weights default 1. Use sample_weight 0 mask values. class can used compute mean IoU multi-class classification tasks labels one-hot encoded (last axis one dimension per class). Note predictions also shape. compute mean IoU, first labels predictions converted back integer format taking argmax class axis. computation steps base MeanIoU class apply. Note, one channel labels predictions, class class metric_mean_iou. case, use metric_mean_iou instead. Also, make sure num_classes equal number classes data, avoid \"labels bound\" error confusion matrix computed.","code":"iou <- true_positives / (true_positives + false_positives + false_negatives)"},{"path":"https://keras.posit.co/reference/metric_one_hot_mean_iou.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes mean Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_mean_iou","text":"","code":"metric_one_hot_mean_iou(   ...,   num_classes,   name = NULL,   dtype = NULL,   ignore_class = NULL,   sparse_y_pred = FALSE,   axis = -1L )"},{"path":"https://keras.posit.co/reference/metric_one_hot_mean_iou.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes mean Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_mean_iou","text":"... forward/backward compatability. num_classes possible number labels prediction task can . name (Optional) string name metric instance. dtype (Optional) data type metric result. ignore_class Optional integer. ID class ignored metric computation. useful, example, segmentation problems featuring \"void\" class (commonly -1 255) segmentation maps. default (ignore_class=NULL), classes considered. sparse_y_pred Whether predictions encoded using natural numbers probability distribution vectors. FALSE, argmax function used determine sample's likely associated label. axis (Optional) dimension containing logits. Defaults -1.","code":""},{"path":"https://keras.posit.co/reference/metric_one_hot_mean_iou.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes mean Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_mean_iou","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_one_hot_mean_iou.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes mean Intersection-Over-Union metric for one-hot encoded labels. — metric_one_hot_mean_iou","text":"Standalone usage:     Usage compile() API:","code":"y_true <- rbind(c(0, 0, 1), c(1, 0, 0), c(0, 1, 0), c(1, 0, 0)) y_pred <- rbind(c(0.2, 0.3, 0.5), c(0.1, 0.2, 0.7), c(0.5, 0.3, 0.1),                 c(0.1, 0.4, 0.5)) sample_weight <- c(0.1, 0.2, 0.3, 0.4) m <- metric_one_hot_mean_iou(num_classes = 3L) m$update_state(     y_true = y_true, y_pred = y_pred, sample_weight = sample_weight) m$result() ## tf.Tensor(0.047619034, shape=(), dtype=float32) model %>% compile(     optimizer = 'sgd',     loss = 'mse',     metrics = list(metric_one_hot_mean_iou(num_classes = 3L)))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Poisson metric between y_true and y_pred. — metric_poisson","title":"Computes the Poisson metric between y_true and y_pred. — metric_poisson","text":"Formula:","code":"metric <- y_pred - y_true * log(y_pred)"},{"path":"https://keras.posit.co/reference/metric_poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Poisson metric between y_true and y_pred. — metric_poisson","text":"","code":"metric_poisson(y_true, y_pred, ..., name = \"poisson\", dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_poisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Poisson metric between y_true and y_pred. — metric_poisson","text":"y_true Ground truth values. shape = [batch_size, d0, .. dN]. y_pred predicted values. shape = [batch_size, d0, .. dN]. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_poisson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the Poisson metric between y_true and y_pred. — metric_poisson","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_poisson.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Poisson metric between y_true and y_pred. — metric_poisson","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_poisson() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0))) m$result() ## tf.Tensor(0.49999997, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(0.99999994, shape=(), dtype=float32) model %>% compile(   optimizer = 'sgd',   loss = 'mse',   metrics = list(metric_poisson()) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the precision of the predictions with respect to the labels. — metric_precision","title":"Computes the precision of the predictions with respect to the labels. — metric_precision","text":"metric creates two local variables, true_positives false_positives used compute precision. value ultimately returned precision, idempotent operation simply divides true_positives sum true_positives false_positives. sample_weight NULL, weights default 1. Use sample_weight 0 mask values. top_k set, calculate precision often average class among top-k classes highest predicted values batch entry correct can found label entry. class_id specified, calculate precision considering entries batch class_id threshold /top-k highest predictions, computing fraction class_id indeed correct label.","code":""},{"path":"https://keras.posit.co/reference/metric_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the precision of the predictions with respect to the labels. — metric_precision","text":"","code":"metric_precision(   ...,   thresholds = NULL,   top_k = NULL,   class_id = NULL,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the precision of the predictions with respect to the labels. — metric_precision","text":"... forward/backward compatability. thresholds (Optional) float value, Python list float threshold values [0, 1]. threshold compared prediction values determine truth value predictions (.e., threshold TRUE, FALSE). used loss function sets from_logits=TRUE (.e. sigmoid applied predictions), thresholds set 0. One metric value generated threshold value. neither thresholds top_k set, default calculate precision thresholds=0.5. top_k (Optional) Unset default. int value specifying top-k predictions consider calculating precision. class_id (Optional) Integer class ID want binary metrics. must half-open interval [0, num_classes), num_classes last dimension predictions. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the precision of the predictions with respect to the labels. — metric_precision","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_precision.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the precision of the predictions with respect to the labels. — metric_precision","text":"Standalone usage:                 Usage compile() API:   Usage loss from_logits=TRUE:","code":"m <- metric_precision() m$update_state(c(0, 1, 1, 1),                c(1, 0, 1, 1)) m$result() |> as.double() |> signif() ## [1] 0.666667 m$reset_state() m$update_state(c(0, 1, 1, 1),                c(1, 0, 1, 1),                sample_weight = c(0, 0, 1, 0)) m$result() |> as.double() |> signif() ## [1] 1 # With top_k=2, it will calculate precision over y_true[1:2] # and y_pred[1:2] m <- metric_precision(top_k = 2) m$update_state(c(0, 0, 1, 1), c(1, 1, 1, 1)) m$result() ## tf.Tensor(0.0, shape=(), dtype=float32) # With top_k=4, it will calculate precision over y_true[1:4] # and y_pred[1:4] m <- metric_precision(top_k = 4) m$update_state(c(0, 0, 1, 1), c(1, 1, 1, 1)) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) model |> compile(   optimizer = 'sgd',   loss = 'binary_crossentropy',   metrics = list(metric_precision()) ) model |> compile(   optimizer = 'adam',   loss = loss_binary_crossentropy(from_logits = TRUE),   metrics = list(metric_precision(thresholds = 0)) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_precision_at_recall.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes best precision where recall is >= specified value. — metric_precision_at_recall","title":"Computes best precision where recall is >= specified value. — metric_precision_at_recall","text":"metric creates four local variables, true_positives, true_negatives, false_positives false_negatives used compute precision given recall. threshold given recall value computed used evaluate corresponding precision. sample_weight NULL, weights default 1. Use sample_weight 0 mask values. class_id specified, calculate precision considering entries batch class_id threshold predictions, computing fraction class_id indeed correct label.","code":""},{"path":"https://keras.posit.co/reference/metric_precision_at_recall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes best precision where recall is >= specified value. — metric_precision_at_recall","text":"","code":"metric_precision_at_recall(   ...,   recall,   num_thresholds = 200L,   class_id = NULL,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_precision_at_recall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes best precision where recall is >= specified value. — metric_precision_at_recall","text":"... forward/backward compatability. recall scalar value range [0, 1]. num_thresholds (Optional) Defaults 200. number thresholds use matching given recall. class_id (Optional) Integer class ID want binary metrics. must half-open interval [0, num_classes), num_classes last dimension predictions. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_precision_at_recall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes best precision where recall is >= specified value. — metric_precision_at_recall","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_precision_at_recall.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes best precision where recall is >= specified value. — metric_precision_at_recall","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_precision_at_recall(recall = 0.5) m$update_state(c(0,   0,   0,   1,   1),                c(0, 0.3, 0.8, 0.3, 0.8)) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(c(0,   0,   0,   1,   1),                c(0, 0.3, 0.8, 0.3, 0.8),                sample_weight = c(2, 2, 2, 1, 1)) m$result() ## tf.Tensor(0.33333334, shape=(), dtype=float32) model |> compile(   optimizer = 'sgd',   loss = 'binary_crossentropy',   metrics = list(metric_precision_at_recall(recall = 0.8)) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_r2_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes R2 score. — metric_r2_score","title":"Computes R2 score. — metric_r2_score","text":"Formula:   also called coefficient determination. indicates close fitted regression line ground-truth data. highest score possible 1.0. indicates predictors perfectly accounts variation target. score 0.0 indicates predictors account variation target. can also negative model worse random. metric can also compute \"Adjusted R2\" score.","code":"sum_squares_residuals <- sum((y_true - y_pred) ** 2) sum_squares <- sum((y_true - mean(y_true)) ** 2) R2 <- 1 - sum_squares_residuals / sum_squares"},{"path":"https://keras.posit.co/reference/metric_r2_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes R2 score. — metric_r2_score","text":"","code":"metric_r2_score(   ...,   class_aggregation = \"uniform_average\",   num_regressors = 0L,   name = \"r2_score\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_r2_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes R2 score. — metric_r2_score","text":"... forward/backward compatability. class_aggregation Specifies aggregate scores corresponding different output classes (target dimensions), .e. different dimensions last axis predictions. Equivalent multioutput argument Scikit-Learn. one NULL (aggregation), \"uniform_average\", \"variance_weighted_average\". num_regressors Number independent regressors used (\"Adjusted R2\" score). 0 standard R2 score. Defaults 0. name Optional. string name metric instance. dtype Optional. data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_r2_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes R2 score. — metric_r2_score","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_r2_score.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes R2 score. — metric_r2_score","text":"","code":"y_true <- rbind(1, 4, 3) y_pred <- rbind(2, 4, 4) metric <- metric_r2_score() metric$update_state(y_true, y_pred) metric$result() ## tf.Tensor(0.57142854, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_recall.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the recall of the predictions with respect to the labels. — metric_recall","title":"Computes the recall of the predictions with respect to the labels. — metric_recall","text":"metric creates two local variables, true_positives false_negatives, used compute recall. value ultimately returned recall, idempotent operation simply divides true_positives sum true_positives false_negatives. sample_weight NULL, weights default 1. Use sample_weight 0 mask values. top_k set, recall computed often average class among labels batch entry top-k predictions. class_id specified, calculate recall considering entries batch class_id label, computing fraction class_id threshold /top-k predictions.","code":""},{"path":"https://keras.posit.co/reference/metric_recall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the recall of the predictions with respect to the labels. — metric_recall","text":"","code":"metric_recall(   ...,   thresholds = NULL,   top_k = NULL,   class_id = NULL,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_recall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the recall of the predictions with respect to the labels. — metric_recall","text":"... forward/backward compatability. thresholds (Optional) float value, Python list float threshold values [0, 1]. threshold compared prediction values determine truth value predictions (.e., threshold TRUE, FALSE). used loss function sets from_logits=TRUE (.e. sigmoid applied predictions), thresholds set 0. One metric value generated threshold value. neither thresholds top_k set, default calculate recall thresholds=0.5. top_k (Optional) Unset default. int value specifying top-k predictions consider calculating recall. class_id (Optional) Integer class ID want binary metrics. must half-open interval [0, num_classes), num_classes last dimension predictions. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_recall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the recall of the predictions with respect to the labels. — metric_recall","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_recall.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the recall of the predictions with respect to the labels. — metric_recall","text":"Standalone usage:         Usage compile() API:   Usage loss from_logits=TRUE:","code":"m <- metric_recall() m$update_state(c(0, 1, 1, 1),                c(1, 0, 1, 1)) m$result() ## tf.Tensor(0.6666667, shape=(), dtype=float32) m$reset_state() m$update_state(c(0, 1, 1, 1),                c(1, 0, 1, 1),                sample_weight = c(0, 0, 1, 0)) m$result() ## tf.Tensor(1.0, shape=(), dtype=float32) model |> compile(   optimizer = 'sgd',   loss = 'binary_crossentropy',   metrics = list(metric_recall()) ) model |> compile(   optimizer = 'adam',   loss = loss_binary_crossentropy(from_logits = TRUE),   metrics = list(metric_recall(thresholds = 0)) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_recall_at_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes best recall where precision is >= specified value. — metric_recall_at_precision","title":"Computes best recall where precision is >= specified value. — metric_recall_at_precision","text":"given score-label-distribution required precision might achievable, case 0.0 returned recall. metric creates four local variables, true_positives, true_negatives, false_positives false_negatives used compute recall given precision. threshold given precision value computed used evaluate corresponding recall. sample_weight NULL, weights default 1. Use sample_weight 0 mask values. class_id specified, calculate precision considering entries batch class_id threshold predictions, computing fraction class_id indeed correct label.","code":""},{"path":"https://keras.posit.co/reference/metric_recall_at_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes best recall where precision is >= specified value. — metric_recall_at_precision","text":"","code":"metric_recall_at_precision(   ...,   precision,   num_thresholds = 200L,   class_id = NULL,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_recall_at_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes best recall where precision is >= specified value. — metric_recall_at_precision","text":"... forward/backward compatability. precision scalar value range [0, 1]. num_thresholds (Optional) Defaults 200. number thresholds use matching given precision. class_id (Optional) Integer class ID want binary metrics. must half-open interval [0, num_classes), num_classes last dimension predictions. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_recall_at_precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes best recall where precision is >= specified value. — metric_recall_at_precision","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_recall_at_precision.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes best recall where precision is >= specified value. — metric_recall_at_precision","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_recall_at_precision(precision = 0.8) m$update_state(c(0,   0,   1,   1),                c(0, 0.5, 0.3, 0.9)) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(c(0,   0,   1,   1),                c(0, 0.5, 0.3, 0.9),                sample_weight = c(1, 0, 0, 1)) m$result() ## tf.Tensor(1.0, shape=(), dtype=float32) model |> compile(   optimizer = 'sgd',   loss = 'binary_crossentropy',   metrics = list(metric_recall_at_precision(precision = 0.8)) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_root_mean_squared_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes root mean squared error metric between y_true and y_pred. — metric_root_mean_squared_error","title":"Computes root mean squared error metric between y_true and y_pred. — metric_root_mean_squared_error","text":"Formula:","code":"loss <- sqrt(mean((y_pred - y_true) ^ 2))"},{"path":"https://keras.posit.co/reference/metric_root_mean_squared_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes root mean squared error metric between y_true and y_pred. — metric_root_mean_squared_error","text":"","code":"metric_root_mean_squared_error(   ...,   name = \"root_mean_squared_error\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_root_mean_squared_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes root mean squared error metric between y_true and y_pred. — metric_root_mean_squared_error","text":"... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_root_mean_squared_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes root mean squared error metric between y_true and y_pred. — metric_root_mean_squared_error","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_root_mean_squared_error.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes root mean squared error metric between y_true and y_pred. — metric_root_mean_squared_error","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_root_mean_squared_error() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0))) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(1, 1), c(0, 0)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(0.70710677, shape=(), dtype=float32) model %>% compile(   optimizer = 'sgd',   loss = 'mse',   metrics = list(metric_root_mean_squared_error()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_sensitivity_at_specificity.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes best sensitivity where specificity is >= specified value. — metric_sensitivity_at_specificity","title":"Computes best sensitivity where specificity is >= specified value. — metric_sensitivity_at_specificity","text":"Sensitivity measures proportion actual positives correctly identified (tp / (tp + fn)). Specificity measures proportion actual negatives correctly identified (tn / (tn + fp)). metric creates four local variables, true_positives, true_negatives, false_positives false_negatives used compute sensitivity given specificity. threshold given specificity value computed used evaluate corresponding sensitivity. sample_weight NULL, weights default 1. Use sample_weight 0 mask values. class_id specified, calculate precision considering entries batch class_id threshold predictions, computing fraction class_id indeed correct label. additional information specificity sensitivity, see following.","code":""},{"path":"https://keras.posit.co/reference/metric_sensitivity_at_specificity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes best sensitivity where specificity is >= specified value. — metric_sensitivity_at_specificity","text":"","code":"metric_sensitivity_at_specificity(   ...,   specificity,   num_thresholds = 200L,   class_id = NULL,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_sensitivity_at_specificity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes best sensitivity where specificity is >= specified value. — metric_sensitivity_at_specificity","text":"... forward/backward compatability. specificity scalar value range [0, 1]. num_thresholds (Optional) Defaults 200. number thresholds use matching given specificity. class_id (Optional) Integer class ID want binary metrics. must half-open interval [0, num_classes), num_classes last dimension predictions. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_sensitivity_at_specificity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes best sensitivity where specificity is >= specified value. — metric_sensitivity_at_specificity","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_sensitivity_at_specificity.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes best sensitivity where specificity is >= specified value. — metric_sensitivity_at_specificity","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_sensitivity_at_specificity(specificity = 0.5) m$update_state(c(0,   0,   0,   1,   1),                c(0, 0.3, 0.8, 0.3, 0.8)) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(c(0,   0,   0,   1,   1),                c(0, 0.3, 0.8, 0.3, 0.8),                sample_weight = c(1, 1, 2, 2, 1)) m$result() ## tf.Tensor(0.33333334, shape=(), dtype=float32) model |> compile(   optimizer = 'sgd',   loss = 'binary_crossentropy',   metrics = list(metric_sensitivity_at_specificity()) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates how often predictions match integer labels. — metric_sparse_categorical_accuracy","title":"Calculates how often predictions match integer labels. — metric_sparse_categorical_accuracy","text":"can provide logits classes y_pred, since argmax logits probabilities . metric creates two local variables, total count used compute frequency y_pred matches y_true. frequency ultimately returned sparse categorical accuracy: idempotent operation simply divides total count. sample_weight NULL, weights default 1. Use sample_weight 0 mask values.","code":"acc <- sample_weight %*% (y_true == which.max(y_pred))"},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates how often predictions match integer labels. — metric_sparse_categorical_accuracy","text":"","code":"metric_sparse_categorical_accuracy(   y_true,   y_pred,   ...,   name = \"sparse_categorical_accuracy\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates how often predictions match integer labels. — metric_sparse_categorical_accuracy","text":"y_true Tensor true targets. y_pred Tensor predicted targets. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates how often predictions match integer labels. — metric_sparse_categorical_accuracy","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_accuracy.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates how often predictions match integer labels. — metric_sparse_categorical_accuracy","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_sparse_categorical_accuracy() m$update_state(rbind(2L, 1L), rbind(c(0.1, 0.6, 0.3), c(0.05, 0.95, 0))) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(2L, 1L), rbind(c(0.1, 0.6, 0.3), c(0.05, 0.95, 0)),                sample_weight = c(0.7, 0.3)) m$result() ## tf.Tensor(0.3, shape=(), dtype=float32) model %>% compile(optimizer = 'sgd',                   loss = 'sparse_categorical_crossentropy',                   metrics = list(metric_sparse_categorical_accuracy()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the crossentropy metric between the labels and predictions. — metric_sparse_categorical_crossentropy","title":"Computes the crossentropy metric between the labels and predictions. — metric_sparse_categorical_crossentropy","text":"Use crossentropy metric two label classes. expects labels provided integers. want provide labels one-hot encoded, please use metric_categorical_crossentropy() metric instead. num_classes floating point values per feature y_pred single floating point value per feature y_true.","code":""},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the crossentropy metric between the labels and predictions. — metric_sparse_categorical_crossentropy","text":"","code":"metric_sparse_categorical_crossentropy(   y_true,   y_pred,   from_logits = FALSE,   ignore_class = NULL,   axis = -1L,   ...,   name = \"sparse_categorical_crossentropy\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the crossentropy metric between the labels and predictions. — metric_sparse_categorical_crossentropy","text":"y_true Ground truth values. y_pred predicted values. from_logits (Optional) Whether output expected logits tensor. default, consider output encodes probability distribution. ignore_class Optional integer. ID class ignored loss computation. useful, example, segmentation problems featuring \"void\" class (commonly -1 255) segmentation maps. default (ignore_class=NULL), classes considered. axis (Optional) Defaults -1. dimension along entropy computed. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the crossentropy metric between the labels and predictions. — metric_sparse_categorical_crossentropy","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_sparse_categorical_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the crossentropy metric between the labels and predictions. — metric_sparse_categorical_crossentropy","text":"Standalone usage:           Usage compile() API:","code":"m <- metric_sparse_categorical_crossentropy() m$update_state(c(1, 2),                rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1))) m$result() ## tf.Tensor(1.1769392, shape=(), dtype=float32) m$reset_state() m$update_state(c(1, 2),                rbind(c(0.05, 0.95, 0), c(0.1, 0.8, 0.1)),                sample_weight = c(0.3, 0.7)) m$result() ## tf.Tensor(1.6271976, shape=(), dtype=float32) # 1.6271976 model %>% compile(     optimizer = 'sgd',     loss = 'mse',     metrics = list(metric_sparse_categorical_crossentropy()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_sparse_top_k_categorical_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes how often integer targets are in the top K predictions. — metric_sparse_top_k_categorical_accuracy","title":"Computes how often integer targets are in the top K predictions. — metric_sparse_top_k_categorical_accuracy","text":"Computes often integer targets top K predictions.","code":""},{"path":"https://keras.posit.co/reference/metric_sparse_top_k_categorical_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes how often integer targets are in the top K predictions. — metric_sparse_top_k_categorical_accuracy","text":"","code":"metric_sparse_top_k_categorical_accuracy(   y_true,   y_pred,   k = 5L,   ...,   name = \"sparse_top_k_categorical_accuracy\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_sparse_top_k_categorical_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes how often integer targets are in the top K predictions. — metric_sparse_top_k_categorical_accuracy","text":"y_true Tensor true targets. y_pred Tensor predicted targets. k (Optional) Number top elements look computing accuracy. Defaults 5. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_sparse_top_k_categorical_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes how often integer targets are in the top K predictions. — metric_sparse_top_k_categorical_accuracy","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_sparse_top_k_categorical_accuracy.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes how often integer targets are in the top K predictions. — metric_sparse_top_k_categorical_accuracy","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_sparse_top_k_categorical_accuracy(k = 1L) m$update_state(   rbind(2, 1),   op_array(rbind(c(0.1, 0.9, 0.8), c(0.05, 0.95, 0)), dtype = \"float32\") ) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(   rbind(2, 1),   op_array(rbind(c(0.1, 0.9, 0.8), c(0.05, 0.95, 0)), dtype = \"float32\"),   sample_weight = c(0.7, 0.3) ) m$result() ## tf.Tensor(0.3, shape=(), dtype=float32) model %>% compile(optimizer = 'sgd',                   loss = 'sparse_categorical_crossentropy',                   metrics = list(metric_sparse_top_k_categorical_accuracy()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_specificity_at_sensitivity.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes best specificity where sensitivity is >= specified value. — metric_specificity_at_sensitivity","title":"Computes best specificity where sensitivity is >= specified value. — metric_specificity_at_sensitivity","text":"Sensitivity measures proportion actual positives correctly identified (tp / (tp + fn)). Specificity measures proportion actual negatives correctly identified (tn / (tn + fp)). metric creates four local variables, true_positives, true_negatives, false_positives false_negatives used compute specificity given sensitivity. threshold given sensitivity value computed used evaluate corresponding specificity. sample_weight NULL, weights default 1. Use sample_weight 0 mask values. class_id specified, calculate precision considering entries batch class_id threshold predictions, computing fraction class_id indeed correct label. additional information specificity sensitivity, see following.","code":""},{"path":"https://keras.posit.co/reference/metric_specificity_at_sensitivity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes best specificity where sensitivity is >= specified value. — metric_specificity_at_sensitivity","text":"","code":"metric_specificity_at_sensitivity(   ...,   sensitivity,   num_thresholds = 200L,   class_id = NULL,   name = NULL,   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_specificity_at_sensitivity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes best specificity where sensitivity is >= specified value. — metric_specificity_at_sensitivity","text":"... forward/backward compatability. sensitivity scalar value range [0, 1]. num_thresholds (Optional) Defaults 200. number thresholds use matching given sensitivity. class_id (Optional) Integer class ID want binary metrics. must half-open interval [0, num_classes), num_classes last dimension predictions. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_specificity_at_sensitivity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes best specificity where sensitivity is >= specified value. — metric_specificity_at_sensitivity","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_specificity_at_sensitivity.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes best specificity where sensitivity is >= specified value. — metric_specificity_at_sensitivity","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_specificity_at_sensitivity(sensitivity = 0.5) m$update_state(c(0,   0,   0,   1,   1),                c(0, 0.3, 0.8, 0.3, 0.8)) m$result() ## tf.Tensor(0.6666667, shape=(), dtype=float32) m$reset_state() m$update_state(c(0,   0,   0,   1,   1),                c(0, 0.3, 0.8, 0.3, 0.8),                sample_weight = c(1, 1, 2, 2, 2)) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) model |> compile(   optimizer = 'sgd',   loss = 'binary_crossentropy',   metrics = list(metric_sensitivity_at_specificity()) )"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_squared_hinge.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the hinge metric between y_true and y_pred. — metric_squared_hinge","title":"Computes the hinge metric between y_true and y_pred. — metric_squared_hinge","text":"Formula:   y_true values expected -1 1. binary (0 1) labels provided convert -1 1.","code":"loss <- mean(square(maximum(1 - y_true * y_pred, 0)))"},{"path":"https://keras.posit.co/reference/metric_squared_hinge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the hinge metric between y_true and y_pred. — metric_squared_hinge","text":"","code":"metric_squared_hinge(y_true, y_pred, ..., name = \"squared_hinge\", dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_squared_hinge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the hinge metric between y_true and y_pred. — metric_squared_hinge","text":"y_true ground truth values. y_true values expected -1 1. binary (0 1) labels provided convert -1 1 shape = [batch_size, d0, .. dN]. y_pred predicted values shape = [batch_size, d0, .. dN]. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_squared_hinge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the hinge metric between y_true and y_pred. — metric_squared_hinge","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_squared_hinge.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the hinge metric between y_true and y_pred. — metric_squared_hinge","text":"Standalone usage:","code":"m <- metric_squared_hinge() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6))) m$result() ## tf.Tensor(1.86, shape=(), dtype=float32) m$reset_state() m$update_state(rbind(c(0, 1), c(0, 0)), rbind(c(0.6, 0.4), c(0.4, 0.6)),                sample_weight = c(1, 0)) m$result() ## tf.Tensor(1.46, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the (weighted) sum of the given values. — metric_sum","title":"Compute the (weighted) sum of the given values. — metric_sum","text":"example, values [1, 3, 5, 7] sum 16. sample_weight specified [1, 1, 0, 0] sum 4. metric creates one variable, total. ultimately returned sum value.","code":""},{"path":"https://keras.posit.co/reference/metric_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the (weighted) sum of the given values. — metric_sum","text":"","code":"metric_sum(..., name = \"sum\", dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the (weighted) sum of the given values. — metric_sum","text":"... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the (weighted) sum of the given values. — metric_sum","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_sum.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the (weighted) sum of the given values. — metric_sum","text":"","code":"m <- metric_sum() m$update_state(c(1, 3, 5, 7)) m$result() ## tf.Tensor(16.0, shape=(), dtype=float32) m <- metric_sum() m$update_state(c(1, 3, 5, 7), sample_weight = c(1, 1, 0, 0)) m$result() ## tf.Tensor(4.0, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_top_k_categorical_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes how often targets are in the top K predictions. — metric_top_k_categorical_accuracy","title":"Computes how often targets are in the top K predictions. — metric_top_k_categorical_accuracy","text":"Computes often targets top K predictions.","code":""},{"path":"https://keras.posit.co/reference/metric_top_k_categorical_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes how often targets are in the top K predictions. — metric_top_k_categorical_accuracy","text":"","code":"metric_top_k_categorical_accuracy(   y_true,   y_pred,   k = 5L,   ...,   name = \"top_k_categorical_accuracy\",   dtype = NULL )"},{"path":"https://keras.posit.co/reference/metric_top_k_categorical_accuracy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes how often targets are in the top K predictions. — metric_top_k_categorical_accuracy","text":"y_true Tensor true targets. y_pred Tensor predicted targets. k (Optional) Number top elements look computing accuracy. Defaults 5. ... forward/backward compatability. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_top_k_categorical_accuracy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes how often targets are in the top K predictions. — metric_top_k_categorical_accuracy","text":"y_true y_pred missing, Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage. y_true y_pred provided, tensor computed value returned.","code":""},{"path":"https://keras.posit.co/reference/metric_top_k_categorical_accuracy.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes how often targets are in the top K predictions. — metric_top_k_categorical_accuracy","text":"Standalone usage:         Usage compile() API:","code":"m <- metric_top_k_categorical_accuracy(k = 1) m$update_state(   rbind(c(0, 0, 1), c(0, 1, 0)),   op_array(rbind(c(0.1, 0.9, 0.8), c(0.05, 0.95, 0)), dtype = \"float32\") ) m$result() ## tf.Tensor(0.5, shape=(), dtype=float32) m$reset_state() m$update_state(   rbind(c(0, 0, 1), c(0, 1, 0)),   op_array(rbind(c(0.1, 0.9, 0.8), c(0.05, 0.95, 0)), dtype = \"float32\"),   sample_weight = c(0.7, 0.3)) m$result() ## tf.Tensor(0.3, shape=(), dtype=float32) model.compile(optimizer = 'sgd',               loss = 'categorical_crossentropy',               metrics = list(metric_top_k_categorical_accuracy()))"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_true_negatives.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the number of true negatives. — metric_true_negatives","title":"Calculates the number of true negatives. — metric_true_negatives","text":"sample_weight given, calculates sum weights true negatives. metric creates one local variable, accumulator used keep track number true negatives. sample_weight NULL, weights default 1. Use sample_weight 0 mask values.","code":""},{"path":"https://keras.posit.co/reference/metric_true_negatives.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the number of true negatives. — metric_true_negatives","text":"","code":"metric_true_negatives(..., thresholds = NULL, name = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_true_negatives.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the number of true negatives. — metric_true_negatives","text":"... forward/backward compatability. thresholds (Optional) Defaults 0.5. float value, Python list float threshold values [0, 1]. threshold compared prediction values determine truth value predictions (.e., threshold TRUE, FALSE). used loss function sets from_logits=TRUE (.e. sigmoid applied predictions), thresholds set 0. One metric value generated threshold value. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_true_negatives.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the number of true negatives. — metric_true_negatives","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_true_negatives.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the number of true negatives. — metric_true_negatives","text":"Standalone usage:","code":"m <- metric_true_negatives() m$update_state(c(0, 1, 0, 0), c(1, 1, 0, 0)) m$result() ## tf.Tensor(2.0, shape=(), dtype=float32) m$reset_state() m$update_state(c(0, 1, 0, 0), c(1, 1, 0, 0), sample_weight = c(0, 0, 1, 0)) m$result() ## tf.Tensor(1.0, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/metric_true_positives.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the number of true positives. — metric_true_positives","title":"Calculates the number of true positives. — metric_true_positives","text":"sample_weight given, calculates sum weights true positives. metric creates one local variable, true_positives used keep track number true positives. sample_weight NULL, weights default 1. Use sample_weight 0 mask values.","code":""},{"path":"https://keras.posit.co/reference/metric_true_positives.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the number of true positives. — metric_true_positives","text":"","code":"metric_true_positives(..., thresholds = NULL, name = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/metric_true_positives.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the number of true positives. — metric_true_positives","text":"... forward/backward compatability. thresholds (Optional) Defaults 0.5. float value, Python list float threshold values [0, 1]. threshold compared prediction values determine truth value predictions (.e., threshold TRUE, FALSE). used loss function sets from_logits=TRUE (.e. sigmoid applied predictions), thresholds set 0. One metric value generated threshold value. name (Optional) string name metric instance. dtype (Optional) data type metric result.","code":""},{"path":"https://keras.posit.co/reference/metric_true_positives.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the number of true positives. — metric_true_positives","text":"Metric instance returned. Metric instance can passed directly compile(metrics = ), used standalone object. See ?Metric example usage.","code":""},{"path":"https://keras.posit.co/reference/metric_true_positives.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the number of true positives. — metric_true_positives","text":"Standalone usage:","code":"m <- metric_true_positives() m$update_state(c(0, 1, 1, 1), c(1, 0, 1, 1)) m$result() ## tf.Tensor(2.0, shape=(), dtype=float32) m$reset_state() m$update_state(c(0, 1, 1, 1), c(1, 0, 1, 1), sample_weight = c(0, 0, 1, 0)) m$result() ## tf.Tensor(1.0, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/multi-assign.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign values to names — %<-%","title":"Assign values to names — %<-%","text":"See %<-% details.","code":""},{"path":"https://keras.posit.co/reference/multi-assign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign values to names — %<-%","text":"","code":"x %<-% value"},{"path":"https://keras.posit.co/reference/multi-assign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign values to names — %<-%","text":"right-hand-side argument, value, invisibly. called primarily side-effect assigning symbols current frame.","code":""},{"path":"https://keras.posit.co/reference/new_callback_class.html","id":null,"dir":"Reference","previous_headings":"","what":"Callback — new_callback_class","title":"Callback — new_callback_class","text":"new_callback_class() alias Callback(). See ?Callback() full documentation.","code":""},{"path":"https://keras.posit.co/reference/new_callback_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Callback — new_callback_class","text":"","code":"new_callback_class(   classname,   on_epoch_begin = NULL,   on_epoch_end = NULL,   on_train_begin = NULL,   on_train_end = NULL,   on_train_batch_begin = NULL,   on_train_batch_end = NULL,   on_test_begin = NULL,   on_test_end = NULL,   on_test_batch_begin = NULL,   on_test_batch_end = NULL,   on_predict_begin = NULL,   on_predict_end = NULL,   on_predict_batch_begin = NULL,   on_predict_batch_end = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/new_callback_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Callback — new_callback_class","text":"classname String, name custom class. (Conventionally, CamelCase). on_epoch_begin   Called start epoch. Subclasses override actions run. function called TRAIN mode. Args: epoch: Integer, index epoch. logs: Named List. Currently data passed argument method may change future. on_epoch_end   Called end epoch. Subclasses override actions run. function called TRAIN mode. Args: epoch: Integer, index epoch. logs: Named List, metric results training epoch, validation epoch validation performed. Validation result keys prefixed val_. training epoch, values Model's metrics returned. Example: list(loss = 0.2, accuracy = 0.7). on_train_begin   Called beginning training. Subclasses override actions run. Args: logs: Named list. Currently data passed argument method may change future. on_train_end   Called end training. Subclasses override actions run. Args: logs: Named list. Currently output last call on_epoch_end() passed argument method may change future. on_train_batch_begin   Called beginning training batch fit() methods. Subclasses override actions run. Note steps_per_execution argument compile Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Currently data passed argument method may change future. on_train_batch_end   Called end training batch fit() methods. Subclasses override actions run. Note steps_per_execution argument compile Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Aggregated metric results batch. on_test_begin   Called beginning evaluation validation. Subclasses override actions run. Args: logs: Named list. Currently data passed argument method may change future. on_test_end   Called end evaluation validation. Subclasses override actions run. Args: logs: Named list. Currently output last call on_test_batch_end() passed argument method may change future. on_test_batch_begin   Called beginning batch evaluate() methods. Also called beginning validation batch fit() methods, validation data provided. Subclasses override actions run. Note steps_per_execution argument compile() Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Currently data passed argument method may change future. on_test_batch_end   Called end batch evaluate() methods. Also called end validation batch fit() methods, validation data provided. Subclasses override actions run. Note steps_per_execution argument compile() Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Aggregated metric results batch. on_predict_begin   Called beginning prediction. Subclasses override actions run. Args: logs: Named list. Currently data passed argument method may change future. on_predict_end   Called end prediction. Subclasses override actions run. Args: logs: Named list. Currently data passed argument method may change future. on_predict_batch_begin   Called beginning batch predict() methods. Subclasses override actions run. Note steps_per_execution argument compile() Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Currently data passed argument method may change future. on_predict_batch_end   Called end batch predict() methods. Subclasses override actions run. Note steps_per_execution argument compile Model set N, method called every N batches. Args: batch: Integer, index batch within current epoch. logs: Named list. Aggregated metric results batch. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":"\\(epoch, logs = NULL) \\(epoch, logs = NULL) \\(logs = NULL) \\(logs = NULL) \\(batch, logs = NULL) \\(batch, logs=NULL) \\(logs = NULL) \\(logs = NULL) \\(batch, logs = NULL) \\(batch, logs = NULL) \\(logs = NULL) \\(logs = NULL) \\(batch, logs = NULL) \\(batch, logs = NULL)"},{"path":"https://keras.posit.co/reference/new_callback_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Callback — new_callback_class","text":"function returns custom Callback instances, similar builtin callback functions.","code":""},{"path":"https://keras.posit.co/reference/new_layer_class.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer — new_layer_class","title":"Layer — new_layer_class","text":"new_layer_class() alias Layer(). See ?Layer() full documentation.","code":""},{"path":"https://keras.posit.co/reference/new_layer_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer — new_layer_class","text":"","code":"new_layer_class(   classname,   initialize = NULL,   call = NULL,   build = NULL,   get_config = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/new_layer_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer — new_layer_class","text":"classname String, name custom class. (Conventionally, CamelCase). initialize, call, build, get_config Recommended methods implement. See description details sections. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":""},{"path":"https://keras.posit.co/reference/new_layer_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer — new_layer_class","text":"composing layer constructor, similar behavior layer functions like layer_dense(). first argument returned function object, enabling initialize()ing call() layer one step composing layer pipe, like   initialize() layer instance call() , pass missing NULL value object, pass arguments initialize() name.","code":"layer_foo <- Layer(\"Foo\", ....) output <- inputs |> layer_foo() layer <- layer_dense(units = 2, activation = \"relu\") layer <- layer_dense(NULL, 2, activation = \"relu\") layer <- layer_dense(, 2, activation = \"relu\")  # then you can call() the layer in a separate step outputs <- inputs |> layer()"},{"path":"https://keras.posit.co/reference/new_learning_rate_schedule_class.html","id":null,"dir":"Reference","previous_headings":"","what":"LearningRateSchedule — new_learning_rate_schedule_class","title":"LearningRateSchedule — new_learning_rate_schedule_class","text":"new_learning_rate_schedule_class() alias LearningRateSchedule(). See ?LearningRateSchedule() full documentation.","code":""},{"path":"https://keras.posit.co/reference/new_learning_rate_schedule_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LearningRateSchedule — new_learning_rate_schedule_class","text":"","code":"new_learning_rate_schedule_class(   classname,   call = NULL,   initialize = NULL,   get_config = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/new_learning_rate_schedule_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LearningRateSchedule — new_learning_rate_schedule_class","text":"classname String, name custom class. (Conventionally, CamelCase). call, initialize, get_config Recommended methods implement. See description details sections. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":""},{"path":"https://keras.posit.co/reference/new_learning_rate_schedule_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LearningRateSchedule — new_learning_rate_schedule_class","text":"function returns LearningRateSchedule instances, similar built-learning_rate_schedule_* family functions.","code":""},{"path":"https://keras.posit.co/reference/new_loss_class.html","id":null,"dir":"Reference","previous_headings":"","what":"Loss — new_loss_class","title":"Loss — new_loss_class","text":"new_loss_class() alias Loss(). See ?Loss() full documentation.","code":""},{"path":"https://keras.posit.co/reference/new_loss_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loss — new_loss_class","text":"","code":"new_loss_class(   classname,   call = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/new_loss_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loss — new_loss_class","text":"classname String, name custom class. (Conventionally, CamelCase). call   Method implemented subclasses: Function contains logic loss calculation using y_true, y_pred. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":"function(y_true, y_pred)"},{"path":"https://keras.posit.co/reference/new_loss_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Loss — new_loss_class","text":"function returns Loss instances, similar builtin loss functions.","code":""},{"path":"https://keras.posit.co/reference/new_metric_class.html","id":null,"dir":"Reference","previous_headings":"","what":"Metric — new_metric_class","title":"Metric — new_metric_class","text":"new_metric_class() alias Metric(). See ?Metric() full documentation.","code":""},{"path":"https://keras.posit.co/reference/new_metric_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metric — new_metric_class","text":"","code":"new_metric_class(   classname,   initialize = NULL,   update_state = NULL,   result = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/new_metric_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Metric — new_metric_class","text":"classname String, name custom class. (Conventionally, CamelCase). initialize, update_state, result Recommended methods implement. See description section. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":""},{"path":"https://keras.posit.co/reference/new_metric_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Metric — new_metric_class","text":"function returns Metric instances, similar builtin metric functions.","code":""},{"path":"https://keras.posit.co/reference/new_model_class.html","id":null,"dir":"Reference","previous_headings":"","what":"Model — new_model_class","title":"Model — new_model_class","text":"new_model_class() alias Model(). See ?Model() full documentation.","code":""},{"path":"https://keras.posit.co/reference/new_model_class.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model — new_model_class","text":"","code":"new_model_class(   classname,   initialize = NULL,   call = NULL,   train_step = NULL,   predict_step = NULL,   test_step = NULL,   compute_loss = NULL,   compute_metrics = NULL,   ...,   public = list(),   private = list(),   inherit = NULL,   parent_env = parent.frame() )"},{"path":"https://keras.posit.co/reference/new_model_class.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model — new_model_class","text":"classname String, name custom class. (Conventionally, CamelCase). initialize, call, train_step, predict_step, test_step, compute_loss, compute_metrics Optional methods can overridden. ..., public Additional methods public members custom class. private Named list R objects (typically, functions) include instance private environments. private methods symbols scope public methods (See section \"Symbols Scope\"). instance private environment. objects private invisible Keras framework Python runtime. inherit custom class subclass. default, base keras class. parent_env R environment class methods grandparent.","code":""},{"path":"https://keras.posit.co/reference/new_model_class.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model — new_model_class","text":"model constructor function, can call create instance new model type.","code":""},{"path":"https://keras.posit.co/reference/normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalizes an array. — normalize","title":"Normalizes an array. — normalize","text":"input R array, R array returned. backend tensor, backend tensor returned.","code":""},{"path":"https://keras.posit.co/reference/normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalizes an array. — normalize","text":"","code":"normalize(x, axis = -1L, order = 2L)"},{"path":"https://keras.posit.co/reference/normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalizes an array. — normalize","text":"x Array normalize. axis axis along normalize. order Normalization order (e.g. order=2 L2 norm).","code":""},{"path":"https://keras.posit.co/reference/normalize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalizes an array. — normalize","text":"normalized copy array.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_abs.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the absolute value element-wise. — op_abs","title":"Compute the absolute value element-wise. — op_abs","text":"Compute absolute value element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_abs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the absolute value element-wise. — op_abs","text":"","code":"op_abs(x)"},{"path":"https://keras.posit.co/reference/op_abs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the absolute value element-wise. — op_abs","text":"x Input tensor","code":""},{"path":"https://keras.posit.co/reference/op_abs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the absolute value element-wise. — op_abs","text":"array containing absolute value element x.","code":""},{"path":"https://keras.posit.co/reference/op_abs.html","id":"example","dir":"Reference","previous_headings":"","what":"Example","title":"Compute the absolute value element-wise. — op_abs","text":"","code":"x <- op_convert_to_tensor(c(-1.2, 1.2)) op_abs(x) ## tf.Tensor([1.2 1.2], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_add.html","id":null,"dir":"Reference","previous_headings":"","what":"Add arguments element-wise. — op_add","title":"Add arguments element-wise. — op_add","text":"Add arguments element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_add.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add arguments element-wise. — op_add","text":"","code":"op_add(x1, x2)"},{"path":"https://keras.posit.co/reference/op_add.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add arguments element-wise. — op_add","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_add.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add arguments element-wise. — op_add","text":"tensor containing element-wise sum x1 x2.","code":""},{"path":"https://keras.posit.co/reference/op_add.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add arguments element-wise. — op_add","text":"op_add also broadcasts shapes:     Note function automatically called using R operator + tensors.","code":"x1 <- op_convert_to_tensor(c(1, 4)) x2 <- op_convert_to_tensor(c(5, 6)) op_add(x1, x2) ## tf.Tensor([ 6. 10.], shape=(2), dtype=float32) # alias for x1 + x2 x1 + x2 ## tf.Tensor([ 6. 10.], shape=(2), dtype=float32) x1 <- op_convert_to_tensor(array(c(5, 5, 4, 6), dim =c(2, 2))) x2 <- op_convert_to_tensor(c(5, 6)) op_add(x1, x2) ## tf.Tensor( ## [[10. 10.] ##  [10. 12.]], shape=(2, 2), dtype=float64) x <- op_ones(c(3)) op_add(x, x) ## tf.Tensor([2. 2. 2.], shape=(3), dtype=float32) x + x ## tf.Tensor([2. 2. 2.], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether all array elements along a given axis evaluate to TRUE. — op_all","title":"Test whether all array elements along a given axis evaluate to TRUE. — op_all","text":"Test whether array elements along given axis evaluate TRUE.","code":""},{"path":"https://keras.posit.co/reference/op_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether all array elements along a given axis evaluate to TRUE. — op_all","text":"","code":"op_all(x, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether all array elements along a given axis evaluate to TRUE. — op_all","text":"x Input tensor. axis integer tuple integers represent axis along logical reduction performed. default (axis = NULL) perform logical dimensions input array. axis may negative, case counts last first axis. keepdims TRUE, axes reduced left result dimensions size one. option, result broadcast correctly input array. Defaults toFALSE.","code":""},{"path":"https://keras.posit.co/reference/op_all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test whether all array elements along a given axis evaluate to TRUE. — op_all","text":"tensor containing logical reduction axis.","code":""},{"path":"https://keras.posit.co/reference/op_all.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether all array elements along a given axis evaluate to TRUE. — op_all","text":"keepdims = TRUE outputs tensor dimensions reduced one.","code":"x <- op_convert_to_tensor(c(TRUE, FALSE)) op_all(x) ## tf.Tensor(False, shape=(), dtype=bool) (x <- op_convert_to_tensor(array(c(TRUE, FALSE, TRUE, TRUE, TRUE, TRUE), dim = c(3, 2)))) ## tf.Tensor( ## [[ True  True] ##  [False  True] ##  [ True  True]], shape=(3, 2), dtype=bool) op_all(x, axis = 1) ## tf.Tensor([False  True], shape=(2), dtype=bool) op_all(x, keepdims = TRUE) ## tf.Tensor([[False]], shape=(1, 1), dtype=bool)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_any.html","id":null,"dir":"Reference","previous_headings":"","what":"Test whether any array element along a given axis evaluates to TRUE. — op_any","title":"Test whether any array element along a given axis evaluates to TRUE. — op_any","text":"Test whether array element along given axis evaluates TRUE.","code":""},{"path":"https://keras.posit.co/reference/op_any.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test whether any array element along a given axis evaluates to TRUE. — op_any","text":"","code":"op_any(x, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_any.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test whether any array element along a given axis evaluates to TRUE. — op_any","text":"x Input tensor. axis integer tuple integers represent axis along logical reduction performed. default (axis = NULL) perform logical dimensions input array. axis may negative, case counts last first axis. keepdims TRUE, axes reduced left result dimensions size one. option, result broadcast correctly input array. Defaults FALSE.","code":""},{"path":"https://keras.posit.co/reference/op_any.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test whether any array element along a given axis evaluates to TRUE. — op_any","text":"tensor containing logical reduction axis.","code":""},{"path":"https://keras.posit.co/reference/op_any.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test whether any array element along a given axis evaluates to TRUE. — op_any","text":"keepdims = TRUE outputs tensor dimensions reduced one.","code":"x <- op_array(c(TRUE, FALSE)) op_any(x) ## tf.Tensor(True, shape=(), dtype=bool) (x <- op_reshape(c(FALSE, FALSE, FALSE,                    TRUE, FALSE, FALSE),                  c(2, 3))) ## tf.Tensor( ## [[False False False] ##  [ True False False]], shape=(2, 3), dtype=bool) op_any(x, axis = 1) ## tf.Tensor([ True False False], shape=(3), dtype=bool) op_any(x, axis = 2) ## tf.Tensor([False  True], shape=(2), dtype=bool) op_any(x, axis = -1) ## tf.Tensor([False  True], shape=(2), dtype=bool) op_any(x, keepdims = TRUE) ## tf.Tensor([[ True]], shape=(1, 1), dtype=bool) op_any(x, 1, keepdims = TRUE) ## tf.Tensor([[ True False False]], shape=(1, 3), dtype=bool)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_append.html","id":null,"dir":"Reference","previous_headings":"","what":"Append tensor x2 to the end of tensor x1. — op_append","title":"Append tensor x2 to the end of tensor x1. — op_append","text":"Append tensor x2 end tensor x1.","code":""},{"path":"https://keras.posit.co/reference/op_append.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Append tensor x2 to the end of tensor x1. — op_append","text":"","code":"op_append(x1, x2, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_append.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Append tensor x2 to the end of tensor x1. — op_append","text":"x1 First input tensor. x2 Second input tensor. axis Axis along tensor x2 appended tensor x1. NULL, tensors flattened use.","code":""},{"path":"https://keras.posit.co/reference/op_append.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Append tensor x2 to the end of tensor x1. — op_append","text":"tensor values x2 appended x1.","code":""},{"path":"https://keras.posit.co/reference/op_append.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Append tensor x2 to the end of tensor x1. — op_append","text":"axis specified, x1 x2 must compatible shapes.","code":"x1 <- op_convert_to_tensor(c(1, 2, 3)) x2 <- op_convert_to_tensor(rbind(c(4, 5, 6), c(7, 8, 9))) op_append(x1, x2) ## tf.Tensor([1. 2. 3. 4. 5. 6. 7. 8. 9.], shape=(9), dtype=float64) x1 <- op_convert_to_tensor(rbind(c(1, 2, 3), c(4, 5, 6))) x2 <- op_convert_to_tensor(rbind(c(7, 8, 9))) op_append(x1, x2, axis = 1) ## tf.Tensor( ## [[1. 2. 3.] ##  [4. 5. 6.] ##  [7. 8. 9.]], shape=(3, 3), dtype=float64) x3 <- op_convert_to_tensor(c(7, 8, 9)) try(op_append(x1, x3, axis = 1)) ## Error in py_call_impl(callable, call_args$unnamed, call_args$named) : ##   tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [2,3] vs. shape[1] = [3] [Op:ConcatV2] name: concat"},{"path":[]},{"path":"https://keras.posit.co/reference/op_arange.html","id":null,"dir":"Reference","previous_headings":"","what":"Return evenly spaced values within a given interval. — op_arange","title":"Return evenly spaced values within a given interval. — op_arange","text":"arange can called varying number positional arguments: arange(stop): Values generated within half-open interval [0, stop) (words, interval including start excluding stop). arange(start, stop): Values generated within half-open interval [start, stop). arange(start, stop, step): Values generated within half-open interval [start, stop), spacing values given step.","code":""},{"path":"https://keras.posit.co/reference/op_arange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return evenly spaced values within a given interval. — op_arange","text":"","code":"op_arange(start, stop = NULL, step = 1L, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_arange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return evenly spaced values within a given interval. — op_arange","text":"start Integer real, representing start interval. interval includes value. stop Integer real, representing end interval. interval include value, except cases step integer floating point round-affects length . Defaults NULL. step Integer real, represent spacing values. output , distance two adjacent values, [+1] - []. default step size 1. step specified position argument, start must also given. dtype type output array. dtype given, infer data type input arguments.","code":""},{"path":"https://keras.posit.co/reference/op_arange.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return evenly spaced values within a given interval. — op_arange","text":"Tensor evenly spaced values. floating point arguments, length result ceiling((stop - start)/step). floating point overflow, rule may result last element greater stop.","code":""},{"path":"https://keras.posit.co/reference/op_arange.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return evenly spaced values within a given interval. — op_arange","text":"","code":"op_arange(3L) ## tf.Tensor([0 1 2], shape=(3), dtype=int32) op_arange(3) # float ## tf.Tensor([0. 1. 2.], shape=(3), dtype=float64) op_arange(3, dtype = 'int32') #int ## tf.Tensor([0 1 2], shape=(3), dtype=int32) op_arange(3L, 7L) ## tf.Tensor([3 4 5 6], shape=(4), dtype=int32) op_arange(3L, 7L, 2L) ## tf.Tensor([3 5], shape=(2), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_arccos.html","id":null,"dir":"Reference","previous_headings":"","what":"Trigonometric inverse cosine, element-wise. — op_arccos","title":"Trigonometric inverse cosine, element-wise. — op_arccos","text":"inverse cos , y = cos(x), x = arccos(y).","code":""},{"path":"https://keras.posit.co/reference/op_arccos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trigonometric inverse cosine, element-wise. — op_arccos","text":"","code":"op_arccos(x)"},{"path":"https://keras.posit.co/reference/op_arccos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trigonometric inverse cosine, element-wise. — op_arccos","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_arccos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trigonometric inverse cosine, element-wise. — op_arccos","text":"Tensor angle ray intersecting unit circle given x-coordinate radians [0, pi].","code":""},{"path":"https://keras.posit.co/reference/op_arccos.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trigonometric inverse cosine, element-wise. — op_arccos","text":"","code":"x <- op_convert_to_tensor(c(1, -1)) op_arccos(x) ## tf.Tensor([0.        3.1415927], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_arccosh.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse hyperbolic cosine, element-wise. — op_arccosh","title":"Inverse hyperbolic cosine, element-wise. — op_arccosh","text":"Inverse hyperbolic cosine, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_arccosh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse hyperbolic cosine, element-wise. — op_arccosh","text":"","code":"op_arccosh(x)"},{"path":"https://keras.posit.co/reference/op_arccosh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse hyperbolic cosine, element-wise. — op_arccosh","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_arccosh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse hyperbolic cosine, element-wise. — op_arccosh","text":"Output tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_arccosh.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse hyperbolic cosine, element-wise. — op_arccosh","text":"","code":"x <- op_convert_to_tensor(c(10, 100)) op_arccosh(x) ## tf.Tensor([2.993223 5.298292], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_arcsin.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse sine, element-wise. — op_arcsin","title":"Inverse sine, element-wise. — op_arcsin","text":"Inverse sine, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_arcsin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse sine, element-wise. — op_arcsin","text":"","code":"op_arcsin(x)"},{"path":"https://keras.posit.co/reference/op_arcsin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse sine, element-wise. — op_arcsin","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_arcsin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse sine, element-wise. — op_arcsin","text":"Tensor inverse sine element x, radians closed interval [-pi/2, pi/2].","code":""},{"path":"https://keras.posit.co/reference/op_arcsin.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse sine, element-wise. — op_arcsin","text":"","code":"x <- op_convert_to_tensor(c(1, -1, 0)) op_arcsin(x) ## tf.Tensor([ 1.5707964 -1.5707964  0.       ], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_arcsinh.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse hyperbolic sine, element-wise. — op_arcsinh","title":"Inverse hyperbolic sine, element-wise. — op_arcsinh","text":"Inverse hyperbolic sine, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_arcsinh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse hyperbolic sine, element-wise. — op_arcsinh","text":"","code":"op_arcsinh(x)"},{"path":"https://keras.posit.co/reference/op_arcsinh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse hyperbolic sine, element-wise. — op_arcsinh","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_arcsinh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse hyperbolic sine, element-wise. — op_arcsinh","text":"Output tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_arcsinh.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse hyperbolic sine, element-wise. — op_arcsinh","text":"","code":"x <- op_convert_to_tensor(c(1, -1, 0)) op_arcsinh(x) ## tf.Tensor([ 0.8813736 -0.8813736  0.       ], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_arctan.html","id":null,"dir":"Reference","previous_headings":"","what":"Trigonometric inverse tangent, element-wise. — op_arctan","title":"Trigonometric inverse tangent, element-wise. — op_arctan","text":"Trigonometric inverse tangent, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_arctan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trigonometric inverse tangent, element-wise. — op_arctan","text":"","code":"op_arctan(x)"},{"path":"https://keras.posit.co/reference/op_arctan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trigonometric inverse tangent, element-wise. — op_arctan","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_arctan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trigonometric inverse tangent, element-wise. — op_arctan","text":"Tensor inverse tangent element x, interval [-pi/2, pi/2].","code":""},{"path":"https://keras.posit.co/reference/op_arctan.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trigonometric inverse tangent, element-wise. — op_arctan","text":"","code":"x <- op_convert_to_tensor(c(0, 1)) op_arctan(x) ## tf.Tensor([0.        0.7853982], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_arctan2.html","id":null,"dir":"Reference","previous_headings":"","what":"Element-wise arc tangent of x1/x2 choosing the quadrant correctly. — op_arctan2","title":"Element-wise arc tangent of x1/x2 choosing the quadrant correctly. — op_arctan2","text":"quadrant (.e., branch) chosen arctan2(x1, x2) signed angle radians ray ending origin passing point (1, 0), ray ending origin passing point (x2, x1). (Note role reversal: \"y-coordinate\" first function parameter, \"x-coordinate\" second.) IEEE convention, function defined x2 = +/-0 either x1 x2 = +/-inf.","code":""},{"path":"https://keras.posit.co/reference/op_arctan2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Element-wise arc tangent of x1/x2 choosing the quadrant correctly. — op_arctan2","text":"","code":"op_arctan2(x1, x2)"},{"path":"https://keras.posit.co/reference/op_arctan2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Element-wise arc tangent of x1/x2 choosing the quadrant correctly. — op_arctan2","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_arctan2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Element-wise arc tangent of x1/x2 choosing the quadrant correctly. — op_arctan2","text":"Tensor angles radians, range [-pi, pi].","code":""},{"path":"https://keras.posit.co/reference/op_arctan2.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Element-wise arc tangent of x1/x2 choosing the quadrant correctly. — op_arctan2","text":"Consider four points different quadrants:     Note order parameters. arctan2 defined also x2 = 0 several points, obtaining values range [-pi, pi]:","code":"x <- op_array(c(-1, 1, 1, -1)) y <- op_array(c(-1, -1, 1, 1)) op_arctan2(y, x) * 180 / pi ## tf.Tensor([-135.  -45.   45.  135.], shape=(4), dtype=float32) op_arctan2(     op_array(c(1, -1)),     op_array(c(0, 0)) ) ## tf.Tensor([ 1.5707964 -1.5707964], shape=(2), dtype=float32) op_arctan2(     op_array(c(0, 0, Inf)),     op_array(c(+0, -0, Inf)) ) ## tf.Tensor([0.        3.1415927 0.7853982], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_arctanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse hyperbolic tangent, element-wise. — op_arctanh","title":"Inverse hyperbolic tangent, element-wise. — op_arctanh","text":"Inverse hyperbolic tangent, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_arctanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse hyperbolic tangent, element-wise. — op_arctanh","text":"","code":"op_arctanh(x)"},{"path":"https://keras.posit.co/reference/op_arctanh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse hyperbolic tangent, element-wise. — op_arctanh","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_arctanh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse hyperbolic tangent, element-wise. — op_arctanh","text":"Output tensor shape x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_argmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the indices of the maximum values along an axis. — op_argmax","title":"Returns the indices of the maximum values along an axis. — op_argmax","text":"Returns indices maximum values along axis.","code":""},{"path":"https://keras.posit.co/reference/op_argmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the indices of the maximum values along an axis. — op_argmax","text":"","code":"op_argmax(x, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_argmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the indices of the maximum values along an axis. — op_argmax","text":"x Input tensor. axis default, index flattened tensor, otherwise along specified axis.","code":""},{"path":"https://keras.posit.co/reference/op_argmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the indices of the maximum values along an axis. — op_argmax","text":"Tensor indices. shape x, dimension along axis removed. Note returned integer 0-based (.e., argmax first index position, returned value 0)","code":""},{"path":"https://keras.posit.co/reference/op_argmax.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Returns the indices of the maximum values along an axis. — op_argmax","text":"similar R max.col(x) - 1 case 2-d array (matrix), nd-array, apply(x, axis, .max) - 1","code":""},{"path":"https://keras.posit.co/reference/op_argmax.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the indices of the maximum values along an axis. — op_argmax","text":"","code":"x <- op_arange(6L) |> op_reshape(c(2, 3)) |> op_add(10) x ## tf.Tensor( ## [[10. 11. 12.] ##  [13. 14. 15.]], shape=(2, 3), dtype=float32) op_argmax(x) ## tf.Tensor(5, shape=(), dtype=int32) op_argmax(x, axis = 1) ## tf.Tensor([1 1 1], shape=(3), dtype=int32) op_argmax(x, axis = 2) ## tf.Tensor([2 2], shape=(2), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_argmin.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the indices of the minimum values along an axis. — op_argmin","title":"Returns the indices of the minimum values along an axis. — op_argmin","text":"Returns indices minimum values along axis.","code":""},{"path":"https://keras.posit.co/reference/op_argmin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the indices of the minimum values along an axis. — op_argmin","text":"","code":"op_argmin(x, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_argmin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the indices of the minimum values along an axis. — op_argmin","text":"x Input tensor. axis default, index flattened tensor, otherwise along specified axis.","code":""},{"path":"https://keras.posit.co/reference/op_argmin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the indices of the minimum values along an axis. — op_argmin","text":"Tensor indices. shape x, dimension along axis removed.","code":""},{"path":"https://keras.posit.co/reference/op_argmin.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Returns the indices of the minimum values along an axis. — op_argmin","text":"similar R expression apply(x, axis, .min) - 1, x R array.","code":""},{"path":"https://keras.posit.co/reference/op_argmin.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the indices of the minimum values along an axis. — op_argmin","text":"","code":"x <- op_arange(6L) |> op_reshape(c(2, 3)) |> op_add(10) x ## tf.Tensor( ## [[10. 11. 12.] ##  [13. 14. 15.]], shape=(2, 3), dtype=float32) op_argmin(x) ## tf.Tensor(0, shape=(), dtype=int32) op_argmin(x, axis = 1) ## tf.Tensor([0 0 0], shape=(3), dtype=int32) op_argmin(x, axis = 2) ## tf.Tensor([0 0], shape=(2), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_argsort.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the indices that would sort a tensor. — op_argsort","title":"Returns the indices that would sort a tensor. — op_argsort","text":"Returns indices sort tensor.","code":""},{"path":"https://keras.posit.co/reference/op_argsort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the indices that would sort a tensor. — op_argsort","text":"","code":"op_argsort(x, axis = -1L)"},{"path":"https://keras.posit.co/reference/op_argsort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the indices that would sort a tensor. — op_argsort","text":"x Input tensor. axis Axis along sort. Defaults -1 (last axis). NULL, flattened tensor used.","code":""},{"path":"https://keras.posit.co/reference/op_argsort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the indices that would sort a tensor. — op_argsort","text":"Tensor indices sort x along specified axis.","code":""},{"path":"https://keras.posit.co/reference/op_argsort.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the indices that would sort a tensor. — op_argsort","text":"One dimensional array:     Two-dimensional array:","code":"x <- op_array(c(3, 1, 2)) op_argsort(x) ## tf.Tensor([1 2 0], shape=(3), dtype=int32) x <- op_array(rbind(c(0, 3),                    c(3, 2),                    c(4, 5)), dtype = \"int32\") op_argsort(x, axis = 1) ## tf.Tensor( ## [[0 1] ##  [1 0] ##  [2 2]], shape=(3, 2), dtype=int32) op_argsort(x, axis = 2) ## tf.Tensor( ## [[0 1] ##  [1 0] ##  [0 1]], shape=(3, 2), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a tensor. — op_array","title":"Create a tensor. — op_array","text":"Create tensor.","code":""},{"path":"https://keras.posit.co/reference/op_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a tensor. — op_array","text":"","code":"op_array(x, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a tensor. — op_array","text":"x Input tensor. dtype desired data-type tensor.","code":""},{"path":"https://keras.posit.co/reference/op_array.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a tensor. — op_array","text":"tensor.","code":""},{"path":"https://keras.posit.co/reference/op_array.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a tensor. — op_array","text":"","code":"op_array(c(1, 2, 3)) ## tf.Tensor([1. 2. 3.], shape=(3), dtype=float32) op_array(c(1, 2, 3), dtype = \"float32\") ## tf.Tensor([1. 2. 3.], shape=(3), dtype=float32) op_array(c(1, 2, 3), dtype = \"int32\") ## tf.Tensor([1 2 3], shape=(3), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_average.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the weighted average along the specified axis. — op_average","title":"Compute the weighted average along the specified axis. — op_average","text":"Compute weighted average along specified axis.","code":""},{"path":"https://keras.posit.co/reference/op_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the weighted average along the specified axis. — op_average","text":"","code":"op_average(x, axis = NULL, weights = NULL)"},{"path":"https://keras.posit.co/reference/op_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the weighted average along the specified axis. — op_average","text":"x Input tensor. axis Integer along average x. default, axis = NULL, average elements input tensor. axis negative counts last first axis. weights Tensor wieghts associated values x. value x contributes average according associated weight. weights array can either 1-D (case length must size along given axis) shape x. weights = NULL (default), data x assumed weight equal one. 1-D calculation : avg = sum(* weights) / sum(weights). constraint weights sum(weights) must 0.","code":""},{"path":"https://keras.posit.co/reference/op_average.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the weighted average along the specified axis. — op_average","text":"Return average along specified axis.","code":""},{"path":"https://keras.posit.co/reference/op_average.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the weighted average along the specified axis. — op_average","text":"","code":"data <- op_arange(1, 5, dtype = \"int32\") data ## tf.Tensor([1 2 3 4], shape=(4), dtype=int32) op_average(data) ## tf.Tensor(2.5, shape=(), dtype=float32) op_average(   op_arange(1, 11),   weights = op_arange(10, 0, -1) ) ## tf.Tensor(4.0, shape=(), dtype=float64) data <- op_arange(6) |> op_reshape(c(3, 2)) data ## tf.Tensor( ## [[0. 1.] ##  [2. 3.] ##  [4. 5.]], shape=(3, 2), dtype=float64) op_average(   data,   axis = 2,   weights = op_array(c(1/4, 3/4)) ) ## tf.Tensor([0.75 2.75 4.75], shape=(3), dtype=float64) # Error: Axis must be specified when shapes of a and weights differ. try(op_average(   data,   weights = op_array(c(1/4, 3/4)) )) ## Error in py_call_impl(callable, call_args$unnamed, call_args$named) : ##   tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: 3, 2 ## 2"},{"path":[]},{"path":"https://keras.posit.co/reference/op_average_pool.html","id":null,"dir":"Reference","previous_headings":"","what":"Average pooling operation. — op_average_pool","title":"Average pooling operation. — op_average_pool","text":"Average pooling operation.","code":""},{"path":"https://keras.posit.co/reference/op_average_pool.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average pooling operation. — op_average_pool","text":"","code":"op_average_pool(   inputs,   pool_size,   strides = NULL,   padding = \"valid\",   data_format = NULL )"},{"path":"https://keras.posit.co/reference/op_average_pool.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average pooling operation. — op_average_pool","text":"inputs Tensor rank N+2. inputs shape (batch_size,) + inputs_spatial_shape + (num_channels,) data_format = \"channels_last\", (batch_size, num_channels) + inputs_spatial_shape data_format = \"channels_first\". Pooling happens spatial dimensions . pool_size int tuple/list integers size len(inputs_spatial_shape), specifying size pooling window spatial dimension input tensor. pool_size int, every spatial dimension shares pool_size. strides int tuple/list integers size len(inputs_spatial_shape). stride sliding window spatial dimension input tensor. strides int, every spatial dimension shares strides. padding string, either \"valid\" \"\". \"valid\" means padding applied, \"\" results padding evenly left/right /input output height/width dimension input strides = 1. data_format string, either \"channels_last\" \"channels_first\". data_format determines ordering dimensions inputs. data_format = \"channels_last\", inputs shape (batch_size, ..., channels) data_format = \"channels_first\", inputs shape (batch_size, channels, ...).","code":""},{"path":"https://keras.posit.co/reference/op_average_pool.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average pooling operation. — op_average_pool","text":"tensor rank N+2, result average pooling operation.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_batch_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalizes x by mean and variance. — op_batch_normalization","title":"Normalizes x by mean and variance. — op_batch_normalization","text":"op typically used batch normalization step neural network. normalizes input tensor along given axis.","code":""},{"path":"https://keras.posit.co/reference/op_batch_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalizes x by mean and variance. — op_batch_normalization","text":"","code":"op_batch_normalization(   x,   mean,   variance,   axis,   offset = NULL,   scale = NULL,   epsilon = 0.001 )"},{"path":"https://keras.posit.co/reference/op_batch_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalizes x by mean and variance. — op_batch_normalization","text":"x Input tensor. mean mean vector length axis dimension input thensor. variance variance vector length axis dimension input tensor. axis Integer, axis normalized. offset offset vector length axis dimension input tensor. NULL, offset added normalized tensor. Defaults NULL. scale scale vector length axis dimension input tensor. NULL, normalized tensor multiplied scale. Defaults NULL. epsilon Small float added variance avoid dividing zero. Defaults 1e-3.","code":""},{"path":"https://keras.posit.co/reference/op_batch_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalizes x by mean and variance. — op_batch_normalization","text":"normalized tensor.","code":""},{"path":"https://keras.posit.co/reference/op_batch_normalization.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalizes x by mean and variance. — op_batch_normalization","text":"","code":"x <- op_convert_to_tensor(rbind(c(0.1, 0.2, 0.3),                                 c(0.4, 0.5, 0.6),                                 c(0.7, 0.8, 0.9))) op_batch_normalization(   x,   mean = c(0.4, 0.5, 0.6),   variance = c(0.67, 0.67, 0.67),   axis = -1 ) ## tf.Tensor( ## [[-0.36623513 -0.36623513 -0.36623513] ##  [ 0.          0.          0.        ] ##  [ 0.36623513  0.36623513  0.36623513]], shape=(3, 3), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_binary_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes binary cross-entropy loss between target and output tensor. — op_binary_crossentropy","title":"Computes binary cross-entropy loss between target and output tensor. — op_binary_crossentropy","text":"binary cross-entropy loss commonly used binary classification tasks input sample belongs one two classes. measures dissimilarity target output probabilities logits.","code":""},{"path":"https://keras.posit.co/reference/op_binary_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes binary cross-entropy loss between target and output tensor. — op_binary_crossentropy","text":"","code":"op_binary_crossentropy(target, output, from_logits = FALSE)"},{"path":"https://keras.posit.co/reference/op_binary_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes binary cross-entropy loss between target and output tensor. — op_binary_crossentropy","text":"target target tensor representing true binary labels. shape match shape output tensor. output output tensor representing predicted probabilities logits. shape match shape target tensor. from_logits (optional) Whether output tensor logits probabilities. Set TRUE output represents logits; otherwise, set FALSE output represents probabilities. Defaults FALSE.","code":""},{"path":"https://keras.posit.co/reference/op_binary_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes binary cross-entropy loss between target and output tensor. — op_binary_crossentropy","text":"Integer tensor: computed binary cross-entropy loss target output.","code":""},{"path":"https://keras.posit.co/reference/op_binary_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes binary cross-entropy loss between target and output tensor. — op_binary_crossentropy","text":"","code":"target <- op_array(c(0, 1, 1, 0)) output <- op_array(c(0.1, 0.9, 0.8, 0.2)) op_binary_crossentropy(target, output) ## tf.Tensor([0.10536055 0.10536055 0.22314353 0.22314353], shape=(4), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_bincount.html","id":null,"dir":"Reference","previous_headings":"","what":"Count the number of occurrences of each value in a tensor of integers. — op_bincount","title":"Count the number of occurrences of each value in a tensor of integers. — op_bincount","text":"Count number occurrences value tensor integers.","code":""},{"path":"https://keras.posit.co/reference/op_bincount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count the number of occurrences of each value in a tensor of integers. — op_bincount","text":"","code":"op_bincount(x, weights = NULL, minlength = 0L)"},{"path":"https://keras.posit.co/reference/op_bincount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count the number of occurrences of each value in a tensor of integers. — op_bincount","text":"x Input tensor. must dimension 1, must contain non-negative integer(s). weights Weight tensor. must length x. default value NULL. specified, x weighted , .e. n = x[], [n] += weight[] instead default behavior [n] += 1. minlength integer. default value 0. specified, least number bins output tensor. greater max(x) + 1, value output index higher max(x) set 0.","code":""},{"path":"https://keras.posit.co/reference/op_bincount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count the number of occurrences of each value in a tensor of integers. — op_bincount","text":"1D tensor element gives number occurrence(s) index value x. length maximum max(x) + 1 minlength.","code":""},{"path":"https://keras.posit.co/reference/op_bincount.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count the number of occurrences of each value in a tensor of integers. — op_bincount","text":"","code":"(x <- op_array(c(1, 2, 2, 3), dtype = \"uint8\")) ## tf.Tensor([1 2 2 3], shape=(4), dtype=uint8) op_bincount(x) ## tf.Tensor([0 1 2 1], shape=(4), dtype=int32) (weights <- x / 2) ## tf.Tensor([0.5 1.  1.  1.5], shape=(4), dtype=float32) op_bincount(x, weights = weights) ## tf.Tensor([0.  0.5 2.  1.5], shape=(4), dtype=float32) minlength <- as.integer(op_max(x) + 1 + 2) # 6 op_bincount(x, minlength = minlength) ## tf.Tensor([0 1 2 1 0 0], shape=(6), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_broadcast_to.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast a tensor to a new shape. — op_broadcast_to","title":"Broadcast a tensor to a new shape. — op_broadcast_to","text":"Broadcast tensor new shape.","code":""},{"path":"https://keras.posit.co/reference/op_broadcast_to.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast a tensor to a new shape. — op_broadcast_to","text":"","code":"op_broadcast_to(x, shape)"},{"path":"https://keras.posit.co/reference/op_broadcast_to.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast a tensor to a new shape. — op_broadcast_to","text":"x tensor broadcast. shape shape desired tensor.","code":""},{"path":"https://keras.posit.co/reference/op_broadcast_to.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast a tensor to a new shape. — op_broadcast_to","text":"tensor desired shape.","code":""},{"path":"https://keras.posit.co/reference/op_broadcast_to.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Broadcast a tensor to a new shape. — op_broadcast_to","text":"","code":"x <- op_array(c(1, 2, 3)) op_broadcast_to(x, shape = c(3, 3)) ## tf.Tensor( ## [[1. 2. 3.] ##  [1. 2. 3.] ##  [1. 2. 3.]], shape=(3, 3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_cast.html","id":null,"dir":"Reference","previous_headings":"","what":"Cast a tensor to the desired dtype. — op_cast","title":"Cast a tensor to the desired dtype. — op_cast","text":"Cast tensor desired dtype.","code":""},{"path":"https://keras.posit.co/reference/op_cast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cast a tensor to the desired dtype. — op_cast","text":"","code":"op_cast(x, dtype)"},{"path":"https://keras.posit.co/reference/op_cast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cast a tensor to the desired dtype. — op_cast","text":"x tensor variable. dtype target type.","code":""},{"path":"https://keras.posit.co/reference/op_cast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cast a tensor to the desired dtype. — op_cast","text":"tensor specified dtype.","code":""},{"path":"https://keras.posit.co/reference/op_cast.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cast a tensor to the desired dtype. — op_cast","text":"","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_cast(x, dtype = \"float16\") ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float16)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_categorical_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes categorical cross-entropy loss between target and output tensor. — op_categorical_crossentropy","title":"Computes categorical cross-entropy loss between target and output tensor. — op_categorical_crossentropy","text":"categorical cross-entropy loss commonly used multi-class classification tasks input sample can belong one multiple classes. measures dissimilarity target output probabilities logits.","code":""},{"path":"https://keras.posit.co/reference/op_categorical_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes categorical cross-entropy loss between target and output tensor. — op_categorical_crossentropy","text":"","code":"op_categorical_crossentropy(target, output, from_logits = FALSE, axis = -1L)"},{"path":"https://keras.posit.co/reference/op_categorical_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes categorical cross-entropy loss between target and output tensor. — op_categorical_crossentropy","text":"target target tensor representing true categorical labels. shape match shape output tensor except last dimension. output output tensor representing predicted probabilities logits. shape match shape target tensor except last dimension. from_logits (optional) Whether output tensor logits probabilities. Set TRUE output represents logits; otherwise, set FALSE output represents probabilities. Defaults FALSE. axis (optional) axis along categorical cross-entropy computed. Defaults -1, corresponds last dimension tensors.","code":""},{"path":"https://keras.posit.co/reference/op_categorical_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes categorical cross-entropy loss between target and output tensor. — op_categorical_crossentropy","text":"Integer tensor: computed categorical cross-entropy loss target output.","code":""},{"path":"https://keras.posit.co/reference/op_categorical_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes categorical cross-entropy loss between target and output tensor. — op_categorical_crossentropy","text":"","code":"target <- op_array(rbind(c(1, 0, 0),                         c(0, 1, 0),                         c(0, 0, 1))) output <- op_array(rbind(c(0.9, 0.05, 0.05),                         c(0.1, 0.8, 0.1),                         c(0.2, 0.3, 0.5))) op_categorical_crossentropy(target, output) ## tf.Tensor([0.10536052 0.22314355 0.69314718], shape=(3), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_ceil.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the ceiling of the input, element-wise. — op_ceil","title":"Return the ceiling of the input, element-wise. — op_ceil","text":"ceil scalar x smallest integer , >= x.","code":""},{"path":"https://keras.posit.co/reference/op_ceil.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the ceiling of the input, element-wise. — op_ceil","text":"","code":"op_ceil(x)"},{"path":"https://keras.posit.co/reference/op_ceil.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the ceiling of the input, element-wise. — op_ceil","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_ceil.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the ceiling of the input, element-wise. — op_ceil","text":"ceiling element x, float dtype.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_cholesky.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Cholesky decomposition of a positive semi-definite matrix. — op_cholesky","title":"Computes the Cholesky decomposition of a positive semi-definite matrix. — op_cholesky","text":"Computes Cholesky decomposition positive semi-definite matrix.","code":""},{"path":"https://keras.posit.co/reference/op_cholesky.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Cholesky decomposition of a positive semi-definite matrix. — op_cholesky","text":"","code":"op_cholesky(x)"},{"path":"https://keras.posit.co/reference/op_cholesky.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Cholesky decomposition of a positive semi-definite matrix. — op_cholesky","text":"x Input tensor shape (..., M, M).","code":""},{"path":"https://keras.posit.co/reference/op_cholesky.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the Cholesky decomposition of a positive semi-definite matrix. — op_cholesky","text":"tensor shape (..., M, M) representing lower triangular Cholesky factor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_clip.html","id":null,"dir":"Reference","previous_headings":"","what":"Clip (limit) the values in a tensor. — op_clip","title":"Clip (limit) the values in a tensor. — op_clip","text":"Given interval, values outside interval clipped interval edges. example, interval [0, 1] specified, values smaller 0 become 0, values larger 1 become 1.","code":""},{"path":"https://keras.posit.co/reference/op_clip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clip (limit) the values in a tensor. — op_clip","text":"","code":"op_clip(x, x_min, x_max)"},{"path":"https://keras.posit.co/reference/op_clip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clip (limit) the values in a tensor. — op_clip","text":"x Input tensor. x_min Minimum value. x_max Maximum value.","code":""},{"path":"https://keras.posit.co/reference/op_clip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clip (limit) the values in a tensor. — op_clip","text":"clipped tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_concatenate.html","id":null,"dir":"Reference","previous_headings":"","what":"Join a sequence of tensors along an existing axis. — op_concatenate","title":"Join a sequence of tensors along an existing axis. — op_concatenate","text":"Join sequence tensors along existing axis.","code":""},{"path":"https://keras.posit.co/reference/op_concatenate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join a sequence of tensors along an existing axis. — op_concatenate","text":"","code":"op_concatenate(xs, axis = 1L)"},{"path":"https://keras.posit.co/reference/op_concatenate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join a sequence of tensors along an existing axis. — op_concatenate","text":"xs sequence tensors concatenate. axis axis along tensors joined. Defaults 0.","code":""},{"path":"https://keras.posit.co/reference/op_concatenate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Join a sequence of tensors along an existing axis. — op_concatenate","text":"concatenated tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_cond.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditionally applies true_fn or false_fn. — op_cond","title":"Conditionally applies true_fn or false_fn. — op_cond","text":"Conditionally applies true_fn false_fn.","code":""},{"path":"https://keras.posit.co/reference/op_cond.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditionally applies true_fn or false_fn. — op_cond","text":"","code":"op_cond(pred, true_fn, false_fn)"},{"path":"https://keras.posit.co/reference/op_cond.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditionally applies true_fn or false_fn. — op_cond","text":"pred Boolean scalar type true_fn Callable returning output pred == TRUE case. false_fn Callable returning output pred == FALSE case.","code":""},{"path":"https://keras.posit.co/reference/op_cond.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditionally applies true_fn or false_fn. — op_cond","text":"output either true_fn false_fn depending pred.","code":""},{"path":"https://keras.posit.co/reference/op_cond.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditionally applies true_fn or false_fn. — op_cond","text":"","code":"fn <- tensorflow::tf_function(function(x) {   op_cond(x > 0,     true_fn = \\() x + 1,     false_fn = \\() x - 1) })  fn(tensorflow::as_tensor(1)) ## tf.Tensor(2.0, shape=(), dtype=float64) fn(tensorflow::as_tensor(-1)) ## tf.Tensor(-2.0, shape=(), dtype=float64) # # Conditional side-effect (print only, no return value). file <- tempfile(fileext = \".txt\") fn <- tensorflow::tf_function(function(epochs) {   op_fori_loop(     0, epochs,     body_fun = \\(epoch, state) {       op_cond(epoch %% 20 == 0,               \\() {                 tensorflow::tf$print(                   \"epoch:\", epoch,                   output_stream = paste0(\"file://\", file))                 NULL               },               \\() {NULL})       state     },     init_val = tensorflow::as_tensor(0)) })  fn(tensorflow::as_tensor(100)) ## tf.Tensor(0.0, shape=(), dtype=float64) readLines(file) ## [1] \"epoch: 0\"  \"epoch: 20\" \"epoch: 40\" \"epoch: 60\" \"epoch: 80\" # cleanup unlink(file)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_conj.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the complex conjugate, element-wise. — op_conj","title":"Returns the complex conjugate, element-wise. — op_conj","text":"complex conjugate complex number obtained changing sign imaginary part.","code":""},{"path":"https://keras.posit.co/reference/op_conj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the complex conjugate, element-wise. — op_conj","text":"","code":"op_conj(x)"},{"path":"https://keras.posit.co/reference/op_conj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the complex conjugate, element-wise. — op_conj","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_conj.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the complex conjugate, element-wise. — op_conj","text":"complex conjugate element x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_conv.html","id":null,"dir":"Reference","previous_headings":"","what":"General N-D convolution. — op_conv","title":"General N-D convolution. — op_conv","text":"ops supports 1D, 2D 3D convolution.","code":""},{"path":"https://keras.posit.co/reference/op_conv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General N-D convolution. — op_conv","text":"","code":"op_conv(   inputs,   kernel,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L )"},{"path":"https://keras.posit.co/reference/op_conv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General N-D convolution. — op_conv","text":"inputs Tensor rank N+2. inputs shape (batch_size,) + inputs_spatial_shape + (num_channels,) data_format = \"channels_last\", (batch_size, num_channels) + inputs_spatial_shape data_format = \"channels_first\". kernel Tensor rank N+2. kernel shape (kernel_spatial_shape, num_input_channels, num_output_channels). num_input_channels match number channels inputs. strides int int tuple/list len(inputs_spatial_shape), specifying strides convolution along spatial dimension. strides int, every spatial dimension shares strides. padding string, either \"valid\" \"\". \"valid\" means padding applied, \"\" results padding evenly left/right /input output height/width dimension input strides = 1. data_format string, either \"channels_last\" \"channels_first\". data_format determines ordering dimensions inputs. data_format = \"channels_last\", inputs shape (batch_size, ..., channels) data_format = \"channels_first\", inputs shape (batch_size, channels, ...). dilation_rate int int tuple/list len(inputs_spatial_shape), specifying dilation rate use dilated convolution. dilation_rate int, every spatial dimension shares dilation_rate.","code":""},{"path":"https://keras.posit.co/reference/op_conv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General N-D convolution. — op_conv","text":"tensor rank N+2, result conv operation.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_conv_transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"General N-D convolution transpose. — op_conv_transpose","title":"General N-D convolution transpose. — op_conv_transpose","text":"Also known de-convolution. ops supports 1D, 2D 3D convolution.","code":""},{"path":"https://keras.posit.co/reference/op_conv_transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General N-D convolution transpose. — op_conv_transpose","text":"","code":"op_conv_transpose(   inputs,   kernel,   strides,   padding = \"valid\",   output_padding = NULL,   data_format = NULL,   dilation_rate = 1L )"},{"path":"https://keras.posit.co/reference/op_conv_transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General N-D convolution transpose. — op_conv_transpose","text":"inputs Tensor rank N+2. inputs shape (batch_size,) + inputs_spatial_shape + (num_channels,) data_format = \"channels_last\", (batch_size, num_channels) + inputs_spatial_shape data_format = \"channels_first\". kernel Tensor rank N+2. kernel shape [kernel_spatial_shape, num_output_channels, num_input_channels], num_input_channels match number channels inputs. strides int int tuple/list len(inputs_spatial_shape), specifying strides convolution along spatial dimension. strides int, every spatial dimension shares strides. padding string, either \"valid\" \"\". \"valid\" means padding applied, \"\" results padding evenly left/right /input output height/width dimension input strides = 1. output_padding int int tuple/list len(inputs_spatial_shape), specifying amount padding along height width output tensor. Can single integer specify value spatial dimensions. amount output padding along given dimension must lower stride along dimension. set NULL (default), output shape inferred. data_format string, either \"channels_last\" \"channels_first\". data_format determines ordering dimensions inputs. data_format = \"channels_last\", inputs shape (batch_size, ..., channels) data_format = \"channels_first\", inputs shape (batch_size, channels, ...). dilation_rate int int tuple/list len(inputs_spatial_shape), specifying dilation rate use dilated convolution. dilation_rate int, every spatial dimension shares dilation_rate.","code":""},{"path":"https://keras.posit.co/reference/op_conv_transpose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General N-D convolution transpose. — op_conv_transpose","text":"tensor rank N+2, result conv operation.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_convert_to_numpy.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a tensor to a NumPy array. — op_convert_to_numpy","title":"Convert a tensor to a NumPy array. — op_convert_to_numpy","text":"Convert tensor NumPy array.","code":""},{"path":"https://keras.posit.co/reference/op_convert_to_numpy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a tensor to a NumPy array. — op_convert_to_numpy","text":"","code":"op_convert_to_numpy(x)"},{"path":"https://keras.posit.co/reference/op_convert_to_numpy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a tensor to a NumPy array. — op_convert_to_numpy","text":"x tensor.","code":""},{"path":"https://keras.posit.co/reference/op_convert_to_numpy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a tensor to a NumPy array. — op_convert_to_numpy","text":"NumPy array.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_convert_to_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an array to a tensor. — op_convert_to_tensor","title":"Convert an array to a tensor. — op_convert_to_tensor","text":"Convert array tensor.","code":""},{"path":"https://keras.posit.co/reference/op_convert_to_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an array to a tensor. — op_convert_to_tensor","text":"","code":"op_convert_to_tensor(x, dtype = NULL, sparse = NULL)"},{"path":"https://keras.posit.co/reference/op_convert_to_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an array to a tensor. — op_convert_to_tensor","text":"x array. dtype target type. sparse Whether keep sparse tensors. FALSE cause sparse tensors densified. default value NULL means sparse tensors kept backend supports .","code":""},{"path":"https://keras.posit.co/reference/op_convert_to_tensor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an array to a tensor. — op_convert_to_tensor","text":"tensor specified dtype.","code":""},{"path":"https://keras.posit.co/reference/op_convert_to_tensor.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert an array to a tensor. — op_convert_to_tensor","text":"","code":"x <- array(c(1, 2, 3)) y <- op_convert_to_tensor(x) y ## tf.Tensor([1. 2. 3.], shape=(3), dtype=float64) op_convert_to_tensor(c(1, 3, 2, 0), \"int32\") ## tf.Tensor([1 3 2 0], shape=(4), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_copy.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a copy of x. — op_copy","title":"Returns a copy of x. — op_copy","text":"Returns copy x.","code":""},{"path":"https://keras.posit.co/reference/op_copy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a copy of x. — op_copy","text":"","code":"op_copy(x)"},{"path":"https://keras.posit.co/reference/op_copy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a copy of x. — op_copy","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_copy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns a copy of x. — op_copy","text":"copy x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_cos.html","id":null,"dir":"Reference","previous_headings":"","what":"Cosine, element-wise. — op_cos","title":"Cosine, element-wise. — op_cos","text":"Cosine, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_cos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cosine, element-wise. — op_cos","text":"","code":"op_cos(x)"},{"path":"https://keras.posit.co/reference/op_cos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cosine, element-wise. — op_cos","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_cos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cosine, element-wise. — op_cos","text":"corresponding cosine values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_cosh.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperbolic cosine, element-wise. — op_cosh","title":"Hyperbolic cosine, element-wise. — op_cosh","text":"Hyperbolic cosine, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_cosh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperbolic cosine, element-wise. — op_cosh","text":"","code":"op_cosh(x)"},{"path":"https://keras.posit.co/reference/op_cosh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperbolic cosine, element-wise. — op_cosh","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_cosh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperbolic cosine, element-wise. — op_cosh","text":"Output tensor shape x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_count_nonzero.html","id":null,"dir":"Reference","previous_headings":"","what":"Counts the number of non-zero values in x along the given axis. — op_count_nonzero","title":"Counts the number of non-zero values in x along the given axis. — op_count_nonzero","text":"axis specified non-zeros tensor counted.","code":""},{"path":"https://keras.posit.co/reference/op_count_nonzero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Counts the number of non-zero values in x along the given axis. — op_count_nonzero","text":"","code":"op_count_nonzero(x, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_count_nonzero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Counts the number of non-zero values in x along the given axis. — op_count_nonzero","text":"x Input tensor. axis Axis tuple axes along count number non-zeros. Defaults NULL.","code":""},{"path":"https://keras.posit.co/reference/op_count_nonzero.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Counts the number of non-zero values in x along the given axis. — op_count_nonzero","text":"integer tensor integers.","code":""},{"path":"https://keras.posit.co/reference/op_count_nonzero.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Counts the number of non-zero values in x along the given axis. — op_count_nonzero","text":"","code":"x <- op_array(rbind(c(0, 1, 7, 0),                    c(3, 0, 2, 19))) op_count_nonzero(x) ## tf.Tensor(5, shape=(), dtype=int32) op_count_nonzero(x, axis = 1) ## tf.Tensor([1 1 2 1], shape=(4), dtype=int32) op_count_nonzero(x, axis = 2) ## tf.Tensor([2 3], shape=(2), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_cross.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the cross product of two (arrays of) vectors. — op_cross","title":"Returns the cross product of two (arrays of) vectors. — op_cross","text":"cross product x1 x2 R^3 vector perpendicular x1 x2. x1 x2 arrays vectors, vectors defined last axis x1 x2 default, axes can dimensions 2 3. dimension either x1 x2 2, third component input vector assumed zero cross product calculated accordingly. cases input vectors dimension 2, z-component cross product returned.","code":""},{"path":"https://keras.posit.co/reference/op_cross.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the cross product of two (arrays of) vectors. — op_cross","text":"","code":"op_cross(x1, x2, axisa = -1L, axisb = -1L, axisc = -1L, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_cross.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the cross product of two (arrays of) vectors. — op_cross","text":"x1 Components first vector(s). x2 Components second vector(s). axisa Axis x1 defines vector(s). Defaults -1. axisb Axis x2 defines vector(s). Defaults -1. axisc Axis result containing cross product vector(s). Ignored input vectors dimension 2, return scalar. default, last axis. axis defined, axis x1, x2 result defines vector(s) cross product(s). Overrides axisa, axisb axisc.","code":""},{"path":"https://keras.posit.co/reference/op_cross.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the cross product of two (arrays of) vectors. — op_cross","text":"Vector cross product(s).","code":""},{"path":"https://keras.posit.co/reference/op_cross.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Returns the cross product of two (arrays of) vectors. — op_cross","text":"Torch backend support two dimensional vectors, arguments axisa, axisb axisc. Use axis instead.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_ctc_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"CTC (Connectionist Temporal Classification) loss. — op_ctc_loss","title":"CTC (Connectionist Temporal Classification) loss. — op_ctc_loss","text":"CTC (Connectionist Temporal Classification) loss.","code":""},{"path":"https://keras.posit.co/reference/op_ctc_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CTC (Connectionist Temporal Classification) loss. — op_ctc_loss","text":"","code":"op_ctc_loss(target, output, target_length, output_length, mask_index = 0L)"},{"path":"https://keras.posit.co/reference/op_ctc_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CTC (Connectionist Temporal Classification) loss. — op_ctc_loss","text":"target tensor shape (batch_size, max_length) containing true labels integer format. output tensor shape (batch_size, max_length, num_classes) containing logits (output model). target_length tensor shape (batch_size) containing true label lengths. output_length tensor shape (batch_size) containing output lengths. mask_index index mask character vocabulary. Defaults 0.","code":""},{"path":"https://keras.posit.co/reference/op_ctc_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CTC (Connectionist Temporal Classification) loss. — op_ctc_loss","text":"tensor, shape (batch_size), loss values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_cumprod.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the cumulative product of elements along a given axis. — op_cumprod","title":"Return the cumulative product of elements along a given axis. — op_cumprod","text":"Return cumulative product elements along given axis.","code":""},{"path":"https://keras.posit.co/reference/op_cumprod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the cumulative product of elements along a given axis. — op_cumprod","text":"","code":"op_cumprod(x, axis = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_cumprod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the cumulative product of elements along a given axis. — op_cumprod","text":"x Input tensor. axis Axis along cumulative product computed. default input flattened. dtype dtype returned tensor. Defaults x$dtype.","code":""},{"path":"https://keras.posit.co/reference/op_cumprod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the cumulative product of elements along a given axis. — op_cumprod","text":"Output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_cumsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the cumulative sum of elements along a given axis. — op_cumsum","title":"Returns the cumulative sum of elements along a given axis. — op_cumsum","text":"Returns cumulative sum elements along given axis.","code":""},{"path":"https://keras.posit.co/reference/op_cumsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the cumulative sum of elements along a given axis. — op_cumsum","text":"","code":"op_cumsum(x, axis = NULL, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_cumsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the cumulative sum of elements along a given axis. — op_cumsum","text":"x Input tensor. axis Axis along cumulative sum computed. default input flattened. dtype dtype returned tensor. Defaults x$dtype.","code":""},{"path":"https://keras.posit.co/reference/op_cumsum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the cumulative sum of elements along a given axis. — op_cumsum","text":"Output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_custom_gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Decorator to define a function with a custom gradient. — op_custom_gradient","title":"Decorator to define a function with a custom gradient. — op_custom_gradient","text":"decorator allows fine grained control gradients sequence operations. may useful multiple reasons, including providing efficient numerically stable gradient sequence operations. Note custom_gradient supports TensorFlow JAX backends.","code":""},{"path":"https://keras.posit.co/reference/op_custom_gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decorator to define a function with a custom gradient. — op_custom_gradient","text":"","code":"op_custom_gradient(f)"},{"path":"https://keras.posit.co/reference/op_custom_gradient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decorator to define a function with a custom gradient. — op_custom_gradient","text":"f Function f(...) returns tuple (y, grad_fn) : x sequence (nested structures ) tensor inputs function. y (nested structure ) tensor outputs applying operations f x. grad_fn function signature g(...) returns list tensors size (flattened) x: derivatives tensors y respect tensors x. Arguments provided ... sequence tensors size (flattened) y holding initial value gradients tensor y.","code":""},{"path":"https://keras.posit.co/reference/op_custom_gradient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decorator to define a function with a custom gradient. — op_custom_gradient","text":"function h(x) returns value f(x)[0] whose gradient determined f(x)[1].","code":""},{"path":"https://keras.posit.co/reference/op_custom_gradient.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decorator to define a function with a custom gradient. — op_custom_gradient","text":"","code":"log1pexp <- op_custom_gradient(\\(x) {      e <- op_exp(x)      grad <- function(upstream) {       op_multiply(upstream, 1.0 - 1.0 / op_add(1, e))     }      tuple(op_log(1 + e), grad) })"},{"path":[]},{"path":"https://keras.posit.co/reference/op_depthwise_conv.html","id":null,"dir":"Reference","previous_headings":"","what":"General N-D depthwise convolution. — op_depthwise_conv","title":"General N-D depthwise convolution. — op_depthwise_conv","text":"ops supports 1D 2D depthwise convolution.","code":""},{"path":"https://keras.posit.co/reference/op_depthwise_conv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General N-D depthwise convolution. — op_depthwise_conv","text":"","code":"op_depthwise_conv(   inputs,   kernel,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L )"},{"path":"https://keras.posit.co/reference/op_depthwise_conv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General N-D depthwise convolution. — op_depthwise_conv","text":"inputs Tensor rank N+2. inputs shape (batch_size,) + inputs_spatial_shape + (num_channels,) data_format = \"channels_last\", (batch_size, num_channels) + inputs_spatial_shape data_format = \"channels_first\". kernel Tensor rank N+2. kernel shape [kernel_spatial_shape, num_input_channels, num_channels_multiplier], num_input_channels match number channels inputs. strides int int tuple/list len(inputs_spatial_shape), specifying strides convolution along spatial dimension. strides int, every spatial dimension shares strides. padding string, either \"valid\" \"\". \"valid\" means padding applied, \"\" results padding evenly left/right /input output height/width dimension input strides = 1. data_format string, either \"channels_last\" \"channels_first\". data_format determines ordering dimensions inputs. data_format = \"channels_last\", inputs shape (batch_size, ..., channels) data_format = \"channels_first\", inputs shape (batch_size, channels, ...). dilation_rate int int tuple/list len(inputs_spatial_shape), specifying dilation rate use dilated convolution. dilation_rate int, every spatial dimension shares dilation_rate.","code":""},{"path":"https://keras.posit.co/reference/op_depthwise_conv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General N-D depthwise convolution. — op_depthwise_conv","text":"tensor rank N+2, result depthwise conv operation.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_det.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the determinant of a square tensor. — op_det","title":"Computes the determinant of a square tensor. — op_det","text":"Computes determinant square tensor.","code":""},{"path":"https://keras.posit.co/reference/op_det.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the determinant of a square tensor. — op_det","text":"","code":"op_det(x)"},{"path":"https://keras.posit.co/reference/op_det.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the determinant of a square tensor. — op_det","text":"x Input tensor shape (..., M, M).","code":""},{"path":"https://keras.posit.co/reference/op_det.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the determinant of a square tensor. — op_det","text":"tensor shape (...) represeting determinant x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_diag.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract a diagonal or construct a diagonal array. — op_diag","title":"Extract a diagonal or construct a diagonal array. — op_diag","text":"Extract diagonal construct diagonal array.","code":""},{"path":"https://keras.posit.co/reference/op_diag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract a diagonal or construct a diagonal array. — op_diag","text":"","code":"op_diag(x, k = 0L)"},{"path":"https://keras.posit.co/reference/op_diag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract a diagonal or construct a diagonal array. — op_diag","text":"x Input tensor. x 2-D, returns k-th diagonal x. x 1-D, return 2-D tensor x k-th diagonal. k diagonal consider. Defaults 0. Use k > 0 diagonals main diagonal, k < 0 diagonals main diagonal.","code":""},{"path":"https://keras.posit.co/reference/op_diag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract a diagonal or construct a diagonal array. — op_diag","text":"extracted diagonal constructed diagonal tensor.","code":""},{"path":"https://keras.posit.co/reference/op_diag.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract a diagonal or construct a diagonal array. — op_diag","text":"","code":"x <- op_arange(9L) |> op_reshape(c(3, 3)) x ## tf.Tensor( ## [[0 1 2] ##  [3 4 5] ##  [6 7 8]], shape=(3, 3), dtype=int32) op_diag(x) ## tf.Tensor([0 4 8], shape=(3), dtype=int32) op_diag(x, k = 1) ## tf.Tensor([1 5], shape=(2), dtype=int32) op_diag(x, k = -1) ## tf.Tensor([3 7], shape=(2), dtype=int32) op_diag(op_diag(x)) ## tf.Tensor( ## [[0 0 0] ##  [0 4 0] ##  [0 0 8]], shape=(3, 3), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_diagonal.html","id":null,"dir":"Reference","previous_headings":"","what":"Return specified diagonals. — op_diagonal","title":"Return specified diagonals. — op_diagonal","text":"x 2-D, returns diagonal x given offset, .e., collection elements form x[, +offset]. x two dimensions, axes specified axis1 axis2 used determine 2-D sub-array whose diagonal returned. shape resulting array can determined removing axis1 axis2 appending index right equal size resulting diagonals.","code":""},{"path":"https://keras.posit.co/reference/op_diagonal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return specified diagonals. — op_diagonal","text":"","code":"op_diagonal(x, offset = 0L, axis1 = 1L, axis2 = 2L)"},{"path":"https://keras.posit.co/reference/op_diagonal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return specified diagonals. — op_diagonal","text":"x Input tensor. offset Offset diagonal main diagonal. Can positive negative. Defaults 0 (main diagonal). axis1 Axis used first axis 2-D sub-arrays. Defaults 1 (first axis). axis2 Axis used second axis 2-D sub-arrays. Defaults 2 (second axis).","code":""},{"path":"https://keras.posit.co/reference/op_diagonal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return specified diagonals. — op_diagonal","text":"Tensor diagonals.","code":""},{"path":"https://keras.posit.co/reference/op_diagonal.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return specified diagonals. — op_diagonal","text":"","code":"x <- op_arange(4L) |> op_reshape(c(2, 2)) x ## tf.Tensor( ## [[0 1] ##  [2 3]], shape=(2, 2), dtype=int32) op_diagonal(x) ## tf.Tensor([0 3], shape=(2), dtype=int32) op_diagonal(x, offset = 1) ## tf.Tensor([1], shape=(1), dtype=int32) x <- op_array(1:8) |> op_reshape(c(2, 2, 2)) x ## tf.Tensor( ## [[[1 2] ##   [3 4]] ## ##  [[5 6] ##   [7 8]]], shape=(2, 2, 2), dtype=int32) x |> op_diagonal(0) ## tf.Tensor( ## [[1 7] ##  [2 8]], shape=(2, 2), dtype=int32) x |> op_diagonal(0, 1, 2) # same as above, the default ## tf.Tensor( ## [[1 7] ##  [2 8]], shape=(2, 2), dtype=int32) x |> op_diagonal(0, 2, 3) ## tf.Tensor( ## [[1 4] ##  [5 8]], shape=(2, 2), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the n-th discrete difference along the given axis. — op_diff","title":"Calculate the n-th discrete difference along the given axis. — op_diff","text":"first difference given [] = [+1] - [] along given axis, higher differences calculated using diff recursively.","code":""},{"path":"https://keras.posit.co/reference/op_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the n-th discrete difference along the given axis. — op_diff","text":"","code":"op_diff(a, n = 1L, axis = -1L)"},{"path":"https://keras.posit.co/reference/op_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the n-th discrete difference along the given axis. — op_diff","text":"Input tensor. n number times values differenced. Defaults 1. axis Axis compute discrete difference(s) along. Defaults -1 (last axis).","code":""},{"path":"https://keras.posit.co/reference/op_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the n-th discrete difference along the given axis. — op_diff","text":"Tensor diagonals.","code":""},{"path":"https://keras.posit.co/reference/op_diff.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the n-th discrete difference along the given axis. — op_diff","text":"","code":"x <- op_array(c(1, 2, 4, 7, 0)) op_diff(x) ## tf.Tensor([ 1.  2.  3. -7.], shape=(4), dtype=float32) op_diff(x, n = 2) ## tf.Tensor([  1.   1. -10.], shape=(3), dtype=float32) x <- op_array(rbind(c(1, 3, 6, 10),                   c(0, 5, 6, 8))) op_diff(x) ## tf.Tensor( ## [[2. 3. 4.] ##  [5. 1. 2.]], shape=(2, 3), dtype=float64) op_diff(x, axis = 1) ## tf.Tensor([[-1.  2.  0. -2.]], shape=(1, 4), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_digitize.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the indices of the bins to which each value in x belongs. — op_digitize","title":"Returns the indices of the bins to which each value in x belongs. — op_digitize","text":"Returns indices bins value x belongs.","code":""},{"path":"https://keras.posit.co/reference/op_digitize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the indices of the bins to which each value in x belongs. — op_digitize","text":"","code":"op_digitize(x, bins)"},{"path":"https://keras.posit.co/reference/op_digitize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the indices of the bins to which each value in x belongs. — op_digitize","text":"x Input array binned. bins Array bins. one-dimensional monotonically increasing.","code":""},{"path":"https://keras.posit.co/reference/op_digitize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the indices of the bins to which each value in x belongs. — op_digitize","text":"Output array indices, shape x.","code":""},{"path":"https://keras.posit.co/reference/op_digitize.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the indices of the bins to which each value in x belongs. — op_digitize","text":"","code":"x <- op_array(c(0.0, 1.0, 3.0, 1.6)) bins <- array(c(0.0, 3.0, 4.5, 7.0)) op_digitize(x, bins) ## tf.Tensor([1 1 2 1], shape=(4), dtype=int32) # array([1, 1, 2, 1])"},{"path":[]},{"path":"https://keras.posit.co/reference/op_divide.html","id":null,"dir":"Reference","previous_headings":"","what":"Divide arguments element-wise. — op_divide","title":"Divide arguments element-wise. — op_divide","text":"Note function automatically called using R operator * tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_divide(x, 2) ## tf.Tensor([0.  0.5 1.  1.5], shape=(4), dtype=float64) x / 2 ## tf.Tensor([0.  0.5 1.  1.5], shape=(4), dtype=float64)"},{"path":"https://keras.posit.co/reference/op_divide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Divide arguments element-wise. — op_divide","text":"","code":"op_divide(x1, x2)"},{"path":"https://keras.posit.co/reference/op_divide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Divide arguments element-wise. — op_divide","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_divide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Divide arguments element-wise. — op_divide","text":"Output tensor, quotient x1/x2, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_divide.html","id":"example","dir":"Reference","previous_headings":"","what":"Example","title":"Divide arguments element-wise. — op_divide","text":"","code":"op_divide(3, 2) ## tf.Tensor(1.5, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_divide_no_nan.html","id":null,"dir":"Reference","previous_headings":"","what":"Safe element-wise division which returns 0 where the denominator is 0. — op_divide_no_nan","title":"Safe element-wise division which returns 0 where the denominator is 0. — op_divide_no_nan","text":"Safe element-wise division returns 0 denominator 0.","code":""},{"path":"https://keras.posit.co/reference/op_divide_no_nan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Safe element-wise division which returns 0 where the denominator is 0. — op_divide_no_nan","text":"","code":"op_divide_no_nan(x1, x2)"},{"path":"https://keras.posit.co/reference/op_divide_no_nan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Safe element-wise division which returns 0 where the denominator is 0. — op_divide_no_nan","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_divide_no_nan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Safe element-wise division which returns 0 where the denominator is 0. — op_divide_no_nan","text":"quotient x1/x2, element-wise, zero x2 zero.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_dot.html","id":null,"dir":"Reference","previous_headings":"","what":"Dot product of two tensors. — op_dot","title":"Dot product of two tensors. — op_dot","text":"x1 x2 1-D tensors, inner product vectors (without complex conjugation). x1 x2 2-D tensors, matrix multiplication. either x1 x2 0-D (scalar), equivalent x1 * x2. x1 N-D tensor x2 1-D tensor, sum product last axis x1 x2. x1 N-D tensor x2 M-D tensor (M >= 2), sum product last axis x1 second--last axis x2: dot(x1, x2)[,j,k,m] = sum([,j,:] * b[k,:,m]).","code":""},{"path":"https://keras.posit.co/reference/op_dot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dot product of two tensors. — op_dot","text":"","code":"op_dot(x1, x2)"},{"path":"https://keras.posit.co/reference/op_dot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dot product of two tensors. — op_dot","text":"x1 First argument. x2 Second argument.","code":""},{"path":"https://keras.posit.co/reference/op_dot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dot product of two tensors. — op_dot","text":"Dot product x1 x2.","code":""},{"path":"https://keras.posit.co/reference/op_dot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Dot product of two tensors. — op_dot","text":"Torch backend accept 0-D tensors arguments.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_eig.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the eigenvalues and eigenvectors of a square matrix. — op_eig","title":"Computes the eigenvalues and eigenvectors of a square matrix. — op_eig","text":"Computes eigenvalues eigenvectors square matrix.","code":""},{"path":"https://keras.posit.co/reference/op_eig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the eigenvalues and eigenvectors of a square matrix. — op_eig","text":"","code":"op_eig(x)"},{"path":"https://keras.posit.co/reference/op_eig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the eigenvalues and eigenvectors of a square matrix. — op_eig","text":"x Input tensor shape (..., M, M).","code":""},{"path":"https://keras.posit.co/reference/op_eig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the eigenvalues and eigenvectors of a square matrix. — op_eig","text":"list two tensors: tensor shape (..., M) containing eigenvalues tensor shape (..., M, M) containing eigenvectors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_einsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluates the Einstein summation convention on the operands. — op_einsum","title":"Evaluates the Einstein summation convention on the operands. — op_einsum","text":"Evaluates Einstein summation convention operands.","code":""},{"path":"https://keras.posit.co/reference/op_einsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluates the Einstein summation convention on the operands. — op_einsum","text":"","code":"op_einsum(subscripts, ...)"},{"path":"https://keras.posit.co/reference/op_einsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates the Einstein summation convention on the operands. — op_einsum","text":"subscripts Specifies subscripts summation comma separated list subscript labels. implicit (classical Einstein summation) calculation performed unless explicit indicator -> included well subscript labels precise output form. ... operands compute Einstein sum .","code":""},{"path":"https://keras.posit.co/reference/op_einsum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluates the Einstein summation convention on the operands. — op_einsum","text":"calculation based Einstein summation convention.","code":""},{"path":"https://keras.posit.co/reference/op_einsum.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluates the Einstein summation convention on the operands. — op_einsum","text":"Trace matrix:     Extract diagonal:     Sum axis:     higher dimensional tensors summing single axis can done ellipsis:     Compute matrix transpose reorder number axes:         Matrix vector multiplication:","code":"a <- op_arange(25) |> op_reshape(c(5, 5)) b <- op_arange(5) c <- op_arange(6) |> op_reshape(c(2, 3)) op_einsum(\"ii\", a) op_trace(a) ## tf.Tensor(60.0, shape=(), dtype=float64) ## tf.Tensor(60.0, shape=(), dtype=float64) op_einsum(\"ii -> i\", a) op_diag(a) ## tf.Tensor([ 0.  6. 12. 18. 24.], shape=(5), dtype=float64) ## tf.Tensor([ 0.  6. 12. 18. 24.], shape=(5), dtype=float64) op_einsum(\"ij -> i\", a) op_sum(a, axis = 2) ## tf.Tensor([ 10.  35.  60.  85. 110.], shape=(5), dtype=float64) ## tf.Tensor([ 10.  35.  60.  85. 110.], shape=(5), dtype=float64) op_einsum(\"...j -> ...\", a) op_sum(a, axis = -1) ## tf.Tensor([ 10.  35.  60.  85. 110.], shape=(5), dtype=float64) ## tf.Tensor([ 10.  35.  60.  85. 110.], shape=(5), dtype=float64) op_einsum(\"ji\", c) # return c unchanged ## tf.Tensor( ## [[0. 1. 2.] ##  [3. 4. 5.]], shape=(2, 3), dtype=float64) op_einsum(\"ij -> ji\", c) # transpose op_transpose(c)          # same as above ## tf.Tensor( ## [[0. 3.] ##  [1. 4.] ##  [2. 5.]], shape=(3, 2), dtype=float64) ## tf.Tensor( ## [[0. 3.] ##  [1. 4.] ##  [2. 5.]], shape=(3, 2), dtype=float64) op_einsum(\"ij, j\", a, b) op_einsum(\"...j, j\", a, b) a %*% b op_matmul(a, b) ## tf.Tensor([ 30.  80. 130. 180. 230.], shape=(5), dtype=float64) ## tf.Tensor([ 30.  80. 130. 180. 230.], shape=(5), dtype=float64) ## tf.Tensor([ 30.  80. 130. 180. 230.], shape=(5), dtype=float64) ## tf.Tensor([ 30.  80. 130. 180. 230.], shape=(5), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_elu.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential Linear Unit activation function. — op_elu","title":"Exponential Linear Unit activation function. — op_elu","text":"defined : f(x) =  alpha * (exp(x) - 1.) x < 0, f(x) = x x >= 0.","code":""},{"path":"https://keras.posit.co/reference/op_elu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential Linear Unit activation function. — op_elu","text":"","code":"op_elu(x, alpha = 1)"},{"path":"https://keras.posit.co/reference/op_elu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential Linear Unit activation function. — op_elu","text":"x Input tensor. alpha scalar, slope positive section. Defaults 1.0.","code":""},{"path":"https://keras.posit.co/reference/op_elu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exponential Linear Unit activation function. — op_elu","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_elu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exponential Linear Unit activation function. — op_elu","text":"","code":"x <- op_array(c(-1., 0., 1.)) op_elu(x) ## tf.Tensor([-0.63212055  0.          1.        ], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_empty.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a tensor of given shape and type filled with uninitialized data. — op_empty","title":"Return a tensor of given shape and type filled with uninitialized data. — op_empty","text":"Return tensor given shape type filled uninitialized data.","code":""},{"path":"https://keras.posit.co/reference/op_empty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a tensor of given shape and type filled with uninitialized data. — op_empty","text":"","code":"op_empty(shape, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_empty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a tensor of given shape and type filled with uninitialized data. — op_empty","text":"shape Shape empty tensor. dtype Desired data type empty tensor.","code":""},{"path":"https://keras.posit.co/reference/op_empty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a tensor of given shape and type filled with uninitialized data. — op_empty","text":"empty tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns (x1 == x2) element-wise. — op_equal","title":"Returns (x1 == x2) element-wise. — op_equal","text":"Note function automatically called using R operator == tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_equal(x, 2) ## tf.Tensor([False False  True False], shape=(4), dtype=bool) x == 2 ## tf.Tensor([False False  True False], shape=(4), dtype=bool)"},{"path":"https://keras.posit.co/reference/op_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns (x1 == x2) element-wise. — op_equal","text":"","code":"op_equal(x1, x2)"},{"path":"https://keras.posit.co/reference/op_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns (x1 == x2) element-wise. — op_equal","text":"x1 Tensor compare. x2 Tensor compare.","code":""},{"path":"https://keras.posit.co/reference/op_equal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns (x1 == x2) element-wise. — op_equal","text":"Output tensor, element-wise comparison x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_erf.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the error function of x, element-wise. — op_erf","title":"Computes the error function of x, element-wise. — op_erf","text":"Computes error function x, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_erf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the error function of x, element-wise. — op_erf","text":"","code":"op_erf(x)"},{"path":"https://keras.posit.co/reference/op_erf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the error function of x, element-wise. — op_erf","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_erf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the error function of x, element-wise. — op_erf","text":"tensor dtype x.","code":""},{"path":"https://keras.posit.co/reference/op_erf.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the error function of x, element-wise. — op_erf","text":"","code":"x <- op_array(c(-3, -2, -1, 0, 1)) op_erf(x) ## tf.Tensor([-0.99997777 -0.9953222  -0.84270084  0.          0.84270084], shape=(5), dtype=float32) # array([-0.99998 , -0.99532, -0.842701,  0.,  0.842701], dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_erfinv.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the inverse error function of x, element-wise. — op_erfinv","title":"Computes the inverse error function of x, element-wise. — op_erfinv","text":"Computes inverse error function x, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_erfinv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the inverse error function of x, element-wise. — op_erfinv","text":"","code":"op_erfinv(x)"},{"path":"https://keras.posit.co/reference/op_erfinv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the inverse error function of x, element-wise. — op_erfinv","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_erfinv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the inverse error function of x, element-wise. — op_erfinv","text":"tensor dtype x.","code":""},{"path":"https://keras.posit.co/reference/op_erfinv.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the inverse error function of x, element-wise. — op_erfinv","text":"","code":"x <- op_array(c(-0.5, -0.2, -0.1, 0.0, 0.3)) op_erfinv(x) ## tf.Tensor([-0.4769363  -0.17914344 -0.088856    0.          0.27246267], shape=(5), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the exponential of all elements in the input tensor. — op_exp","title":"Calculate the exponential of all elements in the input tensor. — op_exp","text":"Calculate exponential elements input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the exponential of all elements in the input tensor. — op_exp","text":"","code":"op_exp(x)"},{"path":"https://keras.posit.co/reference/op_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the exponential of all elements in the input tensor. — op_exp","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_exp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the exponential of all elements in the input tensor. — op_exp","text":"Output tensor, element-wise exponential x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_expand_dims.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand the shape of a tensor. — op_expand_dims","title":"Expand the shape of a tensor. — op_expand_dims","text":"Insert new axis axis position expanded tensor shape.","code":""},{"path":"https://keras.posit.co/reference/op_expand_dims.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand the shape of a tensor. — op_expand_dims","text":"","code":"op_expand_dims(x, axis)"},{"path":"https://keras.posit.co/reference/op_expand_dims.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand the shape of a tensor. — op_expand_dims","text":"x Input tensor. axis Position expanded axes new axis (axes) placed.","code":""},{"path":"https://keras.posit.co/reference/op_expand_dims.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand the shape of a tensor. — op_expand_dims","text":"Output tensor number dimensions increased.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_expm1.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate exp(x) - 1 for all elements in the tensor. — op_expm1","title":"Calculate exp(x) - 1 for all elements in the tensor. — op_expm1","text":"Calculate exp(x) - 1 elements tensor.","code":""},{"path":"https://keras.posit.co/reference/op_expm1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate exp(x) - 1 for all elements in the tensor. — op_expm1","text":"","code":"op_expm1(x)"},{"path":"https://keras.posit.co/reference/op_expm1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate exp(x) - 1 for all elements in the tensor. — op_expm1","text":"x Input values.","code":""},{"path":"https://keras.posit.co/reference/op_expm1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate exp(x) - 1 for all elements in the tensor. — op_expm1","text":"Output tensor, element-wise exponential minus one.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_extract_sequences.html","id":null,"dir":"Reference","previous_headings":"","what":"Expands the dimension of last axis into sequences of sequence_length. — op_extract_sequences","title":"Expands the dimension of last axis into sequences of sequence_length. — op_extract_sequences","text":"Slides window size sequence_length last axis input stride sequence_stride, replacing last axis [num_sequences, sequence_length] sequences. dimension along last axis N, number sequences can computed : num_sequences = 1 + (N - sequence_length) // sequence_stride","code":""},{"path":"https://keras.posit.co/reference/op_extract_sequences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expands the dimension of last axis into sequences of sequence_length. — op_extract_sequences","text":"","code":"op_extract_sequences(x, sequence_length, sequence_stride)"},{"path":"https://keras.posit.co/reference/op_extract_sequences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expands the dimension of last axis into sequences of sequence_length. — op_extract_sequences","text":"x Input tensor. sequence_length integer representing sequences length. sequence_stride integer representing sequences hop size.","code":""},{"path":"https://keras.posit.co/reference/op_extract_sequences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expands the dimension of last axis into sequences of sequence_length. — op_extract_sequences","text":"tensor sequences shape [..., num_sequences, sequence_length].","code":""},{"path":"https://keras.posit.co/reference/op_extract_sequences.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expands the dimension of last axis into sequences of sequence_length. — op_extract_sequences","text":"","code":"x <- op_convert_to_tensor(1:6) op_extract_sequences(x, 3, 2) ## tf.Tensor( ## [[1 2 3] ##  [3 4 5]], shape=(2, 3), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_eye.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a 2-D tensor with ones on the diagonal and zeros elsewhere. — op_eye","title":"Return a 2-D tensor with ones on the diagonal and zeros elsewhere. — op_eye","text":"Return 2-D tensor ones diagonal zeros elsewhere.","code":""},{"path":"https://keras.posit.co/reference/op_eye.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a 2-D tensor with ones on the diagonal and zeros elsewhere. — op_eye","text":"","code":"op_eye(N, M = NULL, k = 0L, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_eye.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a 2-D tensor with ones on the diagonal and zeros elsewhere. — op_eye","text":"N Number rows output. M Number columns output. NULL, defaults N. k Index diagonal: 0 (default) refers main diagonal, positive value refers upper diagonal, negative value lower diagonal. dtype Data type returned tensor.","code":""},{"path":"https://keras.posit.co/reference/op_eye.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a 2-D tensor with ones on the diagonal and zeros elsewhere. — op_eye","text":"Tensor ones k-th diagonal zeros elsewhere.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_fft.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Fast Fourier Transform along last axis of input. — op_fft","title":"Computes the Fast Fourier Transform along last axis of input. — op_fft","text":"Computes Fast Fourier Transform along last axis input.","code":""},{"path":"https://keras.posit.co/reference/op_fft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Fast Fourier Transform along last axis of input. — op_fft","text":"","code":"op_fft(x)"},{"path":"https://keras.posit.co/reference/op_fft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Fast Fourier Transform along last axis of input. — op_fft","text":"x list real imaginary parts input tensor. tensors provided floating type.","code":""},{"path":"https://keras.posit.co/reference/op_fft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the Fast Fourier Transform along last axis of input. — op_fft","text":"list containing two tensors - real imaginary parts output tensor.","code":""},{"path":"https://keras.posit.co/reference/op_fft.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Fast Fourier Transform along last axis of input. — op_fft","text":"","code":"x = c(op_array(c(1., 2.)),       op_array(c(0., 1.))) op_fft(x) ## [[1]] ## tf.Tensor([ 3. -1.], shape=(2), dtype=float32) ## ## [[2]] ## tf.Tensor([ 1. -1.], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_fft2.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the 2D Fast Fourier Transform along the last two axes of input. — op_fft2","title":"Computes the 2D Fast Fourier Transform along the last two axes of input. — op_fft2","text":"Computes 2D Fast Fourier Transform along last two axes input.","code":""},{"path":"https://keras.posit.co/reference/op_fft2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the 2D Fast Fourier Transform along the last two axes of input. — op_fft2","text":"","code":"op_fft2(x)"},{"path":"https://keras.posit.co/reference/op_fft2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the 2D Fast Fourier Transform along the last two axes of input. — op_fft2","text":"x list real imaginary parts input tensor. tensors provided floating type.","code":""},{"path":"https://keras.posit.co/reference/op_fft2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the 2D Fast Fourier Transform along the last two axes of input. — op_fft2","text":"list containing two tensors - real imaginary parts output.","code":""},{"path":"https://keras.posit.co/reference/op_fft2.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the 2D Fast Fourier Transform along the last two axes of input. — op_fft2","text":"","code":"x <- c(op_array(rbind(c(1, 2),                      c(2, 1))),        op_array(rbind(c(0, 1),                      c(1, 0)))) op_fft2(x) ## [[1]] ## tf.Tensor( ## [[ 6.  0.] ##  [ 0. -2.]], shape=(2, 2), dtype=float64) ## ## [[2]] ## tf.Tensor( ## [[ 2.  0.] ##  [ 0. -2.]], shape=(2, 2), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_flip.html","id":null,"dir":"Reference","previous_headings":"","what":"Reverse the order of elements in the tensor along the given axis. — op_flip","title":"Reverse the order of elements in the tensor along the given axis. — op_flip","text":"shape tensor preserved, elements reordered.","code":""},{"path":"https://keras.posit.co/reference/op_flip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reverse the order of elements in the tensor along the given axis. — op_flip","text":"","code":"op_flip(x, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_flip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reverse the order of elements in the tensor along the given axis. — op_flip","text":"x Input tensor. axis Axis axes along flip tensor. default, axis = NULL, flip axes input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_flip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reverse the order of elements in the tensor along the given axis. — op_flip","text":"Output tensor entries axis reversed.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_floor.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the floor of the input, element-wise. — op_floor","title":"Return the floor of the input, element-wise. — op_floor","text":"floor scalar x largest integer , <= x.","code":""},{"path":"https://keras.posit.co/reference/op_floor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the floor of the input, element-wise. — op_floor","text":"","code":"op_floor(x)"},{"path":"https://keras.posit.co/reference/op_floor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the floor of the input, element-wise. — op_floor","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_floor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the floor of the input, element-wise. — op_floor","text":"Output tensor, element-wise floor x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_floor_divide.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the largest integer smaller or equal to the division of inputs. — op_floor_divide","title":"Returns the largest integer smaller or equal to the division of inputs. — op_floor_divide","text":"Note function automatically called using R operator %/% tensor.","code":"(x <- op_arange(10)) ## tf.Tensor([0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], shape=(10), dtype=float64) op_floor_divide(x, 2) ## tf.Tensor([0. 0. 1. 1. 2. 2. 3. 3. 4. 4.], shape=(10), dtype=float64) x %/% 2 ## tf.Tensor([0. 0. 1. 1. 2. 2. 3. 3. 4. 4.], shape=(10), dtype=float64)"},{"path":"https://keras.posit.co/reference/op_floor_divide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the largest integer smaller or equal to the division of inputs. — op_floor_divide","text":"","code":"op_floor_divide(x1, x2)"},{"path":"https://keras.posit.co/reference/op_floor_divide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the largest integer smaller or equal to the division of inputs. — op_floor_divide","text":"x1 Numerator. x2 Denominator.","code":""},{"path":"https://keras.posit.co/reference/op_floor_divide.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the largest integer smaller or equal to the division of inputs. — op_floor_divide","text":"Output tensor, y <- floor(x1/x2)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_fori_loop.html","id":null,"dir":"Reference","previous_headings":"","what":"For loop implementation. — op_fori_loop","title":"For loop implementation. — op_fori_loop","text":"loop implementation.","code":""},{"path":"https://keras.posit.co/reference/op_fori_loop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"For loop implementation. — op_fori_loop","text":"","code":"op_fori_loop(lower, upper, body_fun, init_val)"},{"path":"https://keras.posit.co/reference/op_fori_loop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"For loop implementation. — op_fori_loop","text":"lower initial value loop variable. upper upper bound loop variable. body_fun callable represents loop body. Must take two arguments: loop variable loop state. loop state updated returned function. init_val initial value loop state.","code":""},{"path":"https://keras.posit.co/reference/op_fori_loop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"For loop implementation. — op_fori_loop","text":"final state loop.","code":""},{"path":"https://keras.posit.co/reference/op_fori_loop.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"For loop implementation. — op_fori_loop","text":"","code":"lower <- 0L upper <- 10L body_fun <- function(i, state) state + i init_state <- 0L final_state <- op_fori_loop(lower, upper, body_fun, init_state) final_state ## tf.Tensor(45, shape=(), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a new tensor of given shape and type, filled with fill_value. — op_full","title":"Return a new tensor of given shape and type, filled with fill_value. — op_full","text":"Return new tensor given shape type, filled fill_value.","code":""},{"path":"https://keras.posit.co/reference/op_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a new tensor of given shape and type, filled with fill_value. — op_full","text":"","code":"op_full(shape, fill_value, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_full.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a new tensor of given shape and type, filled with fill_value. — op_full","text":"shape Shape new tensor. fill_value Fill value. dtype Desired data type tensor.","code":""},{"path":"https://keras.posit.co/reference/op_full.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a new tensor of given shape and type, filled with fill_value. — op_full","text":"Output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_full_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a full tensor with the same shape and type as the given tensor. — op_full_like","title":"Return a full tensor with the same shape and type as the given tensor. — op_full_like","text":"Return full tensor shape type given tensor.","code":""},{"path":"https://keras.posit.co/reference/op_full_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a full tensor with the same shape and type as the given tensor. — op_full_like","text":"","code":"op_full_like(x, fill_value, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_full_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a full tensor with the same shape and type as the given tensor. — op_full_like","text":"x Input tensor. fill_value Fill value. dtype Overrides data type result.","code":""},{"path":"https://keras.posit.co/reference/op_full_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a full tensor with the same shape and type as the given tensor. — op_full_like","text":"Tensor fill_value shape type x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_gelu.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian Error Linear Unit (GELU) activation function. — op_gelu","title":"Gaussian Error Linear Unit (GELU) activation function. — op_gelu","text":"approximate TRUE, defined : f(x) = 0.5 * x * (1 + tanh(sqrt(2 / pi) * (x + 0.044715 * x^3))) approximate FALSE, defined : f(x) = x * P(X <= x) = 0.5 * x * (1 + erf(x / sqrt(2))), P(X) ~ N(0, 1).","code":""},{"path":"https://keras.posit.co/reference/op_gelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian Error Linear Unit (GELU) activation function. — op_gelu","text":"","code":"op_gelu(x, approximate = TRUE)"},{"path":"https://keras.posit.co/reference/op_gelu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian Error Linear Unit (GELU) activation function. — op_gelu","text":"x Input tensor. approximate Approximate version GELU activation. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/op_gelu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian Error Linear Unit (GELU) activation function. — op_gelu","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_gelu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian Error Linear Unit (GELU) activation function. — op_gelu","text":"","code":"x <- op_array(c(-1., 0., 1.)) op_gelu(x) ## tf.Tensor([-0.15880796  0.          0.841192  ], shape=(3), dtype=float32) op_gelu(x, FALSE) ## tf.Tensor([-0.15865526  0.          0.8413447 ], shape=(3), dtype=float32) x <- seq(-5, 5, .1) plot(x, op_gelu(x),      type = \"l\", #, frame.plot = FALSE,      panel.first = grid())"},{"path":[]},{"path":"https://keras.posit.co/reference/op_get_item.html","id":null,"dir":"Reference","previous_headings":"","what":"Return x[key]. — op_get_item","title":"Return x[key]. — op_get_item","text":"Return x[key].","code":""},{"path":"https://keras.posit.co/reference/op_get_item.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return x[key]. — op_get_item","text":"","code":"op_get_item(x, key)"},{"path":"https://keras.posit.co/reference/op_get_item.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return x[key]. — op_get_item","text":"x dictionary-like object key Generally, string, object __hash__ method acceptable.","code":""},{"path":"https://keras.posit.co/reference/op_get_item.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return x[key]. — op_get_item","text":"key.","code":""},{"path":"https://keras.posit.co/reference/op_get_item.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Return x[key]. — op_get_item","text":"Generally, calling x[[key]] x$key preferable.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_greater.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the truth value of x1 > x2 element-wise. — op_greater","title":"Return the truth value of x1 > x2 element-wise. — op_greater","text":"Note function automatically called using R operator > tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_greater(x, 2) ## tf.Tensor([False False False  True], shape=(4), dtype=bool) x > 2 ## tf.Tensor([False False False  True], shape=(4), dtype=bool)"},{"path":"https://keras.posit.co/reference/op_greater.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the truth value of x1 > x2 element-wise. — op_greater","text":"","code":"op_greater(x1, x2)"},{"path":"https://keras.posit.co/reference/op_greater.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the truth value of x1 > x2 element-wise. — op_greater","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_greater.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the truth value of x1 > x2 element-wise. — op_greater","text":"Output tensor, element-wise comparison x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_greater_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the truth value of x1 >= x2 element-wise. — op_greater_equal","title":"Return the truth value of x1 >= x2 element-wise. — op_greater_equal","text":"Note function automatically called using R operator >= tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_greater_equal(x, 2) ## tf.Tensor([False False  True  True], shape=(4), dtype=bool) x >= 2 ## tf.Tensor([False False  True  True], shape=(4), dtype=bool)"},{"path":"https://keras.posit.co/reference/op_greater_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the truth value of x1 >= x2 element-wise. — op_greater_equal","text":"","code":"op_greater_equal(x1, x2)"},{"path":"https://keras.posit.co/reference/op_greater_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the truth value of x1 >= x2 element-wise. — op_greater_equal","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_greater_equal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the truth value of x1 >= x2 element-wise. — op_greater_equal","text":"Output tensor, element-wise comparison x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_hard_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Hard sigmoid activation function. — op_hard_sigmoid","title":"Hard sigmoid activation function. — op_hard_sigmoid","text":"defined : 0 x < -2.5, 1 x > 2.5, (0.2 * x) + 0.5 -2.5 <= x <= 2.5.","code":""},{"path":"https://keras.posit.co/reference/op_hard_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hard sigmoid activation function. — op_hard_sigmoid","text":"","code":"op_hard_sigmoid(x)"},{"path":"https://keras.posit.co/reference/op_hard_sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hard sigmoid activation function. — op_hard_sigmoid","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_hard_sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hard sigmoid activation function. — op_hard_sigmoid","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_hard_sigmoid.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hard sigmoid activation function. — op_hard_sigmoid","text":"","code":"x <- op_array(c(-1., 0., 1.)) op_hard_sigmoid(x) ## tf.Tensor([0.33333334 0.5        0.6666667 ], shape=(3), dtype=float32) x <- as.array(seq(-5, 5, .1)) plot(x, op_hard_sigmoid(x),      type = 'l', panel.first = grid(), frame.plot = FALSE)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_hard_silu.html","id":null,"dir":"Reference","previous_headings":"","what":"Hard SiLU activation function, also known as Hard Swish. — op_hard_silu","title":"Hard SiLU activation function, also known as Hard Swish. — op_hard_silu","text":"defined : 0 x < -3 x x > 3 x * (x + 3) / 6 -3 <= x <= 3 faster, piecewise linear approximation silu activation.","code":""},{"path":"https://keras.posit.co/reference/op_hard_silu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hard SiLU activation function, also known as Hard Swish. — op_hard_silu","text":"","code":"op_hard_silu(x)  op_hard_swish(x)"},{"path":"https://keras.posit.co/reference/op_hard_silu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hard SiLU activation function, also known as Hard Swish. — op_hard_silu","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_hard_silu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hard SiLU activation function, also known as Hard Swish. — op_hard_silu","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_hard_silu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hard SiLU activation function, also known as Hard Swish. — op_hard_silu","text":"","code":"x <- op_convert_to_tensor(c(-3.0, -1.0, 0.0, 1.0, 3.0)) op_hard_silu(x) ## tf.Tensor([-0.         -0.33333334  0.          0.6666667   3.        ], shape=(5), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_hstack.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack tensors in sequence horizontally (column wise). — op_hstack","title":"Stack tensors in sequence horizontally (column wise). — op_hstack","text":"equivalent concatenation along first axis 1-D tensors, along second axis tensors.","code":""},{"path":"https://keras.posit.co/reference/op_hstack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack tensors in sequence horizontally (column wise). — op_hstack","text":"","code":"op_hstack(xs)"},{"path":"https://keras.posit.co/reference/op_hstack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack tensors in sequence horizontally (column wise). — op_hstack","text":"xs Sequence tensors.","code":""},{"path":"https://keras.posit.co/reference/op_hstack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack tensors in sequence horizontally (column wise). — op_hstack","text":"tensor formed stacking given tensors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the identity tensor. — op_identity","title":"Return the identity tensor. — op_identity","text":"identity tensor square tensor ones main diagonal zeros elsewhere.","code":""},{"path":"https://keras.posit.co/reference/op_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the identity tensor. — op_identity","text":"","code":"op_identity(n, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the identity tensor. — op_identity","text":"n Number rows (columns) n x n output tensor. dtype Data type output tensor.","code":""},{"path":"https://keras.posit.co/reference/op_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the identity tensor. — op_identity","text":"identity tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_imag.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the imaginary part of the complex argument. — op_imag","title":"Return the imaginary part of the complex argument. — op_imag","text":"Return imaginary part complex argument.","code":""},{"path":"https://keras.posit.co/reference/op_imag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the imaginary part of the complex argument. — op_imag","text":"","code":"op_imag(x)"},{"path":"https://keras.posit.co/reference/op_imag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the imaginary part of the complex argument. — op_imag","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_imag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the imaginary part of the complex argument. — op_imag","text":"imaginary component complex argument.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_image_affine_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies the given transform(s) to the image(s). — op_image_affine_transform","title":"Applies the given transform(s) to the image(s). — op_image_affine_transform","text":"Applies given transform(s) image(s).","code":""},{"path":"https://keras.posit.co/reference/op_image_affine_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies the given transform(s) to the image(s). — op_image_affine_transform","text":"","code":"op_image_affine_transform(   image,   transform,   interpolation = \"bilinear\",   fill_mode = \"constant\",   fill_value = 0L,   data_format = \"channels_last\" )"},{"path":"https://keras.posit.co/reference/op_image_affine_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies the given transform(s) to the image(s). — op_image_affine_transform","text":"image Input image batch images. Must 3D 4D. transform Projective transform matrix/matrices. vector length 8 tensor size N x 8. one row transform [a0, a1, a2, b0, b1, b2, c0, c1], maps output point (x, y) transformed input point (x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k), k = c0 x + c1 y + 1. transform inverted compared transform mapping input points output points. Note gradients backpropagated transformation parameters. Note c0 c1 effective using TensorFlow backend considered 0 using backends. interpolation Interpolation method. Available methods \"nearest\", \"bilinear\". Defaults \"bilinear\". fill_mode Points outside boundaries input filled according given mode. Available methods \"constant\", \"nearest\", \"wrap\" \"reflect\". Defaults \"constant\". \"reflect\": (d c b | b c d | d c b ) input extended reflecting edge last pixel. \"constant\": (k k k k | b c d | k k k k) input extended filling values beyond edge constant value k specified fill_value. \"wrap\": (b c d | b c d | b c d) input extended wrapping around opposite edge. \"nearest\": (| b c d | d d d d) input extended nearest pixel. fill_value Value used points outside boundaries input fill_mode = \"constant\". Defaults 0. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, weight). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\".","code":""},{"path":"https://keras.posit.co/reference/op_image_affine_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Applies the given transform(s) to the image(s). — op_image_affine_transform","text":"Applied affine transform image batch images.","code":""},{"path":"https://keras.posit.co/reference/op_image_affine_transform.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies the given transform(s) to the image(s). — op_image_affine_transform","text":"","code":"x <- random_uniform(c(2, 64, 80, 3)) # batch of 2 RGB images transform <- op_array(rbind(c(1.5, 0, -20, 0, 1.5, -16, 0, 0),  # zoom                            c(1, 0, -20, 0, 1, -16, 0, 0)))  # translation)) y <- op_image_affine_transform(x, transform) shape(y) ## shape(2, 64, 80, 3) # (2, 64, 80, 3) x <- random_uniform(c(64, 80, 3)) # single RGB image transform <- op_array(c(1.0, 0.5, -20, 0.5, 1.0, -16, 0, 0))  # shear y <- op_image_affine_transform(x, transform) shape(y) ## shape(64, 80, 3) # (64, 80, 3) x <- random_uniform(c(2, 3, 64, 80)) # batch of 2 RGB images transform <- op_array(rbind(   c(1.5, 0,-20, 0, 1.5,-16, 0, 0),  # zoom   c(1, 0,-20, 0, 1,-16, 0, 0)  # translation )) y <- op_image_affine_transform(x, transform, data_format = \"channels_first\") shape(y) ## shape(2, 3, 64, 80) # (2, 3, 64, 80)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_image_crop.html","id":null,"dir":"Reference","previous_headings":"","what":"Crop images to a specified height and width. — op_image_crop","title":"Crop images to a specified height and width. — op_image_crop","text":"Crop images specified height width.","code":""},{"path":"https://keras.posit.co/reference/op_image_crop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Crop images to a specified height and width. — op_image_crop","text":"","code":"op_image_crop(   images,   top_cropping = NULL,   left_cropping = NULL,   target_height = NULL,   target_width = NULL,   bottom_cropping = NULL,   right_cropping = NULL )"},{"path":"https://keras.posit.co/reference/op_image_crop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Crop images to a specified height and width. — op_image_crop","text":"images 4-D batch images shape (batch, height, width, channels) 3-D single image shape (height, width, channels). top_cropping Number columns crop top. left_cropping Number columns crop left. target_height Height output images. target_width Width output images. bottom_cropping Number columns crop bottom. right_cropping Number columns crop right.","code":""},{"path":"https://keras.posit.co/reference/op_image_crop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Crop images to a specified height and width. — op_image_crop","text":"images 4D, 4D float Tensor shape (batch, target_height, target_width, channels) images 3D, 3D float Tensor shape (target_height, target_width, channels)","code":""},{"path":"https://keras.posit.co/reference/op_image_crop.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Crop images to a specified height and width. — op_image_crop","text":"","code":"images <- op_reshape(op_arange(1, 28, dtype=\"float32\"), c(3, 3, 3)) images[, , 1] # print the first channel of the images  cropped_images <- op_image_crop(images, 0, 0, 2, 2) cropped_images[, , 1] # print the first channel of the cropped images"},{"path":[]},{"path":"https://keras.posit.co/reference/op_image_extract_patches.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracts patches from the image(s). — op_image_extract_patches","title":"Extracts patches from the image(s). — op_image_extract_patches","text":"Extracts patches image(s).","code":""},{"path":"https://keras.posit.co/reference/op_image_extract_patches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracts patches from the image(s). — op_image_extract_patches","text":"","code":"op_image_extract_patches(   image,   size,   strides = NULL,   dilation_rate = 1L,   padding = \"valid\",   data_format = \"channels_last\" )"},{"path":"https://keras.posit.co/reference/op_image_extract_patches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracts patches from the image(s). — op_image_extract_patches","text":"image Input image batch images. Must 3D 4D. size Patch size int list (patch_height, patch_width) strides strides along height width. specified, NULL, defaults value size. dilation_rate input stride, specifying far two consecutive patch samples input. value 1, strides must 1. NOTE: strides > 1 supported conjunction dilation_rate > 1 padding type padding algorithm use: \"\" \"valid\". data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, weight). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\".","code":""},{"path":"https://keras.posit.co/reference/op_image_extract_patches.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracts patches from the image(s). — op_image_extract_patches","text":"Extracted patches 3D (batched) 4D (batched)","code":""},{"path":"https://keras.posit.co/reference/op_image_extract_patches.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracts patches from the image(s). — op_image_extract_patches","text":"","code":"image <- random_uniform(c(2, 20, 20, 3), dtype = \"float32\") # batch of 2 RGB images patches <- op_image_extract_patches(image, c(5, 5)) shape(patches) ## shape(2, 4, 4, 75) # (2, 4, 4, 75) image <- random_uniform(c(20, 20, 3), dtype = \"float32\") # 1 RGB image patches <- op_image_extract_patches(image, c(3, 3), c(1, 1)) shape(patches) ## shape(18, 18, 27) # (18, 18, 27)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_image_map_coordinates.html","id":null,"dir":"Reference","previous_headings":"","what":"Map the input array to new coordinates by interpolation.. — op_image_map_coordinates","title":"Map the input array to new coordinates by interpolation.. — op_image_map_coordinates","text":"Note interpolation near boundaries differs scipy function, fixed outstanding bug scipy/issues/2640.","code":""},{"path":"https://keras.posit.co/reference/op_image_map_coordinates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map the input array to new coordinates by interpolation.. — op_image_map_coordinates","text":"","code":"op_image_map_coordinates(   input,   coordinates,   order,   fill_mode = \"constant\",   fill_value = 0L )"},{"path":"https://keras.posit.co/reference/op_image_map_coordinates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map the input array to new coordinates by interpolation.. — op_image_map_coordinates","text":"input input array. coordinates coordinates input evaluated. order order spline interpolation. order must 0 1. 0 indicates nearest neighbor 1 indicates linear interpolation. fill_mode Points outside boundaries input filled according given mode. Available methods \"constant\", \"nearest\", \"wrap\" \"mirror\" \"reflect\". Defaults \"constant\". \"constant\": (k k k k | b c d | k k k k) input extended filling values beyond edge constant value k specified fill_value. \"nearest\": (| b c d | d d d d) input extended nearest pixel. \"wrap\": (b c d | b c d | b c d) input extended wrapping around opposite edge. \"mirror\": (c d c b | b c d | c b b) input extended mirroring edge. \"reflect\": (d c b | b c d | d c b ) input extended reflecting edge last pixel. fill_value Value used points outside boundaries input fill_mode = \"constant\". Defaults 0.","code":""},{"path":"https://keras.posit.co/reference/op_image_map_coordinates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map the input array to new coordinates by interpolation.. — op_image_map_coordinates","text":"Output image batch images.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_image_pad.html","id":null,"dir":"Reference","previous_headings":"","what":"Pad images with zeros to the specified height and width. — op_image_pad","title":"Pad images with zeros to the specified height and width. — op_image_pad","text":"Pad images zeros specified height width.","code":""},{"path":"https://keras.posit.co/reference/op_image_pad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pad images with zeros to the specified height and width. — op_image_pad","text":"","code":"op_image_pad(   images,   top_padding = NULL,   left_padding = NULL,   target_height = NULL,   target_width = NULL,   bottom_padding = NULL,   right_padding = NULL )"},{"path":"https://keras.posit.co/reference/op_image_pad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pad images with zeros to the specified height and width. — op_image_pad","text":"images 4D Tensor shape (batch, height, width, channels) 3D Tensor shape (height, width, channels). top_padding Number rows zeros add top. left_padding Number columns zeros add left. target_height Height output images. target_width Width output images. bottom_padding Number rows zeros add bottom. right_padding Number columns zeros add right.","code":""},{"path":"https://keras.posit.co/reference/op_image_pad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pad images with zeros to the specified height and width. — op_image_pad","text":"images 4D, 4D float Tensor shape (batch, target_height, target_width, channels) images 3D, 3D float Tensor shape (target_height, target_width, channels)","code":""},{"path":"https://keras.posit.co/reference/op_image_pad.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pad images with zeros to the specified height and width. — op_image_pad","text":"","code":"images <- random_uniform(c(15, 25, 3)) padded_images <- op_image_pad(     images, 2, 3, target_height = 20, target_width = 30 ) shape(padded_images) ## shape(20, 30, 3) batch_images <- random_uniform(c(2, 15, 25, 3)) padded_batch <- op_image_pad(batch_images, 2, 3,                              target_height = 20,                              target_width = 30) shape(padded_batch) ## shape(2, 20, 30, 3)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_image_resize.html","id":null,"dir":"Reference","previous_headings":"","what":"Resize images to size using the specified interpolation method. — op_image_resize","title":"Resize images to size using the specified interpolation method. — op_image_resize","text":"Resize images size using specified interpolation method.","code":""},{"path":"https://keras.posit.co/reference/op_image_resize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resize images to size using the specified interpolation method. — op_image_resize","text":"","code":"op_image_resize(   image,   size,   interpolation = \"bilinear\",   antialias = FALSE,   data_format = \"channels_last\" )"},{"path":"https://keras.posit.co/reference/op_image_resize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resize images to size using the specified interpolation method. — op_image_resize","text":"image Input image batch images. Must 3D 4D. size Size output image (height, width) format. interpolation Interpolation method. Available methods \"nearest\", \"bilinear\", \"bicubic\". Defaults \"bilinear\". antialias Whether use antialiasing filter downsampling image. Defaults FALSE. data_format string, either \"channels_last\" \"channels_first\". ordering dimensions inputs. \"channels_last\" corresponds inputs shape (batch, height, width, channels) \"channels_first\" corresponds inputs shape (batch, channels, height, weight). defaults image_data_format value found Keras config file ~/.keras/keras.json. never set , \"channels_last\".","code":""},{"path":"https://keras.posit.co/reference/op_image_resize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resize images to size using the specified interpolation method. — op_image_resize","text":"Resized image batch images.","code":""},{"path":"https://keras.posit.co/reference/op_image_resize.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resize images to size using the specified interpolation method. — op_image_resize","text":"","code":"x <- random_uniform(c(2, 4, 4, 3)) # batch of 2 RGB images y <- op_image_resize(x, c(2, 2)) shape(y) ## shape(2, 2, 2, 3) x <- random_uniform(c(4, 4, 3)) # single RGB image y <- op_image_resize(x, c(2, 2)) shape(y) ## shape(2, 2, 3) x <- random_uniform(c(2, 3, 4, 4)) # batch of 2 RGB images y <- op_image_resize(x, c(2, 2), data_format = \"channels_first\") shape(y) ## shape(2, 3, 2, 2)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_in_top_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if the targets are in the top-k predictions. — op_in_top_k","title":"Checks if the targets are in the top-k predictions. — op_in_top_k","text":"Checks targets top-k predictions.","code":""},{"path":"https://keras.posit.co/reference/op_in_top_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if the targets are in the top-k predictions. — op_in_top_k","text":"","code":"op_in_top_k(targets, predictions, k)"},{"path":"https://keras.posit.co/reference/op_in_top_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if the targets are in the top-k predictions. — op_in_top_k","text":"targets tensor true labels. predictions tensor predicted labels. k integer representing number predictions consider.","code":""},{"path":"https://keras.posit.co/reference/op_in_top_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks if the targets are in the top-k predictions. — op_in_top_k","text":"boolean tensor shape targets, element indicates whether corresponding target top-k predictions.","code":""},{"path":"https://keras.posit.co/reference/op_in_top_k.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Checks if the targets are in the top-k predictions. — op_in_top_k","text":"","code":"targets <- op_array(c(2, 5, 3), \"int32\") predictions <- op_array(dtype = \"float32\", rbind(   c(0.1, 0.4, 0.6, 0.9, 0.5),   c(0.1, 0.7, 0.9, 0.8, 0.3),   c(0.1, 0.6, 0.9, 0.9, 0.5) )) op_in_top_k(targets, predictions, k = 3L) ## tf.Tensor([ True False  True], shape=(3), dtype=bool)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the inverse of a square tensor. — op_inv","title":"Computes the inverse of a square tensor. — op_inv","text":"Computes inverse square tensor.","code":""},{"path":"https://keras.posit.co/reference/op_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the inverse of a square tensor. — op_inv","text":"","code":"op_inv(x)"},{"path":"https://keras.posit.co/reference/op_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the inverse of a square tensor. — op_inv","text":"x Input tensor shape (..., M, M).","code":""},{"path":"https://keras.posit.co/reference/op_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the inverse of a square tensor. — op_inv","text":"tensor shape (..., M, M) representing inverse x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_irfft.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse real-valued Fast Fourier transform along the last axis. — op_irfft","title":"Inverse real-valued Fast Fourier transform along the last axis. — op_irfft","text":"Computes inverse 1D Discrete Fourier Transform real-valued signal inner-dimension input. inner-dimension input assumed result RFFT: fft_length / 2 + 1 unique components DFT real-valued signal. fft_length provided, computed size inner-dimension input (fft_length = 2 * (inner - 1)). FFT length used compute odd, provided since inferred properly. Along axis IRFFT computed , fft_length / 2 + 1 smaller corresponding dimension input, dimension cropped. larger, dimension padded zeros.","code":""},{"path":"https://keras.posit.co/reference/op_irfft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse real-valued Fast Fourier transform along the last axis. — op_irfft","text":"","code":"op_irfft(x, fft_length = NULL)"},{"path":"https://keras.posit.co/reference/op_irfft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse real-valued Fast Fourier transform along the last axis. — op_irfft","text":"x List real imaginary parts input tensor. tensors list floating type. fft_length integer representing number fft length. specified, inferred length last axis x. Defaults NULL.","code":""},{"path":"https://keras.posit.co/reference/op_irfft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse real-valued Fast Fourier transform along the last axis. — op_irfft","text":"tensor containing inverse real-valued Fast Fourier Transform along last axis x.","code":""},{"path":"https://keras.posit.co/reference/op_irfft.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse real-valued Fast Fourier transform along the last axis. — op_irfft","text":"","code":"real <- op_array(c(0, 1, 2, 3, 4)) imag <- op_array(c(0, 1, 2, 3, 4)) op_irfft(c(real, imag)) #> tf.Tensor( #> [ 2.         -2.0606601   0.5        -0.35355338  0.          0.06066012 #>  -0.5         0.35355338], shape=(8), dtype=float32) all.equal(op_irfft(op_rfft(real, 5), 5), real) #> [1] TRUE"},{"path":[]},{"path":"https://keras.posit.co/reference/op_is_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether the given object is a tensor. — op_is_tensor","title":"Check whether the given object is a tensor. — op_is_tensor","text":"Check whether given object tensor.","code":""},{"path":"https://keras.posit.co/reference/op_is_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether the given object is a tensor. — op_is_tensor","text":"","code":"op_is_tensor(x)"},{"path":"https://keras.posit.co/reference/op_is_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether the given object is a tensor. — op_is_tensor","text":"x variable.","code":""},{"path":"https://keras.posit.co/reference/op_is_tensor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether the given object is a tensor. — op_is_tensor","text":"TRUE x tensor, otherwise FALSE.","code":""},{"path":"https://keras.posit.co/reference/op_is_tensor.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Check whether the given object is a tensor. — op_is_tensor","text":"checks backend specific tensors passing TensorFlow tensor return FALSE backend PyTorch JAX.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_isclose.html","id":null,"dir":"Reference","previous_headings":"","what":"Return whether two tensors are element-wise almost equal. — op_isclose","title":"Return whether two tensors are element-wise almost equal. — op_isclose","text":"Return whether two tensors element-wise almost equal.","code":""},{"path":"https://keras.posit.co/reference/op_isclose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return whether two tensors are element-wise almost equal. — op_isclose","text":"","code":"op_isclose(x1, x2)"},{"path":"https://keras.posit.co/reference/op_isclose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return whether two tensors are element-wise almost equal. — op_isclose","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_isclose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return whether two tensors are element-wise almost equal. — op_isclose","text":"Output boolean tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_isfinite.html","id":null,"dir":"Reference","previous_headings":"","what":"Return whether a tensor is finite, element-wise. — op_isfinite","title":"Return whether a tensor is finite, element-wise. — op_isfinite","text":"Real values finite NaN, positive infinity, negative infinity. Complex values finite real imaginary parts finite.","code":""},{"path":"https://keras.posit.co/reference/op_isfinite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return whether a tensor is finite, element-wise. — op_isfinite","text":"","code":"op_isfinite(x)"},{"path":"https://keras.posit.co/reference/op_isfinite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return whether a tensor is finite, element-wise. — op_isfinite","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_isfinite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return whether a tensor is finite, element-wise. — op_isfinite","text":"Output boolean tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_isinf.html","id":null,"dir":"Reference","previous_headings":"","what":"Test element-wise for positive or negative infinity. — op_isinf","title":"Test element-wise for positive or negative infinity. — op_isinf","text":"Test element-wise positive negative infinity.","code":""},{"path":"https://keras.posit.co/reference/op_isinf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test element-wise for positive or negative infinity. — op_isinf","text":"","code":"op_isinf(x)"},{"path":"https://keras.posit.co/reference/op_isinf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test element-wise for positive or negative infinity. — op_isinf","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_isinf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test element-wise for positive or negative infinity. — op_isinf","text":"Output boolean tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_isnan.html","id":null,"dir":"Reference","previous_headings":"","what":"Test element-wise for NaN and return result as a boolean tensor. — op_isnan","title":"Test element-wise for NaN and return result as a boolean tensor. — op_isnan","text":"Test element-wise NaN return result boolean tensor.","code":""},{"path":"https://keras.posit.co/reference/op_isnan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test element-wise for NaN and return result as a boolean tensor. — op_isnan","text":"","code":"op_isnan(x)"},{"path":"https://keras.posit.co/reference/op_isnan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test element-wise for NaN and return result as a boolean tensor. — op_isnan","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_isnan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test element-wise for NaN and return result as a boolean tensor. — op_isnan","text":"Output boolean tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_istft.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse Short-Time Fourier Transform along the last axis of the input. — op_istft","title":"Inverse Short-Time Fourier Transform along the last axis of the input. — op_istft","text":"reconstruct original waveform, parameters stft.","code":""},{"path":"https://keras.posit.co/reference/op_istft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse Short-Time Fourier Transform along the last axis of the input. — op_istft","text":"","code":"op_istft(   x,   sequence_length,   sequence_stride,   fft_length,   length = NULL,   window = \"hann\",   center = TRUE )"},{"path":"https://keras.posit.co/reference/op_istft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse Short-Time Fourier Transform along the last axis of the input. — op_istft","text":"x Tuple real imaginary parts input tensor. tensors list floating type. sequence_length integer representing sequence length. sequence_stride integer representing sequence hop size. fft_length integer representing size FFT produced stft. length integer representing output clipped exactly length. specified, padding clipping take place. Defaults NULL. window string, tensor window NULL. window string, available values \"hann\" \"hamming\". window tensor, used directly window length must sequence_length. window NULL, windowing used. Defaults \"hann\". center Whether x padded sides t-th sequence centered time t * sequence_stride. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/op_istft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse Short-Time Fourier Transform along the last axis of the input. — op_istft","text":"tensor containing inverse Short-Time Fourier Transform along last axis x.","code":""},{"path":"https://keras.posit.co/reference/op_istft.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse Short-Time Fourier Transform along the last axis of the input. — op_istft","text":"","code":"x <- op_convert_to_tensor(c(0, 1, 2, 3, 4)) op_istft(op_stft(x, 1, 1, 1), 1, 1, 1) ## tf.Tensor([], shape=(0), dtype=float32) # array([0.0, 1.0, 2.0, 3.0, 4.0])"},{"path":[]},{"path":"https://keras.posit.co/reference/op_leaky_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaky version of a Rectified Linear Unit activation function. — op_leaky_relu","title":"Leaky version of a Rectified Linear Unit activation function. — op_leaky_relu","text":"allows small gradient unit active, defined : f(x) = alpha * x x < 0 f(x) = x x >= 0.","code":""},{"path":"https://keras.posit.co/reference/op_leaky_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leaky version of a Rectified Linear Unit activation function. — op_leaky_relu","text":"","code":"op_leaky_relu(x, negative_slope = 0.2)"},{"path":"https://keras.posit.co/reference/op_leaky_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leaky version of a Rectified Linear Unit activation function. — op_leaky_relu","text":"x Input tensor. negative_slope Slope activation function x < 0. Defaults 0.2.","code":""},{"path":"https://keras.posit.co/reference/op_leaky_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leaky version of a Rectified Linear Unit activation function. — op_leaky_relu","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_leaky_relu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leaky version of a Rectified Linear Unit activation function. — op_leaky_relu","text":"","code":"x <- op_array(c(-1., 0., 1.)) op_leaky_relu(x) ## tf.Tensor([-0.2  0.   1. ], shape=(3), dtype=float32) # array([-0.2,  0. ,  1. ], shape=(3,), dtype=float64) x <- seq(-5, 5, .1) plot(x, op_leaky_relu(x),      type = 'l', panel.first = grid())"},{"path":[]},{"path":"https://keras.posit.co/reference/op_less.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the truth value of x1 < x2 element-wise. — op_less","title":"Return the truth value of x1 < x2 element-wise. — op_less","text":"Note function automatically called using R operator < tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_less(x, 2) ## tf.Tensor([ True  True False False], shape=(4), dtype=bool) x < 2 ## tf.Tensor([ True  True False False], shape=(4), dtype=bool)"},{"path":"https://keras.posit.co/reference/op_less.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the truth value of x1 < x2 element-wise. — op_less","text":"","code":"op_less(x1, x2)"},{"path":"https://keras.posit.co/reference/op_less.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the truth value of x1 < x2 element-wise. — op_less","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_less.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the truth value of x1 < x2 element-wise. — op_less","text":"Output tensor, element-wise comparison x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_less_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the truth value of x1 <= x2 element-wise. — op_less_equal","title":"Return the truth value of x1 <= x2 element-wise. — op_less_equal","text":"Note function automatically called using R operator <= tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_less_equal(x, 2) ## tf.Tensor([ True  True  True False], shape=(4), dtype=bool) x <= 2 ## tf.Tensor([ True  True  True False], shape=(4), dtype=bool)"},{"path":"https://keras.posit.co/reference/op_less_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the truth value of x1 <= x2 element-wise. — op_less_equal","text":"","code":"op_less_equal(x1, x2)"},{"path":"https://keras.posit.co/reference/op_less_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the truth value of x1 <= x2 element-wise. — op_less_equal","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_less_equal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the truth value of x1 <= x2 element-wise. — op_less_equal","text":"Output tensor, element-wise comparison x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_linspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Return evenly spaced numbers over a specified interval. — op_linspace","title":"Return evenly spaced numbers over a specified interval. — op_linspace","text":"Returns num evenly spaced samples, calculated interval [start, stop]. endpoint interval can optionally excluded.","code":""},{"path":"https://keras.posit.co/reference/op_linspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return evenly spaced numbers over a specified interval. — op_linspace","text":"","code":"op_linspace(   start,   stop,   num = 50L,   endpoint = TRUE,   retstep = FALSE,   dtype = NULL,   axis = 1L )"},{"path":"https://keras.posit.co/reference/op_linspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return evenly spaced numbers over a specified interval. — op_linspace","text":"start starting value sequence. stop end value sequence, unless endpoint set FALSE. case, sequence consists last num + 1 evenly spaced samples, stop excluded. Note step size changes endpoint FALSE. num Number samples generate. Defaults 50. Must non-negative. endpoint TRUE, stop last sample. Otherwise, included. Defaults toTRUE. retstep TRUE, return (samples, step), step spacing samples. dtype type output tensor. axis axis result store samples. Relevant start stop array-like. Defaults 1, first axis.","code":""},{"path":"https://keras.posit.co/reference/op_linspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return evenly spaced numbers over a specified interval. — op_linspace","text":"tensor evenly spaced numbers. retstep TRUE, returns (samples, step)","code":""},{"path":"https://keras.posit.co/reference/op_linspace.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Return evenly spaced numbers over a specified interval. — op_linspace","text":"Torch backend support axis argument.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Natural logarithm, element-wise. — op_log","title":"Natural logarithm, element-wise. — op_log","text":"Natural logarithm, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Natural logarithm, element-wise. — op_log","text":"","code":"op_log(x)"},{"path":"https://keras.posit.co/reference/op_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Natural logarithm, element-wise. — op_log","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_log.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Natural logarithm, element-wise. — op_log","text":"Output tensor, element-wise natural logarithm x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_log10.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the base 10 logarithm of the input tensor, element-wise. — op_log10","title":"Return the base 10 logarithm of the input tensor, element-wise. — op_log10","text":"Return base 10 logarithm input tensor, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_log10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the base 10 logarithm of the input tensor, element-wise. — op_log10","text":"","code":"op_log10(x)"},{"path":"https://keras.posit.co/reference/op_log10.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the base 10 logarithm of the input tensor, element-wise. — op_log10","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_log10.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the base 10 logarithm of the input tensor, element-wise. — op_log10","text":"Output tensor, element-wise base 10 logarithm x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the natural logarithm of one plus the x, element-wise. — op_log1p","title":"Returns the natural logarithm of one plus the x, element-wise. — op_log1p","text":"Calculates log(1 + x).","code":""},{"path":"https://keras.posit.co/reference/op_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the natural logarithm of one plus the x, element-wise. — op_log1p","text":"","code":"op_log1p(x)"},{"path":"https://keras.posit.co/reference/op_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the natural logarithm of one plus the x, element-wise. — op_log1p","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_log1p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the natural logarithm of one plus the x, element-wise. — op_log1p","text":"Output tensor, element-wise natural logarithm 1 + x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_log2.html","id":null,"dir":"Reference","previous_headings":"","what":"Base-2 logarithm of x, element-wise. — op_log2","title":"Base-2 logarithm of x, element-wise. — op_log2","text":"Base-2 logarithm x, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_log2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base-2 logarithm of x, element-wise. — op_log2","text":"","code":"op_log2(x)"},{"path":"https://keras.posit.co/reference/op_log2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Base-2 logarithm of x, element-wise. — op_log2","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_log2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Base-2 logarithm of x, element-wise. — op_log2","text":"Output tensor, element-wise base-2 logarithm x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_log_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Logarithm of the sigmoid activation function. — op_log_sigmoid","title":"Logarithm of the sigmoid activation function. — op_log_sigmoid","text":"defined f(x) = log(1 / (1 + exp(-x))).","code":""},{"path":"https://keras.posit.co/reference/op_log_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logarithm of the sigmoid activation function. — op_log_sigmoid","text":"","code":"op_log_sigmoid(x)"},{"path":"https://keras.posit.co/reference/op_log_sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logarithm of the sigmoid activation function. — op_log_sigmoid","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_log_sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logarithm of the sigmoid activation function. — op_log_sigmoid","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_log_sigmoid.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logarithm of the sigmoid activation function. — op_log_sigmoid","text":"","code":"x <- op_convert_to_tensor(c(-0.541391, 0.0, 0.50, 5.0)) op_log_sigmoid(x) ## tf.Tensor([-1.0000418  -0.6931472  -0.474077   -0.00671535], shape=(4), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_log_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-softmax activation function. — op_log_softmax","title":"Log-softmax activation function. — op_log_softmax","text":"defined : f(x) = x - max(x) - log(sum(exp(x - max(x))))","code":""},{"path":"https://keras.posit.co/reference/op_log_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-softmax activation function. — op_log_softmax","text":"","code":"op_log_softmax(x, axis = -1L)"},{"path":"https://keras.posit.co/reference/op_log_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-softmax activation function. — op_log_softmax","text":"x Input tensor. axis Integer, axis along log-softmax applied. Defaults -1.","code":""},{"path":"https://keras.posit.co/reference/op_log_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-softmax activation function. — op_log_softmax","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_log_softmax.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-softmax activation function. — op_log_softmax","text":"","code":"x <- op_array(c(-1., 0., 1.)) op_log_softmax(x) ## tf.Tensor([-2.407606   -1.4076059  -0.40760595], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_logaddexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Logarithm of the sum of exponentiations of the inputs. — op_logaddexp","title":"Logarithm of the sum of exponentiations of the inputs. — op_logaddexp","text":"Calculates log(exp(x1) + exp(x2)).","code":""},{"path":"https://keras.posit.co/reference/op_logaddexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logarithm of the sum of exponentiations of the inputs. — op_logaddexp","text":"","code":"op_logaddexp(x1, x2)"},{"path":"https://keras.posit.co/reference/op_logaddexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logarithm of the sum of exponentiations of the inputs. — op_logaddexp","text":"x1 Input tensor. x2 Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_logaddexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logarithm of the sum of exponentiations of the inputs. — op_logaddexp","text":"Output tensor, element-wise logarithm sum exponentiations inputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_logical_and.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the element-wise logical AND of the given input tensors. — op_logical_and","title":"Computes the element-wise logical AND of the given input tensors. — op_logical_and","text":"Zeros treated FALSE non-zeros treated TRUE.","code":""},{"path":"https://keras.posit.co/reference/op_logical_and.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the element-wise logical AND of the given input tensors. — op_logical_and","text":"","code":"op_logical_and(x1, x2)"},{"path":"https://keras.posit.co/reference/op_logical_and.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the element-wise logical AND of the given input tensors. — op_logical_and","text":"x1 Input tensor. x2 Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_logical_and.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the element-wise logical AND of the given input tensors. — op_logical_and","text":"Output tensor, element-wise logical inputs.","code":""},{"path":"https://keras.posit.co/reference/op_logical_and.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the element-wise logical AND of the given input tensors. — op_logical_and","text":"Note function automatically called using R operator & tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_logical_not.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the element-wise NOT of the given input tensor. — op_logical_not","title":"Computes the element-wise NOT of the given input tensor. — op_logical_not","text":"Zeros treated FALSE non-zeros treated TRUE. Note function automatically called using R operator ! tensor.","code":""},{"path":"https://keras.posit.co/reference/op_logical_not.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the element-wise NOT of the given input tensor. — op_logical_not","text":"","code":"op_logical_not(x)"},{"path":"https://keras.posit.co/reference/op_logical_not.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the element-wise NOT of the given input tensor. — op_logical_not","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_logical_not.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the element-wise NOT of the given input tensor. — op_logical_not","text":"Output tensor, element-wise logical input.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_logical_or.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the element-wise logical OR of the given input tensors. — op_logical_or","title":"Computes the element-wise logical OR of the given input tensors. — op_logical_or","text":"Zeros treated FALSE non-zeros treated TRUE. Note function automatically called using R operator | tensor.","code":""},{"path":"https://keras.posit.co/reference/op_logical_or.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the element-wise logical OR of the given input tensors. — op_logical_or","text":"","code":"op_logical_or(x1, x2)"},{"path":"https://keras.posit.co/reference/op_logical_or.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the element-wise logical OR of the given input tensors. — op_logical_or","text":"x1 Input tensor. x2 Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_logical_or.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the element-wise logical OR of the given input tensors. — op_logical_or","text":"Output tensor, element-wise logical inputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_logical_xor.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the truth value of x1 XOR x2, element-wise. — op_logical_xor","title":"Compute the truth value of x1 XOR x2, element-wise. — op_logical_xor","text":"Compute truth value x1 XOR x2, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_logical_xor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the truth value of x1 XOR x2, element-wise. — op_logical_xor","text":"","code":"op_logical_xor(x1, x2)"},{"path":"https://keras.posit.co/reference/op_logical_xor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the truth value of x1 XOR x2, element-wise. — op_logical_xor","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_logical_xor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the truth value of x1 XOR x2, element-wise. — op_logical_xor","text":"Output boolean tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_logspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns numbers spaced evenly on a log scale. — op_logspace","title":"Returns numbers spaced evenly on a log scale. — op_logspace","text":"linear space, sequence starts base ** start ends base ** stop (see endpoint ).","code":""},{"path":"https://keras.posit.co/reference/op_logspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns numbers spaced evenly on a log scale. — op_logspace","text":"","code":"op_logspace(   start,   stop,   num = 50L,   endpoint = TRUE,   base = 10L,   dtype = NULL,   axis = 1L )"},{"path":"https://keras.posit.co/reference/op_logspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns numbers spaced evenly on a log scale. — op_logspace","text":"start starting value sequence. stop final value sequence, unless endpoint FALSE. case, num + 1 values spaced interval log-space, last (sequence length num) returned. num Number samples generate. Defaults 50. endpoint TRUE, stop last sample. Otherwise, included. Defaults toTRUE. base base log space. Defaults 10. dtype type output tensor. axis axis result store samples. Relevant start stop array-like.","code":""},{"path":"https://keras.posit.co/reference/op_logspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns numbers spaced evenly on a log scale. — op_logspace","text":"tensor evenly spaced samples log scale.","code":""},{"path":"https://keras.posit.co/reference/op_logspace.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Returns numbers spaced evenly on a log scale. — op_logspace","text":"Torch backend support axis argument.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_logsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the logarithm of sum of exponentials of elements in a tensor. — op_logsumexp","title":"Computes the logarithm of sum of exponentials of elements in a tensor. — op_logsumexp","text":"Computes logarithm sum exponentials elements tensor.","code":""},{"path":"https://keras.posit.co/reference/op_logsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the logarithm of sum of exponentials of elements in a tensor. — op_logsumexp","text":"","code":"op_logsumexp(x, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_logsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the logarithm of sum of exponentials of elements in a tensor. — op_logsumexp","text":"x Input tensor. axis integer list integers specifying axis/axes along compute sum. NULL, sum computed elements. Defaults toNULL. keepdims boolean indicating whether keep dimensions input tensor computing sum. Defaults toFALSE.","code":""},{"path":"https://keras.posit.co/reference/op_logsumexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the logarithm of sum of exponentials of elements in a tensor. — op_logsumexp","text":"tensor containing logarithm sum exponentials elements x.","code":""},{"path":"https://keras.posit.co/reference/op_logsumexp.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the logarithm of sum of exponentials of elements in a tensor. — op_logsumexp","text":"","code":"x <- op_convert_to_tensor(c(1, 2, 3)) op_logsumexp(x) ## tf.Tensor(3.407606, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_lu_factor.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the lower-upper decomposition of a square matrix. — op_lu_factor","title":"Computes the lower-upper decomposition of a square matrix. — op_lu_factor","text":"Computes lower-upper decomposition square matrix.","code":""},{"path":"https://keras.posit.co/reference/op_lu_factor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the lower-upper decomposition of a square matrix. — op_lu_factor","text":"","code":"op_lu_factor(x)"},{"path":"https://keras.posit.co/reference/op_lu_factor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the lower-upper decomposition of a square matrix. — op_lu_factor","text":"x tensor shape (..., M, M).","code":""},{"path":"https://keras.posit.co/reference/op_lu_factor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the lower-upper decomposition of a square matrix. — op_lu_factor","text":"tuple two tensors: tensor shape (..., M, M) containing lower upper triangular matrices tensor shape (..., M) containing pivots.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_matmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix product of two tensors. — op_matmul","title":"Matrix product of two tensors. — op_matmul","text":"tensors 1-dimensional, dot product (scalar) returned. either tensor N-D, N > 2, treated stack matrices residing last two indexes broadcast accordingly. first tensor 1-D, promoted matrix prepending 1 dimensions. matrix multiplication prepended 1 removed. second tensor 1-D, promoted matrix appending 1 dimensions. matrix multiplication appended 1 removed.","code":""},{"path":"https://keras.posit.co/reference/op_matmul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix product of two tensors. — op_matmul","text":"","code":"op_matmul(x1, x2)"},{"path":"https://keras.posit.co/reference/op_matmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix product of two tensors. — op_matmul","text":"x1 First tensor. x2 Second tensor.","code":""},{"path":"https://keras.posit.co/reference/op_matmul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix product of two tensors. — op_matmul","text":"Output tensor, matrix product inputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_max.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the maximum of a tensor or maximum along an axis. — op_max","title":"Return the maximum of a tensor or maximum along an axis. — op_max","text":"Return maximum tensor maximum along axis.","code":""},{"path":"https://keras.posit.co/reference/op_max.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the maximum of a tensor or maximum along an axis. — op_max","text":"","code":"op_max(x, axis = NULL, keepdims = FALSE, initial = NULL)"},{"path":"https://keras.posit.co/reference/op_max.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the maximum of a tensor or maximum along an axis. — op_max","text":"x Input tensor. axis Axis axes along operate. default, flattened input used. keepdims set TRUE, axes reduced left result dimensions size one. Defaults toFALSE. initial minimum value output element. Defaults toNULL.","code":""},{"path":"https://keras.posit.co/reference/op_max.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the maximum of a tensor or maximum along an axis. — op_max","text":"Maximum x.","code":""},{"path":"https://keras.posit.co/reference/op_max.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return the maximum of a tensor or maximum along an axis. — op_max","text":"","code":"(x <- op_convert_to_tensor(rbind(c(1, 3, 5), c(1, 5, 2)))) ## tf.Tensor( ## [[1. 3. 5.] ##  [1. 5. 2.]], shape=(2, 3), dtype=float64) op_max(x) ## tf.Tensor(5.0, shape=(), dtype=float64) op_max(x, axis = 1) ## tf.Tensor([1. 5. 5.], shape=(3), dtype=float64) op_max(x, axis = 1, keepdims = TRUE) ## tf.Tensor([[1. 5. 5.]], shape=(1, 3), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_max_pool.html","id":null,"dir":"Reference","previous_headings":"","what":"Max pooling operation. — op_max_pool","title":"Max pooling operation. — op_max_pool","text":"Max pooling operation.","code":""},{"path":"https://keras.posit.co/reference/op_max_pool.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max pooling operation. — op_max_pool","text":"","code":"op_max_pool(   inputs,   pool_size,   strides = NULL,   padding = \"valid\",   data_format = NULL )"},{"path":"https://keras.posit.co/reference/op_max_pool.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max pooling operation. — op_max_pool","text":"inputs Tensor rank N+2. inputs shape (batch_size,) + inputs_spatial_shape + (num_channels,) data_format = \"channels_last\", (batch_size, num_channels) + inputs_spatial_shape data_format = \"channels_first\". Pooling happens spatial dimensions . pool_size int tuple/list integers size len(inputs_spatial_shape), specifying size pooling window spatial dimension input tensor. pool_size int, every spatial dimension shares pool_size. strides int tuple/list integers size len(inputs_spatial_shape). stride sliding window spatial dimension input tensor. strides int, every spatial dimension shares strides. padding string, either \"valid\" \"\". \"valid\" means padding applied, \"\" results padding evenly left/right /input output height/width dimension input strides = 1. data_format string, either \"channels_last\" \"channels_first\". data_format determines ordering dimensions inputs. data_format = \"channels_last\", inputs shape (batch_size, ..., channels) data_format = \"channels_first\", inputs shape (batch_size, channels, ...).","code":""},{"path":"https://keras.posit.co/reference/op_max_pool.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Max pooling operation. — op_max_pool","text":"tensor rank N+2, result max pooling operation.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_maximum.html","id":null,"dir":"Reference","previous_headings":"","what":"Element-wise maximum of x1 and x2. — op_maximum","title":"Element-wise maximum of x1 and x2. — op_maximum","text":"Element-wise maximum x1 x2.","code":""},{"path":"https://keras.posit.co/reference/op_maximum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Element-wise maximum of x1 and x2. — op_maximum","text":"","code":"op_maximum(x1, x2)  op_pmax(x1, x2)"},{"path":"https://keras.posit.co/reference/op_maximum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Element-wise maximum of x1 and x2. — op_maximum","text":"x1 First tensor. x2 Second tensor.","code":""},{"path":"https://keras.posit.co/reference/op_maximum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Element-wise maximum of x1 and x2. — op_maximum","text":"Output tensor, element-wise maximum x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the arithmetic mean along the specified axes. — op_mean","title":"Compute the arithmetic mean along the specified axes. — op_mean","text":"Compute arithmetic mean along specified axes.","code":""},{"path":"https://keras.posit.co/reference/op_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the arithmetic mean along the specified axes. — op_mean","text":"","code":"op_mean(x, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the arithmetic mean along the specified axes. — op_mean","text":"x Input tensor. axis Axis axes along means computed. default compute mean flattened tensor. keepdims set TRUE, axes reduced left result dimensions size one.","code":""},{"path":"https://keras.posit.co/reference/op_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the arithmetic mean along the specified axes. — op_mean","text":"Output tensor containing mean values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the median along the specified axis. — op_median","title":"Compute the median along the specified axis. — op_median","text":"Compute median along specified axis.","code":""},{"path":"https://keras.posit.co/reference/op_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the median along the specified axis. — op_median","text":"","code":"op_median(x, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the median along the specified axis. — op_median","text":"x Input tensor. axis Axis axes along medians computed. Defaults axis = NULL compute median(s) along flattened version array. keepdims set TRUE, axes reduce left result dimensions size one.","code":""},{"path":"https://keras.posit.co/reference/op_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the median along the specified axis. — op_median","text":"output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_meshgrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates grids of coordinates from coordinate vectors. — op_meshgrid","title":"Creates grids of coordinates from coordinate vectors. — op_meshgrid","text":"Given N 1-D tensors T0, T1, ..., TN-1 inputs corresponding lengths S0, S1, ..., SN-1, creates N N-dimensional tensors G0, G1, ..., GN-1 shape (S0, ..., SN-1) output Gi constructed expanding Ti result shape.","code":""},{"path":"https://keras.posit.co/reference/op_meshgrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates grids of coordinates from coordinate vectors. — op_meshgrid","text":"","code":"op_meshgrid(..., indexing = \"xy\")"},{"path":"https://keras.posit.co/reference/op_meshgrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates grids of coordinates from coordinate vectors. — op_meshgrid","text":"... 1-D tensors representing coordinates grid. indexing \"xy\" \"ij\". \"xy\" cartesian; \"ij\" matrix indexing output. Defaults \"xy\".","code":""},{"path":"https://keras.posit.co/reference/op_meshgrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates grids of coordinates from coordinate vectors. — op_meshgrid","text":"Sequence N tensors.","code":""},{"path":"https://keras.posit.co/reference/op_meshgrid.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates grids of coordinates from coordinate vectors. — op_meshgrid","text":"","code":"x <- op_array(c(1, 2, 3), \"int32\") y <- op_array(c(4, 5, 6), \"int32\") c(grid_x, grid_y) %<-% op_meshgrid(x, y, indexing = \"ij\") grid_x ## tf.Tensor( ## [[1 1 1] ##  [2 2 2] ##  [3 3 3]], shape=(3, 3), dtype=int32) # array([[1, 1, 1], #        [2, 2, 2], #        [3, 3, 3])) grid_y ## tf.Tensor( ## [[4 5 6] ##  [4 5 6] ##  [4 5 6]], shape=(3, 3), dtype=int32) # array([[4, 5, 6], #        [4, 5, 6], #        [4, 5, 6]))"},{"path":[]},{"path":"https://keras.posit.co/reference/op_min.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the minimum of a tensor or minimum along an axis. — op_min","title":"Return the minimum of a tensor or minimum along an axis. — op_min","text":"Return minimum tensor minimum along axis.","code":""},{"path":"https://keras.posit.co/reference/op_min.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the minimum of a tensor or minimum along an axis. — op_min","text":"","code":"op_min(x, axis = NULL, keepdims = FALSE, initial = NULL)"},{"path":"https://keras.posit.co/reference/op_min.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the minimum of a tensor or minimum along an axis. — op_min","text":"x Input tensor. axis Axis axes along operate. default, flattened input used. keepdims set TRUE, axes reduced left result dimensions size one. Defaults toFALSE. initial maximum value output element. Defaults toNULL.","code":""},{"path":"https://keras.posit.co/reference/op_min.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the minimum of a tensor or minimum along an axis. — op_min","text":"Minimum x.","code":""},{"path":"https://keras.posit.co/reference/op_min.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return the minimum of a tensor or minimum along an axis. — op_min","text":"","code":"(x <- op_convert_to_tensor(rbind(c(1, 3, 5), c(1, 5, 2)))) ## tf.Tensor( ## [[1. 3. 5.] ##  [1. 5. 2.]], shape=(2, 3), dtype=float64) op_min(x) ## tf.Tensor(1.0, shape=(), dtype=float64) op_min(x, axis = 1) ## tf.Tensor([1. 3. 2.], shape=(3), dtype=float64) op_min(x, axis = 1, keepdims = TRUE) ## tf.Tensor([[1. 3. 2.]], shape=(1, 3), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_minimum.html","id":null,"dir":"Reference","previous_headings":"","what":"Element-wise minimum of x1 and x2. — op_minimum","title":"Element-wise minimum of x1 and x2. — op_minimum","text":"Element-wise minimum x1 x2.","code":""},{"path":"https://keras.posit.co/reference/op_minimum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Element-wise minimum of x1 and x2. — op_minimum","text":"","code":"op_minimum(x1, x2)  op_pmin(x1, x2)"},{"path":"https://keras.posit.co/reference/op_minimum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Element-wise minimum of x1 and x2. — op_minimum","text":"x1 First tensor. x2 Second tensor.","code":""},{"path":"https://keras.posit.co/reference/op_minimum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Element-wise minimum of x1 and x2. — op_minimum","text":"Output tensor, element-wise minimum x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the element-wise remainder of division. — op_mod","title":"Returns the element-wise remainder of division. — op_mod","text":"Note function automatically called using R operator %% tensor.","code":"(x <- op_arange(10)) ## tf.Tensor([0. 1. 2. 3. 4. 5. 6. 7. 8. 9.], shape=(10), dtype=float64) op_mod(x, 3) ## tf.Tensor([0. 1. 2. 0. 1. 2. 0. 1. 2. 0.], shape=(10), dtype=float64) x %% 3 ## tf.Tensor([0. 1. 2. 0. 1. 2. 0. 1. 2. 0.], shape=(10), dtype=float64)"},{"path":"https://keras.posit.co/reference/op_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the element-wise remainder of division. — op_mod","text":"","code":"op_mod(x1, x2)"},{"path":"https://keras.posit.co/reference/op_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the element-wise remainder of division. — op_mod","text":"x1 First tensor. x2 Second tensor.","code":""},{"path":"https://keras.posit.co/reference/op_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the element-wise remainder of division. — op_mod","text":"Output tensor, element-wise remainder division.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_moments.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the mean and variance of x. — op_moments","title":"Calculates the mean and variance of x. — op_moments","text":"mean variance calculated aggregating contents x across axes. x 1-D axes = c(1) just mean variance vector.","code":""},{"path":"https://keras.posit.co/reference/op_moments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the mean and variance of x. — op_moments","text":"","code":"op_moments(x, axes, keepdims = FALSE, synchronized = FALSE)"},{"path":"https://keras.posit.co/reference/op_moments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the mean and variance of x. — op_moments","text":"x Input tensor. axes list axes compute mean variance. keepdims set TRUE, axes reduced left result dimensions size one. synchronized applicable TensorFlow backend. TRUE, synchronizes global batch statistics (mean variance) across devices training step distributed training strategy. FALSE, replica uses local batch statistics.","code":""},{"path":"https://keras.posit.co/reference/op_moments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates the mean and variance of x. — op_moments","text":"list containing two tensors - mean variance.","code":""},{"path":"https://keras.posit.co/reference/op_moments.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates the mean and variance of x. — op_moments","text":"","code":"x <- op_convert_to_tensor(c(0, 1, 2, 3, 100), dtype = \"float32\") op_moments(x, axes = c(1)) ## [[1]] ## tf.Tensor(21.2, shape=(), dtype=float32) ## ## [[2]] ## tf.Tensor(1553.3601, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_moveaxis.html","id":null,"dir":"Reference","previous_headings":"","what":"Move axes of a tensor to new positions. — op_moveaxis","title":"Move axes of a tensor to new positions. — op_moveaxis","text":"axes remain original order.","code":""},{"path":"https://keras.posit.co/reference/op_moveaxis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move axes of a tensor to new positions. — op_moveaxis","text":"","code":"op_moveaxis(x, source, destination)"},{"path":"https://keras.posit.co/reference/op_moveaxis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move axes of a tensor to new positions. — op_moveaxis","text":"x Tensor whose axes reordered. source Original positions axes move. must unique. destination Destinations positions original axes. must also unique.","code":""},{"path":"https://keras.posit.co/reference/op_moveaxis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Move axes of a tensor to new positions. — op_moveaxis","text":"Tensor moved axes.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_multi_hot.html","id":null,"dir":"Reference","previous_headings":"","what":"Encodes integer labels as multi-hot vectors. — op_multi_hot","title":"Encodes integer labels as multi-hot vectors. — op_multi_hot","text":"function encodes integer labels multi-hot vectors, label mapped binary value resulting vector.","code":""},{"path":"https://keras.posit.co/reference/op_multi_hot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Encodes integer labels as multi-hot vectors. — op_multi_hot","text":"","code":"op_multi_hot(inputs, num_classes, axis = -1L, dtype = NULL, ...)"},{"path":"https://keras.posit.co/reference/op_multi_hot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Encodes integer labels as multi-hot vectors. — op_multi_hot","text":"inputs Tensor integer labels converted multi-hot vectors. num_classes Integer, total number unique classes. axis (optional) Axis along multi-hot encoding added. Defaults -1, corresponds last dimension. dtype (optional) data type resulting tensor. Default backend's float type. ... forward/backwards compatability","code":""},{"path":"https://keras.posit.co/reference/op_multi_hot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Encodes integer labels as multi-hot vectors. — op_multi_hot","text":"Tensor: multi-hot encoded tensor.","code":""},{"path":"https://keras.posit.co/reference/op_multi_hot.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Encodes integer labels as multi-hot vectors. — op_multi_hot","text":"","code":"data <- op_convert_to_tensor(c(0, 4)) op_multi_hot(data, num_classes = 5) ## tf.Tensor([1. 0. 0. 0. 1.], shape=(5), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_multiply.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiply arguments element-wise. — op_multiply","title":"Multiply arguments element-wise. — op_multiply","text":"Note function automatically called using R operator * tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_multiply(x, x) ## tf.Tensor([0. 1. 4. 9.], shape=(4), dtype=float64) x * x ## tf.Tensor([0. 1. 4. 9.], shape=(4), dtype=float64)"},{"path":"https://keras.posit.co/reference/op_multiply.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiply arguments element-wise. — op_multiply","text":"","code":"op_multiply(x1, x2)"},{"path":"https://keras.posit.co/reference/op_multiply.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiply arguments element-wise. — op_multiply","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_multiply.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiply arguments element-wise. — op_multiply","text":"Output tensor, element-wise product x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_nan_to_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace NaN with zero and infinity with large finite numbers. — op_nan_to_num","title":"Replace NaN with zero and infinity with large finite numbers. — op_nan_to_num","text":"Replace NaN zero infinity large finite numbers.","code":""},{"path":"https://keras.posit.co/reference/op_nan_to_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace NaN with zero and infinity with large finite numbers. — op_nan_to_num","text":"","code":"op_nan_to_num(x)"},{"path":"https://keras.posit.co/reference/op_nan_to_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace NaN with zero and infinity with large finite numbers. — op_nan_to_num","text":"x Input data.","code":""},{"path":"https://keras.posit.co/reference/op_nan_to_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace NaN with zero and infinity with large finite numbers. — op_nan_to_num","text":"x, non-finite values replaced.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_ndim.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the number of dimensions of a tensor. — op_ndim","title":"Return the number of dimensions of a tensor. — op_ndim","text":"Return number dimensions tensor.","code":""},{"path":"https://keras.posit.co/reference/op_ndim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the number of dimensions of a tensor. — op_ndim","text":"","code":"op_ndim(x)"},{"path":"https://keras.posit.co/reference/op_ndim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the number of dimensions of a tensor. — op_ndim","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_ndim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the number of dimensions of a tensor. — op_ndim","text":"number dimensions x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_negative.html","id":null,"dir":"Reference","previous_headings":"","what":"Numerical negative, element-wise. — op_negative","title":"Numerical negative, element-wise. — op_negative","text":"Note function automatically called using unary R operator - tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_negative(x) ## tf.Tensor([-0. -1. -2. -3.], shape=(4), dtype=float64) -x ## tf.Tensor([-0. -1. -2. -3.], shape=(4), dtype=float64)"},{"path":"https://keras.posit.co/reference/op_negative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numerical negative, element-wise. — op_negative","text":"","code":"op_negative(x)"},{"path":"https://keras.posit.co/reference/op_negative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numerical negative, element-wise. — op_negative","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_negative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Numerical negative, element-wise. — op_negative","text":"Output tensor, y = -x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_nonzero.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the indices of the elements that are non-zero. — op_nonzero","title":"Return the indices of the elements that are non-zero. — op_nonzero","text":"Return indices elements non-zero.","code":""},{"path":"https://keras.posit.co/reference/op_nonzero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the indices of the elements that are non-zero. — op_nonzero","text":"","code":"op_nonzero(x)"},{"path":"https://keras.posit.co/reference/op_nonzero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the indices of the elements that are non-zero. — op_nonzero","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_nonzero.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the indices of the elements that are non-zero. — op_nonzero","text":"Indices elements non-zero.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix or vector norm. — op_norm","title":"Matrix or vector norm. — op_norm","text":"function able return one eight different matrix norms, one infinite number vector norms (described ), depending value ord parameter.","code":""},{"path":"https://keras.posit.co/reference/op_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix or vector norm. — op_norm","text":"","code":"op_norm(x, ord = NULL, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix or vector norm. — op_norm","text":"x Input tensor. ord Order norm (see table Notes). default NULL. axis axis integer, specifies axis x along compute vector norms. axis length 2 vector, specifies axes hold 2-D matrices, matrix norms matrices computed. keepdims set TRUE, axes reduced left result dimensions size one.","code":""},{"path":"https://keras.posit.co/reference/op_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix or vector norm. — op_norm","text":"Norm matrix vector(s).","code":""},{"path":"https://keras.posit.co/reference/op_norm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Matrix or vector norm. — op_norm","text":"values ord < 1, result , strictly speaking, mathematical 'norm', may still useful various numerical purposes. following norms can calculated: matrices: ord=NULL: Frobenius norm ord=\"fro\": Frobenius norm ord=\"nuc\": nuclear norm ord=Inf: max(sum(abs(x), axis=2)) ord=-Inf: min(sum(abs(x), axis=2)) ord=0: supported ord=1: max(sum(abs(x), axis=1)) ord=-1: min(sum(abs(x), axis=1)) ord=2: 2-norm (largest sing. value) ord=-2: smallest singular value : supported vectors: ord=NULL: 2-norm ord=\"fro\": supported ord=\"nuc\": supported ord=Inf: max(abs(x)) ord=-Inf: min(abs(x)) ord=0: sum(x != 0) ord=1: ord=-1: ord=2: ord=-2: : sum(abs(x)^ord)^(1/ord)","code":""},{"path":"https://keras.posit.co/reference/op_norm.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix or vector norm. — op_norm","text":"","code":"x <- op_reshape(op_arange(9, dtype=\"float32\") - 4, c(3, 3)) op_norm(x) ## tf.Tensor(7.745967, shape=(), dtype=float32) # 7.7459664"},{"path":[]},{"path":"https://keras.posit.co/reference/op_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalizes x over the specified axis. — op_normalize","title":"Normalizes x over the specified axis. — op_normalize","text":"defined : normalize(x) = x / max(norm(x), epsilon).","code":""},{"path":"https://keras.posit.co/reference/op_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalizes x over the specified axis. — op_normalize","text":"","code":"op_normalize(x, axis = -1L, order = 2L)"},{"path":"https://keras.posit.co/reference/op_normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalizes x over the specified axis. — op_normalize","text":"x Input tensor. axis axis axes along perform normalization. Default -1. order exponent value norm formulation. Defaults 2.","code":""},{"path":"https://keras.posit.co/reference/op_normalize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalizes x over the specified axis. — op_normalize","text":"normalized array.","code":""},{"path":"https://keras.posit.co/reference/op_normalize.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalizes x over the specified axis. — op_normalize","text":"","code":"x <- op_convert_to_tensor(rbind(c(1, 2, 3), c(4, 5, 6))) x_norm <- op_normalize(x) x_norm ## tf.Tensor( ## [[0.26726124 0.53452248 0.80178373] ##  [0.45584231 0.56980288 0.68376346]], shape=(2, 3), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_not_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Return (x1 != x2) element-wise. — op_not_equal","title":"Return (x1 != x2) element-wise. — op_not_equal","text":"Note function automatically called using R operator != tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_not_equal(x, 2) ## tf.Tensor([ True  True False  True], shape=(4), dtype=bool) x != 2 ## tf.Tensor([ True  True False  True], shape=(4), dtype=bool)"},{"path":"https://keras.posit.co/reference/op_not_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return (x1 != x2) element-wise. — op_not_equal","text":"","code":"op_not_equal(x1, x2)"},{"path":"https://keras.posit.co/reference/op_not_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return (x1 != x2) element-wise. — op_not_equal","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_not_equal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return (x1 != x2) element-wise. — op_not_equal","text":"Output tensor, element-wise comparsion x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_one_hot.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts integer tensor x into a one-hot tensor. — op_one_hot","title":"Converts integer tensor x into a one-hot tensor. — op_one_hot","text":"one-hot encoding representation integer value converted binary vector length equal num_classes, index corresponding integer value marked 1, indices marked 0.","code":""},{"path":"https://keras.posit.co/reference/op_one_hot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts integer tensor x into a one-hot tensor. — op_one_hot","text":"","code":"op_one_hot(x, num_classes, axis = -1L, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_one_hot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts integer tensor x into a one-hot tensor. — op_one_hot","text":"x Integer tensor encoded. shape can arbitrary, dtype integer. R factors coerced integer offset 0-based, .e., .integer(x) - 1L. num_classes Number classes one-hot encoding. axis Axis along encoding performed. Defaults -1, represents last axis. dtype (Optional) Data type output tensor. provided, defaults default data type backend.","code":""},{"path":"https://keras.posit.co/reference/op_one_hot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts integer tensor x into a one-hot tensor. — op_one_hot","text":"Integer tensor: One-hot encoded tensor shape x except specified axis dimension, length num_classes. dtype output tensor determined dtype default data type backend.","code":""},{"path":"https://keras.posit.co/reference/op_one_hot.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts integer tensor x into a one-hot tensor. — op_one_hot","text":"","code":"x <- op_array(c(1, 3, 2, 0), \"int32\") op_one_hot(x, num_classes = 4) ## tf.Tensor( ## [[0. 1. 0. 0.] ##  [0. 0. 0. 1.] ##  [0. 0. 1. 0.] ##  [1. 0. 0. 0.]], shape=(4, 4), dtype=float32) # array([[0. 1. 0. 0.] #        [0. 0. 0. 1.] #        [0. 0. 1. 0.] #        [1. 0. 0. 0.]], shape=(4, 4), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_ones.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a new tensor of given shape and type, filled with ones. — op_ones","title":"Return a new tensor of given shape and type, filled with ones. — op_ones","text":"Return new tensor given shape type, filled ones.","code":""},{"path":"https://keras.posit.co/reference/op_ones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a new tensor of given shape and type, filled with ones. — op_ones","text":"","code":"op_ones(shape, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_ones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a new tensor of given shape and type, filled with ones. — op_ones","text":"shape Shape new tensor. dtype Desired data type tensor.","code":""},{"path":"https://keras.posit.co/reference/op_ones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a new tensor of given shape and type, filled with ones. — op_ones","text":"Tensor ones given shape dtype.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_ones_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a tensor of ones with the same shape and type of x. — op_ones_like","title":"Return a tensor of ones with the same shape and type of x. — op_ones_like","text":"Return tensor ones shape type x.","code":""},{"path":"https://keras.posit.co/reference/op_ones_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a tensor of ones with the same shape and type of x. — op_ones_like","text":"","code":"op_ones_like(x, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_ones_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a tensor of ones with the same shape and type of x. — op_ones_like","text":"x Input tensor. dtype Overrides data type result.","code":""},{"path":"https://keras.posit.co/reference/op_ones_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a tensor of ones with the same shape and type of x. — op_ones_like","text":"tensor ones shape type x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_outer.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the outer product of two vectors. — op_outer","title":"Compute the outer product of two vectors. — op_outer","text":"Given two vectors x1 x2, outer product :","code":"out[i, j] = x1[i] * x2[j]"},{"path":"https://keras.posit.co/reference/op_outer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the outer product of two vectors. — op_outer","text":"","code":"op_outer(x1, x2)"},{"path":"https://keras.posit.co/reference/op_outer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the outer product of two vectors. — op_outer","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_outer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the outer product of two vectors. — op_outer","text":"Outer product x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_pad.html","id":null,"dir":"Reference","previous_headings":"","what":"Pad a tensor. — op_pad","title":"Pad a tensor. — op_pad","text":"Pad tensor.","code":""},{"path":"https://keras.posit.co/reference/op_pad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pad a tensor. — op_pad","text":"","code":"op_pad(x, pad_width, mode = \"constant\", constant_values = NULL)"},{"path":"https://keras.posit.co/reference/op_pad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pad a tensor. — op_pad","text":"x Tensor pad. pad_width Number values padded edges axis. ((before_1, after_1), ...(before_N, after_N)) unique pad widths axis. ((, ),) yields pad axis. (pad,) int shortcut = = pad width axes. mode One \"constant\", \"edge\", \"linear_ramp\", \"maximum\", \"mean\", \"median\", \"minimum\", \"reflect\", \"symmetric\", \"wrap\", \"empty\", \"circular\". Defaults \"constant\". constant_values Value pad mode == \"constant\". Defaults 0. ValueError raised NULL mode != \"constant\".","code":""},{"path":"https://keras.posit.co/reference/op_pad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pad a tensor. — op_pad","text":"Padded tensor.","code":""},{"path":"https://keras.posit.co/reference/op_pad.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pad a tensor. — op_pad","text":"Torch backend supports modes \"constant\", \"reflect\", \"symmetric\" \"circular\". Torch backend supports \"circular\" mode. Note: Tensorflow backend supports modes \"constant\", \"reflect\" \"symmetric\".","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_power.html","id":null,"dir":"Reference","previous_headings":"","what":"First tensor elements raised to powers from second tensor, element-wise. — op_power","title":"First tensor elements raised to powers from second tensor, element-wise. — op_power","text":"Note function automatically called using R operator ^ tensor.","code":"(x <- op_arange(4)) ## tf.Tensor([0. 1. 2. 3.], shape=(4), dtype=float64) op_power(2, x) ## tf.Tensor([1. 2. 4. 8.], shape=(4), dtype=float64) 2 ^ x ## tf.Tensor([1. 2. 4. 8.], shape=(4), dtype=float64)"},{"path":"https://keras.posit.co/reference/op_power.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"First tensor elements raised to powers from second tensor, element-wise. — op_power","text":"","code":"op_power(x1, x2)"},{"path":"https://keras.posit.co/reference/op_power.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"First tensor elements raised to powers from second tensor, element-wise. — op_power","text":"x1 bases. x2 exponents.","code":""},{"path":"https://keras.posit.co/reference/op_power.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"First tensor elements raised to powers from second tensor, element-wise. — op_power","text":"Output tensor, bases x1 raised exponents x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_prod.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the product of tensor elements over a given axis. — op_prod","title":"Return the product of tensor elements over a given axis. — op_prod","text":"Return product tensor elements given axis.","code":""},{"path":"https://keras.posit.co/reference/op_prod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the product of tensor elements over a given axis. — op_prod","text":"","code":"op_prod(x, axis = NULL, keepdims = FALSE, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_prod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the product of tensor elements over a given axis. — op_prod","text":"x Input tensor. axis Axis axes along product performed. default, axis = NULL, compute product elements input tensor. keepdims set TRUE, axes reduce left result dimensions size one. dtype Data type returned tensor.","code":""},{"path":"https://keras.posit.co/reference/op_prod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the product of tensor elements over a given axis. — op_prod","text":"Product elements x given axis axes.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_qr.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the QR decomposition of a tensor. — op_qr","title":"Computes the QR decomposition of a tensor. — op_qr","text":"Computes QR decomposition tensor.","code":""},{"path":"https://keras.posit.co/reference/op_qr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the QR decomposition of a tensor. — op_qr","text":"","code":"op_qr(x, mode = \"reduced\")"},{"path":"https://keras.posit.co/reference/op_qr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the QR decomposition of a tensor. — op_qr","text":"x Input tensor shape (..., M, N). mode string specifying mode QR decomposition. 'reduced': Returns reduced QR decomposition. (default) 'complete': Returns complete QR decomposition.","code":""},{"path":"https://keras.posit.co/reference/op_qr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the QR decomposition of a tensor. — op_qr","text":"list containing two tensors. first tensor shape (..., M, K) orthogonal matrix q second tensor shape (..., K, N)upper triangular matrixr, K = min(M, N)`.","code":""},{"path":"https://keras.posit.co/reference/op_qr.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the QR decomposition of a tensor. — op_qr","text":"","code":"x <- op_convert_to_tensor(rbind(c(1, 2), c(3, 4), c(5, 6))) op_qr(x) ## $q ## tf.Tensor( ## [[-0.16903085  0.89708523] ##  [-0.50709255  0.27602622] ##  [-0.84515425 -0.34503278]], shape=(3, 2), dtype=float64) ## ## $r ## tf.Tensor( ## [[-5.91607978 -7.43735744] ##  [ 0.          0.82807867]], shape=(2, 2), dtype=float64) c(q, r) %<-% op_qr(x)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_quantile.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the q-th quantile(s) of the data along the specified axis. — op_quantile","title":"Compute the q-th quantile(s) of the data along the specified axis. — op_quantile","text":"Compute q-th quantile(s) data along specified axis.","code":""},{"path":"https://keras.posit.co/reference/op_quantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the q-th quantile(s) of the data along the specified axis. — op_quantile","text":"","code":"op_quantile(x, q, axis = NULL, method = \"linear\", keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_quantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the q-th quantile(s) of the data along the specified axis. — op_quantile","text":"x Input tensor. q Probability sequence probabilities quantiles compute. Values must 0 1 inclusive. axis Axis axes along quantiles computed. Defaults axis=NULL compute quantile(s) along flattened version array. method string specifies method use estimating quantile. Available methods \"linear\", \"lower\", \"higher\", \"midpoint\", \"nearest\". Defaults \"linear\". desired quantile lies two data points < j: \"linear\": + (j - ) * fraction, fraction fractional part index surrounded j. \"lower\": . \"higher\": j. \"midpoint\": (+ j) / 2 \"nearest\": j, whichever nearest. keepdims set TRUE, axes reduce left result dimensions size one.","code":""},{"path":"https://keras.posit.co/reference/op_quantile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the q-th quantile(s) of the data along the specified axis. — op_quantile","text":"quantile(s). q single probability axis=NULL, result scalar. multiple probabilies levels given, first axis result corresponds quantiles. axes axes remain reduction x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_ravel.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a contiguous flattened tensor. — op_ravel","title":"Return a contiguous flattened tensor. — op_ravel","text":"1-D tensor, containing elements input, returned.","code":""},{"path":"https://keras.posit.co/reference/op_ravel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a contiguous flattened tensor. — op_ravel","text":"","code":"op_ravel(x)"},{"path":"https://keras.posit.co/reference/op_ravel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a contiguous flattened tensor. — op_ravel","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_ravel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a contiguous flattened tensor. — op_ravel","text":"Output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_real.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the real part of the complex argument. — op_real","title":"Return the real part of the complex argument. — op_real","text":"Return real part complex argument.","code":""},{"path":"https://keras.posit.co/reference/op_real.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the real part of the complex argument. — op_real","text":"","code":"op_real(x)"},{"path":"https://keras.posit.co/reference/op_real.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the real part of the complex argument. — op_real","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_real.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the real part of the complex argument. — op_real","text":"real component complex argument.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_reciprocal.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the reciprocal of the argument, element-wise. — op_reciprocal","title":"Return the reciprocal of the argument, element-wise. — op_reciprocal","text":"Calculates 1/x.","code":""},{"path":"https://keras.posit.co/reference/op_reciprocal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the reciprocal of the argument, element-wise. — op_reciprocal","text":"","code":"op_reciprocal(x)"},{"path":"https://keras.posit.co/reference/op_reciprocal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the reciprocal of the argument, element-wise. — op_reciprocal","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_reciprocal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the reciprocal of the argument, element-wise. — op_reciprocal","text":"Output tensor, element-wise reciprocal x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Rectified linear unit activation function. — op_relu","title":"Rectified linear unit activation function. — op_relu","text":"defined f(x) = max(0, x).","code":""},{"path":"https://keras.posit.co/reference/op_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rectified linear unit activation function. — op_relu","text":"","code":"op_relu(x)"},{"path":"https://keras.posit.co/reference/op_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rectified linear unit activation function. — op_relu","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rectified linear unit activation function. — op_relu","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_relu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rectified linear unit activation function. — op_relu","text":"","code":"x1 <- op_convert_to_tensor(c(-1, 0, 1, 0.2)) op_relu(x1) ## tf.Tensor([0.  0.  1.  0.2], shape=(4), dtype=float32) x <- seq(-10, 10, .1) plot(x, op_relu(x))"},{"path":[]},{"path":"https://keras.posit.co/reference/op_relu6.html","id":null,"dir":"Reference","previous_headings":"","what":"Rectified linear unit activation function with upper bound of 6. — op_relu6","title":"Rectified linear unit activation function with upper bound of 6. — op_relu6","text":"defined f(x) = op_clip(x, 0, 6).","code":""},{"path":"https://keras.posit.co/reference/op_relu6.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rectified linear unit activation function with upper bound of 6. — op_relu6","text":"","code":"op_relu6(x)"},{"path":"https://keras.posit.co/reference/op_relu6.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rectified linear unit activation function with upper bound of 6. — op_relu6","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_relu6.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rectified linear unit activation function with upper bound of 6. — op_relu6","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_relu6.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rectified linear unit activation function with upper bound of 6. — op_relu6","text":"","code":"x <- op_convert_to_tensor(c(-3, -2, 0.1, 0.2, 6, 8)) op_relu6(x) ## tf.Tensor([0.  0.  0.1 0.2 6.  6. ], shape=(6), dtype=float32) x <- seq(-10, 10, .1) plot(x, op_relu6(x))"},{"path":[]},{"path":"https://keras.posit.co/reference/op_repeat.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeat each element of a tensor after themselves. — op_repeat","title":"Repeat each element of a tensor after themselves. — op_repeat","text":"Repeat element tensor .","code":""},{"path":"https://keras.posit.co/reference/op_repeat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeat each element of a tensor after themselves. — op_repeat","text":"","code":"op_repeat(x, repeats, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_repeat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeat each element of a tensor after themselves. — op_repeat","text":"x Input tensor. repeats number repetitions element. axis axis along repeat values. default, use flattened input array, return flat output array.","code":""},{"path":"https://keras.posit.co/reference/op_repeat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repeat each element of a tensor after themselves. — op_repeat","text":"Output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_reshape.html","id":null,"dir":"Reference","previous_headings":"","what":"Gives a new shape to a tensor without changing its data. — op_reshape","title":"Gives a new shape to a tensor without changing its data. — op_reshape","text":"Gives new shape tensor without changing data.","code":""},{"path":"https://keras.posit.co/reference/op_reshape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gives a new shape to a tensor without changing its data. — op_reshape","text":"","code":"op_reshape(x, newshape)"},{"path":"https://keras.posit.co/reference/op_reshape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gives a new shape to a tensor without changing its data. — op_reshape","text":"x Input tensor. newshape new shape compatible original shape. One shape dimension can -1 case value inferred length array remaining dimensions.","code":""},{"path":"https://keras.posit.co/reference/op_reshape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gives a new shape to a tensor without changing its data. — op_reshape","text":"reshaped tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_rfft.html","id":null,"dir":"Reference","previous_headings":"","what":"Real-valued Fast Fourier Transform along the last axis of the input. — op_rfft","title":"Real-valued Fast Fourier Transform along the last axis of the input. — op_rfft","text":"Computes 1D Discrete Fourier Transform real-valued signal inner-dimension input. Since Discrete Fourier Transform real-valued signal Hermitian-symmetric, RFFT returns fft_length / 2 + 1 unique components FFT: zero-frequency term, followed fft_length / 2 positive-frequency terms. Along axis RFFT computed , fft_length smaller corresponding dimension input, dimension cropped. larger, dimension padded zeros.","code":""},{"path":"https://keras.posit.co/reference/op_rfft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Real-valued Fast Fourier Transform along the last axis of the input. — op_rfft","text":"","code":"op_rfft(x, fft_length = NULL)"},{"path":"https://keras.posit.co/reference/op_rfft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Real-valued Fast Fourier Transform along the last axis of the input. — op_rfft","text":"x Input tensor. fft_length integer representing number fft length. specified, inferred length last axis x. Defaults NULL.","code":""},{"path":"https://keras.posit.co/reference/op_rfft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Real-valued Fast Fourier Transform along the last axis of the input. — op_rfft","text":"list containing two tensors - real imaginary parts output.","code":""},{"path":"https://keras.posit.co/reference/op_rfft.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Real-valued Fast Fourier Transform along the last axis of the input. — op_rfft","text":"","code":"x <- op_convert_to_tensor(c(0, 1, 2, 3, 4)) op_rfft(x) ## [[1]] ## tf.Tensor([10.  -2.5 -2.5], shape=(3), dtype=float32) ## ## [[2]] ## tf.Tensor([0.        3.440955  0.8122992], shape=(3), dtype=float32) op_rfft(x, 3) ## [[1]] ## tf.Tensor([ 3.  -1.5], shape=(2), dtype=float32) ## ## [[2]] ## tf.Tensor([0.        0.8660254], shape=(2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_roll.html","id":null,"dir":"Reference","previous_headings":"","what":"Roll tensor elements along a given axis. — op_roll","title":"Roll tensor elements along a given axis. — op_roll","text":"Elements roll beyond last position re-introduced first.","code":""},{"path":"https://keras.posit.co/reference/op_roll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Roll tensor elements along a given axis. — op_roll","text":"","code":"op_roll(x, shift, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_roll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Roll tensor elements along a given axis. — op_roll","text":"x Input tensor. shift number places elements shifted. axis axis along elements shifted. default, array flattened shifting, original shape restored.","code":""},{"path":"https://keras.posit.co/reference/op_roll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Roll tensor elements along a given axis. — op_roll","text":"Output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_round.html","id":null,"dir":"Reference","previous_headings":"","what":"Evenly round to the given number of decimals. — op_round","title":"Evenly round to the given number of decimals. — op_round","text":"Evenly round given number decimals.","code":""},{"path":"https://keras.posit.co/reference/op_round.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evenly round to the given number of decimals. — op_round","text":"","code":"op_round(x, decimals = 0L)"},{"path":"https://keras.posit.co/reference/op_round.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evenly round to the given number of decimals. — op_round","text":"x Input tensor. decimals Number decimal places round . Defaults 0.","code":""},{"path":"https://keras.posit.co/reference/op_round.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evenly round to the given number of decimals. — op_round","text":"Output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_rsqrt.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes reciprocal of square root of x element-wise. — op_rsqrt","title":"Computes reciprocal of square root of x element-wise. — op_rsqrt","text":"Computes reciprocal square root x element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_rsqrt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes reciprocal of square root of x element-wise. — op_rsqrt","text":"","code":"op_rsqrt(x)"},{"path":"https://keras.posit.co/reference/op_rsqrt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes reciprocal of square root of x element-wise. — op_rsqrt","text":"x input tensor","code":""},{"path":"https://keras.posit.co/reference/op_rsqrt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes reciprocal of square root of x element-wise. — op_rsqrt","text":"tensor dtype x.","code":""},{"path":"https://keras.posit.co/reference/op_rsqrt.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes reciprocal of square root of x element-wise. — op_rsqrt","text":"","code":"x <- op_convert_to_tensor(c(1, 10, 100)) op_rsqrt(x) ## tf.Tensor([1.         0.31622776 0.1       ], shape=(3), dtype=float32) # array([1, 0.31622776, 0.1], dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_scatter.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a tensor of shape shape where indices are set to values. — op_scatter","title":"Returns a tensor of shape shape where indices are set to values. — op_scatter","text":"high level, operation zeros[indices] = updates returns output. equivalent :","code":"output <- op_scatter_update(op_zeros(shape), indices, values)"},{"path":"https://keras.posit.co/reference/op_scatter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a tensor of shape shape where indices are set to values. — op_scatter","text":"","code":"op_scatter(indices, values, shape)"},{"path":"https://keras.posit.co/reference/op_scatter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a tensor of shape shape where indices are set to values. — op_scatter","text":"indices tensor list specifying indices values values. values tensor, values set indices. shape Shape output tensor.","code":""},{"path":"https://keras.posit.co/reference/op_scatter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns a tensor of shape shape where indices are set to values. — op_scatter","text":"tensor shape shape indices set values.","code":""},{"path":"https://keras.posit.co/reference/op_scatter.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns a tensor of shape shape where indices are set to values. — op_scatter","text":"","code":"indices <- rbind(c(1, 2), c(2, 2)) values <- op_array(c(1, 1)) op_scatter(indices, values, shape= c(2, 2)) ## tf.Tensor( ## [[0. 1.] ##  [0. 1.]], shape=(2, 2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_scatter_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update inputs via updates at scattered (sparse) indices. — op_scatter_update","title":"Update inputs via updates at scattered (sparse) indices. — op_scatter_update","text":"high level, operation inputs[indices] <- updates. Assume inputs tensor shape (D1, D2, ..., Dn), 2 main usages scatter_update. indices 2D tensor shape (num_updates, n), num_updates number updates perform, updates 1D tensor shape (num_updates). example, inputs op_zeros(c(4, 4, 4)), want update inputs[2, 3, 4] inputs[1, 2, 4] 1, can use:     2 indices 2D tensor shape (num_updates, k), num_updates number updates perform, k (k <= n) size index indices. updates n - k-D tensor shape (num_updates, shape(inputs)[-(1:k)]). example, inputs <- op_zeros(c(4, 4, 4)), want update inputs[1, 2, ] inputs[2, 3, ] [1, 1, 1, 1], indices shape (num_updates, 2) (k = 2), updates shape (num_updates, 4) (shape(inputs)[3:4] == 4). See code :","code":"inputs <- op_zeros(c(4, 4, 4)) indices <- rbind(c(2, 3, 4),                  c(1, 2, 4)) updates <- op_array(c(1, 1), \"float32\") op_scatter_update(inputs, indices, updates) ## tf.Tensor( ## [[[0. 0. 0. 0.] ##   [0. 0. 0. 1.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.]] ## ##  [[0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 1.] ##   [0. 0. 0. 0.]] ## ##  [[0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.]] ## ##  [[0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.]]], shape=(4, 4, 4), dtype=float32) inputs <- op_zeros(c(4, 4, 4)) indices <- rbind(c(2, 3),                  c(3, 4)) updates <- op_array(rbind(c(1, 1, 1, 1),                           c(1, 1, 1, 1)),                     \"float32\") op_scatter_update(inputs, indices, updates) ## tf.Tensor( ## [[[0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.]] ## ##  [[0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [1. 1. 1. 1.] ##   [0. 0. 0. 0.]] ## ##  [[0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [1. 1. 1. 1.]] ## ##  [[0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.] ##   [0. 0. 0. 0.]]], shape=(4, 4, 4), dtype=float32)"},{"path":"https://keras.posit.co/reference/op_scatter_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update inputs via updates at scattered (sparse) indices. — op_scatter_update","text":"","code":"op_scatter_update(inputs, indices, updates)"},{"path":"https://keras.posit.co/reference/op_scatter_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update inputs via updates at scattered (sparse) indices. — op_scatter_update","text":"inputs tensor, tensor updated. indices tensor list shape (N, inputs$ndim), specifying indices update. N number indices update, must equal first dimension updates. updates tensor, new values put inputs indices.","code":""},{"path":"https://keras.posit.co/reference/op_scatter_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update inputs via updates at scattered (sparse) indices. — op_scatter_update","text":"tensor, shape dtype inputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_segment_max.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the max of segments in a tensor. — op_segment_max","title":"Computes the max of segments in a tensor. — op_segment_max","text":"Computes max segments tensor.","code":""},{"path":"https://keras.posit.co/reference/op_segment_max.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the max of segments in a tensor. — op_segment_max","text":"","code":"op_segment_max(data, segment_ids, num_segments = NULL, sorted = FALSE)"},{"path":"https://keras.posit.co/reference/op_segment_max.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the max of segments in a tensor. — op_segment_max","text":"data Input tensor. segment_ids 1-D tensor containing segment indices element data. num_segments integer representing total number segments. specified, inferred maximum value segment_ids. sorted boolean indicating whether segment_ids sorted. Defaults toFALSE.","code":""},{"path":"https://keras.posit.co/reference/op_segment_max.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the max of segments in a tensor. — op_segment_max","text":"tensor containing max segments, element represents max corresponding segment data.","code":""},{"path":"https://keras.posit.co/reference/op_segment_max.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the max of segments in a tensor. — op_segment_max","text":"","code":"data <- op_convert_to_tensor(c(1, 2, 10, 20, 100, 200)) segment_ids <- op_array(c(1, 1, 2, 2, 3, 3), \"int32\") num_segments <- 3 op_segment_max(data, segment_ids, num_segments) ## tf.Tensor([  2.  20. 200.], shape=(3), dtype=float32) # array([2, 20, 200], dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_segment_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the sum of segments in a tensor. — op_segment_sum","title":"Computes the sum of segments in a tensor. — op_segment_sum","text":"Computes sum segments tensor.","code":""},{"path":"https://keras.posit.co/reference/op_segment_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the sum of segments in a tensor. — op_segment_sum","text":"","code":"op_segment_sum(data, segment_ids, num_segments = NULL, sorted = FALSE)"},{"path":"https://keras.posit.co/reference/op_segment_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the sum of segments in a tensor. — op_segment_sum","text":"data Input tensor. segment_ids 1-D tensor containing segment indices element data. num_segments integer representing total number segments. specified, inferred maximum value segment_ids. sorted boolean indicating whether segment_ids sorted. Defaults toFALSE.","code":""},{"path":"https://keras.posit.co/reference/op_segment_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the sum of segments in a tensor. — op_segment_sum","text":"tensor containing sum segments, element represents sum corresponding segment data.","code":""},{"path":"https://keras.posit.co/reference/op_segment_sum.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the sum of segments in a tensor. — op_segment_sum","text":"","code":"data <- op_array(c(1, 2, 10, 20, 100, 200)) segment_ids <- op_array(c(1, 1, 2, 2, 3, 3), \"int32\") num_segments <- 3 op_segment_sum(data, segment_ids, num_segments) ## tf.Tensor([  3.  30. 300.], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_selu.html","id":null,"dir":"Reference","previous_headings":"","what":"Scaled Exponential Linear Unit (SELU) activation function. — op_selu","title":"Scaled Exponential Linear Unit (SELU) activation function. — op_selu","text":"defined : f(x) =  scale * alpha * (exp(x) - 1.) x < 0, f(x) = scale * x x >= 0.","code":""},{"path":"https://keras.posit.co/reference/op_selu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scaled Exponential Linear Unit (SELU) activation function. — op_selu","text":"","code":"op_selu(x)"},{"path":"https://keras.posit.co/reference/op_selu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scaled Exponential Linear Unit (SELU) activation function. — op_selu","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_selu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scaled Exponential Linear Unit (SELU) activation function. — op_selu","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_selu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scaled Exponential Linear Unit (SELU) activation function. — op_selu","text":"","code":"x <- op_array(c(-1, 0, 1)) op_selu(x) ## tf.Tensor([-1.1113307  0.         1.050701 ], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_separable_conv.html","id":null,"dir":"Reference","previous_headings":"","what":"General N-D separable convolution. — op_separable_conv","title":"General N-D separable convolution. — op_separable_conv","text":"ops supports 1D 2D separable convolution. separable_conv depthwise conv followed pointwise conv.","code":""},{"path":"https://keras.posit.co/reference/op_separable_conv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General N-D separable convolution. — op_separable_conv","text":"","code":"op_separable_conv(   inputs,   depthwise_kernel,   pointwise_kernel,   strides = 1L,   padding = \"valid\",   data_format = NULL,   dilation_rate = 1L )"},{"path":"https://keras.posit.co/reference/op_separable_conv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General N-D separable convolution. — op_separable_conv","text":"inputs Tensor rank N+2. inputs shape (batch_size,) + inputs_spatial_shape + (num_channels,) data_format=\"channels_last\", (batch_size, num_channels) + inputs_spatial_shape data_format=\"channels_first\". depthwise_kernel Tensor rank N+2. depthwise_kernel shape [kernel_spatial_shape, num_input_channels, num_channels_multiplier], num_input_channels match number channels inputs. pointwise_kernel Tensor rank N+2. pointwise_kernel shape (*ones_like(kernel_spatial_shape), num_input_channels * num_channels_multiplier, num_output_channels). strides int int tuple/list len(inputs_spatial_shape), specifying strides convolution along spatial dimension. strides int, every spatial dimension shares strides. padding string, either \"valid\" \"\". \"valid\" means padding applied, \"\" results padding evenly left/right /input output height/width dimension input strides=1. data_format string, either \"channels_last\" \"channels_first\". data_format determines ordering dimensions inputs. data_format=\"channels_last\", inputs shape (batch_size, ..., channels) data_format=\"channels_first\", inputs shape (batch_size, channels, ...). dilation_rate int int tuple/list len(inputs_spatial_shape), specifying dilation rate use dilated convolution. dilation_rate int, every spatial dimension shares dilation_rate.","code":""},{"path":"https://keras.posit.co/reference/op_separable_conv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General N-D separable convolution. — op_separable_conv","text":"tensor rank N+2, result depthwise conv operation.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_shape.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the shape of the tensor input. — op_shape","title":"Gets the shape of the tensor input. — op_shape","text":"Gets shape tensor input.","code":""},{"path":"https://keras.posit.co/reference/op_shape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the shape of the tensor input. — op_shape","text":"","code":"op_shape(x)"},{"path":"https://keras.posit.co/reference/op_shape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the shape of the tensor input. — op_shape","text":"x tensor. function try access shape attribute input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_shape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gets the shape of the tensor input. — op_shape","text":"list integers NULL values, indicating shape input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_shape.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Gets the shape of the tensor input. — op_shape","text":"TensorFlow backend, x tf.Tensor dynamic shape, dimensions dynamic context compiled function tf.Tensor value instead static integer value.","code":""},{"path":"https://keras.posit.co/reference/op_shape.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gets the shape of the tensor input. — op_shape","text":"","code":"x <- op_zeros(c(8, 12)) op_shape(x) ## shape(8, 12)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid activation function. — op_sigmoid","title":"Sigmoid activation function. — op_sigmoid","text":"defined f(x) = 1 / (1 + exp(-x)).","code":""},{"path":"https://keras.posit.co/reference/op_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid activation function. — op_sigmoid","text":"","code":"op_sigmoid(x)"},{"path":"https://keras.posit.co/reference/op_sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sigmoid activation function. — op_sigmoid","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sigmoid activation function. — op_sigmoid","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_sigmoid.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sigmoid activation function. — op_sigmoid","text":"","code":"x <- op_convert_to_tensor(c(-6, 1, 0, 1, 6)) op_sigmoid(x) ## tf.Tensor([0.00247262 0.7310586  0.5        0.7310586  0.99752736], shape=(5), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_sign.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a tensor with the signs of the elements of x. — op_sign","title":"Returns a tensor with the signs of the elements of x. — op_sign","text":"Returns tensor signs elements x.","code":""},{"path":"https://keras.posit.co/reference/op_sign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a tensor with the signs of the elements of x. — op_sign","text":"","code":"op_sign(x)"},{"path":"https://keras.posit.co/reference/op_sign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a tensor with the signs of the elements of x. — op_sign","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_sign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns a tensor with the signs of the elements of x. — op_sign","text":"Output tensor shape x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_silu.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid Linear Unit (SiLU) activation function, also known as Swish. — op_silu","title":"Sigmoid Linear Unit (SiLU) activation function, also known as Swish. — op_silu","text":"SiLU activation function computed sigmoid function multiplied input. defined f(x) = x * sigmoid(x).","code":""},{"path":"https://keras.posit.co/reference/op_silu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid Linear Unit (SiLU) activation function, also known as Swish. — op_silu","text":"","code":"op_silu(x)"},{"path":"https://keras.posit.co/reference/op_silu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sigmoid Linear Unit (SiLU) activation function, also known as Swish. — op_silu","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_silu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sigmoid Linear Unit (SiLU) activation function, also known as Swish. — op_silu","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_silu.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sigmoid Linear Unit (SiLU) activation function, also known as Swish. — op_silu","text":"","code":"x <- op_convert_to_tensor(c(-6, 1, 0, 1, 6)) op_sigmoid(x) ## tf.Tensor([0.00247262 0.7310586  0.5        0.7310586  0.99752736], shape=(5), dtype=float32) op_silu(x) ## tf.Tensor([-0.01483574  0.7310586   0.          0.7310586   5.985164  ], shape=(5), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_sin.html","id":null,"dir":"Reference","previous_headings":"","what":"Trigonometric sine, element-wise. — op_sin","title":"Trigonometric sine, element-wise. — op_sin","text":"Trigonometric sine, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_sin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trigonometric sine, element-wise. — op_sin","text":"","code":"op_sin(x)"},{"path":"https://keras.posit.co/reference/op_sin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trigonometric sine, element-wise. — op_sin","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_sin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trigonometric sine, element-wise. — op_sin","text":"Output tensor shape x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_sinh.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperbolic sine, element-wise. — op_sinh","title":"Hyperbolic sine, element-wise. — op_sinh","text":"Hyperbolic sine, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_sinh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperbolic sine, element-wise. — op_sinh","text":"","code":"op_sinh(x)"},{"path":"https://keras.posit.co/reference/op_sinh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperbolic sine, element-wise. — op_sinh","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_sinh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperbolic sine, element-wise. — op_sinh","text":"Output tensor shape x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_size.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the number of elements in a tensor. — op_size","title":"Return the number of elements in a tensor. — op_size","text":"Return number elements tensor.","code":""},{"path":"https://keras.posit.co/reference/op_size.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the number of elements in a tensor. — op_size","text":"","code":"op_size(x)"},{"path":"https://keras.posit.co/reference/op_size.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the number of elements in a tensor. — op_size","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_size.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the number of elements in a tensor. — op_size","text":"Number elements x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_slice.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a slice of an input tensor. — op_slice","title":"Return a slice of an input tensor. — op_slice","text":"high level, operation explicit replacement array slicing e.g. inputs[start_indices:(start_indices + shape)]. Unlike slicing via brackets, operation accept tensor start indices backends, useful indices dynamically computed via tensor operations.","code":"(inputs <- op_arange(5*5) |> op_reshape(c(5, 5))) ## tf.Tensor( ## [[ 0.  1.  2.  3.  4.] ##  [ 5.  6.  7.  8.  9.] ##  [10. 11. 12. 13. 14.] ##  [15. 16. 17. 18. 19.] ##  [20. 21. 22. 23. 24.]], shape=(5, 5), dtype=float64) start_indices <- c(3, 3) shape <- c(2, 2) op_slice(inputs, start_indices, shape) ## tf.Tensor( ## [[12. 13.] ##  [17. 18.]], shape=(2, 2), dtype=float64)"},{"path":"https://keras.posit.co/reference/op_slice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a slice of an input tensor. — op_slice","text":"","code":"op_slice(inputs, start_indices, shape)"},{"path":"https://keras.posit.co/reference/op_slice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a slice of an input tensor. — op_slice","text":"inputs tensor, tensor sliced. start_indices list length inputs$ndim, specifying starting indices updating. shape full shape returned slice.","code":""},{"path":"https://keras.posit.co/reference/op_slice.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a slice of an input tensor. — op_slice","text":"tensor, shape dtype inputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_slice_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an input by slicing in a tensor of updated values. — op_slice_update","title":"Update an input by slicing in a tensor of updated values. — op_slice_update","text":"high level, operation inputs[start_indices: start_indices + updates.shape] = updates. Assume inputs tensor shape (D1, D2, ..., Dn), start_indices must list n integers, specifying starting indices. updates must rank inputs, size dim must exceed Di - start_indices[]. example, 2D inputs inputs = op_zeros(c(5, 5)), want update intersection last 2 rows last 2 columns 1, .e., inputs[4:5, 4:5] = op_ones(c(2, 2)), can use code :","code":"inputs <- op_zeros(c(5, 5)) start_indices <- c(3, 3) updates <- op_ones(c(2, 2)) op_slice_update(inputs, start_indices, updates) ## tf.Tensor( ## [[0. 0. 0. 0. 0.] ##  [0. 0. 0. 0. 0.] ##  [0. 0. 1. 1. 0.] ##  [0. 0. 1. 1. 0.] ##  [0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)"},{"path":"https://keras.posit.co/reference/op_slice_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an input by slicing in a tensor of updated values. — op_slice_update","text":"","code":"op_slice_update(inputs, start_indices, updates)"},{"path":"https://keras.posit.co/reference/op_slice_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an input by slicing in a tensor of updated values. — op_slice_update","text":"inputs tensor, tensor updated. start_indices list length inputs$ndim, specifying starting indices updating. updates tensor, new values put inputs indices. updates must rank inputs.","code":""},{"path":"https://keras.posit.co/reference/op_slice_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update an input by slicing in a tensor of updated values. — op_slice_update","text":"tensor, shape dtype inputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax activation function. — op_softmax","title":"Softmax activation function. — op_softmax","text":"elements output vector lie within range (0, 1), total sum exactly 1 (excluding floating point rounding error). vector processed independently. axis argument specifies axis along function applied within input. defined : f(x) = exp(x) / sum(exp(x))","code":""},{"path":"https://keras.posit.co/reference/op_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax activation function. — op_softmax","text":"","code":"op_softmax(x, axis = -1L)"},{"path":"https://keras.posit.co/reference/op_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax activation function. — op_softmax","text":"x Input tensor. axis Integer, axis along softmax applied.","code":""},{"path":"https://keras.posit.co/reference/op_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax activation function. — op_softmax","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_softmax.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax activation function. — op_softmax","text":"","code":"x <- op_array(c(-1, 0, 1)) op_softmax(x) ## tf.Tensor([0.09003057 0.24472848 0.66524094], shape=(3), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_softplus.html","id":null,"dir":"Reference","previous_headings":"","what":"Softplus activation function. — op_softplus","title":"Softplus activation function. — op_softplus","text":"defined f(x) = log(exp(x) + 1), log natural logarithm exp exponential function.","code":""},{"path":"https://keras.posit.co/reference/op_softplus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softplus activation function. — op_softplus","text":"","code":"op_softplus(x)"},{"path":"https://keras.posit.co/reference/op_softplus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softplus activation function. — op_softplus","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_softplus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softplus activation function. — op_softplus","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_softplus.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softplus activation function. — op_softplus","text":"","code":"x <- op_convert_to_tensor(c(-0.555, 0, 0.555)) op_softplus(x) ## tf.Tensor([0.45366603 0.6931472  1.008666  ], shape=(3), dtype=float32) x <- seq(-10, 10, .1) plot(x, op_softplus(x))"},{"path":[]},{"path":"https://keras.posit.co/reference/op_softsign.html","id":null,"dir":"Reference","previous_headings":"","what":"Softsign activation function. — op_softsign","title":"Softsign activation function. — op_softsign","text":"defined f(x) = x / (abs(x) + 1).","code":""},{"path":"https://keras.posit.co/reference/op_softsign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softsign activation function. — op_softsign","text":"","code":"op_softsign(x)"},{"path":"https://keras.posit.co/reference/op_softsign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softsign activation function. — op_softsign","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_softsign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softsign activation function. — op_softsign","text":"tensor shape x.","code":""},{"path":"https://keras.posit.co/reference/op_softsign.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softsign activation function. — op_softsign","text":"","code":"x <- op_convert_to_tensor(c(-0.100, -10.0, 1.0, 0.0, 100.0)) op_softsign(x) ## tf.Tensor([-0.09090909 -0.90909094  0.5         0.          0.990099  ], shape=(5), dtype=float32) x <- seq(-10, 10, .1) plot(x, op_softsign(x), ylim = c(-1, 1))"},{"path":[]},{"path":"https://keras.posit.co/reference/op_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"Solves a linear system of equations given by a x = b. — op_solve","title":"Solves a linear system of equations given by a x = b. — op_solve","text":"Solves x equation %*% x == b.","code":""},{"path":"https://keras.posit.co/reference/op_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solves a linear system of equations given by a x = b. — op_solve","text":"","code":"op_solve(a, b)"},{"path":"https://keras.posit.co/reference/op_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solves a linear system of equations given by a x = b. — op_solve","text":"tensor shape (..., M, M) representing coefficients matrix. b tensor shape (..., M) (..., M, N) represeting right-hand side \"dependent variable\" matrix.","code":""},{"path":"https://keras.posit.co/reference/op_solve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solves a linear system of equations given by a x = b. — op_solve","text":"tensor shape (..., M) (..., M, N) representing solution linear system. Returned shape identical b.","code":""},{"path":"https://keras.posit.co/reference/op_solve.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solves a linear system of equations given by a x = b. — op_solve","text":"","code":"a <- op_array(c(1, 2, 4, 5), dtype=\"float32\") |> op_reshape(c(2, 2)) b <- op_array(c(2, 4, 8, 10), dtype=\"float32\") |> op_reshape(c(2, 2)) op_solve(a, b) ## tf.Tensor( ## [[2. 0.] ##  [0. 2.]], shape=(2, 2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_solve_triangular.html","id":null,"dir":"Reference","previous_headings":"","what":"Solves a linear system of equations given by a %*% x = b. — op_solve_triangular","title":"Solves a linear system of equations given by a %*% x = b. — op_solve_triangular","text":"Solves linear system equations given %*% x = b.","code":""},{"path":"https://keras.posit.co/reference/op_solve_triangular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solves a linear system of equations given by a %*% x = b. — op_solve_triangular","text":"","code":"op_solve_triangular(a, b, lower = FALSE)"},{"path":"https://keras.posit.co/reference/op_solve_triangular.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solves a linear system of equations given by a %*% x = b. — op_solve_triangular","text":"tensor shape (..., M, M) representing coefficients matrix. b tensor shape (..., M) (..., M, N) represeting right-hand side \"dependent variable\" matrix. lower logical. Use data contained lower triangle . Default use upper triangle.","code":""},{"path":"https://keras.posit.co/reference/op_solve_triangular.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solves a linear system of equations given by a %*% x = b. — op_solve_triangular","text":"tensor shape (..., M) (..., M, N) representing solution linear system. Returned shape identical b.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_sort.html","id":null,"dir":"Reference","previous_headings":"","what":"Sorts the elements of x along a given axis in ascending order. — op_sort","title":"Sorts the elements of x along a given axis in ascending order. — op_sort","text":"Sorts elements x along given axis ascending order.","code":""},{"path":"https://keras.posit.co/reference/op_sort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sorts the elements of x along a given axis in ascending order. — op_sort","text":"","code":"op_sort(x, axis = -1L)"},{"path":"https://keras.posit.co/reference/op_sort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sorts the elements of x along a given axis in ascending order. — op_sort","text":"x Input tensor. axis Axis along sort. NULL, tensor flattened sorting. Defaults -1; last axis.","code":""},{"path":"https://keras.posit.co/reference/op_sort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sorts the elements of x along a given axis in ascending order. — op_sort","text":"Sorted tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_sparse_categorical_crossentropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes sparse categorical cross-entropy loss. — op_sparse_categorical_crossentropy","title":"Computes sparse categorical cross-entropy loss. — op_sparse_categorical_crossentropy","text":"sparse categorical cross-entropy loss similar categorical cross-entropy, used target tensor contains integer class labels instead one-hot encoded vectors. measures dissimilarity target output probabilities logits.","code":""},{"path":"https://keras.posit.co/reference/op_sparse_categorical_crossentropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes sparse categorical cross-entropy loss. — op_sparse_categorical_crossentropy","text":"","code":"op_sparse_categorical_crossentropy(   target,   output,   from_logits = FALSE,   axis = -1L )"},{"path":"https://keras.posit.co/reference/op_sparse_categorical_crossentropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes sparse categorical cross-entropy loss. — op_sparse_categorical_crossentropy","text":"target target tensor representing true class labels integers. shape match shape output tensor except last dimension. output output tensor representing predicted probabilities logits. shape match shape target tensor except last dimension. from_logits (optional) Whether output tensor logits probabilities. Set TRUE output represents logits; otherwise, set FALSE output represents probabilities. Defaults toFALSE. axis (optional) axis along sparse categorical cross-entropy computed. Defaults -1, corresponds last dimension tensors.","code":""},{"path":"https://keras.posit.co/reference/op_sparse_categorical_crossentropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes sparse categorical cross-entropy loss. — op_sparse_categorical_crossentropy","text":"Integer tensor: computed sparse categorical cross-entropy loss target output.","code":""},{"path":"https://keras.posit.co/reference/op_sparse_categorical_crossentropy.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes sparse categorical cross-entropy loss. — op_sparse_categorical_crossentropy","text":"","code":"target <- op_array(c(0, 1, 2), dtype=\"int32\") output <- op_array(rbind(c(0.9, 0.05, 0.05),                         c(0.1, 0.8,  0.1),                         c(0.2, 0.3,  0.5))) op_sparse_categorical_crossentropy(target, output) ## tf.Tensor([0.10536052 0.22314355 0.69314718], shape=(3), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split a tensor into chunks. — op_split","title":"Split a tensor into chunks. — op_split","text":"Split tensor chunks.","code":""},{"path":"https://keras.posit.co/reference/op_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split a tensor into chunks. — op_split","text":"","code":"op_split(x, indices_or_sections, axis = 1L)"},{"path":"https://keras.posit.co/reference/op_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split a tensor into chunks. — op_split","text":"x Input tensor. indices_or_sections integer, N, tensor split N equal sections along axis. 1-D array sorted integers, entries indicate indices tensor split along axis. axis Axis along split. Defaults 1, first axis.","code":""},{"path":"https://keras.posit.co/reference/op_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split a tensor into chunks. — op_split","text":"list tensors.","code":""},{"path":"https://keras.posit.co/reference/op_split.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Split a tensor into chunks. — op_split","text":"split result equal division using Torch backend.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_sqrt.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the non-negative square root of a tensor, element-wise. — op_sqrt","title":"Return the non-negative square root of a tensor, element-wise. — op_sqrt","text":"Return non-negative square root tensor, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_sqrt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the non-negative square root of a tensor, element-wise. — op_sqrt","text":"","code":"op_sqrt(x)"},{"path":"https://keras.posit.co/reference/op_sqrt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the non-negative square root of a tensor, element-wise. — op_sqrt","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_sqrt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the non-negative square root of a tensor, element-wise. — op_sqrt","text":"Output tensor, non-negative square root x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_square.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the element-wise square of the input. — op_square","title":"Return the element-wise square of the input. — op_square","text":"Return element-wise square input.","code":""},{"path":"https://keras.posit.co/reference/op_square.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the element-wise square of the input. — op_square","text":"","code":"op_square(x)"},{"path":"https://keras.posit.co/reference/op_square.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the element-wise square of the input. — op_square","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_square.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the element-wise square of the input. — op_square","text":"Output tensor, square x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_squeeze.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove axes of length one from x. — op_squeeze","title":"Remove axes of length one from x. — op_squeeze","text":"Remove axes length one x.","code":""},{"path":"https://keras.posit.co/reference/op_squeeze.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove axes of length one from x. — op_squeeze","text":"","code":"op_squeeze(x, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_squeeze.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove axes of length one from x. — op_squeeze","text":"x Input tensor. axis Select subset entries length one shape.","code":""},{"path":"https://keras.posit.co/reference/op_squeeze.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove axes of length one from x. — op_squeeze","text":"input tensor subset dimensions length 1 removed.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Join a sequence of tensors along a new axis. — op_stack","title":"Join a sequence of tensors along a new axis. — op_stack","text":"axis parameter specifies index new axis dimensions result.","code":""},{"path":"https://keras.posit.co/reference/op_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join a sequence of tensors along a new axis. — op_stack","text":"","code":"op_stack(x, axis = 1L)"},{"path":"https://keras.posit.co/reference/op_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join a sequence of tensors along a new axis. — op_stack","text":"x sequence tensors. axis Axis along stack. Defaults 1, first axis.","code":""},{"path":"https://keras.posit.co/reference/op_stack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Join a sequence of tensors along a new axis. — op_stack","text":"stacked tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_std.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the standard deviation along the specified axis. — op_std","title":"Compute the standard deviation along the specified axis. — op_std","text":"Compute standard deviation along specified axis.","code":""},{"path":"https://keras.posit.co/reference/op_std.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the standard deviation along the specified axis. — op_std","text":"","code":"op_std(x, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_std.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the standard deviation along the specified axis. — op_std","text":"x Input tensor. axis Axis along compute standard deviation. Default compute standard deviation flattened tensor. keepdims set TRUE, axes reduced left result dimensions size one.","code":""},{"path":"https://keras.posit.co/reference/op_std.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the standard deviation along the specified axis. — op_std","text":"Output tensor containing standard deviation values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_stft.html","id":null,"dir":"Reference","previous_headings":"","what":"Short-Time Fourier Transform along the last axis of the input. — op_stft","title":"Short-Time Fourier Transform along the last axis of the input. — op_stft","text":"STFT computes Fourier transform short overlapping windows input. giving frequency components signal change time.","code":""},{"path":"https://keras.posit.co/reference/op_stft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Short-Time Fourier Transform along the last axis of the input. — op_stft","text":"","code":"op_stft(   x,   sequence_length,   sequence_stride,   fft_length,   window = \"hann\",   center = TRUE )"},{"path":"https://keras.posit.co/reference/op_stft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Short-Time Fourier Transform along the last axis of the input. — op_stft","text":"x Input tensor. sequence_length integer representing sequence length. sequence_stride integer representing sequence hop size. fft_length integer representing size FFT apply. specified, uses smallest power 2 enclosing sequence_length. window string, tensor window NULL. window string, available values \"hann\" \"hamming\". window tensor, used directly window length must sequence_length. window NULL, windowing used. Defaults \"hann\". center Whether pad x sides t-th sequence centered time t * sequence_stride. Otherwise, t-th sequence begins time t * sequence_stride. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/op_stft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Short-Time Fourier Transform along the last axis of the input. — op_stft","text":"list containing two tensors - real imaginary parts STFT output.","code":""},{"path":"https://keras.posit.co/reference/op_stft.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Short-Time Fourier Transform along the last axis of the input. — op_stft","text":"","code":"x <- op_array(c(0, 1, 2, 3, 4)) op_stft(x, 3, 2, 3) ## [[1]] ## tf.Tensor( ## [[ 0.  0.] ##  [ 2. -1.] ##  [ 4. -2.]], shape=(3, 2), dtype=float32) ## ## [[2]] ## tf.Tensor( ## [[ 0.         0.       ] ##  [ 0.        -1.7320508] ##  [ 0.        -3.4641016]], shape=(3, 2), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_stop_gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Stops gradient computation. — op_stop_gradient","title":"Stops gradient computation. — op_stop_gradient","text":"Stops gradient computation.","code":""},{"path":"https://keras.posit.co/reference/op_stop_gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stops gradient computation. — op_stop_gradient","text":"","code":"op_stop_gradient(variable)"},{"path":"https://keras.posit.co/reference/op_stop_gradient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stops gradient computation. — op_stop_gradient","text":"variable tensor variable gradient computation disabled.","code":""},{"path":"https://keras.posit.co/reference/op_stop_gradient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stops gradient computation. — op_stop_gradient","text":"variable gradient computation disabled.","code":""},{"path":"https://keras.posit.co/reference/op_stop_gradient.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stops gradient computation. — op_stop_gradient","text":"","code":"var <- op_convert_to_tensor(c(1, 2, 3), dtype=\"float32\") var <- op_stop_gradient(var)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_subtract.html","id":null,"dir":"Reference","previous_headings":"","what":"Subtract arguments element-wise. — op_subtract","title":"Subtract arguments element-wise. — op_subtract","text":"Note function automatically called using R operator - tensor.","code":"x <- op_ones(c(3)) op_subtract(x, x) ## tf.Tensor([0. 0. 0.], shape=(3), dtype=float32) x - x ## tf.Tensor([0. 0. 0.], shape=(3), dtype=float32)"},{"path":"https://keras.posit.co/reference/op_subtract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subtract arguments element-wise. — op_subtract","text":"","code":"op_subtract(x1, x2)"},{"path":"https://keras.posit.co/reference/op_subtract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subtract arguments element-wise. — op_subtract","text":"x1 First input tensor. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_subtract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subtract arguments element-wise. — op_subtract","text":"Output tensor, element-wise difference x1 x2.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Sum of a tensor over the given axes. — op_sum","title":"Sum of a tensor over the given axes. — op_sum","text":"Sum tensor given axes.","code":""},{"path":"https://keras.posit.co/reference/op_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sum of a tensor over the given axes. — op_sum","text":"","code":"op_sum(x, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sum of a tensor over the given axes. — op_sum","text":"x Input tensor. axis Axis axes along sum computed. default compute sum flattened tensor. keepdims set TRUE, axes reduced left result dimensions size one.","code":""},{"path":"https://keras.posit.co/reference/op_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sum of a tensor over the given axes. — op_sum","text":"Output tensor containing sum.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_svd.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the singular value decomposition of a matrix. — op_svd","title":"Computes the singular value decomposition of a matrix. — op_svd","text":"Computes singular value decomposition matrix.","code":""},{"path":"https://keras.posit.co/reference/op_svd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the singular value decomposition of a matrix. — op_svd","text":"","code":"op_svd(x, full_matrices = TRUE, compute_uv = TRUE)"},{"path":"https://keras.posit.co/reference/op_svd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the singular value decomposition of a matrix. — op_svd","text":"x Input tensor shape (..., M, N). full_matrices Logical compute_uv Logical","code":""},{"path":"https://keras.posit.co/reference/op_svd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the singular value decomposition of a matrix. — op_svd","text":"list three tensors: tensor shape (..., M, M) containing left singular vectors, tensor shape (..., M, N) containing singular values tensor shape (..., N, N) containing right singular vectors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_swapaxes.html","id":null,"dir":"Reference","previous_headings":"","what":"Interchange two axes of a tensor. — op_swapaxes","title":"Interchange two axes of a tensor. — op_swapaxes","text":"Interchange two axes tensor.","code":""},{"path":"https://keras.posit.co/reference/op_swapaxes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interchange two axes of a tensor. — op_swapaxes","text":"","code":"op_swapaxes(x, axis1, axis2)"},{"path":"https://keras.posit.co/reference/op_swapaxes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interchange two axes of a tensor. — op_swapaxes","text":"x Input tensor. axis1 First axis. axis2 Second axis.","code":""},{"path":"https://keras.posit.co/reference/op_swapaxes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interchange two axes of a tensor. — op_swapaxes","text":"tensor axes swapped.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_take.html","id":null,"dir":"Reference","previous_headings":"","what":"Take elements from a tensor along an axis. — op_take","title":"Take elements from a tensor along an axis. — op_take","text":"Take elements tensor along axis.","code":""},{"path":"https://keras.posit.co/reference/op_take.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Take elements from a tensor along an axis. — op_take","text":"","code":"op_take(x, indices, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_take.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Take elements from a tensor along an axis. — op_take","text":"x Source tensor. indices indices values extract. axis axis select values. default, flattened input tensor used.","code":""},{"path":"https://keras.posit.co/reference/op_take.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Take elements from a tensor along an axis. — op_take","text":"corresponding tensor values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_take_along_axis.html","id":null,"dir":"Reference","previous_headings":"","what":"Select values from x at the 1-D indices along the given axis. — op_take_along_axis","title":"Select values from x at the 1-D indices along the given axis. — op_take_along_axis","text":"Select values x 1-D indices along given axis.","code":""},{"path":"https://keras.posit.co/reference/op_take_along_axis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select values from x at the 1-D indices along the given axis. — op_take_along_axis","text":"","code":"op_take_along_axis(x, indices, axis = NULL)"},{"path":"https://keras.posit.co/reference/op_take_along_axis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select values from x at the 1-D indices along the given axis. — op_take_along_axis","text":"x Source tensor. indices indices values extract. axis axis select values. default, flattened input tensor used.","code":""},{"path":"https://keras.posit.co/reference/op_take_along_axis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select values from x at the 1-D indices along the given axis. — op_take_along_axis","text":"corresponding tensor values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_tan.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute tangent, element-wise. — op_tan","title":"Compute tangent, element-wise. — op_tan","text":"Compute tangent, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_tan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute tangent, element-wise. — op_tan","text":"","code":"op_tan(x)"},{"path":"https://keras.posit.co/reference/op_tan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute tangent, element-wise. — op_tan","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_tan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute tangent, element-wise. — op_tan","text":"Output tensor shape x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_tanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperbolic tangent, element-wise. — op_tanh","title":"Hyperbolic tangent, element-wise. — op_tanh","text":"Hyperbolic tangent, element-wise.","code":""},{"path":"https://keras.posit.co/reference/op_tanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperbolic tangent, element-wise. — op_tanh","text":"","code":"op_tanh(x)"},{"path":"https://keras.posit.co/reference/op_tanh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperbolic tangent, element-wise. — op_tanh","text":"x Input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_tanh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperbolic tangent, element-wise. — op_tanh","text":"Output tensor shape x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_tensordot.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the tensor dot product along specified axes. — op_tensordot","title":"Compute the tensor dot product along specified axes. — op_tensordot","text":"Compute tensor dot product along specified axes.","code":""},{"path":"https://keras.posit.co/reference/op_tensordot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the tensor dot product along specified axes. — op_tensordot","text":"","code":"op_tensordot(x1, x2, axes = 3L)"},{"path":"https://keras.posit.co/reference/op_tensordot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the tensor dot product along specified axes. — op_tensordot","text":"x1 First tensor. x2 Second tensor. axes integer, N, sum last N axes x1 first N axes x2 order. sizes corresponding axes must match. , list axes summed , first sequence applying x1, second x2. sequences must length.","code":""},{"path":"https://keras.posit.co/reference/op_tensordot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the tensor dot product along specified axes. — op_tensordot","text":"tensor dot product inputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_tile.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeat x the number of times given by repeats. — op_tile","title":"Repeat x the number of times given by repeats. — op_tile","text":"repeats length d, result dimension max(d, x.ndim). x.ndim < d, x promoted d-dimensional prepending new axes. x.ndim > d, repeats promoted x.ndim prepending 1's .","code":""},{"path":"https://keras.posit.co/reference/op_tile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeat x the number of times given by repeats. — op_tile","text":"","code":"op_tile(x, repeats)"},{"path":"https://keras.posit.co/reference/op_tile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeat x the number of times given by repeats. — op_tile","text":"x Input tensor. repeats number repetitions x along axis.","code":""},{"path":"https://keras.posit.co/reference/op_tile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repeat x the number of times given by repeats. — op_tile","text":"tiled output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_top_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Finds the top-k values and their indices in a tensor. — op_top_k","title":"Finds the top-k values and their indices in a tensor. — op_top_k","text":"Finds top-k values indices tensor.","code":""},{"path":"https://keras.posit.co/reference/op_top_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finds the top-k values and their indices in a tensor. — op_top_k","text":"","code":"op_top_k(x, k, sorted = TRUE)"},{"path":"https://keras.posit.co/reference/op_top_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finds the top-k values and their indices in a tensor. — op_top_k","text":"x Input tensor. k integer representing number top elements retrieve. sorted boolean indicating whether sort output descending order. Defaults toTRUE.","code":""},{"path":"https://keras.posit.co/reference/op_top_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finds the top-k values and their indices in a tensor. — op_top_k","text":"list containing two tensors. first tensor contains top-k values, second tensor contains indices top-k values input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_top_k.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Finds the top-k values and their indices in a tensor. — op_top_k","text":"","code":"x <- op_array(c(5, 2, 7, 1, 9, 3), \"int32\") op_top_k(x, k = 3) ## $values ## tf.Tensor([9 7 5], shape=(3), dtype=int32) ## ## $indices ## tf.Tensor([4 2 0], shape=(3), dtype=int32) c(values, indices) %<-% op_top_k(x, k = 3) values ## tf.Tensor([9 7 5], shape=(3), dtype=int32) indices ## tf.Tensor([4 2 0], shape=(3), dtype=int32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the sum along diagonals of the tensor. — op_trace","title":"Return the sum along diagonals of the tensor. — op_trace","text":"x 2-D, sum along diagonal given offset returned, .e., sum elements x[, +offset] . two dimensions, axes specified axis1 axis2 used determine 2-D sub-arrays whose traces returned. shape resulting tensor x axis1 axis2 removed.","code":""},{"path":"https://keras.posit.co/reference/op_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the sum along diagonals of the tensor. — op_trace","text":"","code":"op_trace(x, offset = 0L, axis1 = 1L, axis2 = 2L)"},{"path":"https://keras.posit.co/reference/op_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the sum along diagonals of the tensor. — op_trace","text":"x Input tensor. offset Offset diagonal main diagonal. Can positive negative. Defaults 0. axis1 Axis used first axis 2-D sub-arrays. Defaults 1. (first axis). axis2 Axis used second axis 2-D sub-arrays. Defaults 2. (second axis).","code":""},{"path":"https://keras.posit.co/reference/op_trace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the sum along diagonals of the tensor. — op_trace","text":"x 2-D, sum diagonal returned. x larger dimensions, tensor sums along diagonals returned.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a tensor with axes transposed. — op_transpose","title":"Returns a tensor with axes transposed. — op_transpose","text":"Returns tensor axes transposed.","code":""},{"path":"https://keras.posit.co/reference/op_transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a tensor with axes transposed. — op_transpose","text":"","code":"op_transpose(x, axes = NULL)"},{"path":"https://keras.posit.co/reference/op_transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a tensor with axes transposed. — op_transpose","text":"x Input tensor. axes Sequence integers. Permutation dimensions x. default, order axes reversed.","code":""},{"path":"https://keras.posit.co/reference/op_transpose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns a tensor with axes transposed. — op_transpose","text":"x axes permuted.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a tensor with ones at and below a diagonal and zeros elsewhere. — op_tri","title":"Return a tensor with ones at and below a diagonal and zeros elsewhere. — op_tri","text":"Return tensor ones diagonal zeros elsewhere.","code":""},{"path":"https://keras.posit.co/reference/op_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a tensor with ones at and below a diagonal and zeros elsewhere. — op_tri","text":"","code":"op_tri(N, M = NULL, k = 0L, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a tensor with ones at and below a diagonal and zeros elsewhere. — op_tri","text":"N Number rows tensor. M Number columns tensor. k sub-diagonal array filled. k = 0 main diagonal, k < 0 , k > 0 . default 0. dtype Data type returned tensor. default \"float32\".","code":""},{"path":"https://keras.posit.co/reference/op_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a tensor with ones at and below a diagonal and zeros elsewhere. — op_tri","text":"Tensor lower triangle filled ones zeros elsewhere. T[, j] == 1 j <= + k, 0 otherwise.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_tril.html","id":null,"dir":"Reference","previous_headings":"","what":"Return lower triangle of a tensor. — op_tril","title":"Return lower triangle of a tensor. — op_tril","text":"tensors ndim exceeding 2, tril apply final two axes.","code":""},{"path":"https://keras.posit.co/reference/op_tril.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return lower triangle of a tensor. — op_tril","text":"","code":"op_tril(x, k = 0L)"},{"path":"https://keras.posit.co/reference/op_tril.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return lower triangle of a tensor. — op_tril","text":"x Input tensor. k Diagonal zero elements. Defaults 0. main diagonal. k < 0 , k > 0 .","code":""},{"path":"https://keras.posit.co/reference/op_tril.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return lower triangle of a tensor. — op_tril","text":"Lower triangle x, shape data type x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_triu.html","id":null,"dir":"Reference","previous_headings":"","what":"Return upper triangle of a tensor. — op_triu","title":"Return upper triangle of a tensor. — op_triu","text":"tensors ndim exceeding 2, triu apply final two axes.","code":""},{"path":"https://keras.posit.co/reference/op_triu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return upper triangle of a tensor. — op_triu","text":"","code":"op_triu(x, k = 0L)"},{"path":"https://keras.posit.co/reference/op_triu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return upper triangle of a tensor. — op_triu","text":"x Input tensor. k Diagonal zero elements. Defaults 0. main diagonal. k < 0 , k > 0 .","code":""},{"path":"https://keras.posit.co/reference/op_triu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return upper triangle of a tensor. — op_triu","text":"Upper triangle x, shape data type x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_unstack.html","id":null,"dir":"Reference","previous_headings":"","what":"Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors. — op_unstack","title":"Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors. — op_unstack","text":"Unpacks given dimension rank-R tensor rank-(R-1) tensors.","code":""},{"path":"https://keras.posit.co/reference/op_unstack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors. — op_unstack","text":"","code":"op_unstack(x, num = NULL, axis = 1L)"},{"path":"https://keras.posit.co/reference/op_unstack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors. — op_unstack","text":"x input tensor. num length dimension axis. Automatically inferred NULL. axis axis along unpack.","code":""},{"path":"https://keras.posit.co/reference/op_unstack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors. — op_unstack","text":"list tensors unpacked along given axis.","code":""},{"path":"https://keras.posit.co/reference/op_unstack.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors. — op_unstack","text":"[3, 4))]: R:3,%204))","code":"x <- op_array(rbind(c(1, 2),                    c(3, 4))) op_unstack(x, axis=1) ## [[1]] ## tf.Tensor([1. 2.], shape=(2), dtype=float64) ## ## [[2]] ## tf.Tensor([3. 4.], shape=(2), dtype=float64) op_unstack(x, axis=2) ## [[1]] ## tf.Tensor([1. 3.], shape=(2), dtype=float64) ## ## [[2]] ## tf.Tensor([2. 4.], shape=(2), dtype=float64) all.equal(op_unstack(x),           op_unstack(x, axis = 1)) ## [1] TRUE all.equal(op_unstack(x, axis = -1),           op_unstack(x, axis = 2)) ## [1] TRUE # [array([1, 2)), array([3, 4))]"},{"path":[]},{"path":"https://keras.posit.co/reference/op_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the variance along the specified axes. — op_var","title":"Compute the variance along the specified axes. — op_var","text":"Compute variance along specified axes.","code":""},{"path":"https://keras.posit.co/reference/op_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the variance along the specified axes. — op_var","text":"","code":"op_var(x, axis = NULL, keepdims = FALSE)"},{"path":"https://keras.posit.co/reference/op_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the variance along the specified axes. — op_var","text":"x Input tensor. axis Axis axes along variance computed. default compute variance flattened tensor. keepdims set TRUE, axes reduced left result dimensions size one.","code":""},{"path":"https://keras.posit.co/reference/op_var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the variance along the specified axes. — op_var","text":"Output tensor containing variance.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_vdot.html","id":null,"dir":"Reference","previous_headings":"","what":"Return the dot product of two vectors. — op_vdot","title":"Return the dot product of two vectors. — op_vdot","text":"first argument complex, complex conjugate first argument used calculation dot product. Multidimensional tensors flattened dot product taken.","code":""},{"path":"https://keras.posit.co/reference/op_vdot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return the dot product of two vectors. — op_vdot","text":"","code":"op_vdot(x1, x2)"},{"path":"https://keras.posit.co/reference/op_vdot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return the dot product of two vectors. — op_vdot","text":"x1 First input tensor. complex, complex conjugate taken calculation dot product. x2 Second input tensor.","code":""},{"path":"https://keras.posit.co/reference/op_vdot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return the dot product of two vectors. — op_vdot","text":"Output tensor.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_vectorized_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel map of function f on the first axis of tensor(s) elements. — op_vectorized_map","title":"Parallel map of function f on the first axis of tensor(s) elements. — op_vectorized_map","text":"Schematically, op_vectorized_map() maps first dimension provided tensors. elements list tensors, tensors required size first dimension, iterated together.","code":""},{"path":"https://keras.posit.co/reference/op_vectorized_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel map of function f on the first axis of tensor(s) elements. — op_vectorized_map","text":"","code":"op_vectorized_map(elements, f)"},{"path":"https://keras.posit.co/reference/op_vectorized_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel map of function f on the first axis of tensor(s) elements. — op_vectorized_map","text":"elements see description f function taking either tensor, list tensors.","code":""},{"path":"https://keras.posit.co/reference/op_vectorized_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel map of function f on the first axis of tensor(s) elements. — op_vectorized_map","text":"tensor list tensors, result mapping f across elements.","code":""},{"path":"https://keras.posit.co/reference/op_vectorized_map.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel map of function f on the first axis of tensor(s) elements. — op_vectorized_map","text":"Note f may traced compiled. Meaning, R function may evaluated symbolic tensors using Jax TensorFlow backends, eager tensors. See output str() examples:","code":"(x <- op_arange(12L) |> op_reshape(c(3, 4))) ## tf.Tensor( ## [[ 0  1  2  3] ##  [ 4  5  6  7] ##  [ 8  9 10 11]], shape=(3, 4), dtype=int32) x |> op_vectorized_map(\\(row) {row + 10}) ## tf.Tensor( ## [[10 11 12 13] ##  [14 15 16 17] ##  [18 19 20 21]], shape=(3, 4), dtype=int32) list(x, x, x) |> op_vectorized_map(\\(rows) Reduce(`+`, rows)) ## tf.Tensor( ## [[ 0  3  6  9] ##  [12 15 18 21] ##  [24 27 30 33]], shape=(3, 4), dtype=int32) # simplest case, map f over rows of x, # where .x is 1 row of x input <- x output <- op_vectorized_map(input, function(.x) {   str(.x)   .x + 10 }) ## <tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32> output ## tf.Tensor( ## [[10 11 12 13] ##  [14 15 16 17] ##  [18 19 20 21]], shape=(3, 4), dtype=int32) # map f over two tensors simultaneously. Here, # `.x` is a list of two # tensors. The return values from each call of `f(row)` are stacked to form the # final output input <- list(x, x) output <- op_vectorized_map(input, function(.x) {   str(.x)   .x[[1]] + 10 }) ## List of 2 ##  $ :<tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32> ##  $ :<tf.Tensor 'loop_body/GatherV2_1:0' shape=(4) dtype=int32> output ## tf.Tensor( ## [[10 11 12 13] ##  [14 15 16 17] ##  [18 19 20 21]], shape=(3, 4), dtype=int32) # same as above, but now returning two tensors in the final output output <- op_vectorized_map(input, function(.x) {   str(.x)   c(.x1, .x2) %<-% .x   list(.x1+10, .x2+20) }) ## List of 2 ##  $ :<tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32> ##  $ :<tf.Tensor 'loop_body/GatherV2_1:0' shape=(4) dtype=int32> output ## [[1]] ## tf.Tensor( ## [[10 11 12 13] ##  [14 15 16 17] ##  [18 19 20 21]], shape=(3, 4), dtype=int32) ## ## [[2]] ## tf.Tensor( ## [[20 21 22 23] ##  [24 25 26 27] ##  [28 29 30 31]], shape=(3, 4), dtype=int32) # passing named lists. # WARNING: if passing a named list, the order of elements of `.x` supplied # to `f` is not stable. Only retrieve elements by name. input <- list(name1 = x, name2 = x) output <- op_vectorized_map(input, function(.x) {   str(.x)   list(outname1 = .x$name1 + 10,        outname2 = .x$name2 + 20) }) ## List of 2 ##  $ name1:<tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32> ##  $ name2:<tf.Tensor 'loop_body/GatherV2_1:0' shape=(4) dtype=int32> output ## $outname1 ## tf.Tensor( ## [[10 11 12 13] ##  [14 15 16 17] ##  [18 19 20 21]], shape=(3, 4), dtype=int32) ## ## $outname2 ## tf.Tensor( ## [[20 21 22 23] ##  [24 25 26 27] ##  [28 29 30 31]], shape=(3, 4), dtype=int32) # passing a tuple() is equivalent to passing an unnamed list() input <- tuple(x, x) output <- op_vectorized_map(input, function(.x) {   str(.x)   list(.x[[1]] + 10) }) ## List of 2 ##  $ :<tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32> ##  $ :<tf.Tensor 'loop_body/GatherV2_1:0' shape=(4) dtype=int32> output ## [[1]] ## tf.Tensor( ## [[10 11 12 13] ##  [14 15 16 17] ##  [18 19 20 21]], shape=(3, 4), dtype=int32)"},{"path":"https://keras.posit.co/reference/op_vectorized_map.html","id":"debugging-f","dir":"Reference","previous_headings":"","what":"Debugging f","title":"Parallel map of function f on the first axis of tensor(s) elements. — op_vectorized_map","text":"Even eager contexts, op_vectorized_map() may trace f. case, want eagerly debug f (e.g., browser()), can swap manual (slow) implementation op_vectorized_map(). Note example debug implementation handle edge cases op_vectorized_map(), particular, f returns structure multiple tensors.","code":"op_vectorized_map_debug <- function(elements, fn) {    if (!is.list(elements)) {     # `elements` is a single tensor     batch_size <- op_shape(elements)[[1]]     out <- elements |>       op_split(batch_size) |>       lapply(fn) |>       op_stack()     return(out)   }    # `elements` is a list of tensors   batch_size <- elements[[1]] |> op_shape() |> _[[1]]   elements |>     lapply(\\(e) op_split(e, batch_size)) |>     zip_lists() |>     lapply(fn) |>     op_stack()  }"},{"path":[]},{"path":"https://keras.posit.co/reference/op_vstack.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack tensors in sequence vertically (row wise). — op_vstack","title":"Stack tensors in sequence vertically (row wise). — op_vstack","text":"Stack tensors sequence vertically (row wise).","code":""},{"path":"https://keras.posit.co/reference/op_vstack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack tensors in sequence vertically (row wise). — op_vstack","text":"","code":"op_vstack(xs)"},{"path":"https://keras.posit.co/reference/op_vstack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack tensors in sequence vertically (row wise). — op_vstack","text":"xs Sequence tensors.","code":""},{"path":"https://keras.posit.co/reference/op_vstack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack tensors in sequence vertically (row wise). — op_vstack","text":"Tensor formed stacking given tensors.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_where.html","id":null,"dir":"Reference","previous_headings":"","what":"Return elements chosen from x1 or x2 depending on condition. — op_where","title":"Return elements chosen from x1 or x2 depending on condition. — op_where","text":"Return elements chosen x1 x2 depending condition.","code":""},{"path":"https://keras.posit.co/reference/op_where.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return elements chosen from x1 or x2 depending on condition. — op_where","text":"","code":"op_where(condition, x1 = NULL, x2 = NULL)"},{"path":"https://keras.posit.co/reference/op_where.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return elements chosen from x1 or x2 depending on condition. — op_where","text":"condition TRUE, yield x1, otherwise yield x2. x1 Values choose condition TRUE. x2 Values choose condition FALSE.","code":""},{"path":"https://keras.posit.co/reference/op_where.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return elements chosen from x1 or x2 depending on condition. — op_where","text":"tensor elements x1 condition TRUE, elements x2 condition FALSE.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_while_loop.html","id":null,"dir":"Reference","previous_headings":"","what":"While loop implementation. — op_while_loop","title":"While loop implementation. — op_while_loop","text":"loop implementation.","code":""},{"path":"https://keras.posit.co/reference/op_while_loop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"While loop implementation. — op_while_loop","text":"","code":"op_while_loop(cond, body, loop_vars, maximum_iterations = NULL)"},{"path":"https://keras.posit.co/reference/op_while_loop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"While loop implementation. — op_while_loop","text":"cond callable represents termination condition loop. Must accept loop_vars like structure argument. loop_vars tuple unnamed list, element loop_vars passed positionally callable. body callable represents loop body. Must accept loop_vars like structure argument, return update value structure. loop_vars tuple unnamed list, element loop_vars passed positionally callable. loop_vars arbitrary nested structure tensor state persist across loop iterations. maximum_iterations Optional maximum number iterations loop run. provided, cond output -ed additional condition ensuring number iterations executed greater maximum_iterations.","code":""},{"path":"https://keras.posit.co/reference/op_while_loop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"While loop implementation. — op_while_loop","text":"list tensors, shape dtype loop_vars.","code":""},{"path":"https://keras.posit.co/reference/op_while_loop.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"While loop implementation. — op_while_loop","text":"","code":"i <- 0 loop_vars <- list(i)  # cond() must return a scalar bool cond <- function(i) i < 10L  # body must return same shape as loop_vars body <- function(i) list(i + 1L)  op_while_loop(cond, body, loop_vars) ## [[1]] ## tf.Tensor(10.0, shape=(), dtype=float32) x <- 0; y <- 1 cond <- \\(x, y) x < 10 body <- \\(x, y) list(x+1, y+1) op_while_loop(cond, body, list(x, y)) ## [[1]] ## tf.Tensor(10.0, shape=(), dtype=float32) ## ## [[2]] ## tf.Tensor(11.0, shape=(), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/op_zeros.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a new tensor of given shape and type, filled with zeros. — op_zeros","title":"Return a new tensor of given shape and type, filled with zeros. — op_zeros","text":"Return new tensor given shape type, filled zeros.","code":""},{"path":"https://keras.posit.co/reference/op_zeros.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a new tensor of given shape and type, filled with zeros. — op_zeros","text":"","code":"op_zeros(shape, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_zeros.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a new tensor of given shape and type, filled with zeros. — op_zeros","text":"shape Shape new tensor. dtype Desired data type tensor.","code":""},{"path":"https://keras.posit.co/reference/op_zeros.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a new tensor of given shape and type, filled with zeros. — op_zeros","text":"Tensor zeros given shape dtype.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/op_zeros_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a tensor of zeros with the same shape and type as x. — op_zeros_like","title":"Return a tensor of zeros with the same shape and type as x. — op_zeros_like","text":"Return tensor zeros shape type x.","code":""},{"path":"https://keras.posit.co/reference/op_zeros_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a tensor of zeros with the same shape and type as x. — op_zeros_like","text":"","code":"op_zeros_like(x, dtype = NULL)"},{"path":"https://keras.posit.co/reference/op_zeros_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a tensor of zeros with the same shape and type as x. — op_zeros_like","text":"x Input tensor. dtype Overrides data type result.","code":""},{"path":"https://keras.posit.co/reference/op_zeros_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a tensor of zeros with the same shape and type as x. — op_zeros_like","text":"tensor zeros shape type x.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_adadelta.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the Adadelta algorithm. — optimizer_adadelta","title":"Optimizer that implements the Adadelta algorithm. — optimizer_adadelta","text":"Adadelta optimization stochastic gradient descent method based adaptive learning rate per dimension address two drawbacks: continual decay learning rates throughout training. need manually selected global learning rate. Adadelta robust extension Adagrad adapts learning rates based moving window gradient updates, instead accumulating past gradients. way, Adadelta continues learning even many updates done. Compared Adagrad, original version Adadelta set initial learning rate. version, initial learning rate can set, Keras optimizers.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adadelta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the Adadelta algorithm. — optimizer_adadelta","text":"","code":"optimizer_adadelta(   learning_rate = 0.001,   rho = 0.95,   epsilon = 1e-07,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"adadelta\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_adadelta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the Adadelta algorithm. — optimizer_adadelta","text":"learning_rate float, [LearningRateSchedule()] instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. Note Adadelta tends benefit higher initial learning rate values compared optimizers. match exact form original paper, use 1.0. rho floating point value. decay rate. Defaults 0.95. epsilon Small floating point value maintaining numerical stability. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema = TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema = TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adadelta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the Adadelta algorithm. — optimizer_adadelta","text":"Optimizer instance","code":""},{"path":"https://keras.posit.co/reference/optimizer_adadelta.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Optimizer that implements the Adadelta algorithm. — optimizer_adadelta","text":"Zeiler, 2012","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_adafactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the Adafactor algorithm. — optimizer_adafactor","title":"Optimizer that implements the Adafactor algorithm. — optimizer_adafactor","text":"Adafactor commonly used NLP tasks, advantage taking less memory saves partial information previous gradients. default argument setup based original paper (see reference). gradients dimension > 2, Adafactor optimizer delete last 2 dimensions separately accumulator variables.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adafactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the Adafactor algorithm. — optimizer_adafactor","text":"","code":"optimizer_adafactor(   learning_rate = 0.001,   beta_2_decay = -0.8,   epsilon_1 = 1e-30,   epsilon_2 = 0.001,   clip_threshold = 1,   relative_step = TRUE,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"adafactor\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_adafactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the Adafactor algorithm. — optimizer_adafactor","text":"learning_rate float, LearningRateSchedule() instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. beta_2_decay float, defaults -0.8. decay rate beta_2. epsilon_1 float, defaults 1e-30. small offset keep denominator away 0. epsilon_2 float, defaults 1e-3. small offset avoid learning rate becoming small time. clip_threshold float, defaults 1.0. Clipping threshold. part Adafactor algorithm, independent clipnorm, clipvalue, global_clipnorm. relative_step bool, defaults TRUE. learning_rate constant relative_step=TRUE, learning rate adjusted based current iterations. default learning rate decay Adafactor. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema = TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adafactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the Adafactor algorithm. — optimizer_adafactor","text":"Optimizer instance","code":""},{"path":"https://keras.posit.co/reference/optimizer_adafactor.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Optimizer that implements the Adafactor algorithm. — optimizer_adafactor","text":"Shazeer, Noam et al., 2018.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_adagrad.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the Adagrad algorithm. — optimizer_adagrad","title":"Optimizer that implements the Adagrad algorithm. — optimizer_adagrad","text":"Adagrad optimizer parameter-specific learning rates, adapted relative frequently parameter gets updated training. updates parameter receives, smaller updates.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adagrad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the Adagrad algorithm. — optimizer_adagrad","text":"","code":"optimizer_adagrad(   learning_rate = 0.001,   initial_accumulator_value = 0.1,   epsilon = 1e-07,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"adagrad\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_adagrad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the Adagrad algorithm. — optimizer_adagrad","text":"learning_rate float, LearningRateSchedule() instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. Note Adagrad tends benefit higher initial learning rate values compared optimizers. match exact form original paper, use 1.0. initial_accumulator_value Floating point value. Starting value accumulators (per-parameter momentum values). Must non-negative. epsilon Small floating point value maintaining numerical stability. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adagrad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the Adagrad algorithm. — optimizer_adagrad","text":"Optimizer instance","code":""},{"path":"https://keras.posit.co/reference/optimizer_adagrad.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Optimizer that implements the Adagrad algorithm. — optimizer_adagrad","text":"Duchi et al., 2011.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_adam.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the Adam algorithm. — optimizer_adam","title":"Optimizer that implements the Adam algorithm. — optimizer_adam","text":"Adam optimization stochastic gradient descent method based adaptive estimation first-order second-order moments. According Kingma et al., 2014, method \"computationally efficient, little memory requirement, invariant diagonal rescaling gradients, well suited problems large terms data/parameters\".","code":""},{"path":"https://keras.posit.co/reference/optimizer_adam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the Adam algorithm. — optimizer_adam","text":"","code":"optimizer_adam(   learning_rate = 0.001,   beta_1 = 0.9,   beta_2 = 0.999,   epsilon = 1e-07,   amsgrad = FALSE,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"adam\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_adam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the Adam algorithm. — optimizer_adam","text":"learning_rate float, LearningRateSchedule() instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. beta_1 float value constant float tensor, callable takes arguments returns actual value use. exponential decay rate 1st moment estimates. Defaults 0.9. beta_2 float value constant float tensor, callable takes arguments returns actual value use. exponential decay rate 2nd moment estimates. Defaults 0.999. epsilon small constant numerical stability. epsilon \"epsilon hat\" Kingma Ba paper (formula just Section 2.1), epsilon Algorithm 1 paper. Defaults 1e-7. amsgrad Boolean. Whether apply AMSGrad variant algorithm paper \"Convergence Adam beyond\". Defaults FALSE. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the Adam algorithm. — optimizer_adam","text":"Optimizer instance","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_adam_w.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the AdamW algorithm. — optimizer_adam_w","title":"Optimizer that implements the AdamW algorithm. — optimizer_adam_w","text":"AdamW optimization stochastic gradient descent method based adaptive estimation first-order second-order moments added method decay weights per techniques discussed paper, 'Decoupled Weight Decay Regularization' Loshchilov, Hutter et al., 2019. According Kingma et al., 2014, underying Adam method \"computationally efficient, little memory requirement, invariant diagonal rescaling gradients, well suited problems large terms data/parameters\".","code":""},{"path":"https://keras.posit.co/reference/optimizer_adam_w.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the AdamW algorithm. — optimizer_adam_w","text":"","code":"optimizer_adam_w(   learning_rate = 0.001,   weight_decay = 0.004,   beta_1 = 0.9,   beta_2 = 0.999,   epsilon = 1e-07,   amsgrad = FALSE,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"adamw\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_adam_w.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the AdamW algorithm. — optimizer_adam_w","text":"learning_rate float, LearningRateSchedule() instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. weight_decay Float. set, weight decay applied. beta_1 float value constant float tensor, callable takes arguments returns actual value use. exponential decay rate 1st moment estimates. Defaults 0.9. beta_2 float value constant float tensor, callable takes arguments returns actual value use. exponential decay rate 2nd moment estimates. Defaults 0.999. epsilon small constant numerical stability. epsilon \"epsilon hat\" Kingma Ba paper (formula just Section 2.1), epsilon Algorithm 1 paper. Defaults 1e-7. amsgrad Boolean. Whether apply AMSGrad variant algorithm paper \"Convergence Adam beyond\". Defaults FALSE. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adam_w.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the AdamW algorithm. — optimizer_adam_w","text":"Optimizer instance","code":""},{"path":"https://keras.posit.co/reference/optimizer_adam_w.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimizer that implements the AdamW algorithm. — optimizer_adam_w","text":"Loshchilov et al., 2019 Kingma et al., 2014 adam Reddi et al., 2018 amsgrad.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_adamax.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the Adamax algorithm. — optimizer_adamax","title":"Optimizer that implements the Adamax algorithm. — optimizer_adamax","text":"Adamax, variant Adam based infinity norm, first-order gradient-based optimization method. Due capability adjusting learning rate based data characteristics, suited learn time-variant process, e.g., speech data dynamically changed noise conditions. Default parameters follow provided paper (see references ). Initialization:   update rule parameter w gradient g described end section 7.1 paper (see referenece section):","code":"m <- 0  # Initialize initial 1st moment vector u <- 0  # Initialize the exponentially weighted infinity norm t <- 0  # Initialize timestep t <-  t + 1 m <- beta1 * m + (1 - beta) * g u <- max(beta2 * u, abs(g)) current_lr <- learning_rate / (1 - beta1 ** t) w <- w - current_lr * m / (u + epsilon)"},{"path":"https://keras.posit.co/reference/optimizer_adamax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the Adamax algorithm. — optimizer_adamax","text":"","code":"optimizer_adamax(   learning_rate = 0.001,   beta_1 = 0.9,   beta_2 = 0.999,   epsilon = 1e-07,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"adamax\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_adamax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the Adamax algorithm. — optimizer_adamax","text":"learning_rate float, LearningRateSchedule() instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. beta_1 float value constant float tensor. exponential decay rate 1st moment estimates. beta_2 float value constant float tensor. exponential decay rate exponentially weighted infinity norm. epsilon small constant numerical stability. name: String. name use momentum accumulator weights created optimizer. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String, name object ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_adamax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the Adamax algorithm. — optimizer_adamax","text":"Optimizer instance","code":""},{"path":"https://keras.posit.co/reference/optimizer_adamax.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Optimizer that implements the Adamax algorithm. — optimizer_adamax","text":"Kingma et al., 2014","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_ftrl.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the FTRL algorithm. — optimizer_ftrl","title":"Optimizer that implements the FTRL algorithm. — optimizer_ftrl","text":"\"Follow Regularized Leader\" (FTRL) optimization algorithm developed Google click-rate prediction early 2010s. suitable shallow models large sparse feature spaces. algorithm described McMahan et al., 2013. Keras version support online L2 regularization (L2 regularization described paper ) shrinkage-type L2 regularization (addition L2 penalty loss function). Initialization:   Update rule one variable w:   Notation: lr learning rate g gradient variable lambda_1 L1 regularization strength lambda_2 L2 regularization strength lr_power power scale n. Check documentation l2_shrinkage_regularization_strength parameter details shrinkage enabled, case gradient replaced gradient shrinkage.","code":"n <- 0 sigma <- 0 z <- 0 prev_n <- n n <- n + g^2 sigma <- (n^(-lr_power) - prev_n^(-lr_power)) / lr z <- z + g - sigma * w if (abs(z) < lambda_1) {   w <- 0 } else {   w <- (sgn(z) * lambda_1 - z) / ((beta + sqrt(n)) / alpha + lambda_2) }"},{"path":"https://keras.posit.co/reference/optimizer_ftrl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the FTRL algorithm. — optimizer_ftrl","text":"","code":"optimizer_ftrl(   learning_rate = 0.001,   learning_rate_power = -0.5,   initial_accumulator_value = 0.1,   l1_regularization_strength = 0,   l2_regularization_strength = 0,   l2_shrinkage_regularization_strength = 0,   beta = 0,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"ftrl\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_ftrl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the FTRL algorithm. — optimizer_ftrl","text":"learning_rate float, LearningRateSchedule() instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. learning_rate_power float value, must less equal zero. Controls learning rate decreases training. Use zero fixed learning rate. initial_accumulator_value starting value accumulators. zero positive values allowed. l1_regularization_strength float value, must greater equal zero. Defaults 0.0. l2_regularization_strength float value, must greater equal zero. Defaults 0.0. l2_shrinkage_regularization_strength float value, must greater equal zero. differs L2 L2 stabilization penalty, whereas L2 shrinkage magnitude penalty. input sparse shrinkage happen active weights. beta float value, representing beta value paper. Defaults 0.0. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_ftrl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the FTRL algorithm. — optimizer_ftrl","text":"Optimizer instance","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_lion.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the Lion algorithm. — optimizer_lion","title":"Optimizer that implements the Lion algorithm. — optimizer_lion","text":"Lion optimizer stochastic-gradient-descent method uses sign operator control magnitude update, unlike adaptive optimizers Adam rely second-order moments. make Lion memory-efficient keeps track momentum. According authors (see reference), performance gain Adam grows batch size. update Lion produced sign operation, resulting larger norm, suitable learning rate Lion typically 3-10x smaller AdamW. weight decay Lion turn 3-10x larger AdamW maintain similar strength (lr * wd).","code":""},{"path":"https://keras.posit.co/reference/optimizer_lion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the Lion algorithm. — optimizer_lion","text":"","code":"optimizer_lion(   learning_rate = 0.001,   beta_1 = 0.9,   beta_2 = 0.99,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"lion\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_lion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the Lion algorithm. — optimizer_lion","text":"learning_rate float, LearningRateSchedule() instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. beta_1 float value constant float tensor, callable takes arguments returns actual value use. rate combine current gradient 1st moment estimate. Defaults 0.9. beta_2 float value constant float tensor, callable takes arguments returns actual value use. exponential decay rate 1st moment estimate. Defaults 0.99. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_lion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the Lion algorithm. — optimizer_lion","text":"Optimizer instance","code":""},{"path":"https://keras.posit.co/reference/optimizer_lion.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimizer that implements the Lion algorithm. — optimizer_lion","text":"Chen et al., 2023 Authors' implementation","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_loss_scale.html","id":null,"dir":"Reference","previous_headings":"","what":"An optimizer that dynamically scales the loss to prevent underflow. — optimizer_loss_scale","title":"An optimizer that dynamically scales the loss to prevent underflow. — optimizer_loss_scale","text":"Loss scaling technique prevent numeric underflow intermediate gradients float16 used. prevent underflow, loss multiplied (\"scaled\") certain factor called \"loss scale\", causes intermediate gradients scaled loss scale well. final gradients divided (\"unscaled\") loss scale bring back original value. LossScaleOptimizer wraps another optimizer applies dynamic loss scaling . loss scale dynamically updated time follows: train step, nonfinite gradient encountered, loss scale halved, train step skipped. dynamic_growth_steps ocurred since last time loss scale updated, nonfinite gradients occurred, loss scale doubled.","code":""},{"path":"https://keras.posit.co/reference/optimizer_loss_scale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An optimizer that dynamically scales the loss to prevent underflow. — optimizer_loss_scale","text":"","code":"optimizer_loss_scale(   inner_optimizer,   initial_scale = 32768,   dynamic_growth_steps = 2000L,   ...,   name = NULL,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = NULL,   ema_momentum = NULL,   ema_overwrite_frequency = NULL,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_loss_scale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"An optimizer that dynamically scales the loss to prevent underflow. — optimizer_loss_scale","text":"inner_optimizer keras Optimizer instance wrap. initial_scale Float. initial loss scale. scale updated training. recommended high number, loss scale high gets lowered far quickly loss scale low gets raised. dynamic_growth_steps Int. often update scale upwards. every dynamic_growth_steps steps finite gradients, loss scale doubled. ... forward/backward compatability. name String. name use momentum accumulator weights created optimizer. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_loss_scale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"An optimizer that dynamically scales the loss to prevent underflow. — optimizer_loss_scale","text":"Optimizer instance","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_nadam.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the Nadam algorithm. — optimizer_nadam","title":"Optimizer that implements the Nadam algorithm. — optimizer_nadam","text":"Much like Adam essentially RMSprop momentum, Nadam Adam Nesterov momentum.","code":""},{"path":"https://keras.posit.co/reference/optimizer_nadam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the Nadam algorithm. — optimizer_nadam","text":"","code":"optimizer_nadam(   learning_rate = 0.001,   beta_1 = 0.9,   beta_2 = 0.999,   epsilon = 1e-07,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"nadam\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_nadam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the Nadam algorithm. — optimizer_nadam","text":"learning_rate float, LearningRateSchedule() instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. beta_1 float value constant float tensor, callable takes arguments returns actual value use. exponential decay rate 1st moment estimates. Defaults 0.9. beta_2 float value constant float tensor, callable takes arguments returns actual value use. exponential decay rate 2nd moment estimates. Defaults 0.999. epsilon small constant numerical stability. epsilon \"epsilon hat\" Kingma Ba paper (formula just Section 2.1), epsilon Algorithm 1 paper. Defaults 1e-7. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_nadam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the Nadam algorithm. — optimizer_nadam","text":"Optimizer instance","code":""},{"path":"https://keras.posit.co/reference/optimizer_nadam.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Optimizer that implements the Nadam algorithm. — optimizer_nadam","text":"Dozat, 2015.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_rmsprop.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimizer that implements the RMSprop algorithm. — optimizer_rmsprop","title":"Optimizer that implements the RMSprop algorithm. — optimizer_rmsprop","text":"gist RMSprop : Maintain moving (discounted) average square gradients Divide gradient root average implementation RMSprop uses plain momentum, Nesterov momentum. centered version additionally maintains moving average gradients, uses average estimate variance.","code":""},{"path":"https://keras.posit.co/reference/optimizer_rmsprop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the RMSprop algorithm. — optimizer_rmsprop","text":"","code":"optimizer_rmsprop(   learning_rate = 0.001,   rho = 0.9,   momentum = 0,   epsilon = 1e-07,   centered = FALSE,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = 100L,   name = \"rmsprop\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_rmsprop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimizer that implements the RMSprop algorithm. — optimizer_rmsprop","text":"learning_rate float, learning_rate_schedule_* instance, callable takes arguments returns actual value use. learning rate. Defaults 0.001. rho float, defaults 0.9. Discounting factor old gradients. momentum float, defaults 0.0. 0.0., optimizer tracks momentum value, decay rate equals 1 - momentum. epsilon small constant numerical stability. epsilon \"epsilon hat\" Kingma Ba paper (formula just Section 2.1), epsilon Algorithm 1 paper. Defaults 1e-7. centered Boolean. TRUE, gradients normalized estimated variance gradient; FALSE, uncentered second moment. Setting TRUE may help training, slightly expensive terms computation memory. Defaults FALSE. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_rmsprop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimizer that implements the RMSprop algorithm. — optimizer_rmsprop","text":"Optimizer instance","code":""},{"path":"https://keras.posit.co/reference/optimizer_rmsprop.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimizer that implements the RMSprop algorithm. — optimizer_rmsprop","text":"","code":"opt <- optimizer_rmsprop(learning_rate=0.1)"},{"path":"https://keras.posit.co/reference/optimizer_rmsprop.html","id":"reference","dir":"Reference","previous_headings":"","what":"Reference","title":"Optimizer that implements the RMSprop algorithm. — optimizer_rmsprop","text":"Hinton, 2012","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/optimizer_sgd.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient descent (with momentum) optimizer. — optimizer_sgd","title":"Gradient descent (with momentum) optimizer. — optimizer_sgd","text":"Update rule parameter w gradient g momentum 0:   Update rule momentum larger 0:   nesterov=TRUE, rule becomes:","code":"w <- w - learning_rate * g velocity <- momentum * velocity - learning_rate * g w <- w + velocity velocity <- momentum * velocity - learning_rate * g w <- w + momentum * velocity - learning_rate * g"},{"path":"https://keras.posit.co/reference/optimizer_sgd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient descent (with momentum) optimizer. — optimizer_sgd","text":"","code":"optimizer_sgd(   learning_rate = 0.01,   momentum = 0,   nesterov = FALSE,   weight_decay = NULL,   clipnorm = NULL,   clipvalue = NULL,   global_clipnorm = NULL,   use_ema = FALSE,   ema_momentum = 0.99,   ema_overwrite_frequency = NULL,   name = \"SGD\",   ...,   loss_scale_factor = NULL,   gradient_accumulation_steps = NULL )"},{"path":"https://keras.posit.co/reference/optimizer_sgd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient descent (with momentum) optimizer. — optimizer_sgd","text":"learning_rate float, learning_rate_schedule_* instance, callable takes arguments returns actual value use. learning rate. Defaults 0.01. momentum float hyperparameter >= 0 accelerates gradient descent relevant direction dampens oscillations. 0 vanilla gradient descent. Defaults 0.0. nesterov boolean. Whether apply Nesterov momentum. Defaults FALSE. weight_decay Float. set, weight decay applied. clipnorm Float. set, gradient weight individually clipped norm higher value. clipvalue Float. set, gradient weight clipped higher value. global_clipnorm Float. set, gradient weights clipped global norm higher value. use_ema Boolean, defaults FALSE. TRUE, exponential moving average (EMA) applied. EMA consists computing exponential moving average weights model (weight values change training batch), periodically overwriting weights moving average. ema_momentum Float, defaults 0.99. used use_ema=TRUE. momentum use computing EMA model's weights: new_average = ema_momentum * old_average + (1 - ema_momentum) * current_variable_value. ema_overwrite_frequency Int NULL, defaults NULL. used use_ema=TRUE. Every ema_overwrite_frequency steps iterations, overwrite model variable moving average. NULL, optimizer overwrite model variables middle training, need explicitly overwrite variables end training calling optimizer$finalize_variable_values() (updates model variables -place). using built-fit() training loop, happens automatically last epoch, need anything. name String. name use momentum accumulator weights created optimizer. ... forward/backward compatability. loss_scale_factor Float NULL. float, scale factor multiplied loss computing gradients, inverse scale factor multiplied gradients updating variables. Useful preventing underflow mixed precision training. Alternately, optimizer_loss_scale() automatically set loss scale factor. gradient_accumulation_steps Int NULL. int, model & optimizer variables updated every step; instead updated every gradient_accumulation_steps steps, using average value gradients since last update. known \"gradient accumulation\". can useful batch size small, order reduce gradient noise update step.","code":""},{"path":"https://keras.posit.co/reference/optimizer_sgd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient descent (with momentum) optimizer. — optimizer_sgd","text":"Optimizer instance","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/pack_x_y_sample_weight.html","id":null,"dir":"Reference","previous_headings":"","what":"Packs user-provided data into a list. — pack_x_y_sample_weight","title":"Packs user-provided data into a list. — pack_x_y_sample_weight","text":"convenience utility packing data list formats fit() uses.","code":""},{"path":"https://keras.posit.co/reference/pack_x_y_sample_weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Packs user-provided data into a list. — pack_x_y_sample_weight","text":"","code":"pack_x_y_sample_weight(x, y = NULL, sample_weight = NULL)"},{"path":"https://keras.posit.co/reference/pack_x_y_sample_weight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Packs user-provided data into a list. — pack_x_y_sample_weight","text":"x Features pass Model. y Ground-truth targets pass Model. sample_weight Sample weight element.","code":""},{"path":"https://keras.posit.co/reference/pack_x_y_sample_weight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Packs user-provided data into a list. — pack_x_y_sample_weight","text":"List format used fit().","code":""},{"path":"https://keras.posit.co/reference/pack_x_y_sample_weight.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Packs user-provided data into a list. — pack_x_y_sample_weight","text":"Standalone usage:","code":"x <- op_ones(c(10, 1)) data <- pack_x_y_sample_weight(x)   y <- op_ones(c(10, 1)) data <- pack_x_y_sample_weight(x, y)"},{"path":[]},{"path":"https://keras.posit.co/reference/pad_sequences.html","id":null,"dir":"Reference","previous_headings":"","what":"Pads sequences to the same length. — pad_sequences","title":"Pads sequences to the same length. — pad_sequences","text":"function transforms list (length num_samples) sequences (lists integers) 2D NumPy array shape (num_samples, num_timesteps). num_timesteps either maxlen argument provided, length longest sequence list. Sequences shorter num_timesteps padded value num_timesteps long. Sequences longer num_timesteps truncated fit desired length. position padding truncation happens determined arguments padding truncating, respectively. Pre-padding removing values beginning sequence default.","code":"sequence <- list(c(1), c(2, 3), c(4, 5, 6)) pad_sequences(sequence) ##      [,1] [,2] [,3] ## [1,]    0    0    1 ## [2,]    0    2    3 ## [3,]    4    5    6 pad_sequences(sequence, value=-1) ##      [,1] [,2] [,3] ## [1,]   -1   -1    1 ## [2,]   -1    2    3 ## [3,]    4    5    6 pad_sequences(sequence, padding='post') ##      [,1] [,2] [,3] ## [1,]    1    0    0 ## [2,]    2    3    0 ## [3,]    4    5    6 pad_sequences(sequence, maxlen=2) ##      [,1] [,2] ## [1,]    0    1 ## [2,]    2    3 ## [3,]    5    6"},{"path":"https://keras.posit.co/reference/pad_sequences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pads sequences to the same length. — pad_sequences","text":"","code":"pad_sequences(   sequences,   maxlen = NULL,   dtype = \"int32\",   padding = \"pre\",   truncating = \"pre\",   value = 0 )"},{"path":"https://keras.posit.co/reference/pad_sequences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pads sequences to the same length. — pad_sequences","text":"sequences List sequences (sequence list integers). maxlen Optional Int, maximum length sequences. provided, sequences padded length longest individual sequence. dtype (Optional, defaults \"int32\"). Type output sequences. pad sequences variable length strings, can use object. padding String, \"pre\" \"post\" (optional, defaults \"pre\"): pad either sequence. truncating String, \"pre\" \"post\" (optional, defaults \"pre\"): remove values sequences larger maxlen, either beginning end sequences. value Float String, padding value. (Optional, defaults 0.)","code":""},{"path":"https://keras.posit.co/reference/pad_sequences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pads sequences to the same length. — pad_sequences","text":"Array shape (len(sequences), maxlen)","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See %>% details.","code":""},{"path":"https://keras.posit.co/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://keras.posit.co/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"commonly, result calling right hand side left hand side argument: rhs(lhs). See magritter vignette , advanced, usages.","code":""},{"path":"https://keras.posit.co/reference/plot.keras.src.models.model.Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a Keras model — plot.keras.src.models.model.Model","title":"Plot a Keras model — plot.keras.src.models.model.Model","text":"Plot Keras model","code":""},{"path":"https://keras.posit.co/reference/plot.keras.src.models.model.Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a Keras model — plot.keras.src.models.model.Model","text":"","code":"# S3 method for keras.src.models.model.Model plot(   x,   show_shapes = FALSE,   show_dtype = FALSE,   show_layer_names = FALSE,   ...,   rankdir = \"TB\",   expand_nested = FALSE,   dpi = 200,   layer_range = NULL,   show_layer_activations = FALSE,   show_trainable = NA,   to_file = NULL )"},{"path":"https://keras.posit.co/reference/plot.keras.src.models.model.Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a Keras model — plot.keras.src.models.model.Model","text":"x Keras model instance show_shapes whether display shape information. show_dtype whether display layer dtypes. show_layer_names whether display layer names. ... passed Python keras.utils.model_to_dot(). Used forward backward compatibility. rankdir string specifying format plot: 'TB' creates vertical plot; 'LR' creates horizontal plot. (argument passed PyDot) expand_nested Whether expand nested models clusters. dpi Dots per inch. Increase value image text appears excessively pixelated. layer_range list containing two character strings, starting layer name ending layer name (inclusive) indicating range layers plot generated. also accepts regex patterns instead exact name. case, start predicate first element matches layer_range[1] end predicate last element matches layer_range[2]. default NULL considers layers model. Note must pass range resultant subgraph must complete. show_layer_activations Display layer activations (layers activation property). show_trainable whether display layer trainable. to_file File name plot image. NULL (default), model drawn default graphics device. Otherwise, file saved.","code":""},{"path":"https://keras.posit.co/reference/plot.keras.src.models.model.Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a Keras model — plot.keras.src.models.model.Model","text":"Nothing, called side effects.","code":""},{"path":"https://keras.posit.co/reference/plot.keras.src.models.model.Model.html","id":"raises","dir":"Reference","previous_headings":"","what":"Raises","title":"Plot a Keras model — plot.keras.src.models.model.Model","text":"ValueError: plot(model) called model built, unless input_shape =  argument supplied keras_model_sequential().","code":""},{"path":"https://keras.posit.co/reference/plot.keras.src.models.model.Model.html","id":"requirements","dir":"Reference","previous_headings":"","what":"Requirements","title":"Plot a Keras model — plot.keras.src.models.model.Model","text":"function requires pydot graphviz. pydot default installed install_keras(), installed keras means, can install pydot directly :   can install graphviz directly : https://graphviz.gitlab.io/download/ Linux platforms, can install graphviz via package manager. example, Ubuntu/Debian can install   conda environment, can install graphviz :","code":"reticulate::py_install(\"pydot\", pip = TRUE) sudo apt install graphviz reticulate::conda_install(packages = \"graphviz\") # Restart the R session after install."},{"path":"https://keras.posit.co/reference/plot.keras_training_history.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot training history — plot.keras_training_history","title":"Plot training history — plot.keras_training_history","text":"Plots metrics recorded training.","code":""},{"path":"https://keras.posit.co/reference/plot.keras_training_history.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot training history — plot.keras_training_history","text":"","code":"# S3 method for keras_training_history plot(   x,   y,   metrics = NULL,   method = c(\"auto\", \"ggplot2\", \"base\"),   smooth = getOption(\"keras.plot.history.smooth\", TRUE),   theme_bw = getOption(\"keras.plot.history.theme_bw\", FALSE),   ... )"},{"path":"https://keras.posit.co/reference/plot.keras_training_history.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot training history — plot.keras_training_history","text":"x Training history object returned fit.keras.src.models.model.Model(). y Unused. metrics One metrics plot (e.g. c('loss', 'accuracy')). Defaults plotting captured metrics. method Method use plotting. default \"auto\" use ggplot2 available, otherwise use base graphics. smooth Whether loess smooth added plot, available ggplot2 method. number epochs smaller ten, forced false. theme_bw Use ggplot2::theme_bw() plot history black white. ... Additional parameters pass plot() method.","code":""},{"path":"https://keras.posit.co/reference/plot.keras_training_history.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot training history — plot.keras_training_history","text":"method == \"ggplot2\", ggplot object returned. method == \"base\", function draw graphics device return NULL, invisibly.","code":""},{"path":"https://keras.posit.co/reference/pop_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove the last layer in a Sequential model — pop_layer","title":"Remove the last layer in a Sequential model — pop_layer","text":"Remove last layer Sequential model","code":""},{"path":"https://keras.posit.co/reference/pop_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove the last layer in a Sequential model — pop_layer","text":"","code":"pop_layer(object)"},{"path":"https://keras.posit.co/reference/pop_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove the last layer in a Sequential model — pop_layer","text":"object Sequential keras model object","code":""},{"path":"https://keras.posit.co/reference/pop_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove the last layer in a Sequential model — pop_layer","text":"input object, invisibly.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/predict.keras.src.models.model.Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates output predictions for the input samples. — predict.keras.src.models.model.Model","title":"Generates output predictions for the input samples. — predict.keras.src.models.model.Model","text":"Generates output predictions input samples.","code":""},{"path":"https://keras.posit.co/reference/predict.keras.src.models.model.Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates output predictions for the input samples. — predict.keras.src.models.model.Model","text":"","code":"# S3 method for keras.src.models.model.Model predict(   object,   x,   ...,   batch_size = NULL,   verbose = getOption(\"keras.verbose\", default = \"auto\"),   steps = NULL,   callbacks = NULL )"},{"path":"https://keras.posit.co/reference/predict.keras.src.models.model.Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates output predictions for the input samples. — predict.keras.src.models.model.Model","text":"object Keras model object x Input samples. : array (array-like), list arrays (case model multiple inputs). tensor, list tensors (case model multiple inputs). TF Dataset. ... forward/backward compatability. batch_size Integer NULL. Number samples per batch. unspecified, batch_size default 32. specify batch_size data form TF Dataset generator (since generate batches). verbose \"auto\", 0, 1, 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. \"auto\" becomes 1 cases, 2 knitr render running distributed training server. Note progress bar particularly useful logged file, verbose=2 recommended running interactively (e.g., production environment). Defaults \"auto\". steps Total number steps (batches samples) declaring prediction round finished. Ignored default value NULL. x TF Dataset steps NULL, predict() run input dataset exhausted. callbacks List Callback instances. List callbacks apply prediction.","code":""},{"path":"https://keras.posit.co/reference/predict.keras.src.models.model.Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates output predictions for the input samples. — predict.keras.src.models.model.Model","text":"R array(s) predictions.","code":""},{"path":"https://keras.posit.co/reference/predict.keras.src.models.model.Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generates output predictions for the input samples. — predict.keras.src.models.model.Model","text":"Computation done batches. method designed batch processing large numbers inputs. intended use inside loops iterate data process small numbers inputs time. small numbers inputs fit one batch, directly call model model$call faster execution, e.g., model(x), model(x, training = FALSE) layers BatchNormalization behave differently inference.","code":""},{"path":"https://keras.posit.co/reference/predict.keras.src.models.model.Model.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Generates output predictions for the input samples. — predict.keras.src.models.model.Model","text":"See FAQ entry details difference Model methods predict() call().","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/predict_on_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns predictions for a single batch of samples. — predict_on_batch","title":"Returns predictions for a single batch of samples. — predict_on_batch","text":"Returns predictions single batch samples.","code":""},{"path":"https://keras.posit.co/reference/predict_on_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns predictions for a single batch of samples. — predict_on_batch","text":"","code":"predict_on_batch(object, x)"},{"path":"https://keras.posit.co/reference/predict_on_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns predictions for a single batch of samples. — predict_on_batch","text":"object Keras model object x Input data. must array-like.","code":""},{"path":"https://keras.posit.co/reference/predict_on_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns predictions for a single batch of samples. — predict_on_batch","text":"Array(s) predictions.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/process_utils.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocessing and postprocessing utilities — process_utils","title":"Preprocessing and postprocessing utilities — process_utils","text":"functions used preprocess postprocess inputs outputs Keras applications.","code":""},{"path":"https://keras.posit.co/reference/process_utils.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocessing and postprocessing utilities — process_utils","text":"","code":"application_preprocess_inputs(model, x, ..., data_format = NULL)  application_decode_predictions(model, preds, top = 5L, ...)"},{"path":"https://keras.posit.co/reference/process_utils.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocessing and postprocessing utilities — process_utils","text":"model Keras model initialized using application_ function. x batch inputs model. ... Additional arguments passed preprocessing decoding function. data_format Optional data format image tensor/array. NULL means global setting config_image_data_format() used (unless changed , uses \"channels_last\"). Defaults NULL. preds batch outputs model. top number top predictions return.","code":""},{"path":"https://keras.posit.co/reference/process_utils.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocessing and postprocessing utilities — process_utils","text":"list decoded predictions case application_decode_predictions(). batch preprocessed inputs case application_preprocess_inputs().","code":""},{"path":"https://keras.posit.co/reference/process_utils.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Preprocessing and postprocessing utilities — process_utils","text":"application_preprocess_inputs(): Pre-process inputs used model application_decode_predictions(): Decode predictions model","code":""},{"path":"https://keras.posit.co/reference/process_utils.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocessing and postprocessing utilities — process_utils","text":"","code":"if (FALSE) { model <- application_convnext_tiny()  inputs <- random_normal(c(32, 224, 224, 3)) processed_inputs <- application_preprocess_inputs(model, inputs)  preds <- random_normal(c(32, 1000)) decoded_preds <- application_decode_predictions(model, preds)  }"},{"path":"https://keras.posit.co/reference/quantize_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantize the weights of a model. — quantize_weights","title":"Quantize the weights of a model. — quantize_weights","text":"Note model must built first calling method. quantize_weights() recursively call layer$quantize(mode) layers skipped layer implement function. Currently Dense EinsumDense layers support quantization.","code":""},{"path":"https://keras.posit.co/reference/quantize_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantize the weights of a model. — quantize_weights","text":"","code":"quantize_weights(object, mode)"},{"path":"https://keras.posit.co/reference/quantize_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantize the weights of a model. — quantize_weights","text":"object Keras Model Layer. mode mode quantization. 'int8' supported time.","code":""},{"path":"https://keras.posit.co/reference/quantize_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantize the weights of a model. — quantize_weights","text":"model, invisibly. Note just convenience usage |>, model modified -place.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_beta.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw samples from a Beta distribution. — random_beta","title":"Draw samples from a Beta distribution. — random_beta","text":"values drawm Beta distribution parametrized alpha beta.","code":""},{"path":"https://keras.posit.co/reference/random_beta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw samples from a Beta distribution. — random_beta","text":"","code":"random_beta(shape, alpha, beta, dtype = NULL, seed = NULL)"},{"path":"https://keras.posit.co/reference/random_beta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw samples from a Beta distribution. — random_beta","text":"shape shape random values generate. alpha Float array floats representing first parameter alpha. Must broadcastable beta shape. beta Float array floats representing second parameter beta. Must broadcastable alpha shape. dtype Optional dtype tensor. floating point types supported. specified, config_floatx() used, defaults \"float32\" unless configured otherwise (via config_set_floatx(float_dtype)). seed integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_beta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw samples from a Beta distribution. — random_beta","text":"tensor random values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_binomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw samples from a Binomial distribution. — random_binomial","title":"Draw samples from a Binomial distribution. — random_binomial","text":"values drawn Binomial distribution specified trial count probability success.","code":""},{"path":"https://keras.posit.co/reference/random_binomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw samples from a Binomial distribution. — random_binomial","text":"","code":"random_binomial(shape, counts, probabilities, dtype = NULL, seed = NULL)"},{"path":"https://keras.posit.co/reference/random_binomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw samples from a Binomial distribution. — random_binomial","text":"shape shape random values generate. counts number array numbers representing number trials. must broadcastable probabilities. probabilities float array floats representing probability success individual event. must broadcastable counts. dtype Optional dtype tensor. floating point types supported. specified, config_floatx() used, defaults \"float32\" unless configured otherwise (via config_set_floatx(float_dtype)). seed Python integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer None (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_binomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw samples from a Binomial distribution. — random_binomial","text":"tensor random values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_categorical.html","id":null,"dir":"Reference","previous_headings":"","what":"Draws samples from a categorical distribution. — random_categorical","title":"Draws samples from a categorical distribution. — random_categorical","text":"function takes input logits, 2-D input tensor shape (batch_size, num_classes). row input represents categorical distribution, column index containing log-probability given class. function output 2-D tensor shape (batch_size, num_samples), row contains samples corresponding row logits. column index contains independent samples drawn input distribution.","code":""},{"path":"https://keras.posit.co/reference/random_categorical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draws samples from a categorical distribution. — random_categorical","text":"","code":"random_categorical(logits, num_samples, dtype = \"int32\", seed = NULL)"},{"path":"https://keras.posit.co/reference/random_categorical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draws samples from a categorical distribution. — random_categorical","text":"logits 2-D Tensor shape (batch_size, num_classes). row define categorical distibution unnormalized log-probabilities classes. num_samples Int, number independent samples draw row input. second dimension output tensor's shape. dtype Optional dtype output tensor. seed R integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_categorical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draws samples from a categorical distribution. — random_categorical","text":"2-D tensor (batch_size, num_samples).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Randomly set some values in a tensor to 0. — random_dropout","title":"Randomly set some values in a tensor to 0. — random_dropout","text":"Randomly set portion values tensor 0.","code":""},{"path":"https://keras.posit.co/reference/random_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randomly set some values in a tensor to 0. — random_dropout","text":"","code":"random_dropout(inputs, rate, noise_shape = NULL, seed = NULL)"},{"path":"https://keras.posit.co/reference/random_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randomly set some values in a tensor to 0. — random_dropout","text":"inputs tensor rate numeric noise_shape shape() value seed Initial seed random number generator","code":""},{"path":"https://keras.posit.co/reference/random_dropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Randomly set some values in a tensor to 0. — random_dropout","text":"tensor copy inputs values set 0.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_gamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw random samples from the Gamma distribution. — random_gamma","title":"Draw random samples from the Gamma distribution. — random_gamma","text":"Draw random samples Gamma distribution.","code":""},{"path":"https://keras.posit.co/reference/random_gamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw random samples from the Gamma distribution. — random_gamma","text":"","code":"random_gamma(shape, alpha, dtype = NULL, seed = NULL)"},{"path":"https://keras.posit.co/reference/random_gamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw random samples from the Gamma distribution. — random_gamma","text":"shape shape random values generate. alpha Float, parameter distribution. dtype Optional dtype tensor. floating point types supported. specified, config_floatx() used, defaults float32 unless configured otherwise (via config_set_floatx(float_dtype)). seed R integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_gamma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw random samples from the Gamma distribution. — random_gamma","text":"tensor random values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_integer.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw random integers from a uniform distribution. — random_integer","title":"Draw random integers from a uniform distribution. — random_integer","text":"generated values follow uniform distribution range [minval, maxval). lower bound minval included range, upper bound maxval excluded. dtype must integer type.","code":""},{"path":"https://keras.posit.co/reference/random_integer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw random integers from a uniform distribution. — random_integer","text":"","code":"random_integer(shape, minval, maxval, dtype = \"int32\", seed = NULL)"},{"path":"https://keras.posit.co/reference/random_integer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw random integers from a uniform distribution. — random_integer","text":"shape shape random values generate. minval integer, lower bound range random values generate (inclusive). maxval integer, upper bound range random values generate (exclusive). dtype Optional dtype tensor. integer types supported. specified, \"int32\" used. seed R integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_integer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw random integers from a uniform distribution. — random_integer","text":"tensor random values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw random samples from a normal (Gaussian) distribution. — random_normal","title":"Draw random samples from a normal (Gaussian) distribution. — random_normal","text":"Draw random samples normal (Gaussian) distribution.","code":""},{"path":"https://keras.posit.co/reference/random_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw random samples from a normal (Gaussian) distribution. — random_normal","text":"","code":"random_normal(shape, mean = 0, stddev = 1, dtype = NULL, seed = NULL)"},{"path":"https://keras.posit.co/reference/random_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw random samples from a normal (Gaussian) distribution. — random_normal","text":"shape shape random values generate. mean Float, defaults 0. Mean random values generate. stddev Float, defaults 1. Standard deviation random values generate. dtype Optional dtype tensor. floating point types supported. specified, config_floatx() used, defaults float32 unless configured otherwise (via config_set_floatx(float_dtype)). seed R integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw random samples from a normal (Gaussian) distribution. — random_normal","text":"tensor random values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_seed_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates variable seeds upon each call to a RNG-using function. — random_seed_generator","title":"Generates variable seeds upon each call to a RNG-using function. — random_seed_generator","text":"Keras, RNG-using methods (random_normal()) stateless, meaning pass integer seed (seed = 42), return values call. order get different values call, must use SeedGenerator instead seed argument. SeedGenerator object stateful.","code":""},{"path":"https://keras.posit.co/reference/random_seed_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates variable seeds upon each call to a RNG-using function. — random_seed_generator","text":"","code":"random_seed_generator(seed = NULL, ...)"},{"path":"https://keras.posit.co/reference/random_seed_generator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates variable seeds upon each call to a RNG-using function. — random_seed_generator","text":"seed Initial seed random number generator ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/random_seed_generator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates variable seeds upon each call to a RNG-using function. — random_seed_generator","text":"SeedGenerator instance, can passed seed = argument random tensor generators.","code":""},{"path":"https://keras.posit.co/reference/random_seed_generator.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates variable seeds upon each call to a RNG-using function. — random_seed_generator","text":"Usage layer:","code":"seed_gen <- random_seed_generator(seed = 42) values <- random_normal(shape = c(2, 3), seed = seed_gen) new_values <- random_normal(shape = c(2, 3), seed = seed_gen) layer_dropout2 <- new_layer_class(   \"dropout2\",   initialize = function(...) {     super$initialize(...)     self$seed_generator <- random_seed_generator(seed = 1337)   },   call = function(x, training = FALSE) {     if (training) {       return(random_dropout(x, rate = 0.5, seed = self$seed_generator))     }     return(x)   } )  out <- layer_dropout(rate = 0.8) out(op_ones(10), training = TRUE) ## tf.Tensor([0. 5. 5. 0. 0. 0. 0. 0. 0. 0.], shape=(10), dtype=float32)"},{"path":[]},{"path":"https://keras.posit.co/reference/random_shuffle.html","id":null,"dir":"Reference","previous_headings":"","what":"Shuffle the elements of a tensor uniformly at random along an axis. — random_shuffle","title":"Shuffle the elements of a tensor uniformly at random along an axis. — random_shuffle","text":"Shuffle elements tensor uniformly random along axis.","code":""},{"path":"https://keras.posit.co/reference/random_shuffle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shuffle the elements of a tensor uniformly at random along an axis. — random_shuffle","text":"","code":"random_shuffle(x, axis = 1L, seed = NULL)"},{"path":"https://keras.posit.co/reference/random_shuffle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shuffle the elements of a tensor uniformly at random along an axis. — random_shuffle","text":"x tensor shuffled. axis integer specifying axis along shuffle. Defaults 0. seed R integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_shuffle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shuffle the elements of a tensor uniformly at random along an axis. — random_shuffle","text":"tensor, copy x axis axis shuffled.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_truncated_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw samples from a truncated normal distribution. — random_truncated_normal","title":"Draw samples from a truncated normal distribution. — random_truncated_normal","text":"values drawn normal distribution specified mean standard deviation, discarding re-drawing samples two standard deviations mean.","code":""},{"path":"https://keras.posit.co/reference/random_truncated_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw samples from a truncated normal distribution. — random_truncated_normal","text":"","code":"random_truncated_normal(shape, mean = 0, stddev = 1, dtype = NULL, seed = NULL)"},{"path":"https://keras.posit.co/reference/random_truncated_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw samples from a truncated normal distribution. — random_truncated_normal","text":"shape shape random values generate. mean Float, defaults 0. Mean random values generate. stddev Float, defaults 1. Standard deviation random values generate. dtype Optional dtype tensor. floating point types supported. specified, config_floatx() used, defaults float32 unless configured otherwise (via config_set_floatx(float_dtype)) seed R integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_truncated_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw samples from a truncated normal distribution. — random_truncated_normal","text":"tensor random values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/random_uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw samples from a uniform distribution. — random_uniform","title":"Draw samples from a uniform distribution. — random_uniform","text":"generated values follow uniform distribution range [minval, maxval). lower bound minval included range, upper bound maxval excluded. dtype must floating point type, default range [0, 1).","code":""},{"path":"https://keras.posit.co/reference/random_uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw samples from a uniform distribution. — random_uniform","text":"","code":"random_uniform(shape, minval = 0, maxval = 1, dtype = NULL, seed = NULL)"},{"path":"https://keras.posit.co/reference/random_uniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw samples from a uniform distribution. — random_uniform","text":"shape shape random values generate. minval Float, defaults 0. Lower bound range random values generate (inclusive). maxval Float, defaults 1. Upper bound range random values generate (exclusive). dtype Optional dtype tensor. floating point types supported. specified, config_floatx() used, defaults float32 unless configured otherwise (via config_set_floatx(float_dtype)) seed R integer instance random_seed_generator(). Used make behavior initializer deterministic. Note initializer seeded integer NULL (unseeded) produce random values across multiple calls. get different random values across multiple calls, use seed instance random_seed_generator().","code":""},{"path":"https://keras.posit.co/reference/random_uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw samples from a uniform distribution. — random_uniform","text":"tensor random values.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics compile, fit magrittr %<>% reticulate array_reshape, np_array, tuple, use_python, use_virtualenv tensorflow all_dims, as_tensor, evaluate, export_savedmodel, tensorboard tfruns flag_boolean, flag_integer, flag_numeric, flag_string, flags, run_dir","code":""},{"path":"https://keras.posit.co/reference/register_keras_serializable.html","id":null,"dir":"Reference","previous_headings":"","what":"Registers a custom object with the Keras serialization framework. — register_keras_serializable","title":"Registers a custom object with the Keras serialization framework. — register_keras_serializable","text":"function registers custom class function Keras custom object registry, can serialized deserialized without needing entry user-provided custom_objects argument. also injects function Keras call get object's serializable string key. Note serialized deserialized, classes must implement get_config() method. Functions requirement. object registered key 'package>name' name, defaults object name passed.","code":""},{"path":"https://keras.posit.co/reference/register_keras_serializable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Registers a custom object with the Keras serialization framework. — register_keras_serializable","text":"","code":"register_keras_serializable(object, name = NULL, package = NULL)"},{"path":"https://keras.posit.co/reference/register_keras_serializable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Registers a custom object with the Keras serialization framework. — register_keras_serializable","text":"object keras object. name name serialize class package. package package class belongs . used key (\"package>name\") identify class. Defaults current package name, \"Custom\" outside package.","code":""},{"path":"https://keras.posit.co/reference/register_keras_serializable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Registers a custom object with the Keras serialization framework. — register_keras_serializable","text":"object returned invisibly, convenient piping. primarily called side effects.","code":""},{"path":"https://keras.posit.co/reference/register_keras_serializable.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Registers a custom object with the Keras serialization framework. — register_keras_serializable","text":"","code":"# Note that `'my_package'` is used as the `package` argument here, and since # the `name` argument is not provided, `'MyDense'` is used as the `name`. layer_my_dense <- Layer(\"MyDense\") register_keras_serializable(layer_my_dense, package = \"my_package\")  MyDense <- environment(layer_my_dense)$`__class__` # the python class obj stopifnot(exprs = {   get_registered_object('my_package>MyDense') == MyDense   get_registered_name(MyDense) == 'my_package>MyDense' })"},{"path":[]},{"path":"https://keras.posit.co/reference/regularizer_l1.html","id":null,"dir":"Reference","previous_headings":"","what":"A regularizer that applies a L1 regularization penalty. — regularizer_l1","title":"A regularizer that applies a L1 regularization penalty. — regularizer_l1","text":"L1 regularization penalty computed : loss = l1 * reduce_sum(abs(x)) L1 may passed layer string identifier:   case, default value used l1=0.01.","code":"dense <- layer_dense(units = 3, kernel_regularizer = 'l1')"},{"path":"https://keras.posit.co/reference/regularizer_l1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A regularizer that applies a L1 regularization penalty. — regularizer_l1","text":"","code":"regularizer_l1(l1 = 0.01)"},{"path":"https://keras.posit.co/reference/regularizer_l1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A regularizer that applies a L1 regularization penalty. — regularizer_l1","text":"l1 float, L1 regularization factor.","code":""},{"path":"https://keras.posit.co/reference/regularizer_l1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A regularizer that applies a L1 regularization penalty. — regularizer_l1","text":"Regularizer instance can passed layer constructors used standalone object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/regularizer_l1_l2.html","id":null,"dir":"Reference","previous_headings":"","what":"A regularizer that applies both L1 and L2 regularization penalties. — regularizer_l1_l2","title":"A regularizer that applies both L1 and L2 regularization penalties. — regularizer_l1_l2","text":"L1 regularization penalty computed : loss = l1 * reduce_sum(abs(x)) L2 regularization penalty computed loss = l2 * reduce_sum(square(x)) L1L2 may passed layer string identifier:   case, default values used l1=0.01 l2=0.01.","code":"dense <- layer_dense(units = 3, kernel_regularizer = 'L1L2')"},{"path":"https://keras.posit.co/reference/regularizer_l1_l2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A regularizer that applies both L1 and L2 regularization penalties. — regularizer_l1_l2","text":"","code":"regularizer_l1_l2(l1 = 0, l2 = 0)"},{"path":"https://keras.posit.co/reference/regularizer_l1_l2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A regularizer that applies both L1 and L2 regularization penalties. — regularizer_l1_l2","text":"l1 float, L1 regularization factor. l2 float, L2 regularization factor.","code":""},{"path":"https://keras.posit.co/reference/regularizer_l1_l2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A regularizer that applies both L1 and L2 regularization penalties. — regularizer_l1_l2","text":"Regularizer instance can passed layer constructors used standalone object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/regularizer_l2.html","id":null,"dir":"Reference","previous_headings":"","what":"A regularizer that applies a L2 regularization penalty. — regularizer_l2","title":"A regularizer that applies a L2 regularization penalty. — regularizer_l2","text":"L2 regularization penalty computed : loss = l2 * reduce_sum(square(x)) L2 may passed layer string identifier:   case, default value used l2=0.01.","code":"dense <- layer_dense(units = 3, kernel_regularizer='l2')"},{"path":"https://keras.posit.co/reference/regularizer_l2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A regularizer that applies a L2 regularization penalty. — regularizer_l2","text":"","code":"regularizer_l2(l2 = 0.01)"},{"path":"https://keras.posit.co/reference/regularizer_l2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A regularizer that applies a L2 regularization penalty. — regularizer_l2","text":"l2 float, L2 regularization factor.","code":""},{"path":"https://keras.posit.co/reference/regularizer_l2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A regularizer that applies a L2 regularization penalty. — regularizer_l2","text":"Regularizer instance can passed layer constructors used standalone object.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/regularizer_orthogonal.html","id":null,"dir":"Reference","previous_headings":"","what":"Regularizer that encourages input vectors to be orthogonal to each other. — regularizer_orthogonal","title":"Regularizer that encourages input vectors to be orthogonal to each other. — regularizer_orthogonal","text":"can applied either rows matrix (mode=\"rows\") columns (mode=\"columns\"). applied Dense kernel shape (input_dim, units), rows mode seek make feature vectors (.e. basis output space) orthogonal .","code":""},{"path":"https://keras.posit.co/reference/regularizer_orthogonal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regularizer that encourages input vectors to be orthogonal to each other. — regularizer_orthogonal","text":"","code":"regularizer_orthogonal(factor = 0.01, mode = \"rows\")"},{"path":"https://keras.posit.co/reference/regularizer_orthogonal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regularizer that encourages input vectors to be orthogonal to each other. — regularizer_orthogonal","text":"factor Float. regularization factor. regularization penalty proportional factor times mean dot products L2-normalized rows (mode=\"rows\", columns mode=\"columns\") inputs, excluding product row/column .  Defaults 0.01. mode String, one {\"rows\", \"columns\"}. Defaults \"rows\". rows mode, regularization effect seeks make rows input orthogonal . columns mode, seeks make columns input orthogonal .","code":""},{"path":"https://keras.posit.co/reference/regularizer_orthogonal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regularizer that encourages input vectors to be orthogonal to each other. — regularizer_orthogonal","text":"Regularizer instance can passed layer constructors used standalone object.","code":""},{"path":"https://keras.posit.co/reference/regularizer_orthogonal.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regularizer that encourages input vectors to be orthogonal to each other. — regularizer_orthogonal","text":"","code":"regularizer <- regularizer_orthogonal(factor=0.01) layer <- layer_dense(units=4, kernel_regularizer=regularizer)"},{"path":[]},{"path":"https://keras.posit.co/reference/reset_state.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset the state for a model, layer or metric. — reset_state","title":"Reset the state for a model, layer or metric. — reset_state","text":"Reset state model, layer metric.","code":""},{"path":"https://keras.posit.co/reference/reset_state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset the state for a model, layer or metric. — reset_state","text":"","code":"reset_state(object)"},{"path":"https://keras.posit.co/reference/reset_state.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset the state for a model, layer or metric. — reset_state","text":"object Model, Layer, Metric instance Layers resettable state (E.g., adapt()-able preprocessing layers rnn layers resettable state, layer_dense() ). Calling Layer instance without resettable-state error.","code":""},{"path":"https://keras.posit.co/reference/reset_state.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reset the state for a model, layer or metric. — reset_state","text":"object, invisibly.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/rnn_cell_gru.html","id":null,"dir":"Reference","previous_headings":"","what":"Cell class for the GRU layer. — rnn_cell_gru","title":"Cell class for the GRU layer. — rnn_cell_gru","text":"class processes one step within whole time sequence input, whereas layer_gru() processes whole sequence.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_gru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cell class for the GRU layer. — rnn_cell_gru","text":"","code":"rnn_cell_gru(   units,   activation = \"tanh\",   recurrent_activation = \"sigmoid\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   reset_after = TRUE,   seed = NULL,   ... )"},{"path":"https://keras.posit.co/reference/rnn_cell_gru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cell class for the GRU layer. — rnn_cell_gru","text":"units Positive integer, dimensionality output space. activation Activation function use. Default: hyperbolic tangent (tanh). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). recurrent_activation Activation function use recurrent step. Default: sigmoid (sigmoid). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). use_bias Boolean, (default TRUE), whether layer use bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. Default: \"glorot_uniform\". recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state. Default: \"orthogonal\". bias_initializer Initializer bias vector. Default: \"zeros\". kernel_regularizer Regularizer function applied kernel weights matrix. Default: NULL. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. Default: NULL. bias_regularizer Regularizer function applied bias vector. Default: NULL. kernel_constraint Constraint function applied kernel weights matrix. Default: NULL. recurrent_constraint Constraint function applied recurrent_kernel weights matrix. Default: NULL. bias_constraint Constraint function applied bias vector. Default: NULL. dropout Float 0 1. Fraction units drop linear transformation inputs. Default: 0. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. Default: 0. reset_after GRU convention (whether apply reset gate matrix multiplication). FALSE = \"\", TRUE = \"\" (default cuDNN compatible). seed Random seed dropout. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_gru.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cell class for the GRU layer. — rnn_cell_gru","text":"Layer instance, intended used layer_rnn().","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_gru.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Cell class for the GRU layer. — rnn_cell_gru","text":"inputs: 2D tensor, shape (batch, features). states: 2D tensor shape (batch, units), state previous time step. training: Python boolean indicating whether layer behave training mode inference mode. relevant dropout recurrent_dropout used.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_gru.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cell class for the GRU layer. — rnn_cell_gru","text":"","code":"inputs <- random_uniform(c(32, 10, 8)) outputs <- inputs |> layer_rnn(rnn_cell_gru(4)) shape(outputs) ## shape(32, 4) rnn <- layer_rnn(    cell = rnn_cell_gru(4),    return_sequences=TRUE,    return_state=TRUE) c(whole_sequence_output, final_state) %<-% rnn(inputs) shape(whole_sequence_output) ## shape(32, 10, 4) shape(final_state) ## shape(32, 4)"},{"path":[]},{"path":"https://keras.posit.co/reference/rnn_cell_lstm.html","id":null,"dir":"Reference","previous_headings":"","what":"Cell class for the LSTM layer. — rnn_cell_lstm","title":"Cell class for the LSTM layer. — rnn_cell_lstm","text":"class processes one step within whole time sequence input, whereas layer_lstm() processes whole sequence.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_lstm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cell class for the LSTM layer. — rnn_cell_lstm","text":"","code":"rnn_cell_lstm(   units,   activation = \"tanh\",   recurrent_activation = \"sigmoid\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   unit_forget_bias = TRUE,   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   seed = NULL,   ... )"},{"path":"https://keras.posit.co/reference/rnn_cell_lstm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cell class for the LSTM layer. — rnn_cell_lstm","text":"units Positive integer, dimensionality output space. activation Activation function use. Default: hyperbolic tangent (tanh). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). recurrent_activation Activation function use recurrent step. Default: sigmoid (sigmoid). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). use_bias Boolean, (default TRUE), whether layer use bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. Default: \"glorot_uniform\". recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state. Default: \"orthogonal\". bias_initializer Initializer bias vector. Default: \"zeros\". unit_forget_bias Boolean (default TRUE). TRUE, add 1 bias forget gate initialization. Setting TRUE also force bias_initializer=\"zeros\". recommended Jozefowicz et al. kernel_regularizer Regularizer function applied kernel weights matrix. Default: NULL. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. Default: NULL. bias_regularizer Regularizer function applied bias vector. Default: NULL. kernel_constraint Constraint function applied kernel weights matrix. Default: NULL. recurrent_constraint Constraint function applied recurrent_kernel weights matrix. Default: NULL. bias_constraint Constraint function applied bias vector. Default: NULL. dropout Float 0 1. Fraction units drop linear transformation inputs. Default: 0. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. Default: 0. seed Random seed dropout. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_lstm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cell class for the LSTM layer. — rnn_cell_lstm","text":"Layer instance, intended used layer_rnn().","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_lstm.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Cell class for the LSTM layer. — rnn_cell_lstm","text":"inputs: 2D tensor, shape (batch, features). states: 2D tensor shape (batch, units), state previous time step. training: Boolean indicating whether layer behave training mode inference mode. relevant dropout recurrent_dropout used.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_lstm.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cell class for the LSTM layer. — rnn_cell_lstm","text":"","code":"inputs <- random_uniform(c(32, 10, 8)) output <- inputs |>   layer_rnn(cell = rnn_cell_lstm(4)) shape(output) ## shape(32, 4) rnn <- layer_rnn(cell = rnn_cell_lstm(4),                  return_sequences = T,                  return_state = T) c(whole_sequence_output, ...final_state) %<-% rnn(inputs) str(whole_sequence_output) ## <tf.Tensor: shape=(32, 10, 4), dtype=float32, numpy=…> str(final_state) ## List of 2 ##  $ :<tf.Tensor: shape=(32, 4), dtype=float32, numpy=…> ##  $ :<tf.Tensor: shape=(32, 4), dtype=float32, numpy=…>"},{"path":[]},{"path":"https://keras.posit.co/reference/rnn_cell_simple.html","id":null,"dir":"Reference","previous_headings":"","what":"Cell class for SimpleRNN. — rnn_cell_simple","title":"Cell class for SimpleRNN. — rnn_cell_simple","text":"class processes one step within whole time sequence input, whereas layer_simple_rnn() processes whole sequence.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_simple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cell class for SimpleRNN. — rnn_cell_simple","text":"","code":"rnn_cell_simple(   units,   activation = \"tanh\",   use_bias = TRUE,   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   bias_initializer = \"zeros\",   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   bias_regularizer = NULL,   kernel_constraint = NULL,   recurrent_constraint = NULL,   bias_constraint = NULL,   dropout = 0,   recurrent_dropout = 0,   seed = NULL,   ... )"},{"path":"https://keras.posit.co/reference/rnn_cell_simple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cell class for SimpleRNN. — rnn_cell_simple","text":"units Positive integer, dimensionality output space. activation Activation function use. Default: hyperbolic tangent (tanh). pass NULL, activation applied (ie. \"linear\" activation: (x) = x). use_bias Boolean, (default TRUE), whether layer use bias vector. kernel_initializer Initializer kernel weights matrix, used linear transformation inputs. Default: \"glorot_uniform\". recurrent_initializer Initializer recurrent_kernel weights matrix, used linear transformation recurrent state. Default: \"orthogonal\". bias_initializer Initializer bias vector. Default: \"zeros\". kernel_regularizer Regularizer function applied kernel weights matrix. Default: NULL. recurrent_regularizer Regularizer function applied recurrent_kernel weights matrix. Default: NULL. bias_regularizer Regularizer function applied bias vector. Default: NULL. kernel_constraint Constraint function applied kernel weights matrix. Default: NULL. recurrent_constraint Constraint function applied recurrent_kernel weights matrix. Default: NULL. bias_constraint Constraint function applied bias vector. Default: NULL. dropout Float 0 1. Fraction units drop linear transformation inputs. Default: 0. recurrent_dropout Float 0 1. Fraction units drop linear transformation recurrent state. Default: 0. seed Random seed dropout. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_simple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cell class for SimpleRNN. — rnn_cell_simple","text":"Layer instance, intended used layer_rnn().","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_simple.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call Arguments","title":"Cell class for SimpleRNN. — rnn_cell_simple","text":"sequence: 2D tensor, shape (batch, features). states: 2D tensor shape (batch, units), state previous time step. training: Python boolean indicating whether layer behave training mode inference mode. relevant dropout recurrent_dropout used.","code":""},{"path":"https://keras.posit.co/reference/rnn_cell_simple.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cell class for SimpleRNN. — rnn_cell_simple","text":"","code":"inputs <- random_uniform(c(32, 10, 8)) rnn <- layer_rnn(cell = rnn_cell_simple(units = 4)) output <- rnn(inputs)  # The output has shape `(32, 4)`. rnn <- layer_rnn(     cell = rnn_cell_simple(units = 4),     return_sequences=TRUE,     return_state=TRUE ) # whole_sequence_output has shape `(32, 10, 4)`. # final_state has shape `(32, 4)`. c(whole_sequence_output, final_state) %<-% rnn(inputs)"},{"path":[]},{"path":"https://keras.posit.co/reference/rnn_cells_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper allowing a stack of RNN cells to behave as a single cell. — rnn_cells_stack","title":"Wrapper allowing a stack of RNN cells to behave as a single cell. — rnn_cells_stack","text":"Used implement efficient stacked RNNs.","code":""},{"path":"https://keras.posit.co/reference/rnn_cells_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper allowing a stack of RNN cells to behave as a single cell. — rnn_cells_stack","text":"","code":"rnn_cells_stack(cells, ...)"},{"path":"https://keras.posit.co/reference/rnn_cells_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper allowing a stack of RNN cells to behave as a single cell. — rnn_cells_stack","text":"cells List RNN cell instances. ... Unnamed arguments treated additional cells. Named arguments passed underlying layer.","code":""},{"path":"https://keras.posit.co/reference/rnn_cells_stack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wrapper allowing a stack of RNN cells to behave as a single cell. — rnn_cells_stack","text":"Layer instance, intended used layer_rnn().","code":""},{"path":"https://keras.posit.co/reference/rnn_cells_stack.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper allowing a stack of RNN cells to behave as a single cell. — rnn_cells_stack","text":"","code":"batch_size <- 3 sentence_length <- 5 num_features <- 2 new_shape <- c(batch_size, sentence_length, num_features) x <- array(1:30, dim = new_shape)  rnn_cells <- lapply(1:2, function(x) rnn_cell_lstm(units = 128)) stacked_lstm <- rnn_cells_stack(rnn_cells) lstm_layer <- layer_rnn(cell = stacked_lstm)  result <- lstm_layer(x) str(result) ## <tf.Tensor: shape=(3, 128), dtype=float32, numpy=…>"},{"path":[]},{"path":"https://keras.posit.co/reference/save_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves a model as a .keras file. — save_model","title":"Saves a model as a .keras file. — save_model","text":"Saves model .keras file.","code":""},{"path":"https://keras.posit.co/reference/save_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves a model as a .keras file. — save_model","text":"","code":"save_model(model, filepath = NULL, overwrite = FALSE, ...)"},{"path":"https://keras.posit.co/reference/save_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves a model as a .keras file. — save_model","text":"model keras model. filepath string, Path save model. Must end .keras. overwrite Whether overwrite existing model target location, instead ask user via interactive prompt. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/save_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Saves a model as a .keras file. — save_model","text":"filepath provided, function called primarily side effects, model returned invisibly. filepath provided NULL, serialized model returned R raw vector.","code":""},{"path":"https://keras.posit.co/reference/save_model.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Saves a model as a .keras file. — save_model","text":"saved .keras file contains: model's configuration (architecture) model's weights model's optimizer's state () Thus models can reinstantiated exact state.","code":"model <- keras_model_sequential(input_shape = c(3)) |>   layer_dense(5) |>   layer_activation_softmax()  model |> save_model(\"model.keras\") loaded_model <- load_model(\"model.keras\") x <- random_uniform(c(10, 3)) stopifnot(all.equal(   model |> predict(x),   loaded_model |> predict(x) )) zip::zip_list(\"model.keras\")[, \"filename\"] ## [1] \"metadata.json\"    \"config.json\"      \"model.weights.h5\""},{"path":[]},{"path":"https://keras.posit.co/reference/save_model_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Save and load model configuration as JSON — save_model_config","title":"Save and load model configuration as JSON — save_model_config","text":"Save re-load models configurations JSON. Note representation include weights, architecture.","code":""},{"path":"https://keras.posit.co/reference/save_model_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save and load model configuration as JSON — save_model_config","text":"","code":"save_model_config(model, filepath = NULL, overwrite = FALSE)  load_model_config(filepath, custom_objects = NULL)"},{"path":"https://keras.posit.co/reference/save_model_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save and load model configuration as JSON — save_model_config","text":"model Model object save filepath path json file model config. overwrite Whether overwrite existing model configuration json filepath, instead ask user via interactive prompt. custom_objects Optional named list mapping names custom classes functions considered deserialization.","code":""},{"path":"https://keras.posit.co/reference/save_model_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save and load model configuration as JSON — save_model_config","text":"called primarily side effects. model returned, invisibly, enable usage pipe.","code":""},{"path":"https://keras.posit.co/reference/save_model_config.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save and load model configuration as JSON — save_model_config","text":"Note: save_model_config() serializes model JSON using serialize_keras_object(), get_config(). serialize_keras_object() returns superset get_config(), additional information needed create class object needed restore model. See example extract get_config() value saved model.","code":"model <- keras_model_sequential(input_shape = 10) |> layer_dense(10) file <- tempfile(\"model-config-\", fileext = \".json\") save_model_config(model, file)  # load a new model instance with the same architecture but different weights model2 <- load_model_config(file)  stopifnot(exprs = {   all.equal(get_config(model), get_config(model2))    # To extract the `get_config()` value from a saved model config:   all.equal(       get_config(model),       structure(jsonlite::read_json(file)$config,                 \"__class__\" = keras_model_sequential()$`__class__`)   ) })"},{"path":[]},{"path":"https://keras.posit.co/reference/save_model_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves all layer weights to a .weights.h5 file. — save_model_weights","title":"Saves all layer weights to a .weights.h5 file. — save_model_weights","text":"Saves layer weights .weights.h5 file.","code":""},{"path":"https://keras.posit.co/reference/save_model_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves all layer weights to a .weights.h5 file. — save_model_weights","text":"","code":"save_model_weights(model, filepath, overwrite = FALSE)"},{"path":"https://keras.posit.co/reference/save_model_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves all layer weights to a .weights.h5 file. — save_model_weights","text":"model keras Model object filepath string. Path save model. Must end .weights.h5. overwrite Whether overwrite existing model target location, instead ask user via interactive prompt.","code":""},{"path":"https://keras.posit.co/reference/save_model_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Saves all layer weights to a .weights.h5 file. — save_model_weights","text":"called primarily side effects. model returned, invisibly, enable usage pipe.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/serialize_keras_object.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the full config by serializing the Keras object. — serialize_keras_object","title":"Retrieve the full config by serializing the Keras object. — serialize_keras_object","text":"serialize_keras_object() serializes Keras object named list represents object, reciprocal function deserialize_keras_object(). See deserialize_keras_object() information full config format.","code":""},{"path":"https://keras.posit.co/reference/serialize_keras_object.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the full config by serializing the Keras object. — serialize_keras_object","text":"","code":"serialize_keras_object(obj)"},{"path":"https://keras.posit.co/reference/serialize_keras_object.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the full config by serializing the Keras object. — serialize_keras_object","text":"obj Keras object serialize.","code":""},{"path":"https://keras.posit.co/reference/serialize_keras_object.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the full config by serializing the Keras object. — serialize_keras_object","text":"named list represents object config. config expected contain simple types , can saved json. object can deserialized config via deserialize_keras_object().","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/set_random_seed.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets all random seeds (Python, NumPy, and backend framework, e.g. TF). — set_random_seed","title":"Sets all random seeds (Python, NumPy, and backend framework, e.g. TF). — set_random_seed","text":"can use utility make almost Keras program fully deterministic. limitations apply cases network communications involved (e.g. parameter server distribution), creates additional sources randomness, certain non-deterministic cuDNN ops involved. sets: R session seed: set.seed() Python session seed: import random; random.seed(seed) Python NumPy seed: import numpy; numpy.random.seed(seed) TensorFlow seed: tf$random$set_seed(seed) (TF installed) Torch seed: import(\"torch\")$manual_seed(seed) (backend torch) disables Python hash randomization. Note TensorFlow seed set even using TensorFlow backend framework, since many workflows leverage tf$data pipelines (feature random shuffling). Likewise many workflows might leverage NumPy APIs.","code":""},{"path":"https://keras.posit.co/reference/set_random_seed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets all random seeds (Python, NumPy, and backend framework, e.g. TF). — set_random_seed","text":"","code":"set_random_seed(seed)"},{"path":"https://keras.posit.co/reference/set_random_seed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets all random seeds (Python, NumPy, and backend framework, e.g. TF). — set_random_seed","text":"seed Integer, random seed use.","code":""},{"path":"https://keras.posit.co/reference/set_random_seed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets all random seeds (Python, NumPy, and backend framework, e.g. TF). — set_random_seed","text":"return value, called side effects.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/shape.html","id":null,"dir":"Reference","previous_headings":"","what":"Tensor shape utility — shape","title":"Tensor shape utility — shape","text":"function can used create get shape object.","code":""},{"path":"https://keras.posit.co/reference/shape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tensor shape utility — shape","text":"","code":"shape(...)  # S3 method for keras_shape format(x, ..., prefix = TRUE)  # S3 method for keras_shape print(x, ...)  # S3 method for keras_shape [(x, ...)  # S3 method for keras_shape as.integer(x, ...)  # S3 method for keras_shape as.list(x, ...)"},{"path":"https://keras.posit.co/reference/shape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tensor shape utility — shape","text":"... shape specification. Numerics, NULL tensors valid. NULL, NA, -1L can used specify unspecified dim size. Tensors dispatched op_shape() extract tensor shape. Values wrapped () used asis (see examples). objects coerced via .integer(). x 'keras_shape' object prefix Whether format shape object prefix. Defaults \"shape\".","code":""},{"path":"https://keras.posit.co/reference/shape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tensor shape utility — shape","text":"list \"keras_shape\" class attribute. element list either ) NULL, b) integer c) scalar integer tensor (e.g., supplied TF tensor unspecified dimension function traced).","code":""},{"path":"https://keras.posit.co/reference/shape.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tensor shape utility — shape","text":"3 ways specify unknown dimension     functions take 'shape' argument also coerce shape()     can also use shape() get shape tensor (excepting scalar integer tensors).             Combine expand shapes         Scalar integer tensors treated axis values. commonly encountered tracing function graph mode, axis size might unknown.     useful pattern unpack shape() %<-%, like :                     want resolve shape tensor can potentially scalar integer, can wrap tensor (), use op_shape().","code":"shape(1, 2, 3) ## shape(1, 2, 3) shape(NA,   2, 3) shape(NULL, 2, 3) shape(-1,   2, 3) ## shape(NA, 2, 3) ## shape(NA, 2, 3) ## shape(NA, 2, 3) layer_input(c(1, 2, 3)) layer_input(shape(1, 2, 3)) ## <KerasTensor shape=(None, 1, 2, 3), dtype=float32, sparse=None, name=keras_tensor> ## <KerasTensor shape=(None, 1, 2, 3), dtype=float32, sparse=None, name=keras_tensor_1> symbolic_tensor <- layer_input(shape(1, 2, 3)) shape(symbolic_tensor) ## shape(NA, 1, 2, 3) eager_tensor <- op_ones(c(1,2,3)) shape(eager_tensor) ## shape(1, 2, 3) op_shape(eager_tensor) ## shape(1, 2, 3) shape(symbolic_tensor, 4) ## shape(NA, 1, 2, 3, 4) shape(5, symbolic_tensor, 4) ## shape(5, NA, 1, 2, 3, 4) tfn <- tensorflow::tf_function(function(x) {   print(op_shape(x))   x }, input_signature = list(tensorflow::tf$TensorSpec(shape(1, NA, 3)))) invisible(tfn(op_ones(shape(1, 2, 3)))) ## shape(1, Tensor(\"strided_slice:0\", shape=(), dtype=int32), 3) c(batch_size, seq_len, channels) %<-% shape(x) echo_print <- function(x) {   message(\"> \", deparse(substitute(x)));   if(!is.null(x)) print(x) } tfn <- tensorflow::tf_function(function(x) {   c(axis1, axis2, axis3) %<-% shape(x)   echo_print(str(list(axis1 = axis1, axis2 = axis2, axis3 = axis3)))    echo_print(shape(axis1))               # use axis1 tensor as axis value   echo_print(shape(axis1, axis2, axis3)) # use axis1 tensor as axis value    # use shape() to compose a new shape, e.g., in multihead attention   n_heads <- 4   echo_print(shape(axis1, axis2, n_heads, axis3/n_heads))    x }, input_signature = list(tensorflow::tf$TensorSpec(shape(NA, 4, 16)))) invisible(tfn(op_ones(shape(2, 4, 16)))) ## > str(list(axis1 = axis1, axis2 = axis2, axis3 = axis3)) ## List of 3 ##  $ axis1:<tf.Tensor 'strided_slice:0' shape=() dtype=int32> ##  $ axis2: int 4 ##  $ axis3: int 16 ## > shape(axis1) ## shape(Tensor(\"strided_slice:0\", shape=(), dtype=int32)) ## > shape(axis1, axis2, axis3) ## shape(Tensor(\"strided_slice:0\", shape=(), dtype=int32), 4, 16) ## > shape(axis1, axis2, n_heads, axis3/n_heads) ## shape(Tensor(\"strided_slice:0\", shape=(), dtype=int32), 4, 4, 4) (x <- op_convert_to_tensor(2L)) ## tf.Tensor(2, shape=(), dtype=int32) # by default, shape() treats scalar integer tensors as axis values shape(x) ## shape(tf.Tensor(2, shape=(), dtype=int32)) # to access the shape of a scalar integer, # call `op_shape()`, or protect with `I()` op_shape(x) ## shape() shape(I(x)) ## shape()"},{"path":[]},{"path":"https://keras.posit.co/reference/split_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Splits a dataset into a left half and a right half (e.g. train / test). — split_dataset","title":"Splits a dataset into a left half and a right half (e.g. train / test). — split_dataset","text":"Splits dataset left half right half (e.g. train / test).","code":""},{"path":"https://keras.posit.co/reference/split_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splits a dataset into a left half and a right half (e.g. train / test). — split_dataset","text":"","code":"split_dataset(   dataset,   left_size = NULL,   right_size = NULL,   shuffle = FALSE,   seed = NULL )"},{"path":"https://keras.posit.co/reference/split_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splits a dataset into a left half and a right half (e.g. train / test). — split_dataset","text":"dataset tf$data$Dataset, torch$utils$data$Dataset object, list arrays length. left_size float (range [0, 1]), signifies fraction data pack left dataset. integer, signifies number samples pack left dataset. NULL, defaults complement right_size. Defaults NULL. right_size float (range [0, 1]), signifies fraction data pack right dataset. integer, signifies number samples pack right dataset. NULL, defaults complement left_size. Defaults NULL. shuffle Boolean, whether shuffle data splitting . seed random seed shuffling.","code":""},{"path":"https://keras.posit.co/reference/split_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splits a dataset into a left half and a right half (e.g. train / test). — split_dataset","text":"list two tf$data$Dataset objects: left right splits.","code":""},{"path":"https://keras.posit.co/reference/split_dataset.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splits a dataset into a left half and a right half (e.g. train / test). — split_dataset","text":"","code":"data <- random_uniform(c(1000, 4)) c(left_ds, right_ds) %<-% split_dataset(list(data$numpy()), left_size = 0.8) left_ds$cardinality() ## tf.Tensor(800, shape=(), dtype=int64) right_ds$cardinality() ## tf.Tensor(200, shape=(), dtype=int64)"},{"path":[]},{"path":"https://keras.posit.co/reference/summary.keras.src.models.model.Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a summary of a Keras Model — summary.keras.src.models.model.Model","title":"Print a summary of a Keras Model — summary.keras.src.models.model.Model","text":"Print summary Keras Model","code":""},{"path":"https://keras.posit.co/reference/summary.keras.src.models.model.Model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a summary of a Keras Model — summary.keras.src.models.model.Model","text":"","code":"# S3 method for keras.src.models.model.Model summary(object, ...)  # S3 method for keras.src.models.model.Model format(   x,   line_length = getOption(\"width\"),   positions = NULL,   expand_nested = FALSE,   show_trainable = NA,   ...,   layer_range = NULL,   compact = TRUE )  # S3 method for keras.src.models.model.Model print(x, ...)"},{"path":"https://keras.posit.co/reference/summary.keras.src.models.model.Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a summary of a Keras Model — summary.keras.src.models.model.Model","text":"object, x Keras model instance ... summary() print(), passed format(). format(), passed model$summary(). line_length Total length printed lines positions Relative absolute positions log elements line. provided, defaults c(0.33, 0.55, 0.67, 1.0). expand_nested Whether expand nested models. provided, defaults FALSE. show_trainable Whether show layer trainable. provided, defaults FALSE. layer_range list, tuple, vector 2 strings, starting layer name ending layer name (inclusive) indicating range layers printed summary. also accepts regex patterns instead exact name. case, start predicate first element matches layer_range[[1]] end predicate last element matches layer_range[[1]]. default NULL considers layers model. compact Whether remove white-space lines model summary. (Default TRUE)","code":""},{"path":"https://keras.posit.co/reference/summary.keras.src.models.model.Model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a summary of a Keras Model — summary.keras.src.models.model.Model","text":"format() returns length 1 character vector. print() returns model object invisibly. summary() returns output format() invisibly printing .","code":""},{"path":"https://keras.posit.co/reference/summary.keras.src.models.model.Model.html","id":"enabling-color-output-in-knitr-rmarkdown-quarto-","dir":"Reference","previous_headings":"","what":"Enabling color output in Knitr (RMarkdown, Quarto)","title":"Print a summary of a Keras Model — summary.keras.src.models.model.Model","text":"order enable color output quarto rmarkdown document html output format (include revealjs presentations), need following setup chunk:","code":"```{r setup, include = FALSE}  options(cli.num_colors = 256)  fansi::set_knit_hooks(knitr::knit_hooks)  options(width = 75) # adjust as needed for format  ```"},{"path":[]},{"path":"https://keras.posit.co/reference/test_on_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Test the model on a single batch of samples. — test_on_batch","title":"Test the model on a single batch of samples. — test_on_batch","text":"Test model single batch samples.","code":""},{"path":"https://keras.posit.co/reference/test_on_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test the model on a single batch of samples. — test_on_batch","text":"","code":"test_on_batch(object, x, y = NULL, sample_weight = NULL, ...)"},{"path":"https://keras.posit.co/reference/test_on_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test the model on a single batch of samples. — test_on_batch","text":"object Keras model object x Input data. Must array-like. y Target data. Must array-like. sample_weight Optional array length x, containing weights apply model's loss sample. case temporal data, can pass 2D array shape (samples, sequence_length), apply different weight every timestep every sample. ... forward/backward compatability","code":""},{"path":"https://keras.posit.co/reference/test_on_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test the model on a single batch of samples. — test_on_batch","text":"scalar loss value (metrics), named list loss metric values (metrics).","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/text_dataset_from_directory.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates a tf.data.Dataset from text files in a directory. — text_dataset_from_directory","title":"Generates a tf.data.Dataset from text files in a directory. — text_dataset_from_directory","text":"directory structure :   calling text_dataset_from_directory(main_directory, labels='inferred') return tf.data.Dataset yields batches texts subdirectories class_a class_b, together labels 0 1 (0 corresponding class_a 1 corresponding class_b). .txt files supported time.","code":"main_directory/ ...class_a/ ......a_text_1.txt ......a_text_2.txt ...class_b/ ......b_text_1.txt ......b_text_2.txt"},{"path":"https://keras.posit.co/reference/text_dataset_from_directory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates a tf.data.Dataset from text files in a directory. — text_dataset_from_directory","text":"","code":"text_dataset_from_directory(   directory,   labels = \"inferred\",   label_mode = \"int\",   class_names = NULL,   batch_size = 32L,   max_length = NULL,   shuffle = TRUE,   seed = NULL,   validation_split = NULL,   subset = NULL,   follow_links = FALSE,   verbose = TRUE )"},{"path":"https://keras.posit.co/reference/text_dataset_from_directory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates a tf.data.Dataset from text files in a directory. — text_dataset_from_directory","text":"directory Directory data located. labels \"inferred\", contain subdirectories, containing text files class. Otherwise, directory structure ignored. labels Either \"inferred\" (labels generated directory structure), NULL (labels), list/tuple integer labels size number text files found directory. Labels sorted according alphanumeric order text file paths (obtained via os.walk(directory) Python). label_mode String describing encoding labels. Options : \"int\": means labels encoded integers (e.g. sparse_categorical_crossentropy loss). \"categorical\" means labels encoded categorical vector (e.g. categorical_crossentropy loss). \"binary\" means labels (can 2) encoded float32 scalars values 0 1 (e.g. binary_crossentropy). NULL (labels). class_names valid \"labels\" \"inferred\". explicit list class names (must match names subdirectories). Used control order classes (otherwise alphanumerical order used). batch_size Size batches data. Defaults 32. NULL, data batched (dataset yield individual samples). max_length Maximum size text string. Texts longer truncated max_length. shuffle Whether shuffle data. Defaults TRUE. set FALSE, sorts data alphanumeric order. seed Optional random seed shuffling transformations. validation_split Optional float 0 1, fraction data reserve validation. subset Subset data return. One \"training\", \"validation\" \"\". used validation_split set. subset=\"\", utility returns tuple two datasets (training validation datasets respectively). follow_links Whether visits subdirectories pointed symlinks. Defaults FALSE. verbose Whether display number information classes number files found. Defaults TRUE.","code":""},{"path":"https://keras.posit.co/reference/text_dataset_from_directory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates a tf.data.Dataset from text files in a directory. — text_dataset_from_directory","text":"tf.data.Dataset object. label_mode NULL, yields string tensors shape (batch_size,), containing contents batch text files. Otherwise, yields tuple (texts, labels), texts shape (batch_size,) labels follows format described . Rules regarding labels format: label_mode int, labels int32 tensor shape (batch_size,). label_mode binary, labels float32 tensor 1s 0s shape (batch_size, 1). label_mode categorical, labels float32 tensor shape (batch_size, num_classes), representing one-hot encoding class index.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/time_distributed.html","id":null,"dir":"Reference","previous_headings":"","what":"layer_time_distributed — time_distributed","title":"layer_time_distributed — time_distributed","text":"time_distributed() alias layer_time_distributed(). See ?layer_time_distributed() full documentation.","code":""},{"path":"https://keras.posit.co/reference/time_distributed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"layer_time_distributed — time_distributed","text":"","code":"time_distributed(object, layer, ...)"},{"path":"https://keras.posit.co/reference/time_distributed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"layer_time_distributed — time_distributed","text":"object Object compose layer . tensor, array, sequential model. layer Layer instance. ... forward/backward compatability.","code":""},{"path":"https://keras.posit.co/reference/time_distributed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"layer_time_distributed — time_distributed","text":"return value depends value provided first argument.  object : keras_model_sequential(), layer added sequential model (modified place). enable piping, sequential model also returned, invisibly. keras_input(), output tensor calling layer(input) returned. NULL missing, Layer instance returned.","code":""},{"path":"https://keras.posit.co/reference/timeseries_dataset_from_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a dataset of sliding windows over a timeseries provided as array. — timeseries_dataset_from_array","title":"Creates a dataset of sliding windows over a timeseries provided as array. — timeseries_dataset_from_array","text":"function takes sequence data-points gathered equal intervals, along time series parameters length sequences/windows, spacing two sequence/windows, etc., produce batches timeseries inputs targets.","code":""},{"path":"https://keras.posit.co/reference/timeseries_dataset_from_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a dataset of sliding windows over a timeseries provided as array. — timeseries_dataset_from_array","text":"","code":"timeseries_dataset_from_array(   data,   targets,   sequence_length,   sequence_stride = 1L,   sampling_rate = 1L,   batch_size = 128L,   shuffle = FALSE,   seed = NULL,   start_index = NULL,   end_index = NULL )"},{"path":"https://keras.posit.co/reference/timeseries_dataset_from_array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a dataset of sliding windows over a timeseries provided as array. — timeseries_dataset_from_array","text":"data array eager tensor containing consecutive data points (timesteps). first dimension expected time dimension. targets Targets corresponding timesteps data. targets[] target corresponding window starts index (see example 2 ). Pass NULL target data (case dataset yield input data). sequence_length Length output sequences (number timesteps). sequence_stride Period successive output sequences. stride s, output samples start index data[], data[+ s], data[+ 2 * s], etc. sampling_rate Period successive individual timesteps within sequences. rate r, timesteps data[], data[+ r], ... data[+ sequence_length] used creating sample sequence. batch_size Number timeseries samples batch (except maybe last one). NULL, data batched (dataset yield individual samples). shuffle Whether shuffle output samples, instead draw chronological order. seed Optional int; random seed shuffling. start_index Optional int; data points earlier (exclusive) start_index used output sequences. useful reserve part data test validation. end_index Optional int; data points later (exclusive) end_index used output sequences. useful reserve part data test validation.","code":""},{"path":"https://keras.posit.co/reference/timeseries_dataset_from_array.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a dataset of sliding windows over a timeseries provided as array. — timeseries_dataset_from_array","text":"tf$data$Dataset instance. targets passed, dataset yields list (batch_of_sequences, batch_of_targets). , dataset yields batch_of_sequences. Example 1: Consider indices [0, 1, ... 98]. sequence_length=10,  sampling_rate=2, sequence_stride=3, shuffle=FALSE, dataset yield batches sequences composed following indices:   case last 2 data points discarded since full sequence can generated include (next sequence started index 81, thus last step gone 98). Example 2: Temporal regression. Consider array data scalar values, shape (steps,). generate dataset uses past 10 timesteps predict next timestep, use:     Example 3: Temporal regression many--many architectures. Consider two arrays scalar values X Y, shape (100,). resulting dataset consist samples 20 timestamps . samples overlap. generate dataset uses current timestamp predict corresponding target timestep, use:","code":"First sequence:  [0  2  4  6  8 10 12 14 16 18] Second sequence: [3  5  7  9 11 13 15 17 19 21] Third sequence:  [6  8 10 12 14 16 18 20 22 24] ... Last sequence:   [78 80 82 84 86 88 90 92 94 96] data <- op_array(1:20) input_data <- data[1:10] targets <- data[11:20] dataset <- timeseries_dataset_from_array(   input_data, targets, sequence_length=10) iter <- reticulate::as_iterator(dataset) reticulate::iter_next(iter) ## [[1]] ## tf.Tensor([[ 1  2  3  4  5  6  7  8  9 10]], shape=(1, 10), dtype=int32) ## ## [[2]] ## tf.Tensor([11], shape=(1), dtype=int32) X <- op_array(1:100) Y <- X*2  sample_length <- 20 input_dataset <- timeseries_dataset_from_array(     X, NULL, sequence_length=sample_length, sequence_stride=sample_length) target_dataset <- timeseries_dataset_from_array(     Y, NULL, sequence_length=sample_length, sequence_stride=sample_length)   inputs <- reticulate::as_iterator(input_dataset) %>% reticulate::iter_next() targets <- reticulate::as_iterator(target_dataset) %>% reticulate::iter_next()"},{"path":[]},{"path":"https://keras.posit.co/reference/to_categorical.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts a class vector (integers) to binary class matrix. — to_categorical","title":"Converts a class vector (integers) to binary class matrix. — to_categorical","text":"E.g. use loss_categorical_crossentropy().","code":""},{"path":"https://keras.posit.co/reference/to_categorical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts a class vector (integers) to binary class matrix. — to_categorical","text":"","code":"to_categorical(x, num_classes = NULL)"},{"path":"https://keras.posit.co/reference/to_categorical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts a class vector (integers) to binary class matrix. — to_categorical","text":"x Array-like class values converted matrix (integers 0 num_classes - 1). R factors coerced integer offset 0-based, .e., .integer(x) - 1L. num_classes Total number classes. NULL, inferred max(x) + 1. Defaults NULL.","code":""},{"path":"https://keras.posit.co/reference/to_categorical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts a class vector (integers) to binary class matrix. — to_categorical","text":"binary matrix representation input R array. class axis placed last.","code":""},{"path":"https://keras.posit.co/reference/to_categorical.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts a class vector (integers) to binary class matrix. — to_categorical","text":"","code":"a <- to_categorical(c(0, 1, 2, 3), num_classes=4) print(a) ##      [,1] [,2] [,3] [,4] ## [1,]    1    0    0    0 ## [2,]    0    1    0    0 ## [3,]    0    0    1    0 ## [4,]    0    0    0    1 b <- array(c(.9, .04, .03, .03,               .3, .45, .15, .13,               .04, .01, .94, .05,               .12, .21, .5, .17),               dim = c(4, 4)) loss <- op_categorical_crossentropy(a, b) loss ## tf.Tensor([0.41284522 0.45601739 0.54430155 0.80437282], shape=(4), dtype=float64) loss <- op_categorical_crossentropy(a, a) loss ## tf.Tensor([1.00000005e-07 1.00000005e-07 1.00000005e-07 1.00000005e-07], shape=(4), dtype=float64)"},{"path":[]},{"path":"https://keras.posit.co/reference/train_on_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Runs a single gradient update on a single batch of data. — train_on_batch","title":"Runs a single gradient update on a single batch of data. — train_on_batch","text":"Runs single gradient update single batch data.","code":""},{"path":"https://keras.posit.co/reference/train_on_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Runs a single gradient update on a single batch of data. — train_on_batch","text":"","code":"train_on_batch(object, x, y = NULL, sample_weight = NULL, class_weight = NULL)"},{"path":"https://keras.posit.co/reference/train_on_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Runs a single gradient update on a single batch of data. — train_on_batch","text":"object Keras model object x Input data. Must array-like. y Target data. Must array-like. sample_weight Optional array length x, containing weights apply model's loss sample. case temporal data, can pass 2D array shape (samples, sequence_length), apply different weight every timestep every sample. class_weight Optional named list mapping class indices (integers, 0-based) weight (float) apply model's loss samples class training. can useful tell model \"pay attention\" samples -represented class. class_weight specified targets rank 2 greater, either y must one-hot encoded, explicit final dimension 1 must included sparse class labels.","code":""},{"path":"https://keras.posit.co/reference/train_on_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Runs a single gradient update on a single batch of data. — train_on_batch","text":"scalar loss value (metrics), named list loss metric values (metrics). property model$metrics_names give display labels scalar outputs.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/unpack_x_y_sample_weight.html","id":null,"dir":"Reference","previous_headings":"","what":"Unpacks user-provided data list. — unpack_x_y_sample_weight","title":"Unpacks user-provided data list. — unpack_x_y_sample_weight","text":"convenience utility used overriding $train_step, $test_step, $predict_step. utility makes easy support data form (x,), (x, y), (x, y, sample_weight).","code":""},{"path":"https://keras.posit.co/reference/unpack_x_y_sample_weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unpacks user-provided data list. — unpack_x_y_sample_weight","text":"","code":"unpack_x_y_sample_weight(data)"},{"path":"https://keras.posit.co/reference/unpack_x_y_sample_weight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unpacks user-provided data list. — unpack_x_y_sample_weight","text":"data list form (x), (x, y), (x, y, sample_weight).","code":""},{"path":"https://keras.posit.co/reference/unpack_x_y_sample_weight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unpacks user-provided data list. — unpack_x_y_sample_weight","text":"unpacked list, NULLs y sample_weight provided.","code":""},{"path":"https://keras.posit.co/reference/unpack_x_y_sample_weight.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unpacks user-provided data list. — unpack_x_y_sample_weight","text":"Standalone usage:","code":"features_batch <- op_ones(c(10, 5)) labels_batch <- op_zeros(c(10, 5)) data <- list(features_batch, labels_batch) # `y` and `sample_weight` will default to `NULL` if not provided. c(x, y, sample_weight) %<-% unpack_x_y_sample_weight(data)"},{"path":[]},{"path":"https://keras.posit.co/reference/use_backend.html","id":null,"dir":"Reference","previous_headings":"","what":"Configure a Keras backend — use_backend","title":"Configure a Keras backend — use_backend","text":"Configure Keras backend","code":""},{"path":"https://keras.posit.co/reference/use_backend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Configure a Keras backend — use_backend","text":"","code":"use_backend(backend)"},{"path":"https://keras.posit.co/reference/use_backend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Configure a Keras backend — use_backend","text":"backend string, can \"tensorflow\", \"jax\", \"numpy\", \"torch\".","code":""},{"path":"https://keras.posit.co/reference/use_backend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Configure a Keras backend — use_backend","text":"Called primarily side effects. Returns provided backend, invisibly.","code":""},{"path":"https://keras.posit.co/reference/use_backend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Configure a Keras backend — use_backend","text":"functions allow configuring backend keras use. Note one backend can configured time. function called library(keras3) calling functions within package (see example). experimental support changing backend keras initialized. using config_set_backend().","code":"library(keras3) use_backend(\"tensorflow\")"},{"path":"https://keras.posit.co/reference/with_custom_object_scope.html","id":null,"dir":"Reference","previous_headings":"","what":"Provide a scope with mappings of names to custom objects — with_custom_object_scope","title":"Provide a scope with mappings of names to custom objects — with_custom_object_scope","text":"Provide scope mappings names custom objects","code":""},{"path":"https://keras.posit.co/reference/with_custom_object_scope.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provide a scope with mappings of names to custom objects — with_custom_object_scope","text":"","code":"with_custom_object_scope(objects, expr)"},{"path":"https://keras.posit.co/reference/with_custom_object_scope.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provide a scope with mappings of names to custom objects — with_custom_object_scope","text":"objects Named list objects expr Expression evaluate","code":""},{"path":"https://keras.posit.co/reference/with_custom_object_scope.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Provide a scope with mappings of names to custom objects — with_custom_object_scope","text":"result evaluating expr within custom object scope.","code":""},{"path":"https://keras.posit.co/reference/with_custom_object_scope.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Provide a scope with mappings of names to custom objects — with_custom_object_scope","text":"many elements Keras models can customized user objects (e.g. losses, metrics, regularizers, etc.). loading saved models use functions typically need explicitly map names user objects via custom_objects parameter. with_custom_object_scope() function provides alternative lets create named alias user object applies entire block code, automatically recognized loading saved models.","code":""},{"path":"https://keras.posit.co/reference/with_custom_object_scope.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Provide a scope with mappings of names to custom objects — with_custom_object_scope","text":"","code":"# define custom metric metric_top_3_categorical_accuracy <-   custom_metric(\"top_3_categorical_accuracy\", function(y_true, y_pred) {     metric_top_k_categorical_accuracy(y_true, y_pred, k = 3)   })  with_custom_object_scope(c(top_k_acc = sparse_top_k_cat_acc), {    # ...define model...    # compile model (refer to \"top_k_acc\" by name)   model |> compile(     loss = \"binary_crossentropy\",     optimizer = optimizer_nadam(),     metrics = c(\"top_k_acc\")   )    # save the model   model |> save_model(\"my_model.keras\")    # loading the model within the custom object scope doesn't   # require explicitly providing the custom_object   reloaded_model <- load_model(\"my_model.keras\") })"},{"path":[]},{"path":"https://keras.posit.co/reference/zip_lists.html","id":null,"dir":"Reference","previous_headings":"","what":"Zip lists — zip_lists","title":"Zip lists — zip_lists","text":"conceptually similar zip() Python, R functions purrr::transpose() data.table::transpose() (albeit, accepting elements ... instead single list), one crucial difference: provided objects named, matching done names, positions.","code":""},{"path":"https://keras.posit.co/reference/zip_lists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zip lists — zip_lists","text":"","code":"zip_lists(...)"},{"path":"https://keras.posit.co/reference/zip_lists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zip lists — zip_lists","text":"... R lists atomic vectors, optionally named.","code":""},{"path":"https://keras.posit.co/reference/zip_lists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zip lists — zip_lists","text":"inverted list","code":""},{"path":"https://keras.posit.co/reference/zip_lists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Zip lists — zip_lists","text":"arguments supplied must length. positional matching required, arguments provided must unnamed. matching names, arguments must set names, can different orders.","code":""},{"path":[]},{"path":"https://keras.posit.co/reference/zip_lists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zip lists — zip_lists","text":"","code":"gradients <- list(\"grad_for_wt_1\", \"grad_for_wt_2\", \"grad_for_wt_3\") weights <- list(\"weight_1\", \"weight_2\", \"weight_3\") str(zip_lists(gradients, weights)) #> List of 3 #>  $ :List of 2 #>   ..$ : chr \"grad_for_wt_1\" #>   ..$ : chr \"weight_1\" #>  $ :List of 2 #>   ..$ : chr \"grad_for_wt_2\" #>   ..$ : chr \"weight_2\" #>  $ :List of 2 #>   ..$ : chr \"grad_for_wt_3\" #>   ..$ : chr \"weight_3\" str(zip_lists(gradient = gradients, weight = weights)) #> List of 3 #>  $ :List of 2 #>   ..$ gradient: chr \"grad_for_wt_1\" #>   ..$ weight  : chr \"weight_1\" #>  $ :List of 2 #>   ..$ gradient: chr \"grad_for_wt_2\" #>   ..$ weight  : chr \"weight_2\" #>  $ :List of 2 #>   ..$ gradient: chr \"grad_for_wt_3\" #>   ..$ weight  : chr \"weight_3\"  names(gradients) <- names(weights) <- paste0(\"layer_\", 1:3) str(zip_lists(gradients, weights[c(3, 1, 2)])) #> List of 3 #>  $ layer_1:List of 2 #>   ..$ : chr \"grad_for_wt_1\" #>   ..$ : chr \"weight_1\" #>  $ layer_2:List of 2 #>   ..$ : chr \"grad_for_wt_2\" #>   ..$ : chr \"weight_2\" #>  $ layer_3:List of 2 #>   ..$ : chr \"grad_for_wt_3\" #>   ..$ : chr \"weight_3\"  names(gradients) <- paste0(\"gradient_\", 1:3) try(zip_lists(gradients, weights)) # error, names don't match #> Error in zip_lists(gradients, weights) :  #>   All names of arguments provided to `zip_lists()` must match. Call `unname()` on each argument if you want positional matching # call unname directly for positional matching str(zip_lists(unname(gradients), unname(weights))) #> List of 3 #>  $ :List of 2 #>   ..$ : chr \"grad_for_wt_1\" #>   ..$ : chr \"weight_1\" #>  $ :List of 2 #>   ..$ : chr \"grad_for_wt_2\" #>   ..$ : chr \"weight_2\" #>  $ :List of 2 #>   ..$ : chr \"grad_for_wt_3\" #>   ..$ : chr \"weight_3\""},{"path":"https://keras.posit.co/news/index.html","id":"keras3-development-version","dir":"Changelog","previous_headings":"","what":"keras3 (development version)","title":"keras3 (development version)","text":"New functions: quantize_weights(): quantize model layer weights -place. Currently, Dense EinsumDense layers supported (enough cover majority transformers today) layer_mel_spectrogram() random_beta() random_binomial() config_set_backend(): change backend Keras initialized. config_dtype_policy() config_set_dtype_policy() New Ops op_custom_gradient() op_batch_normalization() op_image_crop() op_divide_no_nan() op_normalize() New family linear algebra ops op_cholesky() op_det() op_eig() op_inv() op_lu_factor() op_norm() op_erfinv() op_solve_triangular() op_svd() audio_dataset_from_directory(), image_dataset_from_directory() text_dataset_from_directory() gain verbose argument (default TRUE) image_dataset_from_directory() gains pad_to_aspect_ratio argument (default FALSE) to_categorical(), op_one_hot(), fit() can now accept R factors, offset 0-based (reported #1055). op_convert_to_numpy() now returns unconverted NumPy arrays. op_array() op_convert_to_tensor() longer error casting R doubles integer types. Doc improvements.","code":""},{"path":"https://keras.posit.co/news/index.html","id":"keras3-010","dir":"Changelog","previous_headings":"","what":"keras3 0.1.0","title":"keras3 0.1.0","text":"CRAN release: 2024-02-17 package rebuilt Keras 3.0. Refer  overview https://keras.posit.co current --date documentation.","code":""}]
