<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Text classification from scratch • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../../../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../../../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../../../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../../../favicon.ico">
<link rel="manifest" href="../../../site.webmanifest">
<script src="../../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../../../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../../../deps/headroom-0.11.0/headroom.min.js"></script><script src="../../../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../../../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../../../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../../../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../../../deps/search-1.0.0/fuse.min.js"></script><script src="../../../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../../../pkgdown.js"></script><link href="../../../extra.css" rel="stylesheet">
<meta property="og:title" content="Text classification from scratch">
<meta name="description" content="Text sentiment classification starting from raw text files.">
<meta property="og:description" content="Text sentiment classification starting from raw text files.">
<meta name="robots" content="noindex">
<!-- Google Tag Manager --><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-KHBDBW7');</script><!-- End Google Tag Manager -->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    <!-- Google Tag Manager (noscript) --> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KHBDBW7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <!-- End Google Tag Manager (noscript) -->


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="inverse" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../../../index.html">keras3</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">1.4.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../../../articles/getting_started.html">Getting Started</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-guides" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Guides</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-guides">
<li><h6 class="dropdown-header" data-toc-skip>Model definition</h6></li>
    <li><a class="dropdown-item" href="../../../articles/sequential_model.html">Sequential Model</a></li>
    <li><a class="dropdown-item" href="../../../articles/functional_api.html">Functional API</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6></li>
    <li><a class="dropdown-item" href="../../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a></li>
    <li><a class="dropdown-item" href="../../../articles/custom_train_step_in_tensorflow.html">Customizing `fit()` with Tensorflow</a></li>
    <li><a class="dropdown-item" href="../../../articles/writing_your_own_callbacks.html">Writing your own callbacks</a></li>
    <li><a class="dropdown-item" href="../../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a></li>
    <li><a class="dropdown-item" href="../../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a></li>
    <li><a class="dropdown-item" href="../../../articles/serialization_and_saving.html">Serialization and Saving</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Other topics</h6></li>
    <li><a class="dropdown-item" href="../../../articles/transfer_learning.html">Transfer learning and fine tuning</a></li>
    <li><a class="dropdown-item" href="../../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a></li>
    <li><a class="dropdown-item" href="../../../articles/distribution.html">Distributed training with Jax</a></li>
  </ul>
</li>
<li class="active nav-item"><a class="nav-link" href="../../../articles/examples/index.html">Examples</a></li>
<li class="nav-item"><a class="nav-link" href="../../../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../../../news/index.html">News</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../../../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/rstudio/keras3/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Text classification from scratch</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras3/blob/HEAD/vignettes/examples/nlp/text_classification_from_scratch.Rmd" class="external-link"><code>vignettes/examples/nlp/text_classification_from_scratch.Rmd</code></a></small>
      <div class="d-none name"><code>text_classification_from_scratch.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This example shows how to do text classification starting from raw
text (as a set of text files on disk). We demonstrate the workflow on
the IMDB sentiment classification dataset (unprocessed version). We use
<code><a href="../../../reference/layer_text_vectorization.html">layer_text_vectorization()</a></code> for word splitting &amp;
indexing.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow" class="external-link">tensorflow</a></span>, exclude <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"shape"</span>, <span class="st">"set_random_seed"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets" class="external-link">tfdatasets</a></span>, exclude <span class="op">=</span> <span class="st">"shape"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://keras3.posit.co/">keras3</a></span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-the-data-imdb-movie-review-sentiment-classification">Load the data: IMDB movie review sentiment classification<a class="anchor" aria-label="anchor" href="#load-the-data-imdb-movie-review-sentiment-classification"></a>
</h2>
<p>Let’s download the data and inspect its structure.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.exists</a></span><span class="op">(</span><span class="st">"datasets/aclImdb"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="st">"datasets"</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/download.file.html" class="external-link">download.file</a></span><span class="op">(</span></span>
<span>    <span class="st">"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"</span>,</span>
<span>    <span class="st">"datasets/aclImdb_v1.tar.gz"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/untar.html" class="external-link">untar</a></span><span class="op">(</span><span class="st">"datasets/aclImdb_v1.tar.gz"</span>, exdir <span class="op">=</span> <span class="st">"datasets"</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/unlink.html" class="external-link">unlink</a></span><span class="op">(</span><span class="st">"datasets/aclImdb/train/unsup"</span>, recursive <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The <code>aclImdb</code> folder contains a <code>train</code> and
<code>test</code> subfolder:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="st">"datasets/aclImdb/test"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] "labeledBow.feat" "neg"             "pos"             "urls_neg.txt"</span></span>
<span><span class="co">## [5] "urls_pos.txt"</span></span></code></pre>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="st">"datasets/aclImdb/train"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] "labeledBow.feat" "neg"             "pos"             "unsupBow.feat"</span></span>
<span><span class="co">## [5] "urls_neg.txt"    "urls_pos.txt"</span></span></code></pre>
<p>The <code>aclImdb/train/pos</code> and <code>aclImdb/train/neg</code>
folders contain text files, each of which represents one review (either
positive or negative):</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html" class="external-link">writeLines</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/strwrap.html" class="external-link">strwrap</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/readLines.html" class="external-link">readLines</a></span><span class="op">(</span><span class="st">"datasets/aclImdb/train/pos/4229_10.txt"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Don't waste time reading my review. Go out and see this</span></span>
<span><span class="co">## astonishingly good episode, which may very well be the best Columbo</span></span>
<span><span class="co">## ever written! Ruth Gordon is perfectly cast as the scheming yet</span></span>
<span><span class="co">## charming mystery writer who murders her son-in-law to avenge his</span></span>
<span><span class="co">## murder of her daughter. Columbo is his usual rumpled, befuddled and</span></span>
<span><span class="co">## far-cleverer-than-he-seems self, and this particular installment</span></span>
<span><span class="co">## features fantastic chemistry between Gordon and Falk. Ironically,</span></span>
<span><span class="co">## this was not written by heralded creators Levinson or Link yet is</span></span>
<span><span class="co">## possibly the densest, most thoroughly original and twist-laden</span></span>
<span><span class="co">## Columbo plot ever. Utterly satisfying in nearly every department</span></span>
<span><span class="co">## and overflowing with droll and witty dialogue and thinking. Truly</span></span>
<span><span class="co">## unexpected and inventive climax tops all. 10/10...seek this one out</span></span>
<span><span class="co">## on Netflix!</span></span></code></pre>
<p>We are only interested in the <code>pos</code> and <code>neg</code>
subfolders, so let’s delete the other subfolder that has text files in
it:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/unlink.html" class="external-link">unlink</a></span><span class="op">(</span><span class="st">"datasets/aclImdb/train/unsup"</span>, recursive <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>You can use the utility <code><a href="../../../reference/text_dataset_from_directory.html">text_dataset_from_directory()</a></code> to
generate a labeled <code>tf_dataset</code> object from a set of text
files on disk filed into class-specific folders.</p>
<p>Let’s use it to generate the training, validation, and test datasets.
The validation and training datasets are generated from two subsets of
the <code>train</code> directory, with 20% of samples going to the
validation dataset and 80% going to the training dataset.</p>
<p>Having a validation dataset in addition to the test dataset is useful
for tuning hyperparameters, such as the model architecture, for which
the test dataset should not be used.</p>
<p>Before putting the model out into the real world however, it should
be retrained using all available training data (without creating a
validation dataset), so its performance is maximized.</p>
<p>When using the <code>validation_split</code> and <code>subset</code>
arguments, make sure to either specify a random seed, or to pass
<code>shuffle=FALSE</code>, so that the validation &amp; training splits
you get have no overlap.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">batch_size</span> <span class="op">&lt;-</span> <span class="fl">32</span></span>
<span></span>
<span><span class="va">raw_train_ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/text_dataset_from_directory.html">text_dataset_from_directory</a></span><span class="op">(</span></span>
<span>  <span class="st">"datasets/aclImdb/train"</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="va">batch_size</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>  subset <span class="op">=</span> <span class="st">"training"</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">1337</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Found 25000 files belonging to 2 classes.</span></span>
<span><span class="co">## Using 20000 files for training.</span></span></code></pre>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">raw_val_ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/text_dataset_from_directory.html">text_dataset_from_directory</a></span><span class="op">(</span></span>
<span>  <span class="st">"datasets/aclImdb/train"</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="va">batch_size</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>  subset <span class="op">=</span> <span class="st">"validation"</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">1337</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Found 25000 files belonging to 2 classes.</span></span>
<span><span class="co">## Using 5000 files for validation.</span></span></code></pre>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">raw_test_ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/text_dataset_from_directory.html">text_dataset_from_directory</a></span><span class="op">(</span></span>
<span>  <span class="st">"datasets/aclImdb/test"</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="va">batch_size</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Found 25000 files belonging to 2 classes.</span></span></code></pre>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Number of batches in raw_train_ds:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">raw_train_ds</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Number of batches in raw_train_ds: 625</span></span></code></pre>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Number of batches in raw_val_ds:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">raw_val_ds</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Number of batches in raw_val_ds: 157</span></span></code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Number of batches in raw_test_ds:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">raw_test_ds</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Number of batches in raw_test_ds: 782</span></span></code></pre>
<p>Let’s preview a few samples:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># It's important to take a look at your raw data to ensure your normalization</span></span>
<span><span class="co"># and tokenization will work as expected. We can do that by taking a few</span></span>
<span><span class="co"># examples from the training set and looking at them.</span></span>
<span><span class="co"># This is one of the places where eager execution shines:</span></span>
<span><span class="co"># we can just evaluate these tensors using .numpy()</span></span>
<span><span class="co"># instead of needing to evaluate them in a Session/Graph context.</span></span>
<span><span class="va">batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html" class="external-link">iter_next</a></span><span class="op">(</span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html" class="external-link">as_iterator</a></span><span class="op">(</span><span class="va">raw_train_ds</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">batch</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 2</span></span>
<span><span class="co">##  $ :&lt;tf.Tensor: shape=(32), dtype=string, numpy=…&gt;</span></span>
<span><span class="co">##  $ :&lt;tf.Tensor: shape=(32), dtype=int32, numpy=…&gt;</span></span></code></pre>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">text_batch</span>, <span class="va">label_batch</span><span class="op">)</span> <span class="op"><a href="../../../reference/multi-assign.html">%&lt;-%</a></span> <span class="va">batch</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">text_batch</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">label_batch</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(b"I have read the novel Reaper of Ben Mezrich a fews years ago and last night I accidentally came to see this adaption.&lt;br /&gt;&lt;br /&gt;Although it's been years since I read the story the first time, the differences between the novel and the movie are humongous. Very important elements, which made the whole thing plausible are just written out or changed to bad.&lt;br /&gt;&lt;br /&gt;If the plot sounds interesting to you: go and get the novel. Its much, much, much better.&lt;br /&gt;&lt;br /&gt;Still 4 out of 10 since it was hard to stop watching because of the great basic plot by Ben Mezrich.", shape=(), dtype=string)</span></span>
<span><span class="co">## tf.Tensor(0, shape=(), dtype=int32)</span></span>
<span><span class="co">## tf.Tensor(b'After seeing all the Jesse James, Quantrill, jayhawkers,etc films in the fifties, it is quite a thrill to see this film with a new perspective by director Ang Lee. The scene of the attack of Lawrence, Kansas is awesome. The romantic relationship between Jewel and Toby Mcguire turns out to be one of the best parts and Jonathan Rhys-Meyers is outstanding as the bad guy. All the time this film makes you feel the horror of war, and the desperate situation of the main characters who do not know if they are going to survive the next hours. Definitely worth seeing.', shape=(), dtype=string)</span></span>
<span><span class="co">## tf.Tensor(1, shape=(), dtype=int32)</span></span>
<span><span class="co">## tf.Tensor(b'AG was an excellent presentation of drama, suspense and thriller that is so rare to American TV. Sheriff Lucas gave many a viewer the willies. We rooted for Caleb as he strove to resist the overtures of Sheriff Lucas. We became engrossed and fearful upon learning of the unthinkable connection between these two characters. The manipulations which weekly gave cause to fear what Lucas would do next were truly surprising. This show lived up to the "Gothic" moniker in ways American entertainment has so seldom attempted, much less mastered. The suits definitely made a big mistake in not supporting this show. This show puts shame to the current glut of "reality" shows- which are so less than satisfying viewing.The call for a DVD box set is well based. This show is quality viewing for a discerning market hungry for quality viewing. A public that is tiring of over-saturation of mind-numbing reality fare will welcome this gem of real storytelling. Bring on the DVD box set!!', shape=(), dtype=string)</span></span>
<span><span class="co">## tf.Tensor(1, shape=(), dtype=int32)</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="prepare-the-data">Prepare the data<a class="anchor" aria-label="anchor" href="#prepare-the-data"></a>
</h2>
<p>In particular, we remove <code>&lt;br /&gt;</code> tags.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Having looked at our data above, we see that the raw text contains HTML break</span></span>
<span><span class="co"># tags of the form '&lt;br /&gt;'. These tags will not be removed by the default</span></span>
<span><span class="co"># standardizer (which doesn't strip HTML). Because of this, we will need to</span></span>
<span><span class="co"># create a custom standardization function.</span></span>
<span><span class="va">custom_standardization_fn</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">string_tensor</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">string_tensor</span> <span class="op">|&gt;</span></span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">lower</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># convert to all lowercase</span></span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">regex_replace</span><span class="op">(</span><span class="st">"&lt;br /&gt;"</span>, <span class="st">" "</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="co"># remove '&lt;br /&gt;' HTML tag</span></span>
<span>    <span class="va">tf</span><span class="op">$</span><span class="va">strings</span><span class="op">$</span><span class="fu">regex_replace</span><span class="op">(</span><span class="st">"[[:punct:]]"</span>, <span class="st">""</span><span class="op">)</span> <span class="co"># remove punctuation</span></span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="co"># Model constants.</span></span>
<span><span class="va">max_features</span> <span class="op">&lt;-</span> <span class="fl">20000</span></span>
<span><span class="va">embedding_dim</span> <span class="op">&lt;-</span> <span class="fl">128</span></span>
<span><span class="va">sequence_length</span> <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span></span>
<span><span class="co"># Now that we have our custom standardization, we can instantiate our text</span></span>
<span><span class="co"># vectorization layer. We are using this layer to normalize, split, and map</span></span>
<span><span class="co"># strings to integers, so we set our 'output_mode' to 'int'.</span></span>
<span><span class="co"># Note that we're using the default split function,</span></span>
<span><span class="co"># and the custom standardization defined above.</span></span>
<span><span class="co"># We also set an explicit maximum sequence length, since the CNNs later in our</span></span>
<span><span class="co"># model won't support ragged sequences.</span></span>
<span><span class="va">vectorize_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span></span>
<span>  standardize <span class="op">=</span> <span class="va">custom_standardization_fn</span>,</span>
<span>  max_tokens <span class="op">=</span> <span class="va">max_features</span>,</span>
<span>  output_mode <span class="op">=</span> <span class="st">"int"</span>,</span>
<span>  output_sequence_length <span class="op">=</span> <span class="va">sequence_length</span>,</span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Now that the vectorize_layer has been created, call `adapt` on a text-only</span></span>
<span><span class="co"># dataset to create the vocabulary. You don't have to batch, but for very large</span></span>
<span><span class="co"># datasets this means you're not keeping spare copies of the dataset in memory.</span></span>
<span></span>
<span><span class="co"># Let's make a text-only dataset (no labels):</span></span>
<span><span class="va">text_ds</span> <span class="op">&lt;-</span> <span class="va">raw_train_ds</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span>\<span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="co"># Let's call `adapt`:</span></span>
<span><span class="va">vectorize_layer</span> <span class="op">|&gt;</span> <span class="fu"><a href="../../../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">text_ds</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="two-options-to-vectorize-the-data">Two options to vectorize the data<a class="anchor" aria-label="anchor" href="#two-options-to-vectorize-the-data"></a>
</h2>
<p>There are 2 ways we can use our text vectorization layer:</p>
<p><strong>Option 1: Make it part of the model</strong>, so as to obtain
a model that processes raw strings, like this:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">text_input</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/keras_input.html">keras_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1L</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"string"</span>, name <span class="op">=</span> <span class="st">'text'</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">text_input</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">vectorize_layer</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_embedding.html">layer_embedding</a></span><span class="op">(</span><span class="va">max_features</span> <span class="op">+</span> <span class="fl">1</span>, <span class="va">embedding_dim</span><span class="op">)</span></span></code></pre></div>
<p><strong>Option 2: Apply it to the text dataset</strong> to obtain a
dataset of word indices, then feed it into a model that expects integer
sequences as inputs.</p>
<p>An important difference between the two is that option 2 enables you
to do <strong>asynchronous CPU processing and buffering</strong> of your
data when training on GPU. So if you’re training the model on GPU, you
probably want to go with this option to get the best performance. This
is what we will do below.</p>
<p>If we were to export our model to production, we’d ship a model that
accepts raw strings as input, like in the code snippet for option 1
above. This can be done after training. We do this in the last
section.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">vectorize_text</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">text</span>, <span class="va">label</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">text</span> <span class="op">&lt;-</span> <span class="va">text</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../../../reference/op_expand_dims.html">op_expand_dims</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">vectorize_layer</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">text</span>, <span class="va">label</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Vectorize the data.</span></span>
<span><span class="va">train_ds</span> <span class="op">&lt;-</span> <span class="va">raw_train_ds</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="va">vectorize_text</span><span class="op">)</span></span>
<span><span class="va">val_ds</span>   <span class="op">&lt;-</span> <span class="va">raw_val_ds</span>   <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="va">vectorize_text</span><span class="op">)</span></span>
<span><span class="va">test_ds</span>  <span class="op">&lt;-</span> <span class="va">raw_test_ds</span>  <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="va">vectorize_text</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Do async prefetching / buffering of the data for best performance on GPU.</span></span>
<span><span class="va">train_ds</span> <span class="op">&lt;-</span> <span class="va">train_ds</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html" class="external-link">dataset_cache</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_prefetch.html" class="external-link">dataset_prefetch</a></span><span class="op">(</span>buffer_size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">val_ds</span> <span class="op">&lt;-</span> <span class="va">val_ds</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html" class="external-link">dataset_cache</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_prefetch.html" class="external-link">dataset_prefetch</a></span><span class="op">(</span>buffer_size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">test_ds</span> <span class="op">&lt;-</span> <span class="va">test_ds</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_cache.html" class="external-link">dataset_cache</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_prefetch.html" class="external-link">dataset_prefetch</a></span><span class="op">(</span>buffer_size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="build-a-model">Build a model<a class="anchor" aria-label="anchor" href="#build-a-model"></a>
</h2>
<p>We choose a simple 1D convnet starting with an <code>Embedding</code>
layer.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># A integer input for vocab indices.</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/keras_input.html">keras_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="cn">NA</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"int64"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">predictions</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op">|&gt;</span></span>
<span>  <span class="co"># Next, we add a layer to map those vocab indices into a space of dimensionality</span></span>
<span>  <span class="co"># 'embedding_dim'.</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_embedding.html">layer_embedding</a></span><span class="op">(</span><span class="va">max_features</span>, <span class="va">embedding_dim</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="co"># Conv1D + global max pooling</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_conv_1d.html">layer_conv_1d</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fl">7</span>, padding <span class="op">=</span> <span class="st">"valid"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, strides <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_conv_1d.html">layer_conv_1d</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fl">7</span>, padding <span class="op">=</span> <span class="st">"valid"</span>, activation <span class="op">=</span> <span class="st">"relu"</span>, strides <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_global_max_pooling_1d.html">layer_global_max_pooling_1d</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="co"># We add a vanilla hidden layer:</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">128</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_dropout.html">layer_dropout</a></span><span class="op">(</span><span class="fl">0.5</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="co"># We project onto a single unit output layer, and squash it with a sigmoid:</span></span>
<span>  <span class="fu"><a href="../../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">1</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span>, name <span class="op">=</span> <span class="st">"predictions"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">predictions</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="font-weight: bold;">Model: "functional"</span></span></span>
<span><span class="co">## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓</span></span>
<span><span class="co">## ┃<span style="font-weight: bold;"> Layer (type)                    </span>┃<span style="font-weight: bold;"> Output Shape           </span>┃<span style="font-weight: bold;">       Param # </span>┃</span></span>
<span><span class="co">## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩</span></span>
<span><span class="co">## │ input_layer (<span style="color: #0087FF;">InputLayer</span>)        │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00D7FF;">None</span>)           │             <span style="color: #00AF00;">0</span> │</span></span>
<span><span class="co">## ├─────────────────────────────────┼────────────────────────┼───────────────┤</span></span>
<span><span class="co">## │ embedding_1 (<span style="color: #0087FF;">Embedding</span>)         │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">128</span>)      │     <span style="color: #00AF00;">2,560,000</span> │</span></span>
<span><span class="co">## ├─────────────────────────────────┼────────────────────────┼───────────────┤</span></span>
<span><span class="co">## │ dropout (<span style="color: #0087FF;">Dropout</span>)               │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">128</span>)      │             <span style="color: #00AF00;">0</span> │</span></span>
<span><span class="co">## ├─────────────────────────────────┼────────────────────────┼───────────────┤</span></span>
<span><span class="co">## │ conv1d (<span style="color: #0087FF;">Conv1D</span>)                 │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">128</span>)      │       <span style="color: #00AF00;">114,816</span> │</span></span>
<span><span class="co">## ├─────────────────────────────────┼────────────────────────┼───────────────┤</span></span>
<span><span class="co">## │ conv1d_1 (<span style="color: #0087FF;">Conv1D</span>)               │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">128</span>)      │       <span style="color: #00AF00;">114,816</span> │</span></span>
<span><span class="co">## ├─────────────────────────────────┼────────────────────────┼───────────────┤</span></span>
<span><span class="co">## │ global_max_pooling1d            │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">128</span>)            │             <span style="color: #00AF00;">0</span> │</span></span>
<span><span class="co">## │ (<span style="color: #0087FF;">GlobalMaxPooling1D</span>)            │                        │               │</span></span>
<span><span class="co">## ├─────────────────────────────────┼────────────────────────┼───────────────┤</span></span>
<span><span class="co">## │ dense (<span style="color: #0087FF;">Dense</span>)                   │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">128</span>)            │        <span style="color: #00AF00;">16,512</span> │</span></span>
<span><span class="co">## ├─────────────────────────────────┼────────────────────────┼───────────────┤</span></span>
<span><span class="co">## │ dropout_1 (<span style="color: #0087FF;">Dropout</span>)             │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">128</span>)            │             <span style="color: #00AF00;">0</span> │</span></span>
<span><span class="co">## ├─────────────────────────────────┼────────────────────────┼───────────────┤</span></span>
<span><span class="co">## │ predictions (<span style="color: #0087FF;">Dense</span>)             │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">1</span>)              │           <span style="color: #00AF00;">129</span> │</span></span>
<span><span class="co">## └─────────────────────────────────┴────────────────────────┴───────────────┘</span></span>
<span><span class="co">## <span style="font-weight: bold;"> Total params: </span><span style="color: #00AF00;">2,806,273</span> (10.71 MB)</span></span>
<span><span class="co">## <span style="font-weight: bold;"> Trainable params: </span><span style="color: #00AF00;">2,806,273</span> (10.71 MB)</span></span>
<span><span class="co">## <span style="font-weight: bold;"> Non-trainable params: </span><span style="color: #00AF00;">0</span> (0.00 B)</span></span></code></pre>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compile the model with binary crossentropy loss and an adam optimizer.</span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>                 optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>                 metrics <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="train-the-model">Train the model<a class="anchor" aria-label="anchor" href="#train-the-model"></a>
</h2>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">epochs</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span></span>
<span><span class="co"># Fit the model using the train and test datasets.</span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_ds</span>, validation_data <span class="op">=</span> <span class="va">val_ds</span>, epochs <span class="op">=</span> <span class="va">epochs</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/3</span></span>
<span><span class="co">## 625/625 - 5s - 8ms/step - accuracy: 0.6964 - loss: 0.5261 - val_accuracy: 0.8668 - val_loss: 0.3185</span></span>
<span><span class="co">## Epoch 2/3</span></span>
<span><span class="co">## 625/625 - 2s - 3ms/step - accuracy: 0.9074 - loss: 0.2365 - val_accuracy: 0.8754 - val_loss: 0.3245</span></span>
<span><span class="co">## Epoch 3/3</span></span>
<span><span class="co">## 625/625 - 2s - 3ms/step - accuracy: 0.9551 - loss: 0.1220 - val_accuracy: 0.8284 - val_loss: 0.4862</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="evaluate-the-model-on-the-test-set">Evaluate the model on the test set<a class="anchor" aria-label="anchor" href="#evaluate-the-model-on-the-test-set"></a>
</h2>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html" class="external-link">evaluate</a></span><span class="op">(</span><span class="va">test_ds</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## 782/782 - 1s - 2ms/step - accuracy: 0.8115 - loss: 0.5299</span></span></code></pre>
<pre><code><span><span class="co">## $accuracy</span></span>
<span><span class="co">## [1] 0.81152</span></span>
<span><span class="co">##</span></span>
<span><span class="co">## $loss</span></span>
<span><span class="co">## [1] 0.5299004</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="make-an-end-to-end-model">Make an end-to-end model<a class="anchor" aria-label="anchor" href="#make-an-end-to-end-model"></a>
</h2>
<p>If you want to obtain a model capable of processing raw strings, you
can simply create a new model (using the weights we just trained):</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># A string input</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/keras_input.html">keras_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"string"</span><span class="op">)</span></span>
<span><span class="co"># Turn strings into vocab indices</span></span>
<span><span class="va">indices</span> <span class="op">&lt;-</span> <span class="fu">vectorize_layer</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span><span class="co"># Turn vocab indices into predictions</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu">model</span><span class="op">(</span><span class="va">indices</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Our end to end model</span></span>
<span><span class="va">end_to_end_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span><span class="va">end_to_end_model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span></span>
<span>  loss <span class="op">=</span> <span class="st">"binary_crossentropy"</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  metrics <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"accuracy"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Test it with `raw_test_ds`, which yields raw strings</span></span>
<span><span class="va">end_to_end_model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html" class="external-link">evaluate</a></span><span class="op">(</span><span class="va">raw_test_ds</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## 782/782 - 3s - 4ms/step - accuracy: 0.8115 - loss: 0.5299</span></span></code></pre>
<pre><code><span><span class="co">## $accuracy</span></span>
<span><span class="co">## [1] 0.81152</span></span>
<span><span class="co">##</span></span>
<span><span class="co">## $loss</span></span>
<span><span class="co">## [1] 0.5299006</span></span></code></pre>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
