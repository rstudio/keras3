<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Making new layers and models via subclassing • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Making new layers and models via subclassing">
<meta name="description" content="Complete guide to writing `Layer` and `Model` objects from scratch.">
<meta property="og:description" content="Complete guide to writing `Layer` and `Model` objects from scratch.">
<meta name="robots" content="noindex">
<!-- Google Tag Manager --><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-KHBDBW7');</script><!-- End Google Tag Manager -->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    <!-- Google Tag Manager (noscript) --> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KHBDBW7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <!-- End Google Tag Manager (noscript) -->


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="inverse" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">keras3</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">1.4.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/getting_started.html">Getting Started</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-guides" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Guides</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-guides">
<li><h6 class="dropdown-header" data-toc-skip>Model definition</h6></li>
    <li><a class="dropdown-item" href="../articles/sequential_model.html">Sequential Model</a></li>
    <li><a class="dropdown-item" href="../articles/functional_api.html">Functional API</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6></li>
    <li><a class="dropdown-item" href="../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a></li>
    <li><a class="dropdown-item" href="../articles/custom_train_step_in_tensorflow.html">Customizing `fit()` with Tensorflow</a></li>
    <li><a class="dropdown-item" href="../articles/writing_your_own_callbacks.html">Writing your own callbacks</a></li>
    <li><a class="dropdown-item" href="../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a></li>
    <li><a class="dropdown-item" href="../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a></li>
    <li><a class="dropdown-item" href="../articles/serialization_and_saving.html">Serialization and Saving</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Other topics</h6></li>
    <li><a class="dropdown-item" href="../articles/transfer_learning.html">Transfer learning and fine tuning</a></li>
    <li><a class="dropdown-item" href="../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a></li>
    <li><a class="dropdown-item" href="../articles/distribution.html">Distributed training with Jax</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../articles/examples/index.html">Examples</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">News</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/rstudio/keras3/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Making new layers and models via subclassing</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras3/blob/HEAD/vignettes/making_new_layers_and_models_via_subclassing.Rmd" class="external-link"><code>vignettes/making_new_layers_and_models_via_subclassing.Rmd</code></a></small>
      <div class="d-none name"><code>making_new_layers_and_models_via_subclassing.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This guide will cover everything you need to know to build your own
subclassed layers and models. In particular, you’ll learn about the
following features:</p>
<ul>
<li>The <code>Layer</code> class</li>
<li>The <code>add_weight()</code> method</li>
<li>Trainable and non-trainable weights</li>
<li>The <code>build()</code> method</li>
<li>Making sure your layers can be used with any backend</li>
<li>The <code>add_loss()</code> method</li>
<li>The <code>training</code> argument in <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>
</li>
<li>The <code>mask</code> argument in <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>
</li>
<li>Making sure your layers can be serialized</li>
</ul>
<p>Let’s dive in.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://keras3.posit.co/">keras3</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow" class="external-link">tensorflow</a></span>, exclude <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"set_random_seed"</span>, <span class="st">"shape"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets" class="external-link">tfdatasets</a></span>, exclude <span class="op">=</span> <span class="st">"shape"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-layer-class-the-combination-of-state-weights-and-some-computation">The <code>Layer</code> class: the combination of state (weights) and
some computation<a class="anchor" aria-label="anchor" href="#the-layer-class-the-combination-of-state-weights-and-some-computation"></a>
</h2>
<p>One of the central abstractions in Keras is the <code>Layer</code>
class. A layer encapsulates both a state (the layer’s “weights”) and a
transformation from inputs to outputs (a “call”, the layer’s forward
pass).</p>
<p>Here’s a densely-connected layer. It has two state variables: the
variables <code>w</code> and <code>b</code>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span><span class="st">"Linear"</span>,</span>
<span></span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">input_dim</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">input_dim</span>, <span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="../reference/op_matmul.html">op_matmul</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>You would use a layer by calling it on some tensor input(s), much
like an R function.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/op_ones.html">op_ones</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">linear_layer</span> <span class="op">&lt;-</span> <span class="fu">layer_linear</span><span class="op">(</span>units <span class="op">=</span> <span class="fl">4</span>, input_dim <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">linear_layer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(</span></span>
<span><span class="co">## [[0.02153057 0.15450525 0.0205495  0.04493225]</span></span>
<span><span class="co">##  [0.02153057 0.15450525 0.0205495  0.04493225]], shape=(2, 4), dtype=float32)</span></span></code></pre>
<p>Note that the weights <code>w</code> and <code>b</code> are
automatically tracked by the layer upon being set as layer
attributes:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linear_layer</span><span class="op">$</span><span class="va">weights</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">## &lt;Variable path=linear/variable, shape=(2, 4), dtype=float32, value=[[-0.06251299  0.05335509  0.01485647 -0.00985784]</span></span>
<span><span class="co">##  [ 0.08404355  0.10115016  0.00569303  0.05479009]]&gt;</span></span>
<span><span class="co">##</span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">## &lt;Variable path=linear/variable_1, shape=(4), dtype=float32, value=[0. 0. 0. 0.]&gt;</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="layers-can-have-non-trainable-weights">Layers can have non-trainable weights<a class="anchor" aria-label="anchor" href="#layers-can-have-non-trainable-weights"></a>
</h2>
<p>Besides trainable weights, you can add non-trainable weights to a
layer as well. Such weights are meant not to be taken into account
during backpropagation, when you are training the layer.</p>
<p>Here’s how to add and use a non-trainable weight:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_compute_sum</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"ComputeSum"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_dim</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">total</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">input_dim</span><span class="op">)</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">total</span><span class="op">$</span><span class="fu">assign_add</span><span class="op">(</span><span class="fu"><a href="../reference/op_sum.html">op_sum</a></span><span class="op">(</span><span class="va">inputs</span>, axis <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">total</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/op_ones.html">op_ones</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">my_sum</span> <span class="op">&lt;-</span> <span class="fu">layer_compute_sum</span><span class="op">(</span>input_dim <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">my_sum</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/array.html" class="external-link">as.array</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2 2</span></span></code></pre>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">my_sum</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/array.html" class="external-link">as.array</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 4 4</span></span></code></pre>
<p>It’s part of <code>layer$weights</code>, but it gets categorized as a
non-trainable weight:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## weights: 1</span></span></code></pre>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"non-trainable weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">non_trainable_weights</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## non-trainable weights: 1</span></span></code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># It's not included in the trainable weights:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"trainable_weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## trainable_weights: 0</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known">Best practice: deferring weight creation until the shape of the
inputs is known<a class="anchor" aria-label="anchor" href="#best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known"></a>
</h2>
<p>Our <code>Linear</code> layer above took an <code>input_dim</code>
argument that was used to compute the shape of the weights
<code>w</code> and <code>b</code> in <code>initialize()</code>:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span><span class="st">"Linear"</span>,</span>
<span></span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">input_dim</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">input_dim</span>, <span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="../reference/op_matmul.html">op_matmul</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>In many cases, you may not know in advance the size of your inputs,
and you would like to lazily create weights when that value becomes
known, some time after instantiating the layer.</p>
<p>In the Keras API, we recommend creating layer weights in the
<code>build(self, inputs_shape)</code> method of your layer. Like
this:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"Linear"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">units</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  build <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">input_shape</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="../reference/op_matmul.html">op_matmul</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> method of your layer will automatically run
build the first time it is called. You now have a layer that’s lazy and
thus easier to use:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># At instantiation, we don't know on what inputs this is going to get called</span></span>
<span><span class="va">linear_layer</span> <span class="op">&lt;-</span> <span class="fu">layer_linear</span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The layer's weights are created dynamically the first time the layer is called</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">linear_layer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code></pre></div>
<p>Implementing <code>build()</code> separately as shown above nicely
separates creating weights only once from using weights in every
call.</p>
</div>
<div class="section level2">
<h2 id="layers-are-recursively-composable">Layers are recursively composable<a class="anchor" aria-label="anchor" href="#layers-are-recursively-composable"></a>
</h2>
<p>If you assign a Layer instance as an attribute of another Layer, the
outer layer will start tracking the weights created by the inner
layer.</p>
<p>We recommend creating such sublayers in the <code>initialize()</code>
method and leave it to the first <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> to trigger building
their weights.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">MLPBlock</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"MLPBlock"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">linear_1</span> <span class="op">&lt;-</span> <span class="fu">layer_linear</span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">linear_2</span> <span class="op">&lt;-</span> <span class="fu">layer_linear</span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">linear_3</span> <span class="op">&lt;-</span> <span class="fu">layer_linear</span><span class="op">(</span>units <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">inputs</span> <span class="op">|&gt;</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">linear_1</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="../reference/activation_relu.html">activation_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">linear_2</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu"><a href="../reference/activation_relu.html">activation_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">linear_3</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">mlp</span> <span class="op">&lt;-</span> <span class="fu">MLPBlock</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co"># The first call to the `mlp` will create the weights</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">mlp</span><span class="op">(</span><span class="fu"><a href="../reference/op_ones.html">op_ones</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">64</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">mlp</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## weights: 6</span></span></code></pre>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"trainable weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">mlp</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## trainable weights: 6</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="backend-agnostic-layers-and-backend-specific-layers">Backend-agnostic layers and backend-specific layers<a class="anchor" aria-label="anchor" href="#backend-agnostic-layers-and-backend-specific-layers"></a>
</h2>
<p>As long as a layer only uses APIs from the <code>ops</code> namespace
(ie. using functions starting with <code>op_</code>), (or other Keras
namespaces such as <code>activations_*</code>, <code>random_*</code>, or
<code>layer_*</code>), then it can be used with any backend –
TensorFlow, JAX, or PyTorch.</p>
<p>All layers you’ve seen so far in this guide work with all Keras
backends.</p>
<p>The <code>ops</code> namespace gives you access to:</p>
<ul>
<li>The NumPy API, e.g. <code>op_matmul</code>, <code>op_sum</code>,
<code>op_reshape</code>, <code>op_stack</code>, etc.</li>
<li>Neural networks-specific APIs such as <code>op_softmax</code>,
<code>op_conv</code>, <code>op_binary_crossentropy</code>,
<code>op_relu</code>, etc.</li>
</ul>
<p>You can also use backend-native APIs in your layers (such as
<code>tf$nn</code> functions), but if you do this, then your layer will
only be usable with the backend in question. For instance, you could
write the following JAX-specific layer using <code>jax$numpy</code>:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a><span class="co"># keras3::install_keras(backend = c("jax"))</span></span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>jax <span class="ot">&lt;-</span> reticulate<span class="sc">::</span><span class="fu">import</span>(<span class="st">"jax"</span>)</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>Linear <span class="ot">&lt;-</span> <span class="fu">new_layer_class</span>(</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>  ...</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a>  <span class="at">call =</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>    jax<span class="sc">$</span>numpy<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a>  }</span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>)</span></code></pre></div>
<p>This would be the equivalent TensorFlow-specific layer:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>Linear <span class="ot">&lt;-</span> <span class="fu">new_layer_class</span>(</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a>  ...</span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>  <span class="at">call =</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a>    tf<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a>  }</span>
<span id="cb25-8"><a href="#cb25-8" tabindex="-1"></a>)</span></code></pre></div>
<p>And this would be the equivalent PyTorch-specific layer:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>torch <span class="ot">&lt;-</span> reticulate<span class="sc">::</span><span class="fu">import</span>(<span class="st">"torch"</span>)</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>Linear <span class="ot">&lt;-</span> <span class="fu">new_layer_class</span>(</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>  ...</span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a>  <span class="at">call =</span> <span class="cf">function</span>(inputs) {</span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a>    torch<span class="sc">$</span><span class="fu">matmul</span>(inputs, self<span class="sc">$</span>w) <span class="sc">+</span> self<span class="sc">$</span>b</span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a>  }</span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a>)</span></code></pre></div>
<p>Because cross-backend compatibility is a tremendously useful
property, we strongly recommend that you seek to always make your layers
backend-agnostic by leveraging only Keras APIs.</p>
</div>
<div class="section level2">
<h2 id="the-add_loss-method">The <code>add_loss()</code> method<a class="anchor" aria-label="anchor" href="#the-add_loss-method"></a>
</h2>
<p>When writing the <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> method of a layer, you can
create loss tensors that you will want to use later, when writing your
training loop. This is doable by calling
<code>self$add_loss(value)</code>:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># A layer that creates an activity regularization loss</span></span>
<span><span class="va">layer_activity_regularization</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"ActivityRegularizationLayer"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">rate</span> <span class="op">=</span> <span class="fl">1e-2</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">rate</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">rate</span><span class="op">)</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">add_loss</span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">rate</span> <span class="op">*</span> <span class="fu"><a href="../reference/op_mean.html">op_mean</a></span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">inputs</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>These losses (including those created by any inner layer) can be
retrieved via <code>layer$losses</code>. This property is reset at the
start of every <code>call</code> to the top-level layer, so that
<code>layer$losses</code> always contains the loss values created during
the last forward pass.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_outer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"OuterLayer"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">activity_reg</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_activity_regularization.html">layer_activity_regularization</a></span><span class="op">(</span>rate <span class="op">=</span> <span class="fl">1e-2</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">activity_reg</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span>    <span class="va">inputs</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">layer_outer</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co"># No losses yet since the layer has never been called</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"losses:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## losses: 0</span></span></code></pre>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">layer</span><span class="op">(</span><span class="fu"><a href="../reference/op_zeros.html">op_zeros</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># We created one loss value</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"losses:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## losses: 1</span></span></code></pre>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># `layer$losses` gets reset at the start of each call</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">layer</span><span class="op">(</span><span class="fu"><a href="../reference/op_zeros.html">op_zeros</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># This is the loss created during the call above</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"losses:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## losses: 1</span></span></code></pre>
<p>In addition, the <code>loss</code> property also contains
regularization losses created for the weights of any inner layer:</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_outer_with_kernel_regularizer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"OuterLayerWithKernelRegularizer"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span>,</span>
<span>                              kernel_regularizer <span class="op">=</span> <span class="fu"><a href="../reference/regularizer_l2.html">regularizer_l2</a></span><span class="op">(</span><span class="fl">1e-3</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">dense</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">layer_outer_with_kernel_regularizer</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">layer</span><span class="op">(</span><span class="fu"><a href="../reference/op_zeros.html">op_zeros</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This is `1e-3 * sum(layer$dense$kernel ** 2)`,</span></span>
<span><span class="co"># created by the `kernel_regularizer` above.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">## tf.Tensor(0.002025157, shape=(), dtype=float32)</span></span></code></pre>
<p>These losses are meant to be taken into account when writing custom
training loops.</p>
<p>They also work seamlessly with <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> (they get
automatically summed and added to the main loss, if any):</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_input.html">keras_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/layer_activity_regularization.html">layer_activity_regularization</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># If there is a loss passed in `compile`, the regularization</span></span>
<span><span class="co"># losses get added to it</span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"adam"</span>, loss <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="fu"><a href="../reference/random_normal.html">random_normal</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>, <span class="fu"><a href="../reference/random_normal.html">random_normal</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>, epochs <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## 1/1 - 0s - 131ms/step - loss: 1.9081</span></span></code></pre>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># It's also possible not to pass any loss in `compile`,</span></span>
<span><span class="co"># since the model already has a loss to minimize, via the `add_loss`</span></span>
<span><span class="co"># call during the forward pass!</span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"adam"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="fu"><a href="../reference/random_normal.html">random_normal</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>, <span class="fu"><a href="../reference/random_normal.html">random_normal</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>, epochs <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## 1/1 - 0s - 106ms/step - loss: 1.6613</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="you-can-optionally-enable-serialization-on-your-layers">You can optionally enable serialization on your layers<a class="anchor" aria-label="anchor" href="#you-can-optionally-enable-serialization-on-your-layers"></a>
</h2>
<p>If you need your custom layers to be serializable as part of a <a href="functional_api.html">Functional model</a>, you can optionally
implement a <code><a href="../reference/get_config.html">get_config()</a></code> method:</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"Linear"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">units</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  build <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">input_shape</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="../reference/op_matmul.html">op_matmul</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span></span>
<span>  <span class="op">}</span>,</span>
<span>  get_config <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Now you can recreate the layer from its config:</span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">layer_linear</span><span class="op">(</span>units <span class="op">=</span> <span class="fl">64</span><span class="op">)</span></span>
<span><span class="va">config</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_config.html">get_config</a></span><span class="op">(</span><span class="va">layer</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">config</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 1</span></span>
<span><span class="co">##  $ units: int 64</span></span>
<span><span class="co">##  - attr(*, "__class__")=&lt;class '&lt;r-globalenv&gt;.Linear'&gt;</span></span></code></pre>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_config.html">from_config</a></span><span class="op">(</span><span class="va">config</span><span class="op">)</span></span></code></pre></div>
<p>Note that the <code>initialize()</code> method of the base
<code>Layer</code> class takes some keyword arguments, in particular a
<code>name</code> and a <code>dtype</code>. It’s good practice to pass
these arguments to the parent class in <code>initialize()</code> and to
include them in the layer config:</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/new_layer_class.html">new_layer_class</a></span><span class="op">(</span></span>
<span>  <span class="st">"Linear"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">units</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  build <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">input_shape</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="../reference/op_matmul.html">op_matmul</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span></span>
<span>  <span class="op">}</span>,</span>
<span>  get_config <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span>units <span class="op">=</span> <span class="fl">64</span><span class="op">)</span></span>
<span><span class="va">config</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_config.html">get_config</a></span><span class="op">(</span><span class="va">layer</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">config</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 1</span></span>
<span><span class="co">##  $ units: int 64</span></span>
<span><span class="co">##  - attr(*, "__class__")=&lt;class '&lt;r-globalenv&gt;.Linear'&gt;</span></span></code></pre>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_config.html">from_config</a></span><span class="op">(</span><span class="va">config</span><span class="op">)</span></span></code></pre></div>
<p>If you need more flexibility when deserializing the layer from its
config, you can also override the <code><a href="../reference/get_config.html">from_config()</a></code> class
method. This is the base implementation of
<code><a href="../reference/get_config.html">from_config()</a></code>:</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="va">...</span>,</span>
<span>  from_config <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">config</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># calling `__class__`() creates a new instance and calls initialize()</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">`__class__`</span>, <span class="va">config</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>To learn more about serialization and saving, see the complete <a href="serialization_and_saving.html">guide to saving and serializing
models</a>.</p>
</div>
<div class="section level2">
<h2 id="privileged-training-argument-in-the-call-method">Privileged <code>training</code> argument in the <code>call()</code>
method<a class="anchor" aria-label="anchor" href="#privileged-training-argument-in-the-call-method"></a>
</h2>
<p>Some layers, in particular the <code>BatchNormalization</code> layer
and the <code>Dropout</code> layer, have different behaviors during
training and inference. For such layers, it is standard practice to
expose a <code>training</code> (boolean) argument in the
<code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> method.</p>
<p>By exposing this argument in <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>, you enable the
built-in training and evaluation loops (e.g. <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>) to
correctly use the layer in training and inference.</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_custom_dropout</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"CustomDropout"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">rate</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">rate</span> <span class="op">&lt;-</span> <span class="va">rate</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">seed_generator</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/random_seed_generator.html">random_seed_generator</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">training</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Logic.html" class="external-link">isTRUE</a></span><span class="op">(</span><span class="va">training</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="../reference/random_dropout.html">random_dropout</a></span><span class="op">(</span><span class="va">inputs</span>, rate <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">rate</span>,</span>
<span>                            seed <span class="op">=</span> <span class="va">self.seed_generator</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">inputs</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="privileged-mask-argument-in-the-call-method">Privileged <code>mask</code> argument in the <code>call()</code>
method<a class="anchor" aria-label="anchor" href="#privileged-mask-argument-in-the-call-method"></a>
</h2>
<p>The other privileged argument supported by <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> is the
<code>mask</code> argument.</p>
<p>You will find it in all Keras RNN layers. A mask is a boolean tensor
(one boolean value per timestep in the input) used to skip certain input
timesteps when processing timeseries data.</p>
<p>Keras will automatically pass the correct <code>mask</code> argument
to <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> for layers that support it, when a mask is
generated by a prior layer. Mask-generating layers are the
<code>Embedding</code> layer configured with
<code>mask_zero = TRUE</code>, and the <code>Masking</code> layer.</p>
</div>
<div class="section level2">
<h2 id="the-model-class">The <code>Model</code> class<a class="anchor" aria-label="anchor" href="#the-model-class"></a>
</h2>
<p>In general, you will use the <code>Layer</code> class to define inner
computation blocks, and will use the <code>Model</code> class to define
the outer model – the object you will train.</p>
<p>For instance, in a ResNet50 model, you would have several ResNet
blocks subclassing <code>Layer</code>, and a single <code>Model</code>
encompassing the entire ResNet50 network.</p>
<p>The <code>Model</code> class has the same API as <code>Layer</code>,
with the following differences:</p>
<ul>
<li>It exposes built-in training, evaluation, and prediction loops
(<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>, <code><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html" class="external-link">evaluate()</a></code>,
<code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code>).</li>
<li>It exposes the list of its inner layers, via the
<code>model$layers</code> property.</li>
<li>It exposes saving and serialization APIs (<code><a href="https://rdrr.io/r/base/save.html" class="external-link">save()</a></code>,
<code>save_weights()</code>…)</li>
</ul>
<p>Effectively, the <code>Layer</code> class corresponds to what we
refer to in the literature as a “layer” (as in “convolution layer” or
“recurrent layer”) or as a “block” (as in “ResNet block” or “Inception
block”).</p>
<p>Meanwhile, the <code>Model</code> class corresponds to what is
referred to in the literature as a “model” (as in “deep learning model”)
or as a “network” (as in “deep neural network”).</p>
<p>So if you’re wondering, “should I use the <code>Layer</code> class or
the <code>Model</code> class?”, ask yourself: will I need to call
<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> on it? Will I need to call <code><a href="https://rdrr.io/r/base/save.html" class="external-link">save()</a></code> on it?
If so, go with <code>Model</code>. If not (either because your class is
just a block in a bigger system, or because you are writing training
&amp; saving code yourself), use <code>Layer</code>.</p>
<p>For instance, we could take our mini-resnet example above, and use it
to build a <code>Model</code> that we could train with
<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>, and that we could save with
<code>save_weights()</code>:</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ResNet</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Model.html">Model</a></span><span class="op">(</span></span>
<span>  <span class="st">"ResNet"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">num_classes</span> <span class="op">=</span> <span class="fl">1000</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">block_1</span> <span class="op">&lt;-</span> <span class="fu">layer_resnet_block</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">block_2</span> <span class="op">&lt;-</span> <span class="fu">layer_resnet_block</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">global_pool</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_global_average_pooling_2d.html">layer_global_average_pooling_2d</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">classifier</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">num_classes</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">inputs</span> <span class="op">|&gt;</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">block_1</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">block_2</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">global_pool</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">classifier</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">resnet</span> <span class="op">&lt;-</span> <span class="fu">ResNet</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="va">...</span></span>
<span><span class="va">resnet</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dataset</span>, epochs<span class="op">=</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">resnet</span> <span class="op">|&gt;</span> <span class="fu"><a href="../reference/save_model.html">save_model</a></span><span class="op">(</span><span class="st">"filepath.keras"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="putting-it-all-together-an-end-to-end-example">Putting it all together: an end-to-end example<a class="anchor" aria-label="anchor" href="#putting-it-all-together-an-end-to-end-example"></a>
</h2>
<p>Here’s what you’ve learned so far:</p>
<ul>
<li>A <code>Layer</code> encapsulate a state (created in
<code>initialize()</code> or <code>build()</code>) and some computation
(defined in <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>).</li>
<li>Layers can be recursively nested to create new, bigger computation
blocks.</li>
<li>Layers are backend-agnostic as long as they only use Keras APIs. You
can use backend-native APIs (such as <code>jax$numpy</code>,
<code>torch$nn</code> or <code>tf$nn</code>), but then your layer will
only be usable with that specific backend.</li>
<li>Layers can create and track losses (typically regularization losses)
via <code>add_loss()</code>.</li>
<li>The outer container, the thing you want to train, is a
<code>Model</code>. A <code>Model</code> is just like a
<code>Layer</code>, but with added training and serialization
utilities.</li>
</ul>
<p>Let’s put all of these things together into an end-to-end example:
we’re going to implement a Variational AutoEncoder (VAE) in a
backend-agnostic fashion – so that it runs the same with TensorFlow,
JAX, and PyTorch. We’ll train it on MNIST digits.</p>
<p>Our VAE will be a subclass of <code>Model</code>, built as a nested
composition of layers that subclass <code>Layer</code>. It will feature
a regularization loss (KL divergence).</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">layer_sampling</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"Sampling"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">seed_generator</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/random_seed_generator.html">random_seed_generator</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span><span class="op">)</span> <span class="op"><a href="../reference/multi-assign.html">%&lt;-%</a></span> <span class="va">inputs</span></span>
<span>    <span class="va">batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/op_shape.html">op_shape</a></span><span class="op">(</span><span class="va">z_mean</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span>    <span class="va">dim</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/op_shape.html">op_shape</a></span><span class="op">(</span><span class="va">z_mean</span><span class="op">)</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span>
<span>    <span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/random_normal.html">random_normal</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">batch</span>, <span class="va">dim</span><span class="op">)</span>,</span>
<span>                             seed<span class="op">=</span><span class="va">self</span><span class="op">$</span><span class="va">seed_generator</span><span class="op">)</span></span>
<span>    <span class="va">z_mean</span> <span class="op">+</span> <span class="fu"><a href="../reference/op_exp.html">op_exp</a></span><span class="op">(</span><span class="fl">0.5</span> <span class="op">*</span> <span class="va">z_log_var</span><span class="op">)</span> <span class="op">*</span> <span class="va">epsilon</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Maps MNIST digits to a triplet (z_mean, z_log_var, z).</span></span>
<span><span class="va">layer_encoder</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"Encoder"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">latent_dim</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">intermediate_dim</span> <span class="op">=</span> <span class="fl">64</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_proj</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">intermediate_dim</span>,  activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">latent_dim</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_log_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">latent_dim</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">sampling</span> <span class="op">&lt;-</span> <span class="fu">layer_sampling</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_proj</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span>    <span class="va">z_mean</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_mean</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>    <span class="va">z_log_var</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_log_var</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>    <span class="va">z</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">sampling</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span>, <span class="va">z</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Converts z, the encoded digit vector, back into a readable digit.</span></span>
<span><span class="va">layer_decoder</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"Decoder"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">original_dim</span>, <span class="va">intermediate_dim</span> <span class="op">=</span> <span class="fl">64</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_proj</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">intermediate_dim</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">dense_output</span> <span class="op">&lt;-</span></span>
<span>      <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">original_dim</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_proj</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">dense_output</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Combines the encoder and decoder into an end-to-end model for training.</span></span>
<span><span class="va">VariationalAutoEncoder</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Model.html">Model</a></span><span class="op">(</span></span>
<span>  <span class="st">"VariationalAutoEncoder"</span>,</span>
<span></span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">original_dim</span>, <span class="va">intermediate_dim</span> <span class="op">=</span> <span class="fl">64</span>, <span class="va">latent_dim</span> <span class="op">=</span> <span class="fl">32</span>,</span>
<span>                        <span class="va">name</span> <span class="op">=</span> <span class="st">"autoencoder"</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span>name <span class="op">=</span> <span class="va">name</span>, <span class="va">...</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">original_dim</span> <span class="op">&lt;-</span> <span class="va">original_dim</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">encoder</span> <span class="op">&lt;-</span> <span class="fu">layer_encoder</span><span class="op">(</span>latent_dim <span class="op">=</span> <span class="va">latent_dim</span>,</span>
<span>                            intermediate_dim <span class="op">=</span> <span class="va">intermediate_dim</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">decoder</span> <span class="op">&lt;-</span> <span class="fu">layer_decoder</span><span class="op">(</span>original_dim <span class="op">=</span> <span class="va">original_dim</span>,</span>
<span>                            intermediate_dim <span class="op">=</span> <span class="va">intermediate_dim</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span>, <span class="va">z</span><span class="op">)</span> <span class="op"><a href="../reference/multi-assign.html">%&lt;-%</a></span> <span class="va">self</span><span class="op">$</span><span class="fu">encoder</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span>    <span class="va">reconstructed</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">decoder</span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span>    <span class="co"># Add KL divergence regularization loss.</span></span>
<span>    <span class="va">kl_loss</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> <span class="fu"><a href="../reference/op_mean.html">op_mean</a></span><span class="op">(</span><span class="va">z_log_var</span> <span class="op">-</span> <span class="fu"><a href="../reference/op_square.html">op_square</a></span><span class="op">(</span><span class="va">z_mean</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="../reference/op_exp.html">op_exp</a></span><span class="op">(</span><span class="va">z_log_var</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="fu">add_loss</span><span class="op">(</span><span class="va">kl_loss</span><span class="op">)</span></span>
<span>    <span class="va">reconstructed</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Let’s train it on MNIST using the <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> API:</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">.</span><span class="op">)</span>, <span class="va">.</span><span class="op">)</span> <span class="op"><a href="../reference/multi-assign.html">%&lt;-%</a></span> <span class="fu"><a href="../reference/dataset_mnist.html">dataset_mnist</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="va">x_train</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/op_reshape.html">op_reshape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">60000</span>, <span class="fl">784</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/op_cast.html">op_cast</a></span><span class="op">(</span><span class="st">"float32"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/op_divide.html">op_divide</a></span><span class="op">(</span><span class="fl">255</span><span class="op">)</span></span>
<span></span>
<span><span class="va">original_dim</span> <span class="op">&lt;-</span> <span class="fl">784</span></span>
<span><span class="va">vae</span> <span class="op">&lt;-</span> <span class="fu">VariationalAutoEncoder</span><span class="op">(</span></span>
<span>  original_dim <span class="op">=</span> <span class="fl">784</span>,</span>
<span>  intermediate_dim <span class="op">=</span> <span class="fl">64</span>,</span>
<span>  latent_dim <span class="op">=</span> <span class="fl">32</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">optimizer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">1e-3</span><span class="op">)</span></span>
<span><span class="va">vae</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">optimizer</span>, loss <span class="op">=</span> <span class="fu"><a href="../reference/loss_mean_squared_error.html">loss_mean_squared_error</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">vae</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">x_train</span>, epochs <span class="op">=</span> <span class="fl">2</span>, batch_size <span class="op">=</span> <span class="fl">64</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 938/938 - 4s - 4ms/step - loss: 0.0748</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 938/938 - 1s - 1ms/step - loss: 0.0676</span></span></code></pre>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
