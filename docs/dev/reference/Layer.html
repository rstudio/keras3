<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Define a custom Layer class. — Layer • keras3</title><!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet"><meta property="og:title" content="Define a custom Layer class. — Layer"><meta name="description" content="A layer is a callable object that takes as input one or more tensors and
that outputs one or more tensors. It involves computation, defined
in the call() method, and a state (weight variables). State can be
created:
in initialize(), for instance via self$add_weight();
in the optional build() method, which is invoked by the first
call() to the layer, and supplies the shape(s) of the input(s),
which may not have been known at initialization time.


Layers are recursively composable: If you assign a Layer instance as an
attribute of another Layer, the outer layer will start tracking the weights
created by the inner layer. Nested layers should be instantiated in the
initialize() method or build() method.
Users will just instantiate a layer and then treat it as a callable."><meta property="og:description" content="A layer is a callable object that takes as input one or more tensors and
that outputs one or more tensors. It involves computation, defined
in the call() method, and a state (weight variables). State can be
created:
in initialize(), for instance via self$add_weight();
in the optional build() method, which is invoked by the first
call() to the layer, and supplies the shape(s) of the input(s),
which may not have been known at initialization time.


Layers are recursively composable: If you assign a Layer instance as an
attribute of another Layer, the outer layer will start tracking the weights
created by the inner layer. Nested layers should be instantiated in the
initialize() method or build() method.
Users will just instantiate a layer and then treat it as a callable."><meta name="robots" content="noindex"><!-- Google Tag Manager --><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-KHBDBW7');</script><!-- End Google Tag Manager --></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    <!-- Google Tag Manager (noscript) --> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KHBDBW7" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript> <!-- End Google Tag Manager (noscript) -->


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="inverse" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">keras3</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">1.4.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/getting_started.html">Getting Started</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-guides" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Guides</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-guides"><li><h6 class="dropdown-header" data-toc-skip>Model definition</h6></li>
    <li><a class="dropdown-item" href="../articles/sequential_model.html">Sequential Model</a></li>
    <li><a class="dropdown-item" href="../articles/functional_api.html">Functional API</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6></li>
    <li><a class="dropdown-item" href="../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a></li>
    <li><a class="dropdown-item" href="../articles/custom_train_step_in_tensorflow.html">Customizing `fit()` with Tensorflow</a></li>
    <li><a class="dropdown-item" href="../articles/writing_your_own_callbacks.html">Writing your own callbacks</a></li>
    <li><a class="dropdown-item" href="../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a></li>
    <li><a class="dropdown-item" href="../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a></li>
    <li><a class="dropdown-item" href="../articles/serialization_and_saving.html">Serialization and Saving</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Other topics</h6></li>
    <li><a class="dropdown-item" href="../articles/transfer_learning.html">Transfer learning and fine tuning</a></li>
    <li><a class="dropdown-item" href="../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a></li>
    <li><a class="dropdown-item" href="../articles/distribution.html">Distributed training with Jax</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../articles/examples/index.html">Examples</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">News</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/rstudio/keras3/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Define a custom <code>Layer</code> class.</h1>
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras3/blob/HEAD/R/Layer.R" class="external-link"><code>R/Layer.R</code></a></small>
      <div class="d-none name"><code>Layer.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>A layer is a callable object that takes as input one or more tensors and
that outputs one or more tensors. It involves <em>computation</em>, defined
in the <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> method, and a <em>state</em> (weight variables). State can be
created:</p><ul><li><p>in <code>initialize()</code>, for instance via <code>self$add_weight()</code>;</p></li>
<li><p>in the optional <code>build()</code> method, which is invoked by the first
<code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> to the layer, and supplies the shape(s) of the input(s),
which may not have been known at initialization time.</p></li>
</ul><p>Layers are recursively composable: If you assign a Layer instance as an
attribute of another Layer, the outer layer will start tracking the weights
created by the inner layer. Nested layers should be instantiated in the
<code>initialize()</code> method or <code>build()</code> method.</p>
<p>Users will just instantiate a layer and then treat it as a callable.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">Layer</span><span class="op">(</span></span>
<span>  <span class="va">classname</span>,</span>
<span>  initialize <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  call <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  build <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  get_config <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  <span class="va">...</span>,</span>
<span>  public <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  private <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  inherit <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  parent_env <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sys.parent.html" class="external-link">parent.frame</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-classname">classname<a class="anchor" aria-label="anchor" href="#arg-classname"></a></dt>
<dd><p>String, the name of the custom class. (Conventionally, CamelCase).</p></dd>


<dt id="arg-initialize-call-build-get-config">initialize, call, build, get_config<a class="anchor" aria-label="anchor" href="#arg-initialize-call-build-get-config"></a></dt>
<dd><p>Recommended methods to implement. See
description and details sections.</p></dd>


<dt id="arg--public">..., public<a class="anchor" aria-label="anchor" href="#arg--public"></a></dt>
<dd><p>Additional methods or public members of the custom class.</p></dd>


<dt id="arg-private">private<a class="anchor" aria-label="anchor" href="#arg-private"></a></dt>
<dd><p>Named list of R objects (typically, functions) to include in
instance private environments. <code>private</code> methods will have all the same
symbols in scope as public methods (See section "Symbols in Scope"). Each
instance will have it's own <code>private</code> environment. Any objects
in <code>private</code> will be invisible from the Keras framework and the Python
runtime.</p></dd>


<dt id="arg-inherit">inherit<a class="anchor" aria-label="anchor" href="#arg-inherit"></a></dt>
<dd><p>What the custom class will subclass. By default, the base keras class.</p></dd>


<dt id="arg-parent-env">parent_env<a class="anchor" aria-label="anchor" href="#arg-parent-env"></a></dt>
<dd><p>The R environment that all class methods will have as a grandparent.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A composing layer constructor, with similar behavior to other layer
functions like <code><a href="layer_dense.html">layer_dense()</a></code>. The first argument of the returned function
will be <code>object</code>, enabling <code>initialize()</code>ing and <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> the layer in one
step while composing the layer with the pipe, like</p>
<p></p><div class="sourceCode r"><pre><code><span><span class="va">layer_foo</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span><span class="st">"Foo"</span>, <span class="va">....</span><span class="op">)</span></span>
<span><span class="va">output</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op">|&gt;</span> <span class="fu">layer_foo</span><span class="op">(</span><span class="op">)</span></span></code></pre><p></p></div>
<p>To only <code>initialize()</code> a layer instance and not <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> it, pass a missing
or <code>NULL</code> value to <code>object</code>, or pass all arguments to <code>initialize()</code> by name.</p>
<p></p><div class="sourceCode r"><pre><code><span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">2</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="cn">NULL</span>, <span class="fl">2</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>, <span class="fl">2</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># then you can call() the layer in a separate step</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op">|&gt;</span> <span class="fu">layer</span><span class="op">(</span><span class="op">)</span></span></code></pre><p></p></div>
    </div>
    <div class="section level2">
    <h2 id="symbols-in-scope">Symbols in scope<a class="anchor" aria-label="anchor" href="#symbols-in-scope"></a></h2>
    <p>All R function custom methods (public and private) will have the
following symbols in scope:</p><ul><li><p><code>self</code>: The custom class instance.</p></li>
<li><p><code>super</code>: The custom class superclass.</p></li>
<li><p><code>private</code>: An R environment specific to the class instance.
Any objects assigned here are invisible to the Keras framework.</p></li>
<li><p><code>__class__</code> and <code>as.symbol(classname)</code>: the custom class type object.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="attributes">Attributes<a class="anchor" aria-label="anchor" href="#attributes"></a></h2>

<ul><li><p><code>name</code>: The name of the layer (string).</p></li>
<li><p><code>dtype</code>: Dtype of the layer's weights. Alias of <code>layer$variable_dtype</code>.</p></li>
<li><p><code>variable_dtype</code>: Dtype of the layer's weights.</p></li>
<li><p><code>compute_dtype</code>: The dtype of the layer's computations.
Layers automatically cast inputs to this dtype, which causes
the computations and output to also be in this dtype.
When mixed precision is used with a
<code>keras$mixed_precision$DTypePolicy</code>, this will be different
than <code>variable_dtype</code>.</p></li>
<li><p><code>trainable_weights</code>: List of variables to be included in backprop.</p></li>
<li><p><code>non_trainable_weights</code>: List of variables that should not be
included in backprop.</p></li>
<li><p><code>weights</code>: The concatenation of the lists <code>trainable_weights</code> and
<code>non_trainable_weights</code> (in this order).</p></li>
<li><p><code>trainable</code>: Whether the layer should be trained (boolean), i.e.
whether its potentially-trainable weights should be returned
as part of <code>layer$trainable_weights</code>.</p></li>
<li><p><code>input_spec</code>: Optional (list of) <code>InputSpec</code> object(s) specifying the
constraints on inputs that can be accepted by the layer.</p></li>
</ul><p>We recommend that custom <code>Layer</code>s implement the following methods:</p><ul><li><p><code>initialize()</code>: Defines custom layer attributes, and creates layer weights
that do not depend on input shapes, using <code>add_weight()</code>,
or other state.</p></li>
<li><p><code>build(input_shape)</code>: This method can be used to create weights that
depend on the shape(s) of the input(s), using <code>add_weight()</code>, or other
state. Calling <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> will automatically build the layer
(if it has not been built yet) by calling <code>build()</code>.</p></li>
<li><p><code>call(...)</code>: Method called after making
sure <code>build()</code> has been called. <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> performs the logic of applying
the layer to the input arguments.
Two reserved arguments you can optionally use in <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> are:</p><ol><li><p><code>training</code> (boolean, whether the call is in inference mode or
training mode).</p></li>
<li><p><code>mask</code> (boolean tensor encoding masked timesteps in the input,
used e.g. in RNN layers).</p></li>
</ol><p>A typical signature for this method is <code>call(inputs)</code>, and user
could optionally add <code>training</code> and <code>mask</code> if the layer need them.</p></li>
<li><p><code><a href="get_config.html">get_config()</a></code>: Returns a named list containing the configuration
used to initialize this layer. If the list names differ from the arguments
in <code>initialize()</code>, then override <code><a href="get_config.html">from_config()</a></code> as well.
This method is used when saving
the layer or a model that contains this layer.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a></h2>
    <p>Here's a basic example: a layer with two variables, <code>w</code> and <code>b</code>,
that returns <code>y &lt;- (w %*% x) + b</code>.
It shows how to implement <code>build()</code> and <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>.
Variables set as attributes of a layer are tracked as weights
of the layers (in <code>layer$weights</code>).</p>
<p></p><div class="sourceCode r"><pre><code><span><span class="va">layer_simple_dense</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  <span class="st">"SimpleDense"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">units</span> <span class="op">&lt;-</span> <span class="va">units</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  <span class="co"># Create the state of the layer (weights)</span></span>
<span>  build <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">kernel</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">input_shape</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"glorot_uniform"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>      name <span class="op">=</span> <span class="st">"kernel"</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">bias</span> <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>      name <span class="op">=</span> <span class="st">"bias"</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  <span class="co"># Defines the computation</span></span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">self</span>, <span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="../reference/op_matmul.html">op_matmul</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">kernel</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">bias</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Instantiates the layer.</span></span>
<span><span class="co"># Supply missing `object` arg to skip invoking `call()` and instead return</span></span>
<span><span class="co"># the Layer instance</span></span>
<span><span class="va">linear_layer</span> <span class="op">&lt;-</span> <span class="fu">layer_simple_dense</span><span class="op">(</span>, <span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># This will call `build(input_shape)` and create the weights,</span></span>
<span><span class="co"># and then invoke `call()`.</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">linear_layer</span><span class="op">(</span><span class="fu"><a href="../reference/op_ones.html">op_ones</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">linear_layer</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span> <span class="op">==</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># These weights are trainable, so they're listed in `trainable_weights`:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">linear_layer</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span> <span class="op">==</span> <span class="fl">2</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Besides trainable weights, updated via backpropagation during training,
layers can also have non-trainable weights. These weights are meant to
be updated manually during <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>. Here's a example layer that computes
the running sum of its inputs:</p>
<p></p><div class="sourceCode r"><pre><code><span><span class="va">layer_compute_sum</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span></span>
<span>  classname <span class="op">=</span> <span class="st">"ComputeSum"</span>,</span>
<span></span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_dim</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span>    <span class="co"># Create a non-trainable weight.</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">total</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span></span>
<span>      shape <span class="op">=</span> <span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>      initializer <span class="op">=</span> <span class="st">"zeros"</span>,</span>
<span>      trainable <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>      name <span class="op">=</span> <span class="st">"total"</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span></span>
<span>  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">total</span><span class="op">$</span><span class="fu">assign</span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">total</span> <span class="op">+</span> <span class="fu"><a href="../reference/op_sum.html">op_sum</a></span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">total</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">my_sum</span> <span class="op">&lt;-</span> <span class="fu">layer_compute_sum</span><span class="op">(</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/op_ones.html">op_ones</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">my_sum</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span>exprs <span class="op">=</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/all.equal.html" class="external-link">all.equal</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">weights</span>,               <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">total</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/all.equal.html" class="external-link">all.equal</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">non_trainable_weights</span>, <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">total</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/all.equal.html" class="external-link">all.equal</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">trainable_weights</span>,     <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre><p></p></div>
    </div>
    <div class="section level2">
    <h2 id="methods-available">Methods available<a class="anchor" aria-label="anchor" href="#methods-available"></a></h2>

<ul><li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span>,</span>
<span>           activity_regularizer <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>           trainable <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>           dtype <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>           autocast <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>           name <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Initialize self. This method is typically called from a custom <code>initialize()</code> method.
Example:</p>
<p></p><div class="sourceCode r"><pre><code><span><span class="va">layer_my_layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/Layer.html">Layer</a></span><span class="op">(</span><span class="st">"MyLayer"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span>, <span class="va">...</span>, <span class="va">dtype</span> <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">name</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span>, dtype <span class="op">=</span> <span class="va">dtype</span>, name <span class="op">=</span> <span class="va">name</span><span class="op">)</span></span>
<span>    <span class="co"># .... finish initializing `self` instance</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre><p></p></div>
<p>Args:</p><ul><li><p>trainable: Boolean, whether the layer's variables should be trainable.</p></li>
<li><p>name: String name of the layer.</p></li>
<li><p>dtype: The dtype of the layer's computations and weights. Can also be a
<code>keras$DTypePolicy</code>, which allows the computation and weight dtype
to differ. Defaults to <code>NULL</code>. <code>NULL</code> means to use
<code><a href="config_dtype_policy.html">config_dtype_policy()</a></code>, which is a <code>"float32"</code> policy unless
set to different value (via <code><a href="config_set_dtype_policy.html">config_set_dtype_policy()</a></code>).</p></li>
</ul></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">add_loss</span><span class="op">(</span><span class="va">loss</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Can be called inside of the <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> method to add a scalar loss.</p>
<p>Example:</p>
<p></p><div class="sourceCode r"><pre><code>Layer("MyLayer",
  ...
  call = function(x) {
    self$add_loss(op_sum(x))
    x
  }
</code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">add_metric</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">add_variable</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Add a weight variable to the layer.</p>
<p>Alias of <code>add_weight()</code>.</p></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">add_weight</span><span class="op">(</span>shape <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>           initializer <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>           dtype <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>           trainable <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>           autocast <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>           regularizer <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>           constraint <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>           aggregation <span class="op">=</span> <span class="st">'none'</span>,</span>
<span>           overwrite_with_gradient <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>           name <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Add a weight variable to the layer.</p>
<p>Args:</p><ul><li><p><code>shape</code>: shape for the variable (as defined by <code><a href="shape.html">shape()</a></code>)
Must be fully-defined (no <code>NA</code>/<code>NULL</code>/<code>-1</code> entries).
Defaults to <code>()</code> (scalar) if unspecified.</p></li>
<li><p><code>initializer</code>: Initializer object to use to
populate the initial variable value,
or string name of a built-in initializer
(e.g. <code>"random_normal"</code>). If unspecified,
defaults to <code>"glorot_uniform"</code>
for floating-point variables and to <code>"zeros"</code>
for all other types (e.g. int, bool).</p></li>
<li><p><code>dtype</code>: Dtype of the variable to create,
e.g. <code>"float32"</code>. If unspecified,
defaults to the layer's
variable dtype (which itself defaults to
<code>"float32"</code> if unspecified).</p></li>
<li><p><code>trainable</code>: Boolean, whether the variable should
be trainable via backprop or whether its
updates are managed manually.
Defaults to <code>TRUE</code>.</p></li>
<li><p><code>autocast</code>: Boolean, whether to autocast layers variables when
accessing them. Defaults to <code>TRUE</code>.</p></li>
<li><p><code>regularizer</code>: Regularizer object to call to apply penalty on the
weight. These penalties are summed into the loss function
during optimization. Defaults to <code>NULL</code>.</p></li>
<li><p><code>constraint</code>: Constraint object to call on the
variable after any optimizer update,
or string name of a built-in constraint.
Defaults to <code>NULL</code>.</p></li>
<li><p><code>aggregation</code>: Optional string, one of <code>NULL</code>, <code>"none"</code>, <code>"mean"</code>,
<code>"sum"</code> or <code>"only_first_replica"</code>. Annotates the variable with
the type of multi-replica aggregation to be used for this
variable when writing custom data parallel training loops.
Defaults to <code>"none"</code>.</p></li>
<li><p><code>overwrite_with_gradient</code>: Boolean, whether to overwrite the variable with
the computed gradient. Useful for float8 training. Defaults to <code>FALSE</code>.</p></li>
<li><p><code>name</code>: String name of the variable. Useful for debugging purposes.</p></li>
</ul><p>Returns:</p>
<p>A backend tensor, wrapped in a <code>KerasVariable</code> class.
The <code>KerasVariable</code> class has</p>
<p>Methods:</p><ul><li><p><code>assign(value)</code></p></li>
<li><p><code>assign_add(value)</code></p></li>
<li><p><code>assign_sub(value)</code></p></li>
<li><p><code>numpy()</code> (calling <code>as.array(&lt;variable&gt;)</code> is preferred)</p></li>
</ul><p>Properties/Attributes:</p><ul><li><p><code>value</code></p></li>
<li><p><code>dtype</code></p></li>
<li><p><code>ndim</code></p></li>
<li><p><code>shape</code> (calling <code>shape(&lt;variable&gt;)</code> is preferred)</p></li>
<li><p><code>trainable</code></p></li>
</ul></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">build</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">build_from_config</span><span class="op">(</span><span class="va">config</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Builds the layer's states with the supplied config (named list of args).</p>
<p>By default, this method calls the <code>do.call(build, config$input_shape)</code> method,
which creates weights based on the layer's input shape in the supplied
config. If your config contains other information needed to load the
layer's state, you should override this method.</p>
<p>Args:</p><ul><li><p><code>config</code>: Named list containing the input shape associated with this layer.</p></li>
</ul></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu"><a href="https://rdrr.io/r/base/call.html" class="external-link">call</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div>
<p>See description above</p></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">compute_mask</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">previous_mask</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">compute_output_shape</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">compute_output_spec</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">symbolic_call</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu"><a href="../reference/count_params.html">count_params</a></span><span class="op">(</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Count the total number of scalars composing the weights.</p>
<p>Returns:
An integer count.</p></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">get_build_config</span><span class="op">(</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Returns a named list with the layer's input shape.</p>
<p>This method returns a config (named list) that can be used by
<code>build_from_config(config)</code> to create all states (e.g. Variables and
Lookup tables) needed by the layer.</p>
<p>By default, the config only contains the input shape that the layer
was built with. If you're writing a custom layer that creates state in
an unusual way, you should override this method to make sure this state
is already created when Keras attempts to load its value upon model
loading.</p>
<p>Returns:
A named list containing the input shape associated with the layer.</p></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu"><a href="../reference/get_config.html">get_config</a></span><span class="op">(</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Returns the config of the object.</p>
<p>An object config is a named list (serializable)
containing the information needed to re-instantiate it.
The config is expected to be serializable to JSON, and is expected
to consist of a (potentially complex, nested) structure of names lists
consisting of simple objects like strings, ints.</p></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu"><a href="../reference/get_weights.html">get_weights</a></span><span class="op">(</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Return the values of <code>layer$weights</code> as a list of R or NumPy arrays.</p></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">quantize</span><span class="op">(</span><span class="va">mode</span>, type_check <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Currently, only the <code>Dense</code>, <code>EinsumDense</code> and <code>Embedding</code> layers support in-place
quantization via this <code>quantize()</code> method.</p>
<p>Example:</p>
<p></p><div class="sourceCode r"><pre><code><span><span class="va">model</span><span class="op">$</span><span class="fu">quantize</span><span class="op">(</span><span class="st">"int8"</span><span class="op">)</span> <span class="co"># quantize model in-place</span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="co"># faster inference</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">quantized_build</span><span class="op">(</span><span class="va">input_shape</span>, <span class="va">mode</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">quantized_call</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">rematerialized_call</span><span class="op">(</span><span class="va">layer_call</span>, <span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Enable rematerialization dynamically for a layer's <code>call</code> method.</p>
<p>Args:</p><ul><li><p><code>layer_call</code>: The original <code>call</code> method of a layer.</p></li>
<li><p><code>...</code>: additional args</p></li>
</ul><p>Returns:
A rematerialized version of the layer's <code>call</code> method.</p></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">load_own_variables</span><span class="op">(</span><span class="va">store</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Loads the state of the layer.</p>
<p>You can override this method to take full control of how the state of
the layer is loaded upon calling <code><a href="load_model.html">load_model()</a></code>.</p>
<p>Args:</p><ul><li><p><code>store</code>: Named list from which the state of the model will be loaded.</p></li>
</ul></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">save_own_variables</span><span class="op">(</span><span class="va">store</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Saves the state of the layer.</p>
<p>You can override this method to take full control of how the state of
the layer is saved upon calling <code><a href="save_model.html">save_model()</a></code>.</p>
<p>Args:</p><ul><li><p><code>store</code>: Named list where the state of the model will be saved.</p></li>
</ul></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu"><a href="../reference/get_weights.html">set_weights</a></span><span class="op">(</span><span class="va">weights</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Sets the values of <code>weights</code> from a list of R or NumPy arrays.</p></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">stateless_call</span><span class="op">(</span><span class="va">trainable_variables</span>, <span class="va">non_trainable_variables</span>,</span>
<span>               <span class="va">...</span>, return_losses <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Call the layer without any side effects.</p>
<p>Args:</p><ul><li><p><code>trainable_variables</code>: List of trainable variables of the model.</p></li>
<li><p><code>non_trainable_variables</code>: List of non-trainable variables of the
model.</p></li>
<li><p><code>...</code>: Positional and named arguments to be passed to <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>.</p></li>
<li><p><code>return_losses</code>: If <code>TRUE</code>, <code>stateless_call()</code> will return the list of
losses created during <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> as part of its return values.</p></li>
</ul><p>Returns:
An unnamed list. By default, returns <code>list(outputs, non_trainable_variables)</code>.
If <code>return_losses = TRUE</code>, then returns
<code>list(outputs, non_trainable_variables, losses)</code>.</p>
<p>Note: <code>non_trainable_variables</code> include not only non-trainable weights
such as <code>BatchNormalization</code> statistics, but also RNG seed state
(if there are any random operations part of the layer, such as dropout),
and <code>Metric</code> state (if there are any metrics attached to the layer).
These are all elements of state of the layer.</p>
<p>Example:</p>
<p></p><div class="sourceCode r"><pre><code><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="va">...</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">...</span></span>
<span><span class="va">trainable_variables</span> <span class="op">&lt;-</span> <span class="va">model</span><span class="op">$</span><span class="va">trainable_variables</span></span>
<span><span class="va">non_trainable_variables</span> <span class="op">&lt;-</span> <span class="va">model</span><span class="op">$</span><span class="va">non_trainable_variables</span></span>
<span><span class="co"># Call the model with zero side effects</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">outputs</span>, <span class="va">non_trainable_variables</span><span class="op">)</span> <span class="op"><a href="../reference/multi-assign.html">%&lt;-%</a></span> <span class="va">model</span><span class="op">$</span><span class="fu">stateless_call</span><span class="op">(</span></span>
<span>    <span class="va">trainable_variables</span>,</span>
<span>    <span class="va">non_trainable_variables</span>,</span>
<span>    <span class="va">data</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># Attach the updated state to the model</span></span>
<span><span class="co"># (until you do this, the model is still in its pre-call state).</span></span>
<span><span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map2.html" class="external-link">walk2</a></span><span class="op">(</span></span>
<span>  <span class="va">model</span><span class="op">$</span><span class="va">non_trainable_variables</span>, <span class="va">non_trainable_variables</span>,</span>
<span>  \<span class="op">(</span><span class="va">variable</span>, <span class="va">value</span><span class="op">)</span> <span class="va">variable</span><span class="op">$</span><span class="fu">assign</span><span class="op">(</span><span class="va">value</span><span class="op">)</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu">symbolic_call</span><span class="op">(</span><span class="va">...</span><span class="op">)</span></span></code></pre><p></p></div></li>
<li><p></p>
<p></p><div class="sourceCode r"><pre><code><span><span class="fu"><a href="../reference/get_config.html">from_config</a></span><span class="op">(</span><span class="va">config</span><span class="op">)</span></span></code></pre><p></p></div>
<p>Creates a layer from its config.</p>
<p>This is a class method, meaning, the R function will not have a <code>self</code>
symbol (a class instance) in scope. Use <code>__class__</code> or the classname symbol
provided when the <code>Layer()</code> was constructed) to resolve the class definition.
The default implementation is:</p>
<p></p><div class="sourceCode r"><pre><code><span><span class="va">from_config</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">config</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">`__class__`</span>, <span class="va">config</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre><p></p></div>
<p>This method is the reverse of <code><a href="get_config.html">get_config()</a></code>,
capable of instantiating the same layer from the config
named list. It does not handle layer connectivity
(handled by Network), nor weights (handled by <code><a href="get_weights.html">set_weights()</a></code>).</p>
<p>Args:</p><ul><li><p><code>config</code>: A named list, typically the
output of <code><a href="get_config.html">get_config()</a></code>.</p></li>
</ul><p>Returns:
A layer instance.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="readonly-properties-">Readonly properties:<a class="anchor" aria-label="anchor" href="#readonly-properties-"></a></h2>

<ul><li><p><code>compute_dtype</code>
The dtype of the computations performed by the layer.</p></li>
<li><p><code>dtype</code>
Alias of <code>layer$variable_dtype</code>.</p></li>
<li><p><code>input_dtype</code>
The dtype layer inputs should be converted to.</p></li>
<li><p><code>losses</code>
List of scalar losses from <code>add_loss()</code>, regularizers and sublayers.</p></li>
<li><p><code>metrics</code>
List of all metrics.</p></li>
<li><p><code>metrics_variables</code>
List of all metric variables.</p></li>
<li><p><code>non_trainable_variables</code>
List of all non-trainable layer state.</p>
<p>This extends <code>layer$non_trainable_weights</code> to include all state used by
the layer including state for metrics and <code>SeedGenerator</code>s.</p></li>
<li><p><code>non_trainable_weights</code>
List of all non-trainable weight variables of the layer.</p>
<p>These are the weights that should not be updated by the optimizer during
training. Unlike, <code>layer$non_trainable_variables</code> this excludes metric
state and random seeds.</p></li>
<li><p><code>trainable_variables</code>
List of all trainable layer state.</p>
<p>This is equivalent to <code>layer$trainable_weights</code>.</p></li>
<li><p><code>trainable_weights</code>
List of all trainable weight variables of the layer.</p>
<p>These are the weights that get updated by the optimizer during training.</p></li>
<li><p><code>path</code>
The path of the layer.</p>
<p>If the layer has not been built yet, it will be <code>NULL</code>.</p></li>
<li><p><code>quantization_mode</code>
The quantization mode of this layer, <code>NULL</code> if not quantized.</p></li>
<li><p><code>variable_dtype</code>
The dtype of the state (weights) of the layer.</p></li>
<li><p><code>variables</code>
List of all layer state, including random seeds.</p>
<p>This extends <code>layer$weights</code> to include all state used by the layer
including <code>SeedGenerator</code>s.</p>
<p>Note that metrics variables are not included here, use
<code>metrics_variables</code> to visit all the metric variables.</p></li>
<li><p><code>weights</code>
List of all weight variables of the layer.</p>
<p>Unlike, <code>layer$variables</code> this excludes metric state and random seeds.</p></li>
<li><p><code>input</code>
Retrieves the input tensor(s) of a symbolic operation.</p>
<p>Only returns the tensor(s) corresponding to the <em>first time</em>
the operation was called.</p>
<p>Returns:
Input tensor or list of input tensors.</p></li>
<li><p><code>output</code>
Retrieves the output tensor(s) of a layer.</p>
<p>Only returns the tensor(s) corresponding to the <em>first time</em>
the operation was called.</p>
<p>Returns:
Output tensor or list of output tensors.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="data-descriptors-attributes-">Data descriptors (Attributes):<a class="anchor" aria-label="anchor" href="#data-descriptors-attributes-"></a></h2>

<ul><li><p><code>dtype_policy</code></p></li>
<li><p><code>input_spec</code></p></li>
<li><p><code>supports_masking</code>
Whether this layer supports computing a mask using <code>compute_mask</code>.</p></li>
<li><p><code>trainable</code>
Settable boolean, whether this layer should be trainable or not.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index">
<ul><li><p><a href="https://keras.io/api/layers/base_layer#layer-class" class="external-link">https://keras.io/api/layers/base_layer#layer-class</a></p></li>
</ul><p>Other layers: <br><code><a href="layer_activation.html">layer_activation</a>()</code> <br><code><a href="layer_activation_elu.html">layer_activation_elu</a>()</code> <br><code><a href="layer_activation_leaky_relu.html">layer_activation_leaky_relu</a>()</code> <br><code><a href="layer_activation_parametric_relu.html">layer_activation_parametric_relu</a>()</code> <br><code><a href="layer_activation_relu.html">layer_activation_relu</a>()</code> <br><code><a href="layer_activation_softmax.html">layer_activation_softmax</a>()</code> <br><code><a href="layer_activity_regularization.html">layer_activity_regularization</a>()</code> <br><code><a href="layer_add.html">layer_add</a>()</code> <br><code><a href="layer_additive_attention.html">layer_additive_attention</a>()</code> <br><code><a href="layer_alpha_dropout.html">layer_alpha_dropout</a>()</code> <br><code><a href="layer_attention.html">layer_attention</a>()</code> <br><code><a href="layer_aug_mix.html">layer_aug_mix</a>()</code> <br><code><a href="layer_auto_contrast.html">layer_auto_contrast</a>()</code> <br><code><a href="layer_average.html">layer_average</a>()</code> <br><code><a href="layer_average_pooling_1d.html">layer_average_pooling_1d</a>()</code> <br><code><a href="layer_average_pooling_2d.html">layer_average_pooling_2d</a>()</code> <br><code><a href="layer_average_pooling_3d.html">layer_average_pooling_3d</a>()</code> <br><code><a href="layer_batch_normalization.html">layer_batch_normalization</a>()</code> <br><code><a href="layer_bidirectional.html">layer_bidirectional</a>()</code> <br><code><a href="layer_category_encoding.html">layer_category_encoding</a>()</code> <br><code><a href="layer_center_crop.html">layer_center_crop</a>()</code> <br><code><a href="layer_concatenate.html">layer_concatenate</a>()</code> <br><code><a href="layer_conv_1d.html">layer_conv_1d</a>()</code> <br><code><a href="layer_conv_1d_transpose.html">layer_conv_1d_transpose</a>()</code> <br><code><a href="layer_conv_2d.html">layer_conv_2d</a>()</code> <br><code><a href="layer_conv_2d_transpose.html">layer_conv_2d_transpose</a>()</code> <br><code><a href="layer_conv_3d.html">layer_conv_3d</a>()</code> <br><code><a href="layer_conv_3d_transpose.html">layer_conv_3d_transpose</a>()</code> <br><code><a href="layer_conv_lstm_1d.html">layer_conv_lstm_1d</a>()</code> <br><code><a href="layer_conv_lstm_2d.html">layer_conv_lstm_2d</a>()</code> <br><code><a href="layer_conv_lstm_3d.html">layer_conv_lstm_3d</a>()</code> <br><code><a href="layer_cropping_1d.html">layer_cropping_1d</a>()</code> <br><code><a href="layer_cropping_2d.html">layer_cropping_2d</a>()</code> <br><code><a href="layer_cropping_3d.html">layer_cropping_3d</a>()</code> <br><code><a href="layer_cut_mix.html">layer_cut_mix</a>()</code> <br><code><a href="layer_dense.html">layer_dense</a>()</code> <br><code><a href="layer_depthwise_conv_1d.html">layer_depthwise_conv_1d</a>()</code> <br><code><a href="layer_depthwise_conv_2d.html">layer_depthwise_conv_2d</a>()</code> <br><code><a href="layer_discretization.html">layer_discretization</a>()</code> <br><code><a href="layer_dot.html">layer_dot</a>()</code> <br><code><a href="layer_dropout.html">layer_dropout</a>()</code> <br><code><a href="layer_einsum_dense.html">layer_einsum_dense</a>()</code> <br><code><a href="layer_embedding.html">layer_embedding</a>()</code> <br><code><a href="layer_equalization.html">layer_equalization</a>()</code> <br><code><a href="layer_feature_space.html">layer_feature_space</a>()</code> <br><code><a href="layer_flatten.html">layer_flatten</a>()</code> <br><code><a href="layer_flax_module_wrapper.html">layer_flax_module_wrapper</a>()</code> <br><code><a href="layer_gaussian_dropout.html">layer_gaussian_dropout</a>()</code> <br><code><a href="layer_gaussian_noise.html">layer_gaussian_noise</a>()</code> <br><code><a href="layer_global_average_pooling_1d.html">layer_global_average_pooling_1d</a>()</code> <br><code><a href="layer_global_average_pooling_2d.html">layer_global_average_pooling_2d</a>()</code> <br><code><a href="layer_global_average_pooling_3d.html">layer_global_average_pooling_3d</a>()</code> <br><code><a href="layer_global_max_pooling_1d.html">layer_global_max_pooling_1d</a>()</code> <br><code><a href="layer_global_max_pooling_2d.html">layer_global_max_pooling_2d</a>()</code> <br><code><a href="layer_global_max_pooling_3d.html">layer_global_max_pooling_3d</a>()</code> <br><code><a href="layer_group_normalization.html">layer_group_normalization</a>()</code> <br><code><a href="layer_group_query_attention.html">layer_group_query_attention</a>()</code> <br><code><a href="layer_gru.html">layer_gru</a>()</code> <br><code><a href="layer_hashed_crossing.html">layer_hashed_crossing</a>()</code> <br><code><a href="layer_hashing.html">layer_hashing</a>()</code> <br><code><a href="layer_identity.html">layer_identity</a>()</code> <br><code><a href="layer_integer_lookup.html">layer_integer_lookup</a>()</code> <br><code><a href="layer_jax_model_wrapper.html">layer_jax_model_wrapper</a>()</code> <br><code><a href="layer_lambda.html">layer_lambda</a>()</code> <br><code><a href="layer_layer_normalization.html">layer_layer_normalization</a>()</code> <br><code><a href="layer_lstm.html">layer_lstm</a>()</code> <br><code><a href="layer_masking.html">layer_masking</a>()</code> <br><code><a href="layer_max_num_bounding_boxes.html">layer_max_num_bounding_boxes</a>()</code> <br><code><a href="layer_max_pooling_1d.html">layer_max_pooling_1d</a>()</code> <br><code><a href="layer_max_pooling_2d.html">layer_max_pooling_2d</a>()</code> <br><code><a href="layer_max_pooling_3d.html">layer_max_pooling_3d</a>()</code> <br><code><a href="layer_maximum.html">layer_maximum</a>()</code> <br><code><a href="layer_mel_spectrogram.html">layer_mel_spectrogram</a>()</code> <br><code><a href="layer_minimum.html">layer_minimum</a>()</code> <br><code><a href="layer_mix_up.html">layer_mix_up</a>()</code> <br><code><a href="layer_multi_head_attention.html">layer_multi_head_attention</a>()</code> <br><code><a href="layer_multiply.html">layer_multiply</a>()</code> <br><code><a href="layer_normalization.html">layer_normalization</a>()</code> <br><code><a href="layer_permute.html">layer_permute</a>()</code> <br><code><a href="layer_rand_augment.html">layer_rand_augment</a>()</code> <br><code><a href="layer_random_brightness.html">layer_random_brightness</a>()</code> <br><code><a href="layer_random_color_degeneration.html">layer_random_color_degeneration</a>()</code> <br><code><a href="layer_random_color_jitter.html">layer_random_color_jitter</a>()</code> <br><code><a href="layer_random_contrast.html">layer_random_contrast</a>()</code> <br><code><a href="layer_random_crop.html">layer_random_crop</a>()</code> <br><code><a href="layer_random_elastic_transform.html">layer_random_elastic_transform</a>()</code> <br><code><a href="layer_random_erasing.html">layer_random_erasing</a>()</code> <br><code><a href="layer_random_flip.html">layer_random_flip</a>()</code> <br><code><a href="layer_random_gaussian_blur.html">layer_random_gaussian_blur</a>()</code> <br><code><a href="layer_random_grayscale.html">layer_random_grayscale</a>()</code> <br><code><a href="layer_random_hue.html">layer_random_hue</a>()</code> <br><code><a href="layer_random_invert.html">layer_random_invert</a>()</code> <br><code><a href="layer_random_perspective.html">layer_random_perspective</a>()</code> <br><code><a href="layer_random_posterization.html">layer_random_posterization</a>()</code> <br><code><a href="layer_random_rotation.html">layer_random_rotation</a>()</code> <br><code><a href="layer_random_saturation.html">layer_random_saturation</a>()</code> <br><code><a href="layer_random_sharpness.html">layer_random_sharpness</a>()</code> <br><code><a href="layer_random_shear.html">layer_random_shear</a>()</code> <br><code><a href="layer_random_translation.html">layer_random_translation</a>()</code> <br><code><a href="layer_random_zoom.html">layer_random_zoom</a>()</code> <br><code><a href="layer_repeat_vector.html">layer_repeat_vector</a>()</code> <br><code><a href="layer_rescaling.html">layer_rescaling</a>()</code> <br><code><a href="layer_reshape.html">layer_reshape</a>()</code> <br><code><a href="layer_resizing.html">layer_resizing</a>()</code> <br><code><a href="layer_rms_normalization.html">layer_rms_normalization</a>()</code> <br><code><a href="layer_rnn.html">layer_rnn</a>()</code> <br><code><a href="layer_separable_conv_1d.html">layer_separable_conv_1d</a>()</code> <br><code><a href="layer_separable_conv_2d.html">layer_separable_conv_2d</a>()</code> <br><code><a href="layer_simple_rnn.html">layer_simple_rnn</a>()</code> <br><code><a href="layer_solarization.html">layer_solarization</a>()</code> <br><code><a href="layer_spatial_dropout_1d.html">layer_spatial_dropout_1d</a>()</code> <br><code><a href="layer_spatial_dropout_2d.html">layer_spatial_dropout_2d</a>()</code> <br><code><a href="layer_spatial_dropout_3d.html">layer_spatial_dropout_3d</a>()</code> <br><code><a href="layer_spectral_normalization.html">layer_spectral_normalization</a>()</code> <br><code><a href="layer_stft_spectrogram.html">layer_stft_spectrogram</a>()</code> <br><code><a href="layer_string_lookup.html">layer_string_lookup</a>()</code> <br><code><a href="layer_subtract.html">layer_subtract</a>()</code> <br><code><a href="layer_text_vectorization.html">layer_text_vectorization</a>()</code> <br><code><a href="layer_tfsm.html">layer_tfsm</a>()</code> <br><code><a href="layer_time_distributed.html">layer_time_distributed</a>()</code> <br><code><a href="layer_torch_module_wrapper.html">layer_torch_module_wrapper</a>()</code> <br><code><a href="layer_unit_normalization.html">layer_unit_normalization</a>()</code> <br><code><a href="layer_upsampling_1d.html">layer_upsampling_1d</a>()</code> <br><code><a href="layer_upsampling_2d.html">layer_upsampling_2d</a>()</code> <br><code><a href="layer_upsampling_3d.html">layer_upsampling_3d</a>()</code> <br><code><a href="layer_zero_padding_1d.html">layer_zero_padding_1d</a>()</code> <br><code><a href="layer_zero_padding_2d.html">layer_zero_padding_2d</a>()</code> <br><code><a href="layer_zero_padding_3d.html">layer_zero_padding_3d</a>()</code> <br><code><a href="rnn_cell_gru.html">rnn_cell_gru</a>()</code> <br><code><a href="rnn_cell_lstm.html">rnn_cell_lstm</a>()</code> <br><code><a href="rnn_cell_simple.html">rnn_cell_simple</a>()</code> <br><code><a href="rnn_cells_stack.html">rnn_cells_stack</a>()</code> <br></p></div>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

