---
title: "R interface to Keras"
type: docs
repo: https://github.com/rstudio/keras
menu:
  main:
    name: "Overview"
    identifier: "keras-overview"
    parent: "keras-getting-started"
    weight: 10
---


```{r setup, include=FALSE}
library(keras)
knitr::opts_chunk$set(eval = FALSE)
```

# ![](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png){width=300}

<div id="build-status">
[![R build status](https://github.com/rstudio/keras/workflows/R-CMD-check/badge.svg)](https://github.com/rstudio/keras/actions?workflow=R-CMD-check)
[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/keras)](https://cran.r-project.org/package=keras)
[![license](https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000)](https://github.com/keras-team/keras/blob/master/LICENSE)
</div>

## R interface to Keras

[Keras](https://keras.io/) is a high-level neural networks API developed with a focus on enabling fast experimentation. *Being able to go from idea to result with the least possible delay is key to doing good research.* Keras has the following key features:

- Allows the same code to run on CPU or on GPU, seamlessly.

- User-friendly API which makes it easy to quickly prototype deep learning models.

- Built-in support for convolutional networks (for computer vision), recurrent networks (for sequence processing), and any combination of both.

- Supports arbitrary network architectures: multi-input or multi-output models, layer sharing, model sharing, etc. This means that Keras is appropriate for building essentially any deep learning model, from a memory network to a neural Turing machine.

- Is capable of running on top of multiple back-ends including [TensorFlow](https://github.com/tensorflow/tensorflow), [CNTK](https://github.com/Microsoft/cntk), or [Theano](https://github.com/Theano/Theano).

For additional details on why you might consider using Keras for your deep learning projects, see the [Why Use Keras?](articles/why_use_keras.html) article.

This website provides documentation for the R interface to Keras. See the main Keras website at <https://keras.io> for additional information on the project.

## Getting Started

### Installation

First, install the keras R package from GitHub as follows:

```{r, eval=FALSE}
devtools::install_github("rstudio/keras")
```

The Keras R interface uses the [TensorFlow](https://www.tensorflow.org/) backend engine by default. To install both the core Keras library as well as the TensorFlow backend use the `install_keras()` function:

```{r, eval=FALSE}
library(keras)
install_keras()
```

This will provide you with default CPU-based installations of Keras and TensorFlow. If you want a more customized installation, e.g. if you want to take advantage of NVIDIA GPUs, see the documentation for `install_keras()`.

### Learning Keras

Below we walk through a simple example of using Keras to recognize handwritten digits from the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset. After getting familiar with the basics, check out the [tutorials](#tutorials) and additional [learning resources](#learning-more) available on this website.

The [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r-second-edition) book by Fran√ßois Chollet (the creator of Keras) provides a more comprehensive introduction to both Keras and the concepts and practice of deep learning.

You may also find it convenient to download the [Deep Learning with Keras](https://github.com/rstudio/cheatsheets/raw/main/keras.pdf){target="_self"} cheat sheet, a quick high-level reference to all of the capabilities of Keras.

## MNIST Example

We can learn the basics of Keras by walking through a simple example: recognizing handwritten digits from the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset. MNIST consists of 28 x 28 grayscale images of handwritten digits like these:

<img style="width: 50%;" src="images/MNIST.png">

The dataset also includes labels for each image, telling us which digit it is. For example, the labels for the above images are 5, 0, 4, and 1.

### Preparing the Data

The MNIST dataset is included with Keras and can be accessed using the `dataset_mnist()` function. Here we load the dataset then create variables for our test and training data:

```{r}
library(keras)
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
```

The `x` data is a 3-d array `(images,width,height)` of grayscale values . To prepare the data for training we convert the 3-d arrays into matrices by reshaping width and height into a single dimension (28x28 images are flattened into length 784 vectors). Then, we convert the grayscale values from integers ranging between 0 to 255 into floating point values ranging between 0 and 1:

```{r}
# reshape
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
# rescale
x_train <- x_train / 255
x_test <- x_test / 255
```

Note that we use the `array_reshape()` function rather than the `dim<-()` function to reshape the array. This is so that the data is re-interpreted using row-major semantics (as opposed to R's default column-major semantics), which is in turn compatible with the way that the numerical libraries called by Keras interpret array dimensions.

The `y` data is an integer vector with values ranging from 0 to 9. To prepare this data for training we [one-hot encode](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science) the vectors into binary class matrices using the Keras `to_categorical()` function:

```{r}
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
```

### Defining the Model

The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the [Sequential model](https://tensorflow.rstudio.com/articles/sequential_model.html), a linear stack of layers.

We begin by creating a sequential model and then adding layers using the pipe (`%>%`) operator:

```{r}
model <- keras_model_sequential()
model %>%
  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
  layer_dropout(rate = 0.4) %>%
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 10, activation = 'softmax')
```

The `input_shape` argument to the first layer specifies the shape of the input data (a length 784 numeric vector representing a grayscale image). The final layer outputs a length 10 numeric vector (probabilities for each digit) using a [softmax activation function](https://en.wikipedia.org/wiki/Softmax_function).

Use the `summary()` function to print the details of the model:

```{r}
summary(model)
```

<pre style="box-shadow: none;"><code>Model
________________________________________________________________________________
Layer (type)                        Output Shape                    Param #
================================================================================
dense_1 (Dense)                     (None, 256)                     200960
________________________________________________________________________________
dropout_1 (Dropout)                 (None, 256)                     0
________________________________________________________________________________
dense_2 (Dense)                     (None, 128)                     32896
________________________________________________________________________________
dropout_2 (Dropout)                 (None, 128)                     0
________________________________________________________________________________
dense_3 (Dense)                     (None, 10)                      1290
================================================================================
Total params: 235,146
Trainable params: 235,146
Non-trainable params: 0
________________________________________________________________________________</code></pre>

Next, compile the model with appropriate loss function, optimizer, and metrics:

```{r}
model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)
```

### Training and Evaluation

Use the `fit()` function to train the model for 30 epochs using batches of 128 images:

```{r, results='hide'}
history <- model %>% fit(
  x_train, y_train,
  epochs = 30, batch_size = 128,
  validation_split = 0.2
)
```

The `history` object returned by `fit()` includes loss and accuracy metrics which we can plot:

```{r}
plot(history)
```

![](images/training_history_ggplot2.png){width=757 height=489 .r-plot}

Evaluate the model's performance on the test data:

```{r, results = 'hide'}
model %>% evaluate(x_test, y_test)
```
```
$loss
[1] 0.1149

$acc
[1] 0.9807
```

Generate predictions on new data:

```{r, results = 'hide'}
model %>% predict_classes(x_test)
```
```
  [1] 7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2
 [40] 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2
 [79] 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9
 [ reached getOption("max.print") -- omitted 9900 entries ]
```

Keras provides a vocabulary for building deep learning models that is simple, elegant, and intuitive. Building a question answering system, an image classification model, a neural Turing machine, or any other model is just as straightforward.

## Tutorials

To learn the basics of Keras, we recommend the following sequence of tutorials:

- [Basic Classification](articles/tutorial_basic_classification.html) --- In this tutorial, we train a neural network model to classify images of clothing, like sneakers and shirts.

- [Text Classification](articles/tutorial_basic_text_classification.html) --- This tutorial classifies movie reviews as positive or negative using the text of the review.

- [Basic Regression](articles/tutorial_basic_regression.html) --- This tutorial builds a model to predict the median price of homes in a Boston suburb during the mid-1970s.

- [Overfitting and Underfitting](articles/tutorial_overfit_underfit.html) --- In this tutorial, we explore two common regularization techniques (weight regularization and dropout) and use them to improve our movie review classification results.

- [Save and Restore Models](articles/tutorial_save_and_restore.html) --- This tutorial demonstrates various ways to save and share models (after as well as during training).

These tutorials walk you through the main components of the Keras library and demonstrate the core workflows used for training and improving the performance of neural networks. The [Guide to Keras Basics](articles/guide_keras.html) provides a more condensed summary of this material.

The [Deep Learning with Keras](https://github.com/rstudio/cheatsheets/raw/main/keras.pdf) cheat sheet also provides a condensed high level guide to using Keras.

## Learning More

To learn more about Keras, you can check out these articles:

- [Guide to the Sequential Model](articles/sequential_model.html)

- [Guide to the Functional API](articles/functional_api.html)

- [Frequently Asked Questions](articles/faq.html)

- [Training Visualization](articles/training_visualization.html)

- [Using Pre-Trained Models](articles/applications.html)

- [Keras with Eager Execution](articles/eager_guide.html)

The [examples](articles/examples/index.html) demonstrate more advanced models including transfer learning, variational auto-encoding, question-answering with memory networks, text generation with stacked LSTMs, etc.

The [function reference](reference/index.html) includes detailed information on all of the functions available in the package.

[![](https://images.manning.com/264/352/resize/book/a/8f961a8-9cf7-47e8-a69b-949186e59a81/Chollet2-HI.png){width=125 align=right style="margin-left:10px; margin-right: 20px; margin-top: 15px; border: solid 1px #cccccc;"}](https://www.manning.com/books/deep-learning-with-r-second-edition)


### Deep Learning with R Book

If you want a more comprehensive introduction to both Keras and the concepts and practice of deep learning, we recommend the [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r-second-edition) book from Manning. This book is a collaboration between Fran√ßois Chollet, the creator of Keras, J.J. Allaire, who wrote the original R interface to Keras, and Tomasz Kalinowski, who maintains the R interface today.

The book presumes no significant knowledge of machine learning and deep learning, and goes all the way from basic theory to advanced practical applications, all using the R interface to Keras.

<div style="clear: both;"></div>

## Why this name, Keras?

Keras (Œ∫Œ≠œÅŒ±œÇ) means horn in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the Odyssey, where dream spirits (Oneiroi, singular Oneiros) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words Œ∫Œ≠œÅŒ±œÇ (horn) / Œ∫œÅŒ±ŒØŒΩœâ (fulfill), and ·ºêŒªŒ≠œÜŒ±œÇ (ivory) / ·ºêŒªŒµœÜŒ±ŒØœÅŒøŒºŒ±Œπ (deceive).

Keras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).

> "Oneiroi are beyond our unravelling --who can be sure what tale they tell? Not all that men look for comes to pass. Two gates there are that give passage to fleeting Oneiroi; one is made of horn, one of ivory. The Oneiroi that pass through sawn ivory are deceitful, bearing a message that will not be fulfilled; those that come out through polished horn have truth behind them, to be accomplished for men who see them." Homer, Odyssey 19. 562 ff (Shewring translation).
